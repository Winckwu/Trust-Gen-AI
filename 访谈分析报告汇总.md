# Trust-Gen-AI 访谈分析报告汇总

**共49位受访者深度分析报告**

---

## 目录

- [R1: 受访人1：刘艳筝 - 深度分析报告](#受访人1)
- [R2: 受访人2：王莹 - 深度分析报告](#受访人2)
- [R3: 受访人3：宇杰 - 深度分析报告](#受访人3)
- [R4: 受访人4：许军 - 深度分析报告](#受访人4)
- [R5: 受访人5：于 - 深度分析报告](#受访人5)
- [R6: 受访人6：黄双杰 - 深度分析报告](#受访人6)
- [R7: 受访人7：zqz - 深度分析报告](#受访人7)
- [R8: 受访人8：宋柏洋 - 深度分析报告](#受访人8)
- [R9: 受访人9：钟其臻 - 深度分析报告](#受访人9)
- [R10: 受访人10：刘斌 - 深度分析报告](#受访人10)
- [R11: 受访人11：李香香 - 深度分析报告](#受访人11)
- [R12: 受访人12：陈文静（AmazingGrace） - 深度分析报告](#受访人12)
- [R13: 受访人13：张梓敬 - 深度分析报告](#受访人13)
- [R14: 受访人14：吴梓锐 - 深度分析报告](#受访人14)
- [R15: 受访人15：张诗棋 - 深度分析报告](#受访人15)
- [R16: 受访人16：NTU博士 - 深度分析报告](#受访人16)
- [R17: 受访人17：金融经济学研究员 - 深度分析报告](#受访人17)
- [R18: 受访人18：航空航天博后 - 深度分析报告](#受访人18)
- [R19: 受访人19：AI区块链项目支持 - 深度分析报告](#受访人19)
- [R20: 受访人20：NIE教育心理学研究员 - 深度分析报告](#受访人20)
- [R21: 受访人21：NTU传播学院研究生 - 深度分析报告](#受访人21)
- [R22: 受访人22分析报告：强化学习博士生](#受访人22)
- [R23: 受访人23分析报告：WAP3活动运营](#受访人23)
- [R24: 受访人24分析报告：NTU博士后（Software Engineering for AI）](#受访人24)
- [R25: 受访人25分析报告：AI+教育科研从业者](#受访人25)
- [R26: 受访人26分析报告：马来西亚电商创业者](#受访人26)
- [R27: 受访人27分析报告：蛋白质研究员（医学化学领域）](#受访人27)
- [R28: 受访人28分析报告：NTU招生营销主管](#受访人28)
- [R29: 受访人29分析报告：AI创业者（邮件管理产品）](#受访人29)
- [R30: 受访人30分析报告：阿里系电商创业者（Smarty Metrics）](#受访人30)
- [R31: 受访人31分析报告：资深设计师（Amazon/Agency背景）](#受访人31)
- [R32: 受访人32分析报告：咨询公司创意设计师](#受访人32)
- [R33: 受访人33分析报告：量化交易员（Trading行业）](#受访人33)
- [R34: 受访人34：计算化学博后 - 深度分析报告](#受访人34)
- [R35: 受访人35：软件开发者 - 深度分析报告](#受访人35)
- [R36: 受访人36：NTU研究生 - 深度分析报告](#受访人36)
- [R37: 受访人37：数据分析师 - 深度分析报告](#受访人37)
- [R38: 受访人38：AI研究员 - 深度分析报告](#受访人38)
- [R39: 受访人39：安全顾问 - 深度分析报告](#受访人39)
- [R40: 受访人40：航空工程博士生 - 深度分析报告](#受访人40)
- [R41: 受访人41：物理学博士生 - 深度分析报告](#受访人41)
- [R42: 受访人42：材料科学博士生 - 深度分析报告](#受访人42)
- [R43: 受访人43：内容创作者/健身教练 - 深度分析报告](#受访人43)
- [R44: 受访人44：AI视频制作人 - 深度分析报告](#受访人44)
- [R45: 受访人45：生物医学光学研究员 - 深度分析报告](#受访人45)
- [R46: 受访人46：学习科学硕士生 - 深度分析报告](#受访人46)
- [R47: 受访人47：化学工程/销售经理 - 深度分析报告](#受访人47)
- [R48: 受访人48：工程专业本科生 - 深度分析报告](#受访人48)
- [R49: 受访人49：化学工程本科生 - 深度分析报告](#受访人49)

---


<a id="受访人1"></a>

# 受访人1：刘艳筝 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 刘艳筝 |
| 年龄 | 26岁（98年） |
| 学历 | 中国人民大学市场营销博士第三年（硕博连读第五年） |
| 当前状态 | NTU进行CSC交换 |
| 使用频率 | 一周超过五天（如果有工作） |
| 主要工具 | ChatGPT（免费版）+ DeepSeek |

## 使用场景

### 场景1：邮件写作（生活类）
- **具体案例**：nets充值卡错误扣费，需要写英文投诉邮件
- **使用方式**：用中文分条告诉GPT问题和诉求，让其生成英文邮件
- **效果评价**："总体而言还是比较不太日常，就是会有一些机器的那种语言"

### 场景2：学术润色
- **具体案例**：将一万字论文缩减到1000词的会议论文
- **使用方式**：
  1. 自己先缩减到2000词左右
  2. 一段一段输入，让GPT精炼
  3. 最后让GPT检查段落衔接和语法
- **关键策略**："一次性输入的话，它的那个AI可能存在一些偷懒的行为"

### 场景3：实验材料生成
- **具体案例**：生成服务失败的消费场景描述
- **使用方式**：给GPT具体要求（字数限制、格式要求），让其生成多个场景
- **效果评价**："大部分情况下是还可以的，但是肯定还需要改进"
- **信任理由**："这些内容本身对于那种权威性，科学性的要求就不是没有那么高"

### 场景4：代码辅助（文本分析）
- **具体案例**：Python文本数据分析，提取感官相关关键词
- **使用方式**：分块输入需求，边做边改，遇到报错就复制给GPT
- **效果评价**："只能一直试，然后试到能出结果为止"

### 不使用的场景
- **文献阅读**："我文献一般不用GPT，因为我觉得自己看可能快一些"
- **文献搜索**："他不是出现过各种编造参考文献或者提供一些虚假来源"
- **娱乐聊天**："它本质上还是一些代码，还是一些机器"

## 信任轨迹：下降型

### 阶段演变

| 阶段 | 状态 | 关键证据 |
|------|------|----------|
| 初期 | 期待高 | "我以前试过一开始告诉他改哪一点他就只改哪一点" |
| 转折 | 失望 | "他只改了那一点之后，导致他的整个语句或者表述过程会显得很奇怪，前言不搭后语" |
| 现状 | 工具化定位 | "我一般都是让它分成一个草稿一类的，我自己再根据实际情况进行修改" |

### 信任下降的触发事件

1. **修改能力差**
   > "他只改了那一点之后，导致他的整个语句或者表述过程会显得很奇怪，前言不搭后语"

2. **标注功能失效**
   > "我经常有，但是他90%的情况下他标的都是错的...他给我加速的那些内容就没有改动，反而是那些改动的内容，他就完全不加图"

3. **虚假文献**
   > "他不是出现过各种编造参考文献或者提供一些虚假来源"

4. **模板化输出**
   > "会有一些机器的那种语言，就是比如说他的表述会有一些非常刻意的那种邮件语言"

## 专家策略

### 策略1：草稿定位
> "我一般都是让它分成一个草稿一类的，我自己再根据实际情况进行修改"

### 策略2：分段输入
> "我一段一段输入的话，我对比起来会更容易"
> "一次性输入的话，它的那个AI可能存在一些偷懒的行为"

### 策略3：任务边界设定
- 文献搜索：完全不用GPT，自己搜索
- 权威信息：自己验证来源
- 核心写作：自己完成，GPT只做润色

### 策略4：明确指令限定
> "我明确告诉他了，是，比如说帮我提升一些不同段落之间的语言的衔接，保证一些自然过渡。检查一下语法他，我如果给他这种明确的命令，他就不会去给我改动其他的内容"

## 深层认知

### 对AI本质的理解
> "我不太信这些东西，因为我觉得他GPT能够给我提供帮助的，它底层逻辑是文本训练的一个模型...它本质上还是一些代码，还是一些机器，就它没有办法真正的怎么说，满足人们的一些社交，以及娱乐的那些需求，我觉得这些还是得靠人来完成。"

### 学术伦理考量
> "因为你这个内容相当于是让AI帮你进行一些撰写，你不知道如果是其他人也这样撰写，你们最后出来的文本会不会高度类似？"

### 数据隐私态度
> "这个方面我是之前有查过他们的一些政策的...训练是正常的，只是它不联网，不会把内容完整的透露出去就可以。"

**结论**：不担心数据隐私，因为做过调查研究

## 对论文的价值

### 1. Trust-Use Decoupling的典型案例
- 信任下降但使用增加
- 通过策略（草稿定位、分段输入）管理低信任

### 2. 专家识别"AI味"的能力
> "就是会有一些机器的那种语言，就是比如说他的表述会有一些非常刻意的那种邮件语言"

→ 这可以作为区分专家与新手的标准之一

### 3. 任务分化的边界条件
- 不需要权威性的任务（实验场景描述）→ 信任较高
- 需要权威性的任务（文献、理论）→ 完全不信任

### 关键引用（可用于论文）

1. **草稿定位**：
   > "我一般都是让它分成一个草稿一类的，我自己再根据实际情况进行修改"

2. **经验积累后的策略**：
   > "因为是凭我跟GPT打交道的经验，然后找出的，所以对我而言最省时省力的方式"

3. **对AI本质的认知**：
   > "它本质上还是一些代码，还是一些机器"

## 八、分析验证

待核对的关键引用：
- [x] "一般都是让它分成一个草稿一类的" ✓ (line 46)
- [x] "偷懒的行为" ✓ (line 102)
- [x] "编造参考文献或者提供一些虚假来源" ✓ (line 243)
- [x] "本质上还是一些代码，还是一些机器" ✓ (line 299)
- [x] "凭我跟GPT打交道的经验" ✓ (line 118)

---
*分析完成时间：2025年1月*

---


<a id="受访人2"></a>

# 受访人2：王莹 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 王莹 |
| 年龄 | 27岁（生日未过可记26岁） |
| 学历 | 厦门大学会计学博士三年级 |
| 研究方向 | 会计+管理学+政治学 |
| 使用频率 | 每天（置顶在Google首页） |
| 主要工具 | ChatGPT |

## 使用场景

### 场景1：文字润色/邮件写作
- **使用方式**：告诉GPT邮件需要包含哪些内容、场景背景、期望的语气情绪
- **效果评价**：
  > "第一次给他promote的时候，他返回给我的信基本上是不能直接使用的。因为他我觉得第一个版本发送的信就是非常的模板化公式化"

- **情感掌控问题**：
  > "我觉得他给我的情绪会比我想象的更要极端。比方讲我会跟他说，我说可能我比较这个事情我比较抱歉，我希望他稍微带有一些抱歉的情绪，但往往他给我的之后，他会给我很大段的或者很长句的抱歉的语句，我觉得就又有点过了，我觉得他就是掌握不了这个情感的度。"

- **任务分类处理**：
  - 重要邮件：自己修改后再让GPT检查语法
  - 不重要邮件（如问询）：直接用模板

### 场景2：搜索信息/数据
- **官方数据**：准确度高
  > "如果是涉及官方网官方数据的中，就包括中国的还有美国的...它的准确度是很高的，它会直接扔给我具体到那个数据的网页上"

- **私有数据**：编造链接
  > "如果是说一些什么企业类型的数据，或者是我在论文当中看到的数据库，往往他扔给我的链接就是编造的，或者是也不可能不是编造吧，反正就是打不开"

- **文献搜索**：完全不可信
  > "它都会给我一些fake的东西就是很虚，就是他自己编造的东西。就完全不是真的，然后我一条一条去核实之后发现基本上就搜不到，不存在"

### 场景3：代码辅助（Stata/Python）
- **使用方式**：描述具体场景，让GPT生成代码，然后逐一尝试
- **效果评价**：
  > "基本上都一次性跑不通，基本上是一次性跑不通的，我都需要反复的，就根据python的报错，我告诉他，你给我的这个代码出现了这个类型的错误，你帮我解决掉，再给我一个新的代码，再这样就是重复的，基本上34次之后才能真正的开始运行"

- **总体评价**：
  > "我觉得它代码辅助的功能比较好用吧，无论是state还是python，目前我喂给他的，他基本上都能给我尝试几次之后基本上都是能跑通的"
  > "非常省时间。准确度也是很高的"

### 场景4：算命 ⭐⭐⭐（最特殊发现）
- **使用方式**：提供出生年月日和地点，让GPT扮演算命大师
- **信任程度**：最高
  > "很好用，我觉得是最好用的"
  > "我会比较信任吧！"
  > "我会觉得可能他会说的有道理，我注意一些"

- **信任原因**（关键洞见）：
  > "最根本的原因就是他哪怕算错了，对我也不会有什么很大的影响，因为它是个娱乐性。你要明白就是它是一个娱乐性。我避免我通过他的建议，避免一些事情不会对我本人造成巨大的影响。"

### 不使用的场景
- **论文写作**：完全不用
  > "写作过程中我是不会使用CHAT GPT的，因为我知道有一些期刊的网站，或者是一些他们本身...对使用CHAT GPT的辅助写作是持一个非常负面的态度...甚至还有什么AI监测"

- **文献阅读/总结**：不用
  > "我不会让他总结，因为我觉得他文献的话，摘要是最好的总结的方式...拆了GPT有的时候它...你给他一个特别复杂的文件，或者是一些很长的词语的话，它很容易宕机"

## 信任轨迹：任务分化型 + 下降型

### 信任演变过程

| 阶段 | 状态 | 关键证据 |
|------|------|----------|
| 初期 | 期待高 | "在我刚刚使用CHAT GPT的时候，我还会幻想ok他应该能够再让他帮我修改，我应该能修改好" |
| 转折 | 失望 | "后来这次在使用过程中，我发现它是不能够...不能够按照我这个标准去改的" |
| 现状 | 任务分化 | 不同任务信任程度完全不同 |

### 任务分化信任表

| 任务类型 | 信任水平 | 理由 |
|----------|----------|------|
| 算命 | ⭐⭐⭐⭐⭐ 最高 | "算错了对我也不会有什么很大的影响" |
| 代码辅助 | ⭐⭐⭐⭐ 高 | "非常省时间。准确度也是很高的" |
| 官方数据搜索 | ⭐⭐⭐⭐ 高 | "准确度是很高的" |
| 纲要/模板生成 | ⭐⭐⭐ 中等 | "基本上不会出大错的" |
| 邮件润色 | ⭐⭐ 低 | "模板化公式化"、"掌握不了情感的度" |
| 私有数据搜索 | ⭐ 很低 | "编造的，反正就是打不开" |
| 文献搜索 | ⭐ 最低 | "fake的东西...编造的东西" |
| 论文写作 | ❌ 完全不用 | AI检测风险、数据隐私 |

## 专家策略

### 策略1：一版原则
> "我是问他一次，他给我一个答案，然后我自己修改一下"
> "不会让他再给我进行内容上的生成了"

### 策略2：多次确认（核心策略）⭐
> "然后我重复几次之后就比方讲我重复两三次吧，然后他每这两三次过程两三次他都告诉我你真的没有问题了，真的没有语法问题，重复两三次，这样的回答我基本上就不会再更改了"

### 策略3：搜索限制
> "假如说他找不到可以打开的链接就不要给我了。我会加上这么一句"

### 策略4：任务重要性分层
- 重要邮件：仔细修改
- 不重要邮件：直接用模板
> "如果是那种就是不是特别怎么讲，就是不是那么重要的邮件吧...我对他的要求就不会很高"

### 策略5：语气限定
> "我只是会特定一下他的那个情绪特定一下他的情绪，然后特定一下他的语调就是那种信件的整体风格而已"

## 深层认知

### 对AI检测的担忧
> "有一些期刊的网站，或者是一些他们本身对使用CHAT GPT的辅助写作是持一个非常负面的态度...甚至还有什么AI监测"

### 数据隐私担忧
> "我觉得CHAT GPT我记得好像CHAT GPT它的这个底层算法逻辑也是一直用我们用户的数据进行训练的第一个我会存在这样的担忧，因为怕他可能会拿到我的数据，然后随便喂给一个别的人"

### 对高频词/模板化的敏感
> "你只要这句话被无数人使用了，它其实就是查重率不过关...在别人看来，这就是一句模板的话"

### 对"思考过程"的信任
> "deep seek它有的时候思考的时候会先出一些很小的小字...我会比较相信"

## 对论文的核心价值

### 1. "算命悖论" ⭐⭐⭐⭐⭐

这是最重要的发现，揭示了**信任的边界条件**：

| 维度 | 学术任务 | 算命任务 |
|------|----------|----------|
| 信任水平 | 最低 | 最高 |
| 错误后果 | 严重（论文发表失败）| 无影响（娱乐性）|
| 验证成本 | 高（需要核实文献）| 低（无需验证）|

**关键引用**：
> "最根本的原因就是他哪怕算错了，对我也不会有什么很大的影响，因为它是个娱乐性"

**理论启示**：
- 信任水平与**错误后果的严重性/可逆性**直接相关
- 这可以作为Trust-Use Decoupling的**边界条件变量**

### 2. 信任-使用脱钩的机制

她展示了典型的"低信任+高使用"模式：
- 知道GPT会编造文献 → 但还是每天用
- 知道邮件模板化 → 但还是用它生成初稿
- **机制**：通过策略（一版原则、多次确认、搜索限制）管理低信任

### 3. 专家策略的系统性

她的策略形成了一个完整的**质量控制体系**：
1. 输入端：限制搜索（"找不到可以打开的链接就不要给我"）
2. 输出端：一版原则（不期待多轮修改）
3. 验证端：多次确认（"重复两三次"）

### 关键引用（可用于论文）

1. **信任下降轨迹**：
   > "在我刚刚使用CHAT GPT的时候，我还会幻想ok他应该能够再让他帮我修改，我应该能修改好，但是后来这次在使用过程中，我发现它是不能够...不能够按照我这个标准去改的"

2. **算命信任的原因**：
   > "最根本的原因就是他哪怕算错了，对我也不会有什么很大的影响，因为它是个娱乐性"

3. **虚假信息体验**：
   > "它都会给我一些fake的东西就是很虚，就是他自己编造的东西。就完全不是真的，然后我一条一条去核实之后发现基本上就搜不到，不存在"

4. **多次确认策略**：
   > "重复两三次吧，然后他每这两三次过程两三次他都告诉我你真的没有问题了，真的没有语法问题，重复两三次，这样的回答我基本上就不会再更改了"

## 八、分析验证

待核对的关键引用：
- [x] "算错了，对我也不会有什么很大的影响" ✓ (line 640)
- [x] "fake的东西...自己编造的东西" ✓ (line 496)
- [x] "重复两三次" ✓ (line 441)
- [x] "还会幻想ok他应该能够再让他帮我修改" ✓ (line 431)
- [x] "掌握不了这个情感的度" ✓ (line 427)

---
*分析完成时间：2025年1月*

---


<a id="受访人3"></a>

# 受访人3：宇杰 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 宇杰 |
| 年龄 | 26岁（99年） |
| 学历 | 南开大学企业管理博士一年级 |
| 使用频率 | 几乎每天 |
| 主要工具 | ChatGPT（4 mini）+ DeepSeek，现在转向ChatGPT更多 |

## 对不同工具的评价

### DeepSeek vs ChatGPT

> "最开始我觉得就是deep seek他在回答你问题的时候会给出非常多的专业性名词，但专业性名词是带引号的，然后其实这些专业性名词是他自己编的...deep seek它看起来就是给你的内容就是非常华丽，但是它不实在...所以现在而言，转到用CHAT GPT比较多"

**结论**：DeepSeek幻觉更严重，转向ChatGPT

## 使用场景

### 场景1：研究思路生成
- **使用时机**："我有思路的时候，我不会用CHAT GPT，但我没有思路的话，我才会想"
- **具体用法**：输入自变量和因变量，让GPT给出可能的逻辑链/机制
- **关键策略**：双重验证
  > "我不会太信任他，只会给我一个方向，我看有没有这个方向的文献，相当于进行一种双重验证，我才会去用他的这个建议"

### 场景2：政策/工具变量搜索
- **具体案例**：做内生性分析时搜索政策作为IV
- **使用方式**：让GPT给一个范围，再验证政策是否存在、是否有文献支撑
- **关键策略**：双重验证
  > "每次都是双重验证，就是我要看他给的这个政策到底存不存在这个政策的具体内容，是不是跟他说的一样，然后还要看这个工具变量，它是否在文献中是用过的，是一有文献支撑的"

### 场景3：文献理解/概念解释
- **使用方式**：把不理解的英文文献段落输入GPT，让其解释
- **效果评价**：
  > "它不仅可以把原文的就是这个原文的内容，用一个通俗的语言解释出来，给你举一些例子，方便理解。这个是我在看文献的时候经常用到"
- **信任程度**：高信任，不验证
  > "这个时候我不会做信息验证，因为我本来就是不太理解这段内容"

### 场景4：文献汇报（已放弃）
- **尝试过的用法**：把多篇文献投喂给GPT，让其生成展示内容
- **放弃原因**：
  > "它的一个展示效果，就是跟我们正常学生读文献的侧重点是不一样的"
- **现状**：
  > "现在都是我比较多的时候是我自己读文献，然后遇到不理解的再问他是这是什么意思"

### 场景5：代码辅助
- **使用方式**：
  - 自己能做的部分自己做
  - 完全不会的部分（如文本相似度计算）让GPT生成
- **关键策略**：三角验证
  > "自己人工核对，然后在网上一些找一些包，然后再用它这个三者相当于一个三角验证，我才敢去用"
- **容错机制**：
  > "超过三次以上他都改不对的话，我就不会再用它了，我就是找一些这方面做的比较好的再去问"

### 场景6：课程学习（管理哲学）
- **认真学习时**：让GPT解释晦涩的哲学概念
- **应付作业时**：让GPT根据内容快速写essay
  > "我对于课后作业是比较不想付出时间的"

### 不使用的场景
- **让GPT直接写内容**：
  > "我不会这样的写的...他写东西就是非常绕...非常冗余的感觉"
- **让GPT列举参考文献**：
  > "不能用它去就是给一段内容让他去告诉你列举出一些参考文献是不可取的...他会直接编几个参考文件给你"

## 信任轨迹：稳定低信任型

### 信任特征

从一开始就保持谨慎，建立了系统的验证机制。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 概念解释 | ⭐⭐⭐⭐⭐ 高 | 直接采用，不验证 |
| 研究思路 | ⭐⭐⭐ 条件信任 | 必须有文献验证 |
| 代码辅助 | ⭐⭐⭐ 中等 | 三角验证 |
| 文献汇报 | ⭐ 最低 | 已放弃使用 |
| 参考文献 | ❌ 完全不信任 | 从不使用 |

### 信任下降的触发事件

1. **DeepSeek编造专业名词**：
   > "专业性名词是他自己编的...根本就不存在这个专业性名词"

2. **编造参考文献**：
   > "他会直接编几个参考文件给你就是根本找不到"

3. **文献汇报侧重点错误**：
   > "它的一个展示效果，就是跟我们正常学生读文献的侧重点是不一样的"

## 核心专家策略 ⭐⭐⭐⭐⭐

### 策略1：双重验证原则（最核心）

> "我不会太信任他，只会给我一个方向，我看有没有这个方向的文献，相当于进行一种双重验证，我才会去用他的这个建议"

> "每次都是双重验证，就是我要看他给的这个政策到底存不存在...然后还要看这个工具变量，它是否在文献中是用过的"

### 策略2：自主优先原则

> "我能做的，我都自己做，很少会去用到它"
> "并不会把一些自己也能做的，我也会去丢给他，这种情况是很少的"

### 策略3：困境求助原则

> "我有思路的时候，我不会用CHAT GPT，但我没有思路的话，我才会想"
> "我需要在我不会的时候才会找的"

### 策略4：分块提问

> "我只会把我自己不懂的那部分给他"
> "我只会投喂到我需要那部分"

### 策略5：容错上限

> "如果实在出不来的话，就只能自己再从文献更大的范围里面去找"
> "超过三次以上他都改不对的话，我就不会再用它了"

## 深层认知

### 对AI能力的判断

> "这个AI它有的时候其实是在不懂装懂，就是它也会给你编一些参考文献"

### 对创造性的看法

> "创造性的，我觉得这种最好是由人自己去做。他只是去负责帮你把后续的完善就可以了"

### 数据隐私态度

> "其实我不担心数据隐私的泄露...好多人都这样做，就可能就不存在这种泄露风险"

### 对依赖程度的自评

> "我是还好，虽然我每天都会用它，但是这是一个频率的问题，并不代表我的任务非常依赖它"

## 与其他受访者的对比

### 与受访人1、2的关键差异

访谈者特别指出：
> "今天晚上你访谈了两个完全相反的"

| 维度 | 受访人1/2 | 受访人3 |
|------|-----------|---------|
| 耗时任务 | 让GPT做 | 自己做 |
| 创意任务 | 自己做 | 让GPT给思路 |
| 依赖程度 | 高度依赖 | 部分依赖 |

## 对论文的核心价值

### 1. Trust-Use Decoupling的机制解释 ⭐⭐⭐⭐⭐

他展示了"低信任+高使用"的核心机制：
- **信任低**："我不会太信任他"
- **使用高**："几乎每天"
- **机制**：**验证策略作为缓冲**

> "相当于进行一种双重验证，我才会去用他的这个建议"

### 2. 专家策略的系统化

他的策略形成了一个完整的框架：
1. **输入端**：只在困境时求助
2. **过程中**：分块提问
3. **输出端**：双重/三角验证
4. **容错机制**：超过3次放弃

### 3. 任务分化的边界条件

| 任务特征 | 信任水平 | 原因 |
|----------|----------|------|
| 解释性任务 | 高 | "我本来就不理解，我验证不了" |
| 创造性任务 | 低 | "创造性的最好是由人自己去做" |
| 可验证任务 | 条件信任 | 有文献支撑才采用 |

### 关键引用（可用于论文）

1. **双重验证原则**：
   > "我不会太信任他，只会给我一个方向，我看有没有这个方向的文献，相当于进行一种双重验证，我才会去用他的这个建议"

2. **自主优先原则**：
   > "我能做的，我都自己做，很少会去用到它"

3. **对AI能力的判断**：
   > "这个AI它有的时候其实是在不懂装懂，就是它也会给你编一些参考文献"

4. **创造性任务的看法**：
   > "创造性的，我觉得这种最好是由人自己去做。他只是去负责帮你把后续的完善就可以了"

5. **依赖程度的自评**：
   > "虽然我每天都会用它，但是这是一个频率的问题，并不代表我的任务非常依赖它"

## 八、分析验证

待核对的关键引用：
- [x] "双重验证，我才会去用他的这个建议" ✓ (line 813)
- [x] "不懂装懂，就是它也会给你编一些参考文献" ✓ (line 812)
- [x] "频率的问题，并不代表我的任务非常依赖它" ✓ (line 1107)
- [x] "准确率可能百分之跟一半" ✓ (line 1776)
- [x] "太生硬了，没有深度" ✓ (line 1339)

---
*分析完成时间：2025年1月*

---


<a id="受访人4"></a>

# 受访人4：许军 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 许军 |
| 年龄 | 21岁 |
| 学历 | NTU会计学（Accountancy）本科在读 |
| 使用频率 | 基本上每天 |
| 主要工具 | ChatGPT（付费会员） |

## 使用场景

### 场景1：课程学习与复习
- **100+页PPT处理策略**：
  > "100多页PPT我丢进去我知道的效果不会好"
  - 只用于获取大概了解
  - 不会根据其大纲复习，自己从头整理

- **20-30页PPT处理策略**：
  > "就算有遗漏的话，我在它的大纲的基础上去修改我的工作量比较小"
  - 会根据GPT大纲修改，作为笔记基础
  - 原因：内容少，不是很重要

- **截图提问方式**：
  > "如果有看到不懂的地方，我可能会直接截图发给他"
  - 让GPT解释单页PPT内容
  - 举例说明，用更直白的话解释
  - 效果评价："大部分时候都可以"

### 场景2：邮件写作
- **功能性邮件（调课等）**：
  > "如果是调课就很功能性的，目的性很强的，我觉得有模板的话无所谓"
  - 直接使用GPT生成的内容

- **套词邮件（学术申请）**：
  > "一方面还是我觉得它写用这个语气有点太人气了，没有人味儿"
  > "太生硬了，没有深度"
  - 效果不好，需要自己动手改
  - 尝试喂论文给GPT也不行
  - 最终流程：自己写完 → GPT润色

### 场景3：论文阅读与写作
- **论文筛选流程**：
  1. 先读摘要，判断相关性
  2. 把论文丢给GPT总结
  3. 对比摘要与GPT总结，验证准确性
  4. 根据总结决定是否细读

- **论文写作流程**：
  > "我一般直接跟他讲说就是用学术写作的方式的风格帮我翻译成英文"
  - 自己写中文核心内容
  - GPT翻译成英文学术风格
  - 让GPT做段落润色和衔接

- **数据隐私考量** ⭐⭐⭐：
  > "不是特别能接受把我自己已经写完的东西全部丢给他"
  > "我可能会对它生成东西进行汇总，而不是把修改完的东西全部丢给他"
  - 策略：让GPT根据自己生成的内容总结，而不是提交修改后的完整内容

### 场景4：代码辅助
- **分块生成策略**：
  > "感觉好像任务特别复杂的时候，他生成代码效果就不好了，还是要我自己去分"
  - 拆分功能，分块生成代码

- **整合问题**：
  > "每个代码的片段单独运行是可以的，如果我把这几个合在一起的话，可能会出现bug"
  - Debug能力不足

- **使用态度**：
  > "因为有GPT，我试错成本很低，骑到骑大巴速度快很多"
  - 即使不完美，仍然比自己写快

### 场景5：日常生活
- **药品说明翻译**：
  > "因为要说明书不是一般都很大一段吗，我可能就会直接让他帮我翻译总结一下"
  - 不会再去核对原文

- **生活信息搜索**：
  > "他会联网的话，他会给那个链接给来源，然后我可能自己再去判断一下是不是真的"
  - 80%准确，会添油加醋做推断

### 不使用的场景
- **搜索文献**：
  > "所有信息我不太相信他"
  > "不会我们一般都会自己找"

- **算命娱乐**：
  > "我没有这个需求"

## 信任轨迹：任务分化型

### 信任特征

根据任务类型和内容长度调整使用策略。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 概念解释 | ⭐⭐⭐⭐ 高 | 直接采用，很少验证 |
| 短PPT总结 | ⭐⭐⭐⭐ 较高 | 在其基础上修改 |
| 长PPT总结 | ⭐⭐ 低 | 仅获取大概，自己整理 |
| 功能性邮件 | ⭐⭐⭐⭐ 高 | 直接使用 |
| 套词邮件 | ⭐⭐ 低 | 仅用于润色 |
| 代码生成 | ⭐⭐⭐ 中等 | 分块生成，试错成本低 |
| 信息搜索 | ⭐⭐ 低 | 需验证来源 |
| 文献搜索 | ❌ 不信任 | 从不使用 |

### 关键区分维度

1. **内容长度**：
   - 20-30页 vs 100+页处理策略完全不同

2. **任务正式性**：
   - 功能性邮件 vs 套词邮件

3. **数据敏感性**：
   - 高度重视数据隐私

## 核心专家策略

### 策略1：内容长度分层策略

> "二三十页是因为内容比较少，所以就算有遗漏的话，我在它的大纲的基础上去修改我的工作量比较小"

- 短内容：GPT主导，自己修改
- 长内容：自己主导，GPT辅助

### 策略2：摘要对比验证

> "我会先看摘要，所以如果我如果发现摘要就跟他总结的不一样的话，那可能就有问题"

- 用已知信息（摘要）验证GPT输出

### 策略3：数据隐私保护策略

> "我可能会对它生成东西进行汇总，而不是把修改完的东西全部丢给他"

- 只提交GPT生成的内容让其总结
- 不提交自己修改后的完整内容

### 策略4：修改标记请求

> "我会直接问问他，就是你修改了哪些地方，然后它一般就会加粗指出来"
> "这就是给我省时间，因为它可能生成的内容有很大一段有重复的"

### 策略5：背景信息预设

> "我会跟他讲这门课是什么，比如说这门课是新加坡会计，会计的相关课程，然后适用什么准则之类的"

- 提供课程大纲或背景信息
- 帮助GPT理解具体语境

## 深层认知

### 对GPT能力边界的认知

> "因为100多页PPT我丢进去我知道的效果不会好"

- 清楚了解GPT处理长文档的局限性

### 对创造性任务的看法

> "比如说他给你提供这些信息，那你就会自己去写吗？后面就自己去写，写完之后还是会让他再帮我润色"

- 创造性内容自己完成
- GPT只负责润色

### 对深度问题的认知

> "太生硬了，没有深度"
> "只能做补充，主要的观点还是要自己写"

### 对试错成本的认识

> "因为有GPT，我试错成本很低"

- 即使GPT不完美，仍比纯手工快

### DeepSeek vs ChatGPT的评价

> "我反倒觉得deep seek更严重一点"（关于幻觉）
> "很跌位...经常服务器崩掉，要不然就是敏感话题不愿意输出"

## 对论文的核心价值

### 1. 数据隐私作为使用边界 ⭐⭐⭐⭐

她展示了**数据隐私意识如何影响AI使用策略**：
- 不会提交完整的修改后内容
- 创造性地使用"让GPT总结自己生成的内容"策略
- 这揭示了**信任不仅关乎准确性，也关乎隐私安全**

### 2. 内容长度作为策略调节变量 ⭐⭐⭐⭐

| 内容长度 | 策略 | 原因 |
|----------|------|------|
| 短（20-30页）| GPT主导 | 修改工作量小 |
| 长（100+页）| 自己主导 | GPT效果差，且需要深度理解 |

### 3. 任务正式性分层

功能性任务 vs 重要任务的使用策略差异显著。

### 关键引用（可用于论文）

1. **内容长度策略**：
   > "100多页PPT我丢进去我知道的效果不会好"
   > "二三十页是因为内容比较少，就算有遗漏的话，我在它的大纲的基础上去修改我的工作量比较小"

2. **数据隐私考量**：
   > "不是特别能接受把我自己已经写完的东西全部丢给他"

3. **试错成本认知**：
   > "因为有GPT，我试错成本很低"

4. **深度不足的评价**：
   > "太生硬了，没有深度...没有人味儿"

5. **摘要验证策略**：
   > "我会先看摘要，如果发现摘要就跟他总结的不一样的话，那可能就有问题"

## 八、分析验证

待核对的关键引用：
- [x] "100多页PPT我丢进去我知道的效果不会好" ✓ (line 1272)
- [x] "不是特别能接受，把我自己已经写完" ✓ (line 1447)
- [x] "太生硬了，没有深度" ✓ (line 1339)
- [x] "没有人味儿" ✓ (line 1324)
- [x] "先看摘要，如果发现摘要就跟他总结的不一样" ✓ (line 1373)

---
*分析完成时间：2025年1月*

---


<a id="受访人5"></a>

# 受访人5：于 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 于（＆） |
| 年龄 | 23岁（01年） |
| 学历 | NTU物理与数学学院，分析学硕士在读 |
| 本科背景 | 东北大学应用统计 |
| 使用频率 | 几乎每天 |
| 主要工具 | DeepSeek、豆包、ChatGPT，偶尔kimi |

## 使用场景

### 场景1：课堂学习
- **实时概念解释**：
  > "上课正在上课中的时候，比如说老师在PPT上有一些词汇，或者是有一些英文的专属名词...我就会把它复制到GPT，然后让他先解释这个词的基本意思，然后再让他给我举几个例子"

- **课后PPT理解**：
  > "有些PPT老师在PPT，然后看不懂，然后就会把整页截图给他"
  - 一页一页提问，不整体投喂
  - 让GPT翻译+拓展

- **整体投喂效果差**：
  > "之前尝试过把整个文档丢给他，但是觉得那种就是太粗略了，后来还是主要是以PPT一页一页的形式"

### 场景2：专业概念 vs 数学计算（关键差异）

- **专业概念**：高信任
  > "像这些，比如说在上一些financial的课，这些基本专业的这些名词，包括解释，这些比较偏专业性的东西，我还是比较相信GPT的准确性"

- **数学计算**：低信任 ⭐⭐⭐
  > "碰到了一些概率论的那些计算，细微的计算，GPT的准确性还是有待提高的"
  > "我觉得可能准确率可能百分之跟一半"
  - 策略：GPT给思路，自己验算
  - 会尝试引导修正，"有时候可以成功，有时候提示不过来，然后我就放弃了"

### 场景3：项目代码（Kaggle比赛等）
- **选择模型**：
  > "然后让他帮我们想有什么可以比较创新的模型...它提供的还是挺全面的"
  - GPT提供选项，团队人工筛选
  - 只选择"有学过或者是大家有了解的"

- **代码生成流程**：
  > "会让他先写一个基础的模型...基本上一小块一小块的写"
  - 数据清洗："我觉得还是挺不错的"
  - 建模代码："要一直反反复复改好几次才能改对"

- **代码学习**：
  > "有些代码是他生成的，然后可能不太了解，我想如果想知道每行代码的意思，就会让他解释一下"

- **手写代码减少**：
  > "本科大一大二的时候敲一敲，大三就有（GPT）...几乎没有了吧"

### 场景4：工作中的SQL
> "工作中会让他帮我写写sql...基本上会跟他讲一个逻辑，然后让他实现代码，然后自己再改"
- SQL报错比较少
- Python/模型代码报错较多

### 场景5：邮件写作
> "一般是会先写个中文，然后让他写英文...语气格式没什么要改"
- 使用频率低
- 满意度高（因为用得少，没发现问题）

### 场景6：简历/模拟面试 ⭐⭐⭐（独特场景）
> "比如说把一段经历发给他，然后让他针对这段经历...从各个方面提出什么问题"
> "假如你是面试官，针对我的经历从不同方面提出几个问题"

- 不是让GPT修改简历
- 是让GPT扮演面试官提问
- 效果："有少数会被问到，主要是在让我对一段经验思考能更加全面一些"

### 场景7：生活信息搜索
- **药品/症状查询**：
  > "因为之前说GPT4水平相当于一家三甲医院的医生...不是什么大病的话，我觉得还是可以相信"
  > "确实有一些用"

### 场景8：算命（娱乐）
> "效果就看个乐吧...主要还是好玩"
> "我可能会等那年过了看看他说的准不准"
- 纯娱乐，不会认真对待
- 不会追问细节

### 不使用的场景
- **PPT制作**：
  > "因为我觉得要他封顶的话，我觉得我自己差不多"
  > "基本很少有文字"（内容偏数理）

- **文献搜索**：
  > "论文，可能我就是要不就直接看，就没有问过GPT"

- **学术写作**：
  > "硕士项目没有论文，就是实习答辩"

## 信任轨迹：实用主义型

### 信任特征

基于任务性质（解释性 vs 计算性）区分信任程度。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 专业概念解释 | ⭐⭐⭐⭐⭐ 高 | 直接采用，不验证 |
| 代码生成 | ⭐⭐⭐⭐ 较高 | 分块生成，出错再改 |
| SQL代码 | ⭐⭐⭐⭐ 较高 | 报错少，逻辑对 |
| 模拟面试 | ⭐⭐⭐⭐ 较高 | 帮助全面思考 |
| 药品咨询 | ⭐⭐⭐⭐ 较高 | 小病可信 |
| 数学计算 | ⭐⭐ 低 | "准确率一半"，需自己验算 |
| 算命娱乐 | ⭐ 娱乐 | 看个乐 |
| PPT制作 | ❌ 不需要 | 内容偏数理 |

### 核心信任逻辑

> "大体的逻辑跟思路肯定是没有问题，遇到一些比较繁琐计算题的时候，它的一些计算过程中间经常会有一些小小问题"

**结论**：逻辑思路可信，数值计算需验证

## 核心专家策略

### 策略1：逐页投喂原则

> "之前尝试过把整个文档丢给他，但是觉得那种就是太粗略了"
> "还是主要是以PPT一页一页的形式"

### 策略2：角色扮演提示词

> "我比较喜欢让他带入，比如说如果你是一个什么什么，然后让他给我解答"
> "比如说如果你是一名医生，如果你是一名面试官"

- 特定场景使用角色设定
- 承认可能是"心理作用"

### 策略3：思路采纳+自我验算

> "GPT给思路，自己验算"
> "会提示他，会引导他，有时候可以成功，有时候提示不过来就放弃"

### 策略4：模型选择的边界控制

> "我们一般都会选有学过或者是大家有了解的，就不会选完全没有接触过的"

- GPT提供选项
- 只采用熟悉的选项

### 策略5：代码依赖但学习意识

> "有些代码是他生成的，然后可能不太了解，我想如果想知道每行代码的意思，就会让他解释一下"

- 生成代码后会学习理解

## 深层认知

### 对AI能力的边界认知

> "解释一些概念的东西...第二个就是代码的方面"（出色）
> "复杂的计算数字的计算那种"（不行）

### 对专业匹配的认知

> "因为我们这个专业也不像计算机那...主要是数理，对代码要求其实没有特别高"

- 使用方式与专业需求匹配
- 不需要深度学习代码，只需完成任务

### 对手写代码减少的认知

> "本科大一大二的时候敲一敲，大三就有（GPT）"
> "几乎没有了吧"

### 数据隐私态度

> "没怎么担心过，因为我给他的数据不是隐私的数据"
> "简历我觉得无所谓"

### 对提示词效果的怀疑

> "感觉有可能加不加差别不大，我加了可能是心理作用"
> "会觉得他可能会输出的更好"

## 独特发现

### 1. 模拟面试场景 ⭐⭐⭐⭐

这是一个**独特且有价值的使用场景**：
- 不是让AI修改简历
- 而是让AI扮演面试官提问
- 目的是"让我对一段经验思考能更加全面一些"

**理论价值**：AI作为思维训练工具，而非内容生成工具

### 2. 解释性 vs 计算性的信任分化 ⭐⭐⭐⭐⭐

| 任务性质 | 信任程度 | 原因 |
|----------|----------|------|
| 解释性任务 | 高 | "比较偏专业性的东西，我还是比较相信" |
| 计算性任务 | 低 | "准确率可能百分之跟一半" |

**这是一个重要的边界条件**：任务是否涉及精确计算

### 3. 工具依赖的专业差异

> "因为会计真的不要求你代码能力有多好"

- 专业需求决定使用深度
- 不需要学习代码 → 完全依赖GPT生成

## 对论文的核心价值

### 1. 解释性 vs 计算性任务的信任边界

> "这些比较偏专业性的东西，我还是比较相信GPT的准确性"
> "概率论的那些计算...准确率可能百分之跟一半"

**理论启示**：AI信任不仅与任务领域相关，也与任务性质（解释vs计算）相关

### 2. AI作为思维训练工具

模拟面试场景展示了AI的**非生成性用途**：
- 不是让AI产出内容
- 而是让AI帮助人类思考更全面

### 3. 专业背景对使用深度的影响

数理分析专业 → 对代码学习需求低 → 完全依赖AI生成

### 关键引用（可用于论文）

1. **解释性任务信任**：
   > "像这些financial的课，这些基本专业的这些名词，包括解释，这些比较偏专业性的东西，我还是比较相信GPT的准确性"

2. **计算性任务不信任**：
   > "概率论的那些计算，细微的计算，GPT的准确性还是有待提高的，可能准确率百分之跟一半"

3. **模拟面试用法**：
   > "假如你是面试官，针对我的经历从不同方面提出几个问题...主要是在让我对一段经验思考能更加全面一些"

4. **角色扮演提示词**：
   > "我比较喜欢让他带入，比如说如果你是一个什么什么...可能是心理作用，会觉得他可能会输出的更好"

5. **手写代码减少**：
   > "本科大一大二的时候敲一敲，大三就有（GPT）...几乎没有了吧"

6. **药品咨询信任来源**：
   > "之前说GPT4水平相当于一家三甲医院的医生...不是什么大病的话，我觉得还是可以相信"

## 八、分析验证

待核对的关键引用：
- [x] "比较偏专业性的东西，我还是比较相信GPT" ✓ (line 1756)
- [x] "准确率可能百分之跟一半" ✓ (line 1776)
- [x] "假如你是面试官，针对我的最大从不同方面提出几个问题" ✓ (line 1968)
- [x] "三甲医院的医生" ✓ (line 2008)
- [x] "本科大一大二的时候敲一敲大三就有" ✓ (line 1888)

---
*分析完成时间：2025年1月*

---


<a id="受访人6"></a>

# 受访人6：黄双杰 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 黄双杰 |
| 年龄 | 25岁 |
| 学历 | 厦门大学医学院硕士，健康大数据与智能医学专业 |
| 研究方向 | 医院急诊科医疗运营管理 |
| 使用频率 | 几乎每天 |
| 主要工具 | DeepSeek（默认）、OpenAI GPT（备选） |
| 工具偏好变化 | 从90% DeepSeek → 55开（各有优势） |

## 使用场景

### 场景1：陌生领域探索
- **使用流程**：
  1. 先看综述或经典论文
  2. 遇到陌生概念时上传论文给AI
  3. 让AI解释概念并举例

> "AI能够给我一个快速的给我一个准确的一些关于这些概念的定义，以及会举一些例子，这个例子也是举的很好"

- **信任判断标准**：
> "他的那个逻辑我觉得和我的直觉是相符合的，我就是觉得没问题了。如果我看着觉得有点奇怪，那我可能就会去找别的资料"

### 场景2：论文对比分析
- **使用流程**：
  1. 分别上传两篇论文
  2. 各自总结内容和创新点
  3. 请求比较两篇论文区别

- **效果评价**：
> "只能给一个比较相对比较表面的一个对比"
> "你光看他给你罗列出来这个对比，有时候你自身没有一定水平的话...我没有什么感觉"

- **核心策略：验证思维模式** ⭐⭐⭐⭐⭐
> "我的思维就会变成去验证这个GPT他给的这些结论是否是合理，是不是正确的"
> "我看了这两篇文章，我大致看一下，觉得没问题，那我可能就会写到综述里去"

### 场景3：毕业论文写作（重要性分层策略）

**重要部分（Introduction、摘要等）**：
> "像很重要的一些part，我就会主要是想靠依靠我自己，然后去有一个去组织一下这个逻辑"
> "我初步把我的逻辑用我自己的话写出来之后，再让GPT来帮我润色这个词藻"

**次要部分（图表分析等）**：
> "比如说我要描述一下这个图的结果...可能就会把这个图上传给GPT，然后让他帮我去描述一下"
- 完全让GPT生成，自己检查修改后使用

**信息搜索（支撑论点）**：
> "我在写introduction的时候，虽然我是自己写，但是我需要一些这方面的信息"
> "比如说帮我找一些急诊拥堵的一些新闻，或者是一些数字"
- 会点击链接验证信息准确性

### 场景4：LaTeX代码与格式调整
- 已有代码基础上让GPT修改
- 图片位置、公式换行等格式调整

> "总体表现还是不错的，但是也有时候会出现一些，就是我们交互了好几次，但是还是达不到我理想中的效果"

**工具切换策略**：
> "同样的东西同指令我比如说我换到那个OPEN I的那个GPT的话，那他确实能够一次或者两次就能够get到我的意思"

### 场景5：算法与代码生成

**两种途径**：
1. **从无到有**：提供算法框架和详细定义（描述性语言，非伪代码）
2. **优化现有代码**：
   > "自己根据那个算法写了一段，但是跑的很慢...让GPT帮我去重新的去调整了我代码的结构，那确实效果就是它那个速度就提高了好几倍"

**效果评价**：
> "从无到有我觉得问题不是很大，取决于你这个算法的一个复杂程度...他一般能够比较好的去完成你的期待"

### 场景6：邮件写作
- **流程**：直接给要点 → GPT生成 → 自己修改
- **中文邮件问题**：
  > "它有时候会有一些成语，我会觉得看起来好像有点别扭...特别像AI生成"
- **英文邮件**：较少修改（可能因为水平不够，看不出问题）

### 场景7：调研报告整理
- 提供调研要点 → GPT整理成完整报告
- 录音转文字效果"一般般"（噪音太多）

### 不使用的场景

**定理证明**：
> "我甚至没有尝试过，因为我觉得他一定满足不了，我觉得他一定做不好"
> "我觉得他很难理解我现在做的这个东西"

**原因分析**：
1. 能力不足以理解复杂模型
2. 提供充分信息的工作量太大

## 信任轨迹：验证导向型

### 信任特征

基于自身判断能力和任务重要性调整策略。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 基础概念解释 | ⭐⭐⭐⭐⭐ 高 | 直接采用，符合直觉即可 |
| 代码生成/优化 | ⭐⭐⭐⭐ 较高 | 报错再改，效果满意 |
| 信息搜索 | ⭐⭐⭐⭐ 较高 | 采用但会验证链接 |
| 论文对比 | ⭐⭐⭐ 中等 | 作为起点，自己验证 |
| 重要写作 | ⭐⭐ 低 | 自己写，GPT润色 |
| 定理证明 | ❌ 不使用 | 认为一定做不好 |

### 核心信任逻辑

> "GPT的话，都还是在提升效率上，就你让他想让他帮你做一些讲idea，或者是说一些比较需要创造力比较需要想象力的这种活，我觉得他做的还是不是很好"

## 核心专家策略

### 策略1：验证思维模式 ⭐⭐⭐⭐⭐

> "我的思维就会变成去验证这个GPT他给的这些结论是否是合理，是不是正确的"

- 不是完全依赖GPT输出
- 把GPT输出作为"假设"去验证
- 加速阅读而非替代阅读

### 策略2：提示词文档化 ⭐⭐⭐⭐

> "对于是我经常用的场景，我会有一个专门的一个文档去专门去记录一些我常用的提示词"

**示例（论文总结）**：
> "总结这篇文章，包括问题背景，研究意义，创新点，方法结论，管理启示"

### 策略3：重要性分层策略

| 重要性 | 策略 |
|--------|------|
| 高（intro、摘要）| 自己写逻辑 → GPT润色 |
| 中（综述）| GPT总结 → 自己验证 |
| 低（图表描述）| GPT生成 → 自己检查修改 |

### 策略4：工具切换策略

> "一开始我是90%使用DC，后来慢慢的可能就是55开了"
> "有一些任务可能DC那个open的那个GPT也解决不了，但是DC可能解决的很好"

- 一个工具失败就换另一个
- 各工具有各自优势

### 策略5：数据脱敏策略

> "我会给他部分的一个数据，比如说我复制粘贴一部分可能两行或者三行的这样一个数据"

- 只提供格式示例，不上传完整数据
- 保护签署保密协议的数据

### 策略6：清晰指令原则

> "之前有过教训吗？你如果没写清楚的话，他可能会误解你，生成的东西就不是你想要的"
> "唯一的一个要求就是你把要求写清楚就可以了"

## 深层认知

### 对GPT定位的认知

> "代码对我而言就是能够去跑通，能够给我一个想要的结果放在我的那个论文里，其实就已经够了"
> "更重要的是我对于我来说，我的研究更重要的可能是从数学的一个模型上"

- 代码是工具，不是核心
- 核心竞争力在数学建模

### 对创造性任务的认知

> "比较需要创造力比较需要想象力的这种活，我觉得他做的还是不是很好，最主要的还是可以帮我提升效率"

### 对AI"做不到"的归因

> "如果我自己也弄不出来的话，那我可能就会觉得可能就是这个问题，它本身就是一个比较复杂的问题"
> "如果我自己能做出来的话，那你为什么做不出来？"

### DeepSeek vs OpenAI GPT

> "有时候DS上交互好几次，它就是达不到你想要的...同样的指令换到OpenAI的GPT，他一次或者两次就能get到我的意思"

## 独特发现

### 1. 验证思维模式 ⭐⭐⭐⭐⭐

这是一个**高度成熟的AI使用策略**：
- 不把GPT当作"答案提供者"
- 而是把GPT当作"假设生成器"
- 自己的角色从"创作者"转变为"验证者"

**理论价值**：展示了专家用户如何在保持批判性思维的同时提升效率

### 2. 提示词文档化管理 ⭐⭐⭐⭐

系统化管理常用提示词，提高复用效率。

### 3. 重要性分层的清晰边界

重要部分（需要逻辑和创意）→ 自己主导
次要部分（描述性、机械性）→ GPT主导

### 4. 对复杂任务的预判性放弃

> "我甚至没有尝试过，因为我觉得他一定满足不了"

- 基于对AI能力边界的判断
- 权衡"提供充分信息的成本" vs "可能的收益"

## 对论文的核心价值

### 1. 验证思维模式作为专家策略

> "我的思维就会变成去验证这个GPT他给的这些结论是否是合理，是不是正确的"

**理论启示**：专家用户通过"验证者角色转换"实现效率与质量的平衡

### 2. 重要性分层策略

清晰展示了用户如何根据任务重要性分配AI使用程度。

### 3. 工具切换作为问题解决策略

当单一工具失效时，切换工具而非放弃AI辅助。

### 关键引用（可用于论文）

1. **验证思维模式**：
   > "我的思维就会变成去验证这个GPT他给的这些结论是否是合理，是不是正确的"

2. **重要性分层**：
   > "像很重要的一些part，我就会主要是想靠依靠我自己...再让GPT来帮我润色"

3. **创造性任务认知**：
   > "比较需要创造力比较需要想象力的这种活，我觉得他做的还是不是很好，最主要的还是可以帮我提升效率"

4. **提示词文档化**：
   > "对于是我经常用的场景，我会有一个专门的一个文档去专门去记录一些我常用的提示词"

5. **直觉验证标准**：
   > "他的那个逻辑我觉得和我的直觉是相符合的，我就是觉得没问题了"

6. **定理证明放弃原因**：
   > "我如果想要让他去尝试...光是给他这个信息，我就有很多的工作量"

7. **工具切换逻辑**：
   > "一开始我是90%使用DC，后来慢慢的可能就是55开了...各自有各自的优点"

## 八、分析验证

待核对的关键引用：
- [x] "我的思维就会变成去验证这个GPT他给的这些结论" ✓ (line 2409)
- [x] "90%使用DC...55开了" ✓ (line 2481)
- [x] "不会完全抄他的" ✓ (line 2948)
- [x] "明天要交的时候，这种时候你肯定最想用它" ✓ (line 3800)
- [x] "没有思考能力，那我要思考" ✓ (line 3221)

---
*分析完成时间：2025年1月*

---


<a id="受访人7"></a>

# 受访人7：zqz - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | zqz |
| 年龄 | 21岁 |
| 学历 | 本科，管理科学专业，电子商务方向 |
| 使用频率 | 看情况，有任务时使用 |
| 主要工具 | ChatGPT（4o免费版）、DeepSeek、Kimi |

## 使用场景

### 场景1：信息搜索
- **替代百度**：
> "现在有ChatGPT之后，你应该就不一定会在百度搜了"
> "他至少能直接给出来一个答案"

- **常识性信息**：直接相信
> "相信常识性的"

- **理论/算法**：
> "先大致先了解一下...看一下要不要用"
- 后续会搜资料补充

### 场景2：代码辅助
**完整工作流程**：
1. **任务开始前**：让GPT解释算法原理
   > "先信息检索一下"

2. **任务进行中**：
   - 让GPT生成代码
   - **绝不完全抄袭** ⭐⭐⭐⭐⭐
   > "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"
   - 在自己理解基础上改变

3. **遇到报错**：
   - 方案1：让GPT从前面重新生成
   - 方案2：去CSDN等权威渠道搜索
   > "有时候会很蠢"
   > "很正常，这个挺正常的，肯定会出现不能解决报错的情况"

4. **任务结束后**：写实验报告
   - 让GPT生成算法原理综述
   - 让GPT解释每段代码作用
   - 让GPT总结可能的问题
   > "看看他有没有多提一点什么我没有注意到问题"

### 场景3：文献阅读
- **快速筛选**：
> "先大概先看一下"
> "让他先阅读，先大概先看一下，下一步之后我就先大致有一个了解"

- **信任程度**：
> "他再怎么生成，你自己肯定也得看一下的"

- **相关性判断**：
  - 相关 → 看原文
  - 不相关 → 暂时忽略
  > "有可能会有问题...暂时忽略了吧"

### 场景4：论文写作（Method部分）

**核心评价**：
> "用ChatGPT没什么用，顶多就是把中文翻译成英文"

**工作流程**：
1. 自己写中文大概
2. 让GPT翻译成英文
3. 让GPT润色/完善

**为什么不直接投喂**：
> "理论上来说应该直接丢进去，它会应该会过于雷同"

**遇到的问题**：
> "他没有办法完全理解"
> "他理解能力没有很强"

### 场景5：心得感想等内容生成
> "跟报告其实差不多"
- AI痕迹明显
> "有AI痕迹的话就比较，就表达就比较雷同，我反正我感觉就是他就首先其次然而这种就特别多"

### 不使用/规避的场景

1. **隐私敏感内容**
2. **需要特别准确的场景**
   > "法律78的政治相关"
   > "不能出错的地方"

## 信任轨迹：实用怀疑型

### 信任特征

高度实用但保持怀疑，不完全依赖。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 常识性搜索 | ⭐⭐⭐⭐ 较高 | 直接采用 |
| 代码生成 | ⭐⭐⭐ 中等 | 绝不完全抄，自己改 |
| 报告写作 | ⭐⭐⭐ 中等 | 生成后修改 |
| 文献筛选 | ⭐⭐⭐ 中等 | 参考但必看原文 |
| 论文写作 | ⭐⭐ 低 | 仅翻译润色 |
| 法律/政治 | ❌ 不使用 | 刻意规避 |

### 核心信任逻辑

> "他就是擅长搜还有写，我就是擅长分析输入"
> "没有思考能力...那我要思考，那我不思考，那这做了还有任何意义吗？"

## 核心专家策略

### 策略1：反模板化意识 ⭐⭐⭐⭐⭐

> "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"

- 代码：在自己理解基础上修改
- 文字：删除AI痕迹词汇
- 论文：不直接投喂，怕"过于雷同"

### 策略2：分段式代码调试

> "并不是一次性全部都跑，他们是一个框跑了"

- 一段一段验证
- 前面跑通的不再动
- 错误的地方重新生成

### 策略3：模板优于参考

> "如果你在这种情况下把它放进去的话，它有时候就会出现一些莫名那篇文章里面的词"

- 自己写步骤模板 > 喂别人论文
- GPT无法区分"仿照文章"还是"仿照写法"

### 策略4：时间驱动使用

> "需要快速的时候会最想要用"
> "比如说让你写一个东西明天要交的时候，这种时候你肯定最想用它"

### 策略5：多渠道验证

> "那就再是在别的地方再搜呗，百度啊"
> "去比较权威的，比如说什么CSDN，一些七七八八的地方"

- 常识内的：可不验证
- 非常识内的：被发现后才知道错

## 深层认知

### 对GPT理解能力的评价

> "他没有办法完全理解"
> "他理解能力没有很强"
> "有时候会很蠢"

### 对自身角色的认知

> "他就是擅长搜还有写，我就是擅长分析输入"
> "没有思考能力...那我要思考，那我不思考，那这做了还有任何意义吗？"

- 明确分工：GPT负责搜索和生成，人负责分析和判断

### 对错误信息的态度

> "不是常识之内，那应该判断不出来"
> "只有到后面发现他是错了，你才知道他是错的"

- 承认局限性
- 时间允许会验证

### 对隐私风险的态度

> "用都用了，对，你肯定至少意识到会有可能会有这个问题，也没办法采取任何措施"

- 意识到风险
- 但无可奈何

### 对AI痕迹的敏感

> "首先其次然而这种就特别多，然后还得这个还得改"

- 高度敏感
- 主动去除

## 独特发现

### 1. 反模板化作为核心原则 ⭐⭐⭐⭐⭐

这是本受访者最显著的特征：
- 不完全抄代码
- 不完全抄文字
- 不直接投喂论文

**原因**："完全抄就会出现很多人都是差不多的情况"

### 2. 模板 vs 参考的区分 ⭐⭐⭐⭐

> "他没办法理解你这个真正的仿照是仿照这个文章，还是只是仿照写法"

**洞察**：GPT无法理解用户的深层意图（仿照内容 vs 仿照形式）

### 3. 时间压力作为使用驱动力

> "比如说让你写一个东西明天要交的时候，这种时候你肯定最想用它"

### 4. 人机分工的清晰认知

> "他就是擅长搜还有写，我就是擅长分析输入"

## 对论文的核心价值

### 1. 反模板化意识

> "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"

**理论启示**：用户主动规避GPT输出的同质化风险

### 2. GPT理解能力的边界

> "他没办法理解你这个真正的仿照是仿照这个文章，还是只是仿照写法"

**理论启示**：GPT无法理解用户的深层意图和语境

### 3. 时间压力与使用意愿的关系

时间紧迫程度正向影响GPT使用意愿。

### 关键引用（可用于论文）

1. **反模板化意识**：
   > "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"

2. **GPT理解能力不足**：
   > "他没有办法完全理解...理解能力没有很强"
   > "有时候会很蠢"

3. **人机分工**：
   > "他就是擅长搜还有写，我就是擅长分析输入"

4. **时间驱动使用**：
   > "需要快速的时候会最想要用"
   > "比如说让你写一个东西明天要交的时候"

5. **模板vs参考**：
   > "他没办法理解你这个真正的仿照是仿照这个文章，还是只是仿照写法"

6. **AI痕迹意识**：
   > "首先其次然而这种就特别多，然后还得这个还得改"

7. **隐私风险态度**：
   > "用都用了...也没办法采取任何措施"

## 八、分析验证

待核对的关键引用：
- [x] "没有办法完全理解" ✓ (line 3572)
- [x] "有时候会很蠢" ✓ (line 3026)
- [x] "明天要交的时候，这种时候你肯定最想用它" ✓ (line 3800)
- [x] "用都用了...也没办法采取任何措施" ✓ (line 3956)
- [x] "没有思考能力，那我要思考" ✓ (line 3221)

---
*分析完成时间：2025年1月*

---


<a id="受访人8"></a>

# 受访人8：宋柏洋 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 宋柏洋（橘子） |
| 年龄 | 21岁 |
| 学历 | 厦门大学本科（Finance），UCB交换（Computer Science） |
| 使用频率 | "没关过，天天在用" |
| 主要工具 | ChatGPT 4o |

## 使用场景

### 场景1：算法学习
- **使用方式**：
> "它的知识库是完全可以cover掉我现阶段的算法学习的，所以我不用再去教他"
> "请给出Q learning的例子，这样就差不多了"

- **迭代优化**：
> "迭代两三次基本上都是可以的"
- 针对不足强调改进（prompt chain）
- GPT有时会自动高亮修改处

### 场景2：代码学习与调试 ⭐⭐⭐⭐

**学习优先原则**：
> "代码是你先写，而不是让他直接给你代码"
> "因为我觉得这样学习会比较有效"

**工作流程**：
1. 先学好算法（让GPT举例）
2. 自己动手写代码
3. 遇到bug再找GPT

**Debug评价**：
> "我觉得挺强的"

**局限性**：
> "有的时候他会陷入循环，确实是怎么搞都搞不出来"
> "有一些不足就是对debug方面，我觉得他有很多时候都会用超出我现在能使用的那些方法"

### 场景3：文献阅读
- **翻译**：看不懂时截图或上传
- **技术讲解**：
> "如果有某些技术看不懂的话，我也会让它生成一些讲解"

- **提高准确率策略**：
> "如果它能读取整份文档，他给我的讲解准确率可能会更高一些"
> "它其实就是internal knowledge不够了，喂文档进去作为它对现有知识体系有一个补充，就像模型微调一样"

### 场景4：报告/小论文写作

**核心观点**：
> "直接写，我觉得会很差，一般都得先把过程告诉他，然后让他做文字上的拓展"

**问题**：
> "它有的时候会自己引出来很多没有用到的或者是把自己用的东西写错了"
> "自己手写这种情况出现过一些次数不是很少"

### 场景5：邮件写作 ⭐⭐⭐⭐⭐

**核心态度**：
> "不大是因为我对它生成式的内容不信任"
> "因为我觉得写邮件要真情实感，所以会自己写一下"

**工作流程**：
1. 自己先写一份（包含语法错误、逻辑问题）
2. 丢给GPT让他修改
3. 只用于润色，不影响整体逻辑

**为什么不让GPT直接生成**：
> "前者的那个方法我也试过，我觉得效果不是很好"
> "general AI如果没有给他非常详细的prompt，他非常有可能超越界限，而且生成出来非常假"

**具体问题**：
> "他可能会说出来很多我没有做过的"
> 比如联系教授时会说"your research includes blah blah blah"但都是没研究过的

### 场景6：头脑风暴（有限使用）

> "我觉得还蛮好用的，但我们最后也没有用"

**严重问题**：
> "有一个比较严重的，他给思路会限制我的思路"
> "一般没思路的时候也是有一些小灵感的，看了他的之后，我就彻底没有灵感"

### 不使用/规避的场景

**数学领域** ⭐⭐⭐⭐⭐：
> "CHAT GPT对于数学方面的能力非常的弱"
> "得分门别类，只有数学是这样"
> "数学和经济学，他表现的都不是很好"
> "对他完全没有信心"

**假文献生成**：
> "生成文献，这个毛病还是没有改过来"

## 信任轨迹：生成内容不信任型

### 信任特征

高度不信任GPT的生成内容，仅作为辅助工具使用。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 算法学习 | ⭐⭐⭐⭐ 较高 | 举例学习，迭代优化 |
| 代码Debug | ⭐⭐⭐⭐ 较高 | 自己先写，GPT检查 |
| 翻译 | ⭐⭐⭐⭐ 较高 | 直接使用 |
| 文献讲解 | ⭐⭐⭐ 中等 | 喂文档提高准确率 |
| 报告写作 | ⭐⭐ 低 | 自己写过程，GPT扩展 |
| 邮件写作 | ⭐⭐ 低 | 只润色，不生成 |
| 头脑风暴 | ⭐⭐ 低 | 会限制思路 |
| 数学 | ❌ 不使用 | 完全没信心 |

### 核心信任逻辑

> "不大是因为我对它生成式的内容不信任"
> "general AI如果没有给他非常详细的prompt，他非常有可能超越界限"

## 核心专家策略

### 策略1：学习优先原则 ⭐⭐⭐⭐⭐

> "因为我觉得这样学习会比较有效"

- 代码自己先写
- GPT用于检查和解惑
- 不直接让GPT做作业

### 策略2：答案比较验证法 ⭐⭐⭐⭐

> "我不会直接把我的答案截给他，我会先让它产生一个他自己的答案出来，然后我再核对"
> "如果不一样，我再把我的答案给他，让他分析为什么不一样，谁错"

**准确率评估**：
- 数学：55开
- 计算机：91开

### 策略3：文档喂入策略

> "它其实就是internal knowledge不够了，喂文档进去作为它对现有知识体系有一个补充"

### 策略4：润色而非生成

> "基本上只能我基本上只会用它来进行润色，就是进行一些文字上的调整，但不会影响整体逻辑"

自己写的内容相当于"非常精细的prompt"

### 策略5：高频句警惕

> "他的答案如果太高频了，大家都在用，我觉得我也用这个有点雷同"
> "看看能不能小改一下"

## 深层认知

### 对GPT定位的认知

> "我觉得他对我来说只是辅助，到没有他我倒也能活"
> "就是一个比较全能的assistant"

**与访谈者的对话**：
- 访谈者：感觉它像一个工具而不是teammate
- 受访者："我觉得他不太行"

### 对生成内容的深度不信任

> "general AI如果没有给他非常详细的prompt，他非常有可能超越界限，而且生成出来非常假"

### 对思维限制的警觉 ⭐⭐⭐⭐

> "我觉得它局限我的思路的一个问题是原因是因为停留在GPT上面太长的时间"
> "就会忘掉自己的本来的想法忘掉初心"
> "我觉得重新提取出来自己本来想干什么还挺困难的，如果完全陷入到他的思维里面"

### 对数学能力的评价

> "我觉得他对于数学的能力完全就是一个本科生"
> "稍微难一点的，比如说什么实分析什么，问问他就完全回答不了"

### 对隐私的态度

> "不会完全不担心"
> "我不觉得他会把我们这些用户的输入作为训练模型"

## 独特发现

### 1. 生成内容不信任作为核心原则 ⭐⭐⭐⭐⭐

> "不大是因为我对它生成式的内容不信任"

这是贯穿所有使用场景的核心态度。

### 2. 思维被限制的风险意识 ⭐⭐⭐⭐

> "有一个比较严重的，他给思路会限制我的思路"
> "一般没思路的时候也是有一些小灵感的，看了他的之后，我就彻底没有灵感"

**理论价值**：GPT可能对用户原创思维产生负面影响

### 3. 答案比较验证法 ⭐⭐⭐⭐

独特的使用策略：先让GPT独立生成答案，再比较分析差异。

### 4. Computer Science视角的专业认知

作为CS学生，对GPT技术有深入理解：
- 理解temperature参数
- 理解internal knowledge局限
- 理解模型微调概念

## 对论文的核心价值

### 1. 生成内容不信任作为使用边界

> "general AI如果没有给他非常详细的prompt，他非常有可能超越界限"

**理论启示**：专业用户基于对AI生成机制的理解，选择性不信任生成内容

### 2. 思维限制风险

> "停留在GPT上面太长的时间...就会忘掉自己的本来的想法"

**理论启示**：过度依赖AI可能损害用户原创思维能力

### 3. 学习优先vs效率优先的选择

> "因为我觉得这样学习会比较有效"

与其他受访者形成对比：选择学习而非效率最大化

### 关键引用（可用于论文）

1. **生成内容不信任**：
   > "不大是因为我对它生成式的内容不信任"
   > "general AI如果没有给他非常详细的prompt，他非常有可能超越界限，而且生成出来非常假"

2. **学习优先原则**：
   > "代码是你先写，而不是让他直接给你代码...因为我觉得这样学习会比较有效"

3. **思维限制风险**：
   > "有一个比较严重的，他给思路会限制我的思路"
   > "一般没思路的时候也是有一些小灵感的，看了他的之后，我就彻底没有灵感"

4. **答案比较验证**：
   > "我不会直接把我的答案截给他，我会先让它产生一个他自己的答案出来，然后我再核对"

5. **数学能力评价**：
   > "CHAT GPT对于数学方面的能力非常的弱"
   > "对他完全没有信心"

6. **邮件写作态度**：
   > "因为我觉得写邮件要真情实感，所以会自己写一下"

7. **工具定位**：
   > "我觉得他对我来说只是辅助，到没有他我倒也能活"
   > "就是一个比较全能的assistant"

8. **高频句警惕**：
   > "他的答案如果太高频了，大家都在用，我觉得我也用这个有点雷同"

## 八、分析验证

待核对的关键引用：
- [x] "对它生成式的内容不信任" ✓ (line 4280)
- [x] "给思路会限制我的思路" ✓ (line 4497)
- [x] "我就彻底没有灵感" ✓ (line 4499)
- [x] "写邮件要真情实感" ✓ (line 4273)
- [x] "数学方面的能力非常的弱" ✓ (line 4115)

---
*分析完成时间：2025年1月*

---


<a id="受访人9"></a>

# 受访人9：钟其臻 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 钟其臻 |
| 年龄 | 22岁 |
| 学历 | 厦门大学电子商务专业，本科大四 |
| 使用频率 | 每天（工作时） |
| 主要工具 | ChatGPT（4o免费版）、DeepSeek |

## 使用场景

### 场景1：课程作业/案例分析

**工作流程**：
1. PDF转Word上传给GPT
2. 先测试GPT能否识别
3. 直接丢问题效果不好，改为一个个拆解

> "你全部问题，丢进去的时候一般它效果都不会太好。因为他的回答永远是有限的"

**内容采用策略**：
- 有些理由"很强行"就不采用
- 课程比较水就可能直接用

> "我这课可能比较水，我可能直接用"
> "我是就是做材料的，然后汇报的不是我"

**GPT阅读替代**：
> "GPT就是可以帮你阅读，主要是你阅读就很强了"
- 案例自己"简单瞄了一眼"
- 主要靠GPT阅读和回答

### 场景2：代码辅助（Stata/Python）

**基础功能**：
> "前面的可以就是他跑寻跑回归肯定是可以的"

**复杂功能的问题** ⭐⭐⭐⭐：
> "后面我想让他直接帮我把能不能直接把能显著的找出来...然后就不行了"
> "它这个代码输进去它是能跑出来，但是它结果是错的"
> "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果，就他这个东西是不会回答这个东西没有办法实现的"

**报错处理**：
> "我就会把那个报错，它不会显示不是会显示东西，就把那个显示的东西放进去"
- 有时行，有时不行
- 不行就搜Google

### 场景3：论文写作（复现论文）

**核心态度**：
> "我觉得完全生成效果不会好"
> "因为他不可能生成，你如果不先把它提前给一点东西给他，怎么可能生成能直接生成"

**工作流程**：
1. 把原文method部分喂给GPT（作为背景信息）
2. 找写得好的参考文章
3. 自己先改写（英文夹杂中文）
4. 让GPT改写润色连接

> "我一般就是不可能全部一起，我就是有一比如说一句一句话写。或者是一段一段一段一段话写"
> "我自己会先改，然后改完之后我让他再改改写论"

**GPT角色**：
- 改写润色
- 连接句子
- 不完全生成段落

### 场景4：学习/信息搜索

**DID方法论学习**：
> "先问的如何解决内生性问题，然后如何使用DID解决内生性问题解决的思路是怎么样的"

**为什么选择GPT而非视频**：
> "因为视频之前看过...如果要马上的话，我就想先看一下CHAT GPT，他直接文字出来的话也很快的"
> "你看了GPT你问他之后，你又可以马上直接把你要解决的事情，你又可以再问他"

**效果评价**：
> "挺好的...然后再往下我就提出了一个提出一点特定的问题"

### 场景5：文献阅读

> "论文我感觉基本上要么是翻译，要么是概括了"
> "有的时候也会针对于文章中某一个东西让他去解答"
> "感觉他至少会根据文章内容来给你解释"

### 不使用/规避的场景

**完全生成内容**：
> "我感觉他，你让他自己写的话，应该效果不会很好"
> "肯定写出来就是AI的味道会很重"

## 信任轨迹：效率导向型

### 信任特征

以任务完成为导向，信任程度随课程/任务重要性调整。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 水课作业 | ⭐⭐⭐⭐ 较高 | 可能直接用 |
| 基础代码 | ⭐⭐⭐⭐ 较高 | 能跑通 |
| 复杂代码 | ⭐⭐ 低 | 会强行输出错误 |
| 论文写作 | ⭐⭐ 低 | 只润色不生成 |
| 信息搜索 | ⭐⭐⭐⭐ 较高 | 快速获取 |
| 幻觉问题 | ⭐⭐⭐ 中等 | 只作为参考 |

### 核心信任逻辑

> "只作为参考。只做一参考吧"
> "这个理由感觉写的挺正常的，我原本就觉得不一定可以，我只是满问他一下"

## 核心专家策略

### 策略1：问题拆解策略

> "后面就给他说清楚...1.1开始只想去试一下"
> "一个问题，一个问题"

- 全部问题效果差
- 拆解后逐个提问

### 策略2：多方参考策略

> "我肯定多方参考，一般做作业的时候，我就不会只看一个"
> "比如说老师又特别强调了。我们还会把那一部稍微多多写一点"

### 策略3：阅读替代策略

> "GPT就是可以帮你阅读，主要是你阅读就很强了"

- 让GPT阅读材料
- 自己只看GPT输出
- 判断输出合不合理

### 策略4：改写而非生成

> "我一般让他改写乱色，我也没有说时间很多让他把这两句话连在一起"

- 自己先写内容
- GPT负责改写润色
- 不完全依赖GPT生成

### 策略5：任务重要性分层

> "我这课可能比较水，我可能直接用"

- 水课：可直接使用
- 重要任务：自己多参与

## 深层认知

### 对GPT能力边界的认知

> "他一开始没有领会你的意思"
> "你全部问题，丢进去的时候一般它效果都不会太好"
> "我觉得完全生成效果不会好"

### 对GPT"强行输出"的发现 ⭐⭐⭐⭐

> "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果"
> "就他这个东西是不会回答这个东西没有办法实现的"

**理论价值**：GPT不会承认自己做不到，而是强行给出错误答案

### 对隐私的态度

> "还是会担心吧，但是我感觉我肯定算比较不担心的"
> "因为我感觉也没有什么什么什么好泄露的"

### DeepSeek vs ChatGPT

> "deep seek他有时候就会弄出来很多七七八八的东西，我觉得就很不好"
> "有很多中国人才会有表了这种一些词汇"

## 独特发现

### 1. GPT"强行输出"问题 ⭐⭐⭐⭐⭐

> "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果"

**理论价值**：GPT不会告知用户某任务无法实现，而是强行生成错误结果，这增加了用户判断负担

### 2. 阅读替代模式 ⭐⭐⭐⭐

让GPT阅读材料，自己只判断输出是否合理。这是一种**极致效率导向**的使用方式。

### 3. 任务重要性决定使用深度

> "我这课可能比较水，我可能直接用"

课程/任务的重要程度直接影响GPT使用策略。

### 4. 交互式学习优势

> "你看了GPT你问他之后，你又可以马上直接把你要解决的事情，你又可以再问他"

GPT的交互性让学习更连贯，可以即时追问。

## 对论文的核心价值

### 1. GPT"强行输出"作为信任风险

> "它这个代码输进去它是能跑出来，但是它结果是错的"
> "就他这个东西是不会回答这个东西没有办法实现的"

**理论启示**：GPT不会主动告知能力边界，用户需自行判断输出是否可靠

### 2. 任务重要性作为使用策略调节变量

不同重要程度的任务采用不同的GPT使用深度。

### 3. 阅读替代作为效率最大化策略

让GPT承担阅读工作，用户只需判断输出质量。

### 关键引用（可用于论文）

1. **问题拆解必要性**：
   > "你全部问题，丢进去的时候一般它效果都不会太好。因为他的回答永远是有限的"

2. **GPT强行输出**：
   > "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果，就他这个东西是不会回答这个东西没有办法实现的"

3. **阅读替代**：
   > "GPT就是可以帮你阅读，主要是你阅读就很强了"

4. **完全生成效果差**：
   > "我觉得完全生成效果不会好"
   > "因为他不可能生成，你如果不先把它提前给一点东西给他，怎么可能生成能直接生成"

5. **任务重要性分层**：
   > "我这课可能比较水，我可能直接用"

6. **交互式学习优势**：
   > "你看了GPT你问他之后，你又可以马上直接把你要解决的事情，你又可以再问他"

7. **只作为参考**：
   > "只作为参考。只做一参考吧"

8. **多方参考**：
   > "我肯定多方参考，一般做作业的时候，我就不会只看一个"

## 八、分析验证

待核对的关键引用：
- [x] "强行给你输出一个结果" ✓ (line 4759)
- [x] "这课可能比较水，我可能直接用" ✓ (line 4665)
- [x] "只作为参考" ✓ (line 4841)
- [x] "多方参考" ✓ (line 4850)
- [x] "帮你阅读，主要是你阅读就很强了" ✓ (line 4690)

---
*分析完成时间：2025年1月*

---


<a id="受访人10"></a>

# 受访人10：刘斌 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 刘斌 |
| 年龄 | 37岁（87年） |
| 学历 | 博士 |
| 职业 | MBA老师/助理教授 |
| 使用频率 | 较低（保守型使用者） |
| 主要工具 | ChatGPT（OpenAI）、国产AI（DeepSeek等） |

## 使用场景

### 场景1：报告/课题润色

**核心用途**：
> "我一般主要用于润色一些文字"
> "它是一个比较常规性的routinized工作"

**工作流程**：
1. 自己先写好内容
2. 让GPT润色调整
3. 要求GPT标记新增内容
4. 自己再做删减调整

**标记差异策略** ⭐⭐⭐⭐⭐：
> "我一般会让它生成一个对比前后的一个内容，然后我自己再做一些斟酌"
> "比如说我会说你给我做一些改进，同时让他帮我特别标记出来，新增的内容部分"

**为什么需要标记**：
> "担心他有一些内容，他写的其实也很一般...有一些他只会写一些套话"
> "我一般会让他帮我标记出来，我自己再做一些删减和调整"

### 场景2：语法检查（搜索工具）

> "中文的一些地方，举个简单例子，比如说三种的使用，我也会把它当做一个搜索工具来去问一下"

**验证行为**：
> "如果觉得还是不太确定，我还会再用别的工具，不管是搜索引擎或者说搜例句，我会再去做一个检查"

### 场景3：常识性信息搜索

> "比如说问今天是什么节日，或者这种非常规的问题，我觉得大概率应该CHAT GPT不会骗我吧"
> "我很少再去做一个核实"

**替代百度**：
> "完全可以替代掉百度，因为它的搜索...给人感觉上是这个信息的这个对更加准确吧"

### 场景4：概念学习/理论检索

> "比如说一个理论的概念，我可能完全不知道，那这个功能我更多的也是类似，就是把它当做搜索引擎，像百度百科一样"

**后续验证**：
> "这个时候我更多的还是依赖，比如说google scholar我去research这个scholars...他的文章，然后再去看"

### 场景5：访谈问题设计 ⭐⭐⭐

**使用场景**：
> "我会给他输出一个，比如说我关注的研究问题是这样，你能不能帮我去构思一些访谈的问题"

**迭代修改**：
> "我会持续的追问他...你能不能再做一些哪些地方，我觉得还不太好，你能不能再做一些调整"

**定位**：
> "我觉得他能给我一个初步的一个guideline"
> "我会拿它做一个初步的...等于给一些启发吧"

**最终使用**：
> "不能我不太信赖他能直接给我一个标准的答案"
> "我会采纳他几个问题"

### 不使用的场景

**科研论文**：
> "对我基本没有使用过"

**需要深度思考的任务**：
> "如果需要思考的我其实不是很信任他"

**创新性工作**：
> "它并不是一个创造性的工作"

## 信任轨迹：保守怀疑型

### 信任特征

高度保守，仅在低风险、低创造性任务中使用。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 常识搜索 | ⭐⭐⭐⭐ 较高 | 直接采用 |
| 语法检查 | ⭐⭐⭐⭐ 较高 | 基本信任，偶尔验证 |
| 报告润色 | ⭐⭐⭐ 中等 | 标记差异，自己判断 |
| 访谈设计 | ⭐⭐⭐ 中等 | 作为启发，部分采纳 |
| 概念学习 | ⭐⭐ 低 | 需Google Scholar验证 |
| 科研论文 | ❌ 不使用 | 完全不使用 |
| 创新思考 | ❌ 不使用 | 不信任 |

### 核心信任逻辑

> "GPT的话，都还是在提升效率上...比较需要创造力比较需要想象力的这种活，我觉得他做的还是不是很好"
> "我本身会对这个任务做一个界定，他确实不是我感兴趣，也不是我觉得是一个值得投入时间的事情"

**任务分类原则**：
> "garbage in garbage out就是我处理一些垃圾任务的时候"

## 核心专家策略

### 策略1：标记差异策略 ⭐⭐⭐⭐⭐

> "我会让它生成一个对比前后的一个内容"
> "让他帮我特别标记出来，新增的内容部分"

**目的**：
- 快速识别GPT的修改
- 便于判断是否采用
- 过滤套话和冗余

### 策略2：任务重要性分层 ⭐⭐⭐⭐⭐

> "我本身会对这个任务做一个界定"
> "确实不是我感兴趣，也不是我觉得是一个值得投入时间的事情，我就是...处理一些垃圾任务"

- 重要任务（科研）：完全不用GPT
- 常规任务（报告）：用GPT润色
- 垃圾任务（应付差事）：更依赖GPT

### 策略3：迭代追问策略

> "我会尝试再问一两次，如果他持续还是不行，我就失去这个耐心了"
> "我会直接给他口头指令让他修改"

### 策略4：多源验证策略

> "如果觉得还是不太确定，我还会再用别的工具"
> "我更多的还是依赖，比如说google scholar"

## 深层认知

### 对GPT定位的认知

> "我觉得可能更多是自己的一个保守的观念吧"
> "也可能其实CHAT GPT远比这个功能要强大，但是我对他没有太高的一个信赖"

**工具定位**：
> "我期待新观点，我没有看到他能给出一些新观点，所以我目前就把它当做一个对普通的工具来使用"

### 对GPT能力不足的认知

> "他会写的内容会比较泛，就是范医师，就是没有感觉他没有生成特别至少感觉跟我匹配能力的一个状态的内容"
> "有些时候他会话非常累赘，就是他会重复叫所谓的车轱辘话"

### 对数据隐私的态度

> "我一般都是放一些不痛不痒的一些内容，我才会给他"
> "确实能保证我的隐私的话，我大部分就是应付差事的一些报告了"

### 对AI未来的展望

> "我自己设想过...比如说我让他每天都去阅读...某一个领域的研究"
> "或者说某一个学者，他的论文的写作风格，持续让他去模仿和学习和阅读"
> "我猜他是有能力去写出来学者风格的文字"

## 独特发现

### 1. "Garbage in Garbage out"使用哲学 ⭐⭐⭐⭐⭐

> "我处理一些垃圾任务的时候"

**理论价值**：这是一种独特的AI使用哲学——将GPT定位为处理不重要任务的工具，重要任务完全不用

### 2. 标记差异作为核心需求 ⭐⭐⭐⭐

> "它自己默认的，比如说我用这个OPEN AI，它就不会直接给我显示这个内容"
> "必须来，我跟他说一下，我觉得他才会加粗"

**改进建议**：希望GPT默认标记修改内容

### 3. 能力匹配问题

> "没有感觉他没有生成特别至少感觉跟我匹配能力的一个状态的内容"

**理论启示**：专家用户认为GPT输出水平与自身能力不匹配

### 4. 保守观念的自我认知

> "可能更多是自己的一个保守的观念吧"
> "也可能其实CHAT GPT远比这个功能要强大"

**理论价值**：用户对自身保守态度有清晰认知

## 对论文的核心价值

### 1. 任务重要性作为使用边界

> "garbage in garbage out就是我处理一些垃圾任务的时候"

**理论启示**：专家用户根据任务重要性决定是否使用AI，重要任务完全排斥AI

### 2. 标记差异作为信任建立机制

让GPT标记修改内容，便于用户判断和筛选，这是建立有限信任的策略

### 3. 专家用户的能力不匹配感

专家认为GPT输出水平与自身能力不匹配，这限制了使用深度

### 关键引用（可用于论文）

1. **任务重要性分层**：
   > "我本身会对这个任务做一个界定，他确实不是我感兴趣，也不是我觉得是一个值得投入时间的事情"
   > "garbage in garbage out就是我处理一些垃圾任务的时候"

2. **标记差异策略**：
   > "我一般会让它生成一个对比前后的一个内容，然后我自己再做一些斟酌"
   > "让他帮我特别标记出来，新增的内容部分"

3. **不信任创造性输出**：
   > "如果需要思考的我其实不是很信任他"
   > "我期待新观点，我没有看到他能给出一些新观点"

4. **套话问题**：
   > "有一些他只会写一些套话。那这些套话我就对我觉得反而没有什么价值，让整个报告显得更加冗长"

5. **能力不匹配**：
   > "没有感觉他没有生成特别至少感觉跟我匹配能力的一个状态的内容"

6. **数据隐私意识**：
   > "我一般都是放一些不痛不痒的一些内容，我才会给他"

7. **保守态度自知**：
   > "可能更多是自己的一个保守的观念吧，也可能其实CHAT GPT远比这个功能要强大，但是我对他没有太高的一个信赖"

8. **访谈设计使用**：
   > "他能给我一个初步的一个guideline...等于给一些启发吧"
   > "不能我不太信赖他能直接给我一个标准的答案"

## 八、分析验证

待核对的关键引用：
- [x] "garbage in garbage out就是我处理一些垃圾任务" ✓ (line 5302)
- [x] "只会写一些套话" ✓ (line 5217)
- [x] "保守的观念" ✓ (line 5259)
- [x] "不痛不痒的一些内容" ✓ (line 5318)
- [x] "能给我一个初步的一个guideline" ✓ (line 5295)

---
*分析完成时间：2025年1月*

---


<a id="受访人11"></a>

# 受访人11：李香香 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 李香香 |
| 年龄 | 28岁 |
| 学历 | 湖南大学软件硕士 |
| 职业 | 字节跳动产品经理（内部中后台工具产品设计） |
| 使用频率 | 每天 |
| 主要工具 | DeepSeek、豆包 |

## 使用场景

### 场景1：文档撰写（最常用）

**核心用途**：
> "写文档的工作的场景是最常使用的"
> "如果遇到一些不太懂的文档类型，会先让GPT给我生成一个大的提纲文档提纲"

**工作流程**：
1. 描述背景，让GPT生成大纲
2. 先拿出来用
3. 遇到问题再追问修改

**大模块vs小模块的认知** ⭐⭐⭐⭐：
> "从让它给我生成大模块会更符合我的预期"
> "因为让他给我生成大模块的时候，是我确实对这个方向基本上没有什么内容的理解"

**小模块生成的困难**：
> "在小模块的生成，我其实也没有办法很具体的描绘出我要怎么表达这个背景"
> "他的大模型的数据是很少有我这部分的数据的，所以它也很难去生成这个结果"

### 场景2：抖音博主内容创作

**使用背景**：
> "我个人想做一个博主，但是这个博主的我一直觉得我的内容很差"
> "我不太会表达，然后分享的内容也就是没有一个很强的分享的欲望"

**工作流程**：
1. 自己先拍视频
2. 告诉GPT角色定位和垂直类型
3. 让GPT帮助编辑和配文案

**效果评价**：
> "这个事情我做了，我用GPT做了很多次，但是他们基本上得不到我想要的结果"
> "我感觉那些信息不符合我想要的，但是我想要的其实不一定是那个算法想要的"

**实际使用方式**：
> "我可能每次有一个想法，然后我会把我的想法告诉他之后他会跟我生成好多个想法，然后我在基于他这5、6个想法里面拼凑出最重要的结果"

### 场景3：数据处理/分析

**使用方式**：
> "比如说我有一个大的表，然后每表里面数据特别多，我需要分析其中一列的数据的词语出现最多的是哪个"
> "他会自己帮我生成代码，然后给我得出结果"

**信任程度**：
> "我给他的指令很清晰，他不会出有额外的一些想法"
> "可能如果遇到那种比较大的项目，就或者复杂一点，我就不会使用它，因为我可能也不信任他"

**间接验证**：
> "我自己也在那个表里面去做统计，我发现他统计的一些词跟我之前花的一些时间统计的内容是大差不差的"

### 场景4：英语口语练习（豆包）

**使用体验**：
> "我觉得挺好的，感觉都可以省外教的钱了"
> "他就会一下理解我意思，他说你刚刚是不是想这么问怎么怎么怎么说"

**不足之处**：
> "可能不够那么的口语化，就他的英语还是比如说语法都很正确，但可能大家在说英语没有那么语法正确"

### 场景5：心理咨询（DeepSeek）⭐⭐⭐⭐⭐

**使用背景**：
> "我有一段时间非常的焦虑。因为感情上的事情"
> "我就太焦虑了，我就感觉我浑身不，我就非常能感觉我现在特别的不高兴"

**使用体验**：
> "他说的内容还挺触动我的"
> "他就像心理医生那样，非常站在我这边的先肯定了我的一些状态"
> "感觉好像有人懂我了"

**核心洞察 - 对AI信任高于人** ⭐⭐⭐⭐⭐：
> "deep seek更好的在于我不用担心他对我有任何的评判，就是人人性的评判"
> "无论是心理医生他怎么厉害，但他毕竟是个人，我都或多或少会觉得你会对我知道我现在这个事情不好"
> "我在跟他聊的时候，其实我是不太敢说，我其实有很多信息我不敢说，是因为我就是怕他会对我有一些异样的眼光"

**与真人心理医生的对比**：
> "我觉得人跟人的信任是很难去建立起来的"
> "我可能就是联系个一两次两三次那种，我就觉得很难对他就很有信任去说这些信息"

### 不使用/效果差的场景

**小模块生成**：
> "在小模块的生成，我其实也没有办法很具体的描绘出我要怎么表达这个背景"

**专业健身领域**：
> "在健身这方面，我感觉我还挺专业的，他可能给我的都是很通泛的东西"
> "我现在要的是很定制化的东西"

## 信任轨迹：效率便捷型

### 信任特征

以快捷方便为主，不完全信任但部分采纳。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 大纲生成 | ⭐⭐⭐⭐ 较高 | 直接采用，遇问题再改 |
| 常识搜索 | ⭐⭐⭐⭐ 较高 | 当百度用，不验证 |
| 简单数据分析 | ⭐⭐⭐⭐ 较高 | 指令清晰即可信任 |
| 心理咨询 | ⭐⭐⭐⭐⭐ 很高 | 比人更值得信任 |
| 英语口语 | ⭐⭐⭐⭐ 较高 | 效果不错 |
| 视频文案 | ⭐⭐⭐ 中等 | 作为头脑风暴，部分采纳 |
| 小模块生成 | ⭐⭐ 低 | 效果差，不如自己写 |
| 复杂任务 | ⭐⭐ 低 | 不信任 |

### 核心信任逻辑

> "优点就是快捷吧，快捷方便是一是对我而言是最主要的"
> "最主要的还是我在一些遇到不懂的及时的做，我就把它当个百度去用"

## 核心专家策略

### 策略1：大模块优先策略 ⭐⭐⭐⭐

> "从让它给我生成大模块会更符合我的预期"
> "因为让他给我生成大模块的时候，是我确实对这个方向基本上没有什么内容的理解"

- 不懂的领域：让GPT生成大模块
- 具体细节：自己填充

### 策略2：拼凑整合策略

> "我可能每次有一个想法，然后我会把我的想法告诉他之后他会跟我生成好多个想法，然后我在基于他这5、6个想法里面拼凑出最重要的结果"

- 不完全采纳任何一个方案
- 从多个方案中拼凑整合

### 策略3：详细模板策略

> "我觉得那个效果很差...只给他几个要点，它是生成不了我想要的结果的"
> "不如我先把我的内容先串好之后带给到他"

- 提供详细模板 > 只给要点
- 限定内容后生成更符合预期

### 策略4：迭代修改策略

> "大概得有个3、4次。就是平均下来看下来"

迭代原因：
> "因为我一开始也不清楚，我最终想要的一个结果是什么样"
> "我在描述这个过程不是那么的详细"

## 深层认知

### 对Prompt学习的态度 ⭐⭐⭐⭐

> "我不会花很多时间去写，我就是大概花一些时间去写一下"
> "如果当我很认真的去写这个prompt的话，这个时间经历不如我很认真的去写我想要的内容了"

**对未来的期待**：
> "以后不需要你写很详细的prompt，而是你就是去描述一些你大概想要的内容，它会自己帮你去生成"
> "我可能会等这个事情会慢慢的发生"

### 对通用大模型的不满 ⭐⭐⭐⭐

> "你太通用了，你要是通用我就觉得你不会那么的精"
> "在很多很垂直领域下，我觉得我也问不到什么东西，我还不如自己去找自己去想"
> "我觉得他不止于是百度"

**从产品角度的看法**：
> "他们封装的产品的程度还不够，就是这些大模型可能从学术领域上他们是很好的，但是我觉得他们作为一个产品来说不是那么的好"

### 对模型选择的态度

> "如果我作为用户，我看到4.5和o3我不知道什么意思"
> "这个事情本来就不应该交给用户去做选择的"
> "甚至觉得是大模型该判断的"

### 对隐私的态度

> "不会因为我觉得这个社会已经没有什么隐私可言"
> "只要不是被我身边具体的人知道我的一些事情"
> "你要被大众知道，你就知道，我也无所谓"

### 对LUI vs GUI的思考 ⭐⭐⭐

> "为什么一定要走LUI，我感觉我说话并不一定比我去操作一些事情，点一些按钮，得出一个结果更方便"
> "我上班我都不想说话，我就一个劲在那打字，我就觉得挺好的"

## 独特发现

### 1. 心理咨询场景中的人机信任反转 ⭐⭐⭐⭐⭐

> "deep seek更好的在于我不用担心他对我有任何的评判"
> "人跟人的信任是很难去建立起来的"

**理论价值**：在情感支持场景中，用户对AI的信任可能超过对人的信任，因为：
- 无评判风险
- 无需担心隐私泄露给"真人"
- 可以完全敞开心扉

### 2. 产品经理视角的大模型批评 ⭐⭐⭐⭐

> "你太通用了，你要是通用我就觉得你不会那么的精"
> "他们封装的产品的程度还不够"

从产品设计角度对当前大模型的批评。

### 3. Prompt学习的机会成本意识

> "如果当我很认真的去写这个prompt的话，这个时间经历不如我很认真的去写我想要的内容了"

用户权衡学习prompt的时间成本vs直接完成任务。

### 4. 大模块vs小模块的使用边界

> "从让它给我生成大模块会更符合我的预期"
> "在小模块的生成...效果差"

明确了GPT在宏观框架vs具体细节上的能力差异。

## 对论文的核心价值

### 1. 心理咨询场景中的人机信任反转

> "deep seek更好的在于我不用担心他对我有任何的评判"
> "我在跟他聊的时候，其实我是不太敢说，我其实有很多信息我不敢说"

**理论启示**：在需要情感支持的场景中，AI的"非人性"反而成为优势，用户可以无顾虑地敞开心扉

### 2. 任务粒度与使用效果的关系

大模块生成效果好，小模块生成效果差，这反映了GPT在不同任务粒度上的能力差异

### 3. 产品思维对AI信任的影响

作为产品经理，对AI有更理性的评估，既不过度信任也不完全排斥

### 关键引用（可用于论文）

1. **心理咨询信任反转**：
   > "deep seek更好的在于我不用担心他对我有任何的评判，就是人人性的评判"
   > "人跟人的信任是很难去建立起来的"

2. **大模块vs小模块**：
   > "从让它给我生成大模块会更符合我的预期"
   > "在小模块的生成，我其实也没有办法很具体的描绘出我要怎么表达这个背景"

3. **Prompt学习成本**：
   > "如果当我很认真的去写这个prompt的话，这个时间经历不如我很认真的去写我想要的内容了"

4. **通用大模型不足**：
   > "你太通用了，你要是通用我就觉得你不会那么的精"
   > "在很多很垂直领域下，我觉得我也问不到什么东西"

5. **隐私态度**：
   > "这个社会已经没有什么隐私可言，只要不是被我身边具体的人知道我的一些事情"

6. **拼凑整合策略**：
   > "我可能每次有一个想法，然后我会把我的想法告诉他之后他会跟我生成好多个想法，然后我在基于他这5、6个想法里面拼凑出最重要的结果"

7. **快捷方便为核心**：
   > "优点就是快捷吧，快捷方便是一是对我而言是最主要的"

8. **详细模板策略**：
   > "只给他几个要点，它是生成不了我想要的结果的。不如我先把我的内容先串好之后带给到他"

## 八、分析验证

待核对的关键引用：
- [x] "让它给我生成大模块会更符合我的预期" ✓ (line 5829)
- [x] "快捷方便是一是对我而言是最主要的" ✓ (line 6271)
- [x] "这个社会已经没有什么隐私可言" ✓ (line 6397)
- [x] "拼凑出最重要的结果" ✓ (line 5869)
- [x] "太通用了，你要是通用我就觉得你不会那么的精" ✓ (line 6135)

---
*分析完成时间：2025年1月*

---


<a id="受访人12"></a>

# 受访人12：陈文静（AmazingGrace） - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 陈文静 |
| 年龄 | 30岁 |
| 学历 | 暨南大学法律硕士（专业硕士，偏实务） |
| 职业 | 金融风控 |
| 使用频率 | 一天3-4次 |
| 主要工具 | DeepSeek |

## 使用场景

### 场景1：工作报告/风控方案 ⭐⭐⭐⭐⭐

**核心用途**：
> "请他作为我这个职业去帮一些关于风控或者是审查的一些方案"

**工作流程**：
1. 角色设定："请你作为一个金融机构的风控人员"
2. 上传公开财务报表（非涉密）
3. 让GPT生成风控策略
4. 看思路，找自己没考虑到的点
5. 参考后自己扩充内容

**使用重点 - 只看思路** ⭐⭐⭐⭐⭐：
> "我首先比较看重的是，第一个是他的思路"
> "我可能会首先看一下它是从哪几个方面去思考的，他思考的大的方向和我一不一样"
> "它有没有提出来一些我平时做方案设计没有想到的一些点"

**采纳标准**：
> "他考虑到了，我完全没有考虑到的点，我觉得点又在这个方案中非常重要"
> "他考虑到了我考虑的点，但是角度和我不一样，可能会又给我一些新的思路"
> "它可能提示了一些我的错误，或者它让我发现我原本的想法可能是不对的"

**内容生成的不足**：
> "他们自己生成的可能都是一些比较大概的不是很具体的一些东西"
> "我们的报告里面是会需要一些非常具体的步骤，包括你还要结合你自己的工作实际"
> "可能用的还是比较多的，还是他的思路"

### 场景2：旅游攻略

**使用方式**：
> "比如说五一有五天小长假，请你帮我做一份关于江西景德镇的攻略"
> "要求跟他说，大概人均预算要是多少酒店的标准是怎么样"

**效果评价**：
> "他甚至可能会把你第一天去哪里，第二天去哪里，这些很具体的都的建议都会给到你"
> "一份我们在小红书上点赞收藏的旅行攻略那样"

**使用态度**：
> "可能会结合参考他的，然后再结合自身的一个体力，一个景点的需求方面，综合去考虑"
> "可能还是参考作用会比较大，不会说完全和他一样"

### 场景3：信息搜索（当百度用）

> "经常把它当百度用"
> "就把它当成百度一下，什么都在上面问一下"

**验证行为**：
> "如果他就他出来的答案可能和我想的差不多，我可能会点进去看"
> "如果出来的答案和我想的不太一样，或者是一些我没有接触到的东西，我可能会比较想再进去看"

### 场景4：财务数据分析

**使用方式**：
> "给他几份报表，让他帮我分析一下，然后我在他分析的基础上，然后再去补充一些自己的分析"

**效果评价**：
> "我觉得他这个效果还挺不错的"
> "deep seek 的思路和我的思路会不太一样，但是他的一些得出来的一些数据我们是可以参考的"

**使用态度**：
> "如果说到最最底层的话，其实还是在做参考"

### 场景5：纠错/验算

> "我们也会用deep seek去检查我们的一些行为的错误"
> "像个别字，这些一些计算上的错误对他有的时候也是可以帮我们去做一个纠正的"

**验证流程**：
> "它可能计算的结果和我是不一样的，那我会反过来倒算一下到底是谁出了错"

### 不使用/规避的场景

**隐私和工作机密**：
> "可能刻意规避的可能主要还是在刚刚跟你聊的人隐私方面，包括一些工作机密方面"

**涉密内容**：
> "我们自己系统内的一些东西，我们是不能传到这个DEEP S上"

## 信任轨迹：参考验证型

### 信任特征

核心原则：只做参考，不完全采纳。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 思路启发 | ⭐⭐⭐⭐ 较高 | 主要依赖，采纳有价值的点 |
| 旅游攻略 | ⭐⭐⭐⭐ 较高 | 参考但结合自身情况 |
| 信息搜索 | ⭐⭐⭐ 中等 | 需验证，尤其不一致时 |
| 财务分析 | ⭐⭐⭐ 中等 | 参考数据，思路自己判断 |
| 内容生成 | ⭐⭐ 低 | 太空泛，需自己完善 |
| 隐私数据 | ❌ 不使用 | 刻意规避 |

### 核心信任逻辑

> "如果说到最最底层的话，其实还是在做参考"
> "因为我发现在他们自己生存的可能都是一些比较大概的不是很具体的一些东西"

## 核心专家策略

### 策略1：角色设定策略 ⭐⭐⭐⭐

> "我觉得首先一定最重要的就是要跟他明确他的角色，比如你是一个什么岗位要和他说清楚"
> "再把一些关键的要素，比如说风险报告，或者是一些融资方案，这些我想要的东西要跟他讲清楚"

### 策略2：思路优先策略 ⭐⭐⭐⭐⭐

> "我首先比较看重的是，第一个是他的思路"
> "可能用的还是比较多的，还是他的思路"

- 不依赖内容生成
- 主要获取思路和框架
- 具体内容自己填充

### 策略3：差异验证策略

> "如果出来的答案和我想的不太一样...我可能会比较想再进去看"
> "我会反过来倒算一下到底是谁出了错"

- 与自己判断一致：可能接受
- 与自己判断不一致：需验证

### 策略4：底稿辅助策略

> "我还是会有自己的一个底稿"
> "从参考的角度上来说，如果他能提出一些之前没有考虑到的点...那我可能才会去用它"

- 自己先有底稿
- GPT用于完善和补充
- 不完全依赖GPT框架

### 策略5：一次交互原则

> "目前的经验来看，交互一下可能就结束了"

- 不反复追问
- 一次不行就放弃
- 自己完成剩余工作

## 深层认知

### 对GPT定位的认知

> "它可能在提供思路方面，他确实非常的高效"
> "到一些具体的措施，可能他自己的这个数据源可能并没有掌握到这么具体"
> "他提出来的一些东西还是会比较比较空一些"

**核心定位**：思路提供者，而非内容生成者

### 对内容生成的认知

> "因为每每个人的想法都不一样"
> "deep seek 它可能从一加一等于二这个方面去出发了，但是我没有办法去一定要求他就一定按我的这个思路去写"

### 对数据隐私的态度

> "可能也存在一种道德伦理上的风险"
> "你把一些东西上传到deep seek上面后会不会有一个后台数据泄露的风险"
> "可能刻意规避的可能主要还是在刚刚跟你聊的人隐私方面，包括一些工作机密方面"

### 内网版本的使用

> "我们单位内网接入的这个deep seek，它可能是已经有设置了一些我们行业内的一些文件"
> "这样可能会更加具体，给到的这个策略会更加具体"

## 独特发现

### 1. "只做参考"作为核心使用哲学 ⭐⭐⭐⭐⭐

> "如果说到最最底层的话，其实还是在做参考"

**理论价值**：这是一种高度理性的使用态度，将GPT定位为参考工具而非替代工具

### 2. 思路vs内容的明确区分 ⭐⭐⭐⭐

> "可能用的还是比较多的，还是他的思路"

明确区分GPT的思路价值和内容价值，只采用前者

### 3. 一次交互原则

> "目前的经验来看，交互一下可能就结束了"

反映了对GPT能力边界的清晰认知

### 4. 法律背景带来的隐私意识

虽然受访者表示"并不是因为法律这个专业"，但法律背景可能潜移默化地影响了其对数据隐私的重视

## 对论文的核心价值

### 1. "只做参考"作为使用策略

> "如果说到最最底层的话，其实还是在做参考"

**理论启示**：专业用户将GPT定位为参考工具，保持人的主导地位

### 2. 思路价值vs内容价值的区分

> "我首先比较看重的是，第一个是他的思路"
> "可能用的还是比较多的，还是他的思路"

**理论启示**：用户明确区分GPT在思路启发和内容生成上的不同价值

### 3. 行业特性对使用策略的影响

金融风控行业的特殊性（涉密、个性化需求）导致用户只能将GPT用于辅助参考

### 关键引用（可用于论文）

1. **只做参考原则**：
   > "如果说到最最底层的话，其实还是在做参考"
   > "我不会说完全去借用他的一个思维这样子"

2. **思路优先**：
   > "我首先比较看重的是，第一个是他的思路"
   > "可能用的还是比较多的，还是他的思路"

3. **内容生成不足**：
   > "他们自己生成的可能都是一些比较大概的不是很具体的一些东西"
   > "他提出来的一些东西还是会比较比较空一些"

4. **角色设定策略**：
   > "我觉得首先一定最重要的就是要跟他明确他的角色，比如你是一个什么岗位要和他说清楚"

5. **采纳标准**：
   > "他考虑到了，我完全没有考虑到的点，我觉得点又在这个方案中非常重要，那我会把它再加进来"

6. **一次交互原则**：
   > "目前的经验来看，交互一下可能就结束了"

7. **数据隐私意识**：
   > "可能也存在一种道德伦理上的风险就是可能你把一些东西上传到deep seek上面后会不会有一个后台数据泄露的风险"

8. **多信息源**：
   > "我觉得对于我来说就是多了一个信息的来源"

## 八、分析验证

待核对的关键引用：
- [x] "如果说到最最底层的话，其实还是在做参考" ✓ (line 6582)
- [x] "比较看重的是，第一个是他的思路" ✓ (line 6444)
- [x] "交互一下可能就结束了" ✓ (line 6499)
- [x] "明确他的角色" ✓ (line 6476)
- [x] "多了一个信息的来源" ✓ (line 6614)

---
*分析完成时间：2025年1月*

---


<a id="受访人13"></a>

# 受访人13：张梓敬 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 张梓敬 |
| 年龄 | 22-23岁（02年） |
| 学历 | 北大深研院硕士研一，国土空间规划专业（实际做AI相关研究） |
| 职业 | 腾讯实习（大模型垂直领域应用、工具调用能力、Agent研究） |
| 使用频率 | "非常频繁，基本上每小时都会用" |
| 主要工具 | ChatGPT、DeepSeek、多模型聚合工具 |

## 使用场景

### 场景1：概念检索/专家系统

**使用背景**：
> "有些平时有些不会的，不知道的一些陌生的概念，可能把它当做一个顾问，这样子的当做一个专家系统这样子的去问"

**典型场景**：
> "读论文的读到某一个具体的东西是不太理解的...比如说之前的研究主要是使用了这个习书奖励模型，那可能在这里面对这个系数奖励的概念就不是很清楚"

**效率提升**：
> "但是现在的话，一般就是用这些AI工具，它可以直接去做提问，直接去给你做通俗的解释，就不需要再花这些时间了"

### 场景2：论文总结 ⭐⭐⭐⭐

**核心洞察 - 从多到少vs从少到多**：
> "我算是重度的重度使用者，我对他那个能力边界也是比较清楚的"
> "他去做这种总结性的任务从多变少，一般是没什么问题"
> "如果让他去找信息的话，他可能会产生幻觉"

**预制Prompt模板**：
> "我经常看计算机的文献的话，我就会去有一个prompt预制好的prompt"
> "让他去一个是说摘要这篇文章主要做了什么，然后还有一个就是这个问题研究的背景和挑战，然后就是现存的一些研究的现状和分类，然后再者就是这个本文的实验框架"

**使用原则**：
> "这一步基本不会产生幻觉，就是它这个信息从多变少基本上没有问题，但是你的信息从少变多，可能就会有问题"

### 场景3：论文写作/润色

**工作流程**：
1. 先给初稿/初步片段
2. 让大模型提建议（逻辑问题、表述问题）
3. 给一段润色后的中文文章
4. 自己按思路再改
5. 确保意思对齐后翻译和语法润色

> "我不会让他直接去写，我会让他相对于说只是给我提一些建议，然后我参考他的建议和我自己的意思去做一些中文上的修改"

### 场景4：需求文档/报告撰写 ⭐⭐⭐⭐⭐

**发散与收敛理论框架**：
> "这两个步骤，我把它归纳为就是发散和收束"
> "在大模型创造性的研究领域一般和心理学挂钩一般就是人的创造力，一般分为这个发散和收数两个阶段"

**工作流程**：
1. **发散阶段**：让模型补充思路，扩展框架
   > "让他先给我去进行一个思维的发散补充"
2. **收敛阶段**：人工筛选，去除幻觉
   > "我就把那些比较天马行空的一些关键点给它删掉"
3. **填充阶段**：确定框架后让模型填充内容
   > "每一块内容去做填充的时候已经确保了这一块是我想要的东西了"

### 场景5：Coding辅助

**任务拆解原则**：
> "我肯定会对我要做的任务先去进行一个分解"
> "现在模型能力还不还没达到，说能完全去搭建一个项目"

**使用边界判断**：
> "这个功能是一个比较经常被实现的功能，而不是一个特别冷门的功能，然后我会用这个弹幕显示，它本来帮我写基本都没什么问题"

**知识储备与使用策略的关系** ⭐⭐⭐⭐⭐：
> "你人的知识储备如果比它高，那他写出来的东西肯定是没有你参与进来的质量高的"
> "你完全丢给他的，如果你的水平都不如他的话，那他质量就是比你高的"

### 不使用/规避的场景

**信息检索（从论文中找特定信息）**：
> "有时候如果让他去找信息的话，他可能会产生幻觉"
> "这个过程就可能引入不少的这种幻觉"

**生活计划**：
> "比较少，因为我发现他做的这些计划什么的都比较空"

## 信任轨迹：技术洞察型

### 信任特征

基于对模型技术原理的深入理解，精准把控使用边界。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 总结（多→少） | ⭐⭐⭐⭐⭐ 很高 | 基本不会产生幻觉 |
| 通用代码 | ⭐⭐⭐⭐ 较高 | 常见功能可信任 |
| 概念解释 | ⭐⭐⭐⭐ 较高 | 可作为专家系统 |
| 框架扩展 | ⭐⭐⭐ 中等 | 需人工收敛筛选 |
| 信息检索（少→多） | ⭐⭐ 低 | 会产生幻觉 |
| 冷门领域代码 | ⭐⭐ 低 | 可能胡扯 |
| 不熟悉领域 | ⭐⭐⭐ 中等 | 只能单向接收 |

### 核心信任逻辑

> "这个信息从多变少基本上没有问题，但是你的信息从少变多，可能就会有问题"
> "你这个幻觉是没法根除的，但是从创造性的视角来看，大模型的创造性又可以来源于它的幻觉"

## 核心专家策略

### 策略1：发散与收敛框架 ⭐⭐⭐⭐⭐

> "发散和收敛两个阶段"
> "发散就意味着你需要...生成一些非常浮夸的东西"
> "收敛的话，你就意味着这个东西它一定要是实用的，一定要尽可能的减少这个幻觉的存在"

**核心洞察**：
> "这两者对于一个模型来说是冲突的，但我觉得对于人机交互的过程，或者对于这么一个工作的流程来说，它是两个阶段，它不冲突"

**人机分工**：
> "既然根除不了，那就把它利用起来。你人目前在鉴别这种幻觉的能力上，它是更强的，那你就让人来做这个收敛的过程"

### 策略2：Prompt模板化 ⭐⭐⭐⭐

> "我就会去有一个prompt预制好的prompt"

系统化管理常用场景的提问方式。

### 策略3：多模型并行策略 ⭐⭐⭐⭐

> "我有一个用一个聚合的网站，它里面可以选择几个不同的模型，针对我的提问同时生成回答"

**发散阶段价值**：
> "在发散阶段我觉得很有用，因为你不同加大模型上传的东西不一样"
> "我用一个大模型，我就只能收获五个不同的答案，但是我用五家不同的大模型...可能最后会有十几20个"

### 策略4：任务拆解策略

> "我肯定会对我要做的任务先去进行一个分解"
> "把它拆成一个模块或者甚至拆成一个函数"

### 策略5：知识储备判断策略

> "你人的知识储备如果比它高，那他写出来的东西肯定是没有你参与进来的质量高的"

- 知识储备高于模型：人主导，模型辅助
- 知识储备低于模型：模型主导，人被动接收

## 深层认知

### 对GPT能力边界的深度理解 ⭐⭐⭐⭐⭐

> "我对他那个能力边界也是比较清楚的"
> "这个信息从多变少基本上没有问题，但是你的信息从少变多，可能就会有问题"

**识别错误来源**：
> "这个东西并不一定是大模型本身所带来的能力缺陷，它在这个从PDF或者这种多模态的文档转化为文本的这个过程中可能就发生了一些识别上的错误"

### 对幻觉的辩证认知

> "你这个幻觉是没法根除的，但是从创造性的视角来看，大模型的创造性又可以来源于它的幻觉"
> "换句话说，人类的创造性也来源于人类的幻觉"

### 对隐私的态度

> "我基本没怎么担心，因为我觉得我不值得他们来窥探我的隐私"
> "你的数据混合在这个数据当中，就跟一滴水注入了海洋里面一样"

**技术视角的理解**：
> "因为我是太了解这个模型的这个工作链路了，那我知道我这个数据最后是通过这个网络传输到哪，最终又会汇聚到哪"

### 对人机协作的认知

> "他就是来帮我提效的"
> "我要靠我的知识，我的积累，把它拆成一个模块"

## 独特发现

### 1. 发散与收敛理论框架 ⭐⭐⭐⭐⭐

这是本研究中最具理论价值的发现之一：
- **发散阶段**：信息从少到多，模型主导，可能产生幻觉但有创造性价值
- **收敛阶段**：信息筛选验证，人主导，去除幻觉确保实用性

> "这两者对于一个模型来说是冲突的，但我觉得对于人机交互的过程，或者对于这么一个工作的流程来说，它是两个阶段，它不冲突"

### 2. "多变少"vs"少变多"的信任边界 ⭐⭐⭐⭐⭐

> "这个信息从多变少基本上没有问题，但是你的信息从少变多，可能就会有问题"

**理论价值**：清晰定义了GPT可信任与不可信任的任务类型边界

### 3. 知识储备作为使用策略的决定因素 ⭐⭐⭐⭐

> "你人的知识储备如果比它高，那他写出来的东西肯定是没有你参与进来的质量高的"

### 4. 幻觉的辩证价值

> "大模型的创造性又可以来源于它的幻觉"

**理论启示**：幻觉不仅是缺陷，也可以是创造性来源

### 5. 技术背景带来的精准边界认知

作为AI研究者，对模型能力边界有极其精准的认知，使用策略高度理性

## 对论文的核心价值

### 1. 发散与收敛作为人机协作框架

> "发散阶段主要是大模型参与的阶段...收敛那一阶段主要是人为参与的阶段"

**理论启示**：人机协作可以按发散-收敛阶段进行分工

### 2. 信息流向作为信任判断标准

> "这个信息从多变少基本上没有问题，但是你的信息从少变多，可能就会有问题"

**理论启示**：可以用信息流向来判断任务的可信任程度

### 3. 专业知识储备与使用策略的关系

用户在不同领域的知识储备决定了人机分工方式

### 关键引用（可用于论文）

1. **发散与收敛框架**：
   > "这两个步骤，我把它归纳为就是发散和收束"
   > "这两者对于一个模型来说是冲突的，但我觉得对于人机交互的过程，或者对于这么一个工作的流程来说，它是两个阶段，它不冲突"

2. **信息流向与幻觉**：
   > "这个信息从多变少基本上没有问题，但是你的信息从少变多，可能就会有问题"
   > "这一步基本不会产生幻觉，就是它这个信息从多变少基本上没有问题"

3. **人机分工**：
   > "既然根除不了，那就把它利用起来。你人目前在鉴别这种幻觉的能力上，它是更强的，那你就让人来做这个收敛的过程"

4. **幻觉的辩证价值**：
   > "你这个幻觉是没法根除的，但是从创造性的视角来看，大模型的创造性又可以来源于它的幻觉"

5. **知识储备决定策略**：
   > "你人的知识储备如果比它高，那他写出来的东西肯定是没有你参与进来的质量高的"

6. **能力边界认知**：
   > "我算是重度的重度使用者，我对他那个能力边界也是比较清楚的"

7. **多模型并行**：
   > "我用一个大模型，我就只能收获五个不同的答案，但是我用五家不同的大模型...可能最后会有十几20个"

8. **隐私态度**：
   > "我基本没怎么担心，因为我觉得我不值得他们来窥探我的隐私"
   > "你的数据混合在这个数据当中，就跟一滴水注入了海洋里面一样"

## 八、分析验证

待核对的关键引用：
- [x] "发散和收束" ✓ (line 6754)
- [x] "信息从多变少基本上没有问题" ✓ (line 6713)
- [x] "一滴水注入了海洋里面一样" ✓ (line 7002)
- [x] "重度使用者，我对他那个能力边界也是比较清楚" ✓ (line 6888)
- [x] "幻觉是没法根除的，但是从创造性的视角来看" ✓ (line 6768)

---
*分析完成时间：2025年1月*

---


<a id="受访人14"></a>

# 受访人14：吴梓锐 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 吴梓锐 |
| 年龄 | 23岁（02年） |
| 学历 | 清华大学工商管理硕士 |
| 职业 | 雀巢实习（5个月） |
| 使用频率 | 两三天一次（较低） |
| 主要工具 | Kimi |

## 使用场景

### 场景1：课程作业/案例分析 ⭐⭐⭐⭐⭐

**核心用途**：
> "我一般就是在课程作业，我会直接把案例以及对应的问题，然后丢给kimi"

**工作流程**：
1. 把案例、课程PPT、问题一起丢给Kimi
2. 使用结构化prompt
3. 直接使用生成的答案

**效果评价**：
> "挺好的，我每次作业都是A"

**完全依赖策略** ⭐⭐⭐⭐⭐：
> "完完全没有任何的是因为这个作业是比较无所谓吗？也算我本身对这门课也没什么兴趣"

**结构化Prompt**：
> "我会要求说他可能要先给到结论，然后再把结论进行分拆，然后拆的时候要根据知识点和案例子进行阐述"

**Kimi vs DeepSeek选择** ⭐⭐⭐⭐：
> "kimi不会胡编乱造一些别的地方的东西，但是deep seek它会他会多多一些案例里没有的东西"
> "多了一些就显得很丑。感觉太联网了"

### 场景2：广告创意/Slogan ⭐⭐⭐⭐

**使用背景**：
> "你很多时候基于一个产品，你要给出一些定位或者slogan的时候，我会直接让他帮我往各个方面去生成一些文案"

**工作流程**：
1. 告诉GPT代言人名字和产品信息
2. GPT生成多个方向
3. 选择好的方向继续迭代
4. 如果多次不满意，自己想

**效果评价**：
> "我觉得其实挺有参考价值的，因为在你没有思路的时候，他会给到你一些方向"

**创意边界认知** ⭐⭐⭐⭐⭐：
> "如果你真的想要一个什么很好的创意，你还是不能靠它。还是得靠自己"
> "他给的很general的，很公开的东西"

### 场景3：面试准备

**使用方式**：
> "比如说我要面试什么什么公司的什么什么岗位，然后对于这个问题，你会怎么回答"

**使用态度**：
> "更多的其实是关于行为上的问题...我就只是需要一个方向"

**不给简历的原因**：
> "我会觉得关于简历上的问题，我肯定比他说的更清楚，我不会用它来帮我搜索答案"
> "他肯定没有我自己那么了解那么极端的经历"

### 场景4：大众点评评论

> "经常不是收藏打卡，然后写评论或者送东西，我可能直接让他来生成对应的评论"

**使用态度**：
> "你肯定就不会考虑它生成怎么样，就直接贴进去了。因为这属于一个无关紧要的东西"

### 场景5：常识性信息搜索

> "有的时候有一些疑问就是搜不到的，我也会试着问他"

**信任逻辑**：
> "这种风险方面，我还是会觉得说只要逻辑合理，我都接受"
> "他说到了可能旅游局就是会查...我会倾向于去相信可能会查，我会去规避这个风险"

### 不使用/规避的场景

**重要创意工作**：
> "对于一些很需要非常创新，或者说需要很让大家出其不意，又在情理之中的这种方案的时候，那肯定是不行的"

**工作中偏执行的任务**：
> "我更多就是比较偏执行的方面，可能是需要我本人来执行他，并他只能在创意上对我有帮助"

**制定计划**：
> "我觉得这计划这个就很不合理，因为这个东西就很动态，没有办法让他来安排你的日程"

## 信任轨迹：任务重要性导向型

### 信任特征

核心原则：只处理不重要的事情。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 不感兴趣的作业 | ⭐⭐⭐⭐⭐ 很高 | 完全依赖，直接用 |
| 广告创意初稿 | ⭐⭐⭐⭐ 较高 | 作为思路参考 |
| 常识搜索 | ⭐⭐⭐⭐ 较高 | 逻辑合理即接受 |
| 面试准备 | ⭐⭐⭐ 中等 | 只获取方向 |
| 重要创意工作 | ⭐ 很低 | 不依赖 |
| 个人经历相关 | ❌ 不使用 | 自己更了解 |

### 核心信任逻辑

> "它更多就是帮我解决一些对我来说不重要的事情和麻烦"
> "看看事情重不重要吧，不重要，他可能会给我提供一些方向，然后我就用了。如果比较重要的话，可能还是偏向自己去上吧"

## 核心专家策略

### 策略1：结构化Prompt策略 ⭐⭐⭐⭐⭐

> "我会要求说他可能要先给到结论，然后再把结论进行分拆"
> "拆的时候要根据知识点和案例子进行阐述"

- 先总后分的输出结构
- 结合知识点分析
- 经过多次尝试总结出的规律

### 策略2：任务重要性分层策略 ⭐⭐⭐⭐⭐

> "它更多就是帮我解决一些对我来说不重要的事情和麻烦"

- 不重要的事情：完全依赖GPT
- 重要创意工作：完全自己做
- 中间任务：参考GPT思路

### 策略3：工具选择策略 ⭐⭐⭐⭐

> "kimi不会胡编乱造一些别的地方的东西，但是deep seek它会多一些案例里没有的东西"

- 案例分析选择Kimi（不联网，不添加额外信息）
- 避免使用DeepSeek（会引入无关内容）

### 策略4：迭代筛选策略

> "他可能会给到五个方向，然后我可能觉得哪个方向比较好，我会让他在这个方向继续多生成一些文案"

- 第一轮获取多个方向
- 筛选满意的方向
- 在选定方向上继续迭代

## 深层认知

### 对GPT创意能力的认知

> "如果你真的想要一个什么很好的创意，你还是不能靠它。还是得靠自己"
> "他给的很general的，很公开的东西"

**核心判断**：GPT只能提供一般性的、公开的创意，无法产生真正的创新

### 对GPT定位的认知

> "它更多就是帮我解决一些对我来说不重要的事情和麻烦"

**核心定位**：处理不重要事务的效率工具

### 对数据隐私的态度

> "不会不行。因为我没有什么很隐私的数据"
> "我本质上认为它不会泄露。或者说我这些东西对于他们聪明的人来说，没有什么商业价值"

### 对工作场景AI应用的认知 ⭐⭐⭐⭐

> "我们尝试了大概几个月都会发现没有什么很出色的案例，大部分都是像刚才说到比较general的文案什么"

**飞书实验经验**：在飞书实习时尝试将大模型接入客户工作流程，发现效果有限

### 对GPT进步的认知

> "也没有很高的期待，因为他之前也是慢慢的从他起步开始用的，然后也会知道其实现在已经比以前好很多了"

## 独特发现

### 1. "只处理不重要的事情"作为核心使用哲学 ⭐⭐⭐⭐⭐

> "它更多就是帮我解决一些对我来说不重要的事情和麻烦"

**理论价值**：用户明确将GPT定位为处理琐事的工具，重要任务完全保留给自己

### 2. Kimi vs DeepSeek的差异化选择 ⭐⭐⭐⭐

> "kimi不会胡编乱造一些别的地方的东西"

**理论价值**：用户根据任务特性选择不同模型，Kimi的"不联网"特性反而成为优势

### 3. 飞书大模型商业化实验的失败经验 ⭐⭐⭐⭐

> "我们尝试了大概几个月都会发现没有什么很出色的案例"

**理论价值**：来自一线商业实践的反馈，验证了GPT在实际工作场景中的局限性

### 4. 效率vs质量的权衡意识

> "这个时间经历不如我自己写了...你还要告诉他背景跟他分手的东西其实就那么一两句话"

对于简单任务，直接自己做可能比使用GPT更高效

## 对论文的核心价值

### 1. 任务重要性作为信任边界

> "它更多就是帮我解决一些对我来说不重要的事情和麻烦"

**理论启示**：用户根据任务对自己的重要程度决定是否使用AI，形成清晰的使用边界

### 2. 创意工作的信任边界

> "如果你真的想要一个什么很好的创意，你还是不能靠它"

**理论启示**：用户认为GPT无法产生真正有价值的创意，创意工作需要人主导

### 3. 工具差异化选择策略

根据任务特性选择不同的AI工具，体现了用户对不同模型能力边界的认知

### 关键引用（可用于论文）

1. **核心使用哲学**：
   > "它更多就是帮我解决一些对我来说不重要的事情和麻烦"

2. **任务重要性分层**：
   > "看看事情重不重要吧，不重要，他可能会给我提供一些方向，然后我就用了。如果比较重要的话，可能还是偏向自己去上吧"

3. **创意能力边界**：
   > "如果你真的想要一个什么很好的创意，你还是不能靠它。还是得靠自己"
   > "他给的很general的，很公开的东西"

4. **工具选择策略**：
   > "kimi不会胡编乱造一些别的地方的东西，但是deep seek它会他会多多一些案例里没有的东西"

5. **结构化Prompt**：
   > "我会要求说他可能要先给到结论，然后再把结论进行分拆，然后拆的时候要根据知识点和案例子进行阐述"

6. **效率节省**：
   > "自己做可能一两个小时去的GPT之类的东西56分钟"

7. **商业实践反馈**：
   > "我们尝试了大概几个月都会发现没有什么很出色的案例，大部分都是像刚才说到比较general的文案什么"

8. **信任逻辑**：
   > "这种风险方面，我还是会觉得说只要逻辑合理，我都接受"

## 八、分析验证

待核对的关键引用：
- [x] "帮我解决一些对我来说不重要的事情和麻烦" ✓ (line 7309)
- [x] "看看事情重不重要吧" ✓ (line 7248)
- [x] "kimi不会胡编乱造" ✓ (line 7284)
- [x] "逻辑合理，我都接受" ✓ (line 7340)
- [x] "自己做可能一两个小时去的GPT之类的东西56分钟" ✓ (line 7329)

---
*分析完成时间：2025年1月*

---


<a id="受访人15"></a>

# 受访人15：张诗棋 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 张诗棋 |
| 年龄 | 23周岁 |
| 学历 | 厦门大学企业管理研二 |
| 职业 | 工业自动化战略分析（实习）/ 美团骑行策略运营（即将入职） |
| 使用频率 | 每天都用 |
| 主要工具 | DeepSeek、Kimi、元宝 |

## 使用场景

### 场景1：行业报告框架搭建 ⭐⭐⭐⭐⭐

**核心用途**：
> "帮我搭框架，就比如说有个行业的报告，然后我大概确定是某个行业某个细分领域之后，我会直接叫他给我一份报告的一个框架"

**工作流程**：
1. 告诉GPT行业和细分领域
2. 让GPT生成报告框架
3. 自己调整逻辑不顺畅的地方
4. 返给GPT再调整一遍

**双向迭代策略** ⭐⭐⭐⭐⭐：
> "我拿过来自己调调完也要返给他，我可能他在能在我的基础上再进行调整，反正我基本上会调两遍，自己调一遍，他调一遍这样"

**领域熟悉度与策略选择**：
> "半行业有些行业的研究范式比较确定的话，我还比较了解的话，我会直接自己先打完一个粗略的框架，然后叫他帮我调整，如果行业比较新，没有接触过，我会叫他直接给一版看一下"

### 场景2：看图说话/描述性文字 ⭐⭐⭐⭐

**使用方式**：
> "我现在有一个流程图，我自己画的一个流程图...我把这个图截一个图，然后发给AI，然后让他给我一段描述性的话"

**效果评价**：
> "基本肯定会写的稍微正式一点，然后在它基础上可以去进行调整，基本都要进行调整，但他一开始写出来的东西内容会比较书面化规范化"

**不需验证**：
> "不需要验证，它只是一个描述性的画，就图是我自己画的，我也知道那个图的内容是什么，我只是懒得自己描述"

### 场景3：信息收集

**使用方式**：
> "基本上的作用在信息收集以及给一些可能没见过的概念去问问GPT。可能需要某方面的信息会叫他直接帮我收集"

**验证策略**：
> "我一般是叫他给我收完信息之后叫我付给我付链接。然后我链接会点进去搂一眼"
> "一般点两三个看一下，如果那个网站是确实跟他给的东西是相关的，我就我其他的我就不点了"

### 场景4：课堂作业生成 ⭐⭐⭐⭐

**使用方式**：
> "有一些paperwork的部分直接把内容要求输给他，让他先出一份框架也好，一般这个时候就直接叫他出内容"

**迭代修改**：
> "就叫他帮我改了，就比如说我这个点，我觉得可能要一些其他内容，我就直接叫他加我，一般不会自己上手修改了"

**AI味处理**：
> "你可以给他就给他要求提示词说不要有AI位或者AI位，不要那么重，直接就这么跟他说，他会稍微写的没有那么口语没有那么正式"

**与工作区分**：
> "课堂作业的话无所谓，反正也对看看场景看用途吧，如果工作当中的话，肯定是要自己确认一遍的肯定要修改一遍的"

### 场景5：简历润色

**使用方式**：
> "我一般直接先上传之后叫他给修改意见，然后他给完修了一件，对他给完修改意见之后，你可以去判断他给的修改意见是不是合理"

**场景化描述**：
> "比如说我现在要应聘某个岗位，然后岗位JD发给他。然后把简历传给他，就这是我的简历，你帮我按照GD要求提一些修改意见"

**润色效果**：
> "你整理了什么一万条或者几千条什么什么钢铁的产量的数据，他就可能会写的花里胡哨一点说什么独立从iphone的数据库筛选，提取什么什么几千条钢材生产数据"

### 不使用/规避的场景

**文献综述**：
> "其实很多文献它都不存在，就后面也不太敢用了"
> "反正上文章库里面去web science或者就网上面自己去找一些相关的综述性的review的文章会比较可靠一点"

**论文写作**：
> "比较少，论文的东西大部分是自己洗，好像没有叫他帮我写基本"

**核心工作内容**：
> "比较可能principal的一些事情，我自己要把控的，或者说比较核心的事情，基本上都是自己把握"

## 信任轨迹：核心-边缘分工型

### 信任特征

核心原则：核心自己做，dirty work交给AI。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 框架搭建 | ⭐⭐⭐⭐ 较高 | 双向迭代调整 |
| 描述性文字 | ⭐⭐⭐⭐ 较高 | 基本采用，微调 |
| 课堂作业 | ⭐⭐⭐⭐⭐ 很高 | 完全依赖 |
| 信息收集 | ⭐⭐⭐ 中等 | 需验证链接 |
| 简历润色 | ⭐⭐⭐⭐ 较高 | 包装话语 |
| 文献综述 | ⭐ 很低 | 不信任，文献不存在 |
| 核心工作 | ❌ 不使用 | 自己把控 |

### 核心信任逻辑

> "现在的G AI我觉得就是在做一个辅助的作用，可能我需要有一些比较dirty work的事情，我会让他去做。比较可能principal的一些事情，我自己要把控的"

## 核心专家策略

### 策略1：双向迭代策略 ⭐⭐⭐⭐⭐

> "我拿过来自己调调完也要返给他...反正我基本上会调两遍，自己调一遍，他调一遍这样"

- GPT生成初稿
- 自己调整逻辑
- 返给GPT再调整
- 看GPT调整是否有道理

### 策略2：核心vs边缘分工策略 ⭐⭐⭐⭐⭐

> "比较可能principal的一些事情，我自己要把控的，或者说比较核心的事情，基本上都是自己把握，不会让他去"

- 核心工作：自己完成
- dirty work：交给AI
- 明确的分工边界

### 策略3：链接验证策略

> "我一般是叫他给我收完信息之后叫我付给我付链接。然后我链接会点进去搂一眼"
> "一般点两三个看一下，如果那个网站是确实跟他给的东西是相关的，我就我其他的我就不点了"

- 要求GPT附带链接
- 抽查2-3个验证
- 验证通过即信任

### 策略4：去AI味策略

> "你可以给他就给他要求提示词说不要有AI位或者AI位，不要那么重"

直接在prompt中要求降低AI痕迹

## 深层认知

### 对GPT定位的认知 ⭐⭐⭐⭐⭐

> "现在的G AI我觉得就是在做一个辅助的作用"
> "可能我需要有一些比较dirty work的事情，我会让他去做"

**核心定位**：辅助工具，处理边缘工作

### 对文献幻觉的认知

> "以前有时候用用过的时候没有去细看的时候是看着好像还挺像回事，那后面其实有去稍微核查一下它的文献的真实性的时候，就发现其实很多文献它都不存在"

**经验教训**：文献综述领域不可信任

### 对GPT算力与性能关系的认知 ⭐⭐⭐⭐⭐

> "早上的GPT是比较聪明的。一到下午就变蠢了"
> "下午和中午可能下午的时候可能大家都在用的时候，高峰期那个时候算力比较紧张的时候，他就会输出到一半，他就停掉了"

**独特发现**：用户观察到AI性能随使用高峰期变化

### 对工作场景AI应用的认知

> "也不存在提高创造力"
> "增加了牛马的劳动效率。也不需要牛马提供什么创造力"

**理性认知**：工作中AI只能提高效率，不能提升创造力

### 对数据隐私的态度

> "我不会没什么隐私。不是什么保密的数据，也不是什么保密的内容"

## 独特发现

### 1. "Principal vs Dirty Work"分工框架 ⭐⭐⭐⭐⭐

> "比较可能principal的一些事情，我自己要把控的，或者说比较核心的事情，基本上都是自己把握"

**理论价值**：用户建立了清晰的核心-边缘分工模型，核心工作自己做，边缘工作交给AI

### 2. AI算力与输出质量的时段关系 ⭐⭐⭐⭐⭐

> "早上的GPT是比较聪明的。一到下午就变蠢了"

**理论价值**：用户观察到AI性能随使用高峰期波动，这是独特的用户体验洞察

### 3. 双向迭代的工作流程 ⭐⭐⭐⭐

> "反正我基本上会调两遍，自己调一遍，他调一遍这样"

**理论价值**：人机协作的具体实践模式——交替迭代

### 4. 文献幻觉的实际验证经历

> "其实很多文献它都不存在"

从实际核查中发现问题，形成对特定领域的不信任

### 5. 工作场景的效率vs创造力认知

> "也不存在提高创造力...增加了牛马的劳动效率"

对工作中AI价值的理性认知

## 对论文的核心价值

### 1. 核心-边缘分工作为人机协作模型

> "比较可能principal的一些事情，我自己要把控的，或者说比较核心的事情，基本上都是自己把握，不会让他去"

**理论启示**：用户根据任务的核心程度进行人机分工，核心任务保留给人类

### 2. 双向迭代作为协作模式

人和AI交替调整，形成迭代式的协作流程

### 3. 时段性能差异的用户感知

用户观察到AI性能随使用高峰期变化，这反映了对AI系统的深入理解

### 关键引用（可用于论文）

1. **核心-边缘分工**：
   > "现在的G AI我觉得就是在做一个辅助的作用，可能我需要有一些比较dirty work的事情，我会让他去做。比较可能principal的一些事情，我自己要把控的"

2. **双向迭代策略**：
   > "反正我基本上会调两遍，自己调一遍，他调一遍这样"
   > "我看他调整的东西有没有道理，如果没有道理的话，我就直接用我原来调完的那个"

3. **文献幻觉经历**：
   > "后面其实有去稍微核查一下它的文献的真实性的时候，就发现其实很多文献它都不存在，就后面也不太敢用了"

4. **算力与性能**：
   > "早上的GPT是比较聪明的。一到下午就变蠢了"
   > "高峰期那个时候算力比较紧张的时候，他就会输出到一半，他就停掉了"

5. **效率vs创造力**：
   > "也不存在提高创造力。增加了牛马的劳动效率。也不需要牛马提供什么创造力"

6. **验证策略**：
   > "一般点两三个看一下，如果那个网站是确实跟他给的东西是相关的，我就我其他的我就不点了"

7. **去AI味**：
   > "你可以给他就给他要求提示词说不要有AI位或者AI位，不要那么重"

8. **工作vs课堂区分**：
   > "课堂作业的话无所谓...如果工作当中的话，肯定是要自己确认一遍的"

## 八、分析验证

待核对的关键引用：
- [x] "增加了牛马的劳动效率。也不需要牛马提供什么创造力" ✓ (line 7575)
- [x] "课堂作业的话无所谓...工作当中的话，肯定是要自己确认" ✓ (line 7454)
- [x] "点两三个看一下" ✓ (line 7462)
- [x] "不要有AI位或者AI位，不要那么重" ✓ (line 7553)
- [x] "模拟面试" ✓ (line 7503)

---
*分析完成时间：2025年1月*

---


<a id="受访人16"></a>

# 受访人16：NTU博士 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 南洋理工大学CCDS学院博士三年级 |
| 研究方向 | 大语言模型安全性、自动驾驶领域应用 |
| 专业背景 | 软件工程 |
| 使用起始 | 2023年8月入学后开始使用 |
| 使用频率 | 重度使用者 |
| 主要工具 | Gemini（主力，开会员）、GPT（辅助验证）、Claude |

## 使用场景

### 场景1：代码编写 ⭐⭐⭐⭐⭐（最核心）

**使用方式演变**：

早期模式：
> "如果说是在我初期使用的时候，我可能还是会比如说写一个大概，然后只有这个我觉得比较复杂的步骤，我会把它空下，然后我说你请帮我补全这部分代码"

现在模式：
> "现在我是说我直接有点略有偷懒的嫌疑...我会先写，OK，下面我想我就要做的任务是比如说我要写一段这个自动驾驶的这个代码，首先要处理图像，然后再把那个什么拼起来再怎么样"

**AI承担比例**：
> "我觉得至少在写代码这个任务上的话，现在人工智能就是AI的话，它大概承担了得有80%的任务，我主要是做一个double check后续检测"

**效率提升**：
> "很可能之前一周的工作，现在大概一两天就可以完成"

### 场景2：学术写作润色 ⭐⭐⭐⭐

**使用方式**：
> "我会先写一个大概，然后让他帮我润色，这样我觉得效率会更高一些"

**不让AI主导逻辑**：
> "我不想让我的逻辑跟着人工智能走"
> "我不会让它就是说完全改变我的逻辑，或者让它自己创造逻辑"

**对AI写作水平的评价**：
> "他的写作水平似乎这以雅思的来说的话得在8.0以上，我感觉就是他的流畅度确实非常好"

### 场景3：知识检索与学习 ⭐⭐⭐

**使用方式**：
> "大概把它当成一个历史检索引擎"
> "比如说一八几年就有一个学者提出了一种...这种我会让他给我讲一下，然后这样就我就不用去搜了嘛"

**验证逻辑**：
> "我看到他说的差不多符合老师讲的和我...就觉得OK，好像这个是对的"

### 场景4：日常写作 ⭐⭐⭐

**邮件撰写**：
> "你帮我一封给这个实验室管理员的邮件，说我键盘坏掉了，然后语气要得体，然后是询问帮助，然后吧一下就给我写完了"

### 场景5：科研Brainstorm ⭐⭐

**使用方式**：
> "我可能有一个初步的idea...我可能会问他一下，就是你觉得可能怎么做？就是让他帮我指指一些路径"

**对效果的认知**：
> "他可能不能直接说出一个完成的新的可行的idea，但是就是你在这种对话过程中他的一些想法...可能会多多少少跟之前的人有一些不一样的地方"
> "我只会把他和他的这种科研上的brainstorm当做一种给自己思维的发散和参考"

## 信任轨迹：渐进信任型

### 信任演变过程 ⭐⭐⭐⭐⭐

**初期不信任**：
> "那个时候的AI也比那个时候的GPT也比较笨，比如说它比不出来2.11和2.9谁比较大这种问题它就比不出来，所以我也不太信任他"

**逐步建立信任**：
> "随着这个人工智能...他们开发这个谷歌、Germany这几个模型进步实在是太快了...我的使用是逐渐加深，就是我感觉对他的信任度也是逐渐加深"

**现在高度信任**：
> "我现在更加信任Jamie的答案"

### 信任边界

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 简单代码 | ⭐⭐⭐⭐⭐ 很高 | 直接使用 |
| 复杂代码 | ⭐⭐⭐⭐ 较高 | 多轮修正 |
| 写作润色 | ⭐⭐⭐⭐ 较高 | 不改变原有逻辑 |
| 知识检索 | ⭐⭐⭐ 中等 | 需验证 |
| 科研创新 | ⭐⭐ 较低 | 仅做参考 |
| 新领域知识 | ⭐⭐ 较低 | 必须double check |

## 核心专家策略

### 策略1：分条分点策略 ⭐⭐⭐⭐⭐

> "一定要呃，就是分条分点地告诉他，AI更喜欢这种分条分点的东西，就是很明确地告诉他，你第一步要干什么，第二步要干什么"
> "指令越明晰，他任完成任务的这个质量就会越高"

**反面教训**：
> "如果你的指令不分条分点，嗯，你是想到哪里写到哪...他写出来的代码有的时候那个逻辑结构就会乱一些"

### 策略2：双模型互补策略（左右脑互补）⭐⭐⭐⭐⭐

> "让两个AI左右脑互补"
> "我问一个问题，然后Jimmy给我一段答案。嗯，如果我对答案里面有不确定的地方...我就会把这条命令移到GPT上去问问它"

**使用场景**：
- 高风险操作验证
- 不确定答案验证
- 新领域知识获取

### 策略3：搜索功能应对幻觉 ⭐⭐⭐⭐

> "对于一个他会乱说的情况，我往往会打开搜索功能，就是让他去检索一下当今互联网上真实存在的东西"
> "参考链接如果能点开的话，一般就是对的"

### 策略4：Double Check策略 ⭐⭐⭐⭐⭐

> "一定要记住人工智能也会犯错，这一点就是当你问他一个事情的时候，要养成，就是要养成double check的习惯"
> "我强烈建议就是人工double check，就是一定要去自己搜索一下，然后看一看大家就是真人说的话"

### 策略5：角色从"补全"到"主导"的转变 ⭐⭐⭐⭐⭐

> "之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑"

## 深层认知

### 对AI本质的理解 ⭐⭐⭐⭐⭐

> "我只觉得它是一种基于历史的，能够提高生产力的非常好用的工具"
> "它只是一种基于历史经验能给我们一些建议的东西"

### 对AI科研能力的认知

> "在科研这块上的话，我觉得他是不太行的，就是它的发散，它并不是真的在发散，它只能帮助人来发散"
> "它能回答出来的大概率...可以作为负例，就是可以排除的那一块"

### 对AI依赖性的警惕 ⭐⭐⭐⭐⭐

> "我感觉我的写作上好像不如之前流畅了"
> "我甚至有一点提笔困难，就是如果就是总依赖他去帮我写东西的话"
> "大模型这东西挺像吸...有点有会让人上瘾"

**应对措施**：
> "我会强迫自己说一定要先用，哪怕是先用自己的母语汉语去把逻辑写一遍，也不要直接让大模型来帮我写"
> "尽量要少用一些，然后就是关于逻辑组织的部分，嗯，要自己来"

### 对幻觉的认知

> "当他出现幻觉的时候，你跟他说这个东西他并不存在，他就会说你是对的，这个东西并不存在，然后开始给你就是用另一个幻觉来演示这个幻觉"
> "他一旦陷入幻觉，我感觉他就难以自拔"

### 对隐私的担忧

> "我会把那个隐私相关的东西给它关掉，就是比如说improve the model for everyone，share your data之类的"

## 独特发现

### 1. 角色演变理论：从补全到主导 ⭐⭐⭐⭐⭐

用户与AI的协作模式经历了根本性转变：
- 早期：用户主导，AI补全
- 现在：AI主导，用户验证

> "之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑"

### 2. 双模型互补（左右脑）策略 ⭐⭐⭐⭐⭐

> "让两个AI左右脑互补"

**理论价值**：用户发展出多模型交叉验证的策略，用不同AI的"思维方式"互补验证

### 3. 幻觉陷入的自我强化现象

> "他一旦陷入幻觉，我感觉他就难以自拔，这个模型它会变得难以自拔"

**理论价值**：观察到AI幻觉的自我强化特性

### 4. AI依赖的上瘾性认知 ⭐⭐⭐⭐⭐

> "大模型这东西挺像吸...有点有会让人上瘾"
> "刚开始可能并没有那么依赖，但是如果用多了确实依赖性会变强"

**理论价值**：将AI依赖比喻为成瘾行为，提出了依赖性递增的观察

### 5. 指令明晰度与输出质量的正相关

> "指令越明晰，他任完成任务的这个质量就会越高"

### 6. 科研中AI的"负例"价值

> "它能回答出来的大概率...可以作为负例，就是可以排除的那一块"

**理论价值**：在科研创新中，AI的价值在于排除已知路径

## 对论文的核心价值

### 1. 信任演变的纵向视角

从不信任到信任的完整过程记录，展示了用户信任如何随AI能力提升而变化

### 2. 人机协作模式的转变

从"人主导-AI辅助"到"AI主导-人验证"的转变，反映了人机协作范式的根本变化

### 3. 依赖性警惕与自我调节

用户意识到依赖风险并主动采取措施，展示了高水平用户的自我调节能力

### 关键引用（可用于论文）

1. **80%任务承担**：
   > "我觉得至少在写代码这个任务上的话，现在人工智能就是AI的话，它大概承担了得有80%的任务，我主要是做一个double check后续检测"

2. **角色转变**：
   > "之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑"

3. **左右脑互补**：
   > "让两个AI左右脑互补"

4. **指令明晰度**：
   > "指令越明晰，他任完成任务的这个质量就会越高"

5. **AI上瘾性**：
   > "大模型这东西挺像吸...有点有会让人上瘾...刚开始可能并没有那么依赖，但是如果用多了确实依赖性会变强"

6. **能力下降**：
   > "我感觉我的写作上好像不如之前流畅了"
   > "我甚至有一点提笔困难"

7. **科研负例价值**：
   > "它能回答出来的大概率...可以作为负例，就是可以排除的那一块"

8. **Double Check建议**：
   > "一定要记住人工智能也会犯错...要养成double check的习惯"

9. **效率提升**：
   > "很可能之前一周的工作，现在大概一两天就可以完成"

## 八、分析验证

待核对的关键引用：
- [x] "大模型这东西挺像吸...有点有会让人上瘾" ✓ (line 609)
- [x] "我甚至有一点提笔困难" ✓ (line 330)
- [x] "让两个AI左右脑互补" ✓ (line 78)
- [x] "分条分点地告诉他" ✓ (line 135)
- [x] "人工double check" ✓ (line 582)

---
*分析完成时间：2025年1月*

---


<a id="受访人17"></a>

# 受访人17：金融经济学研究员 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 研究人员（Researcher） |
| 研究领域 | 金融经济学 |
| 本科背景 | 计算机（C++、算法、ML、DL） |
| 使用起始 | 23年底或24年开始使用 |
| 使用频率 | 每天使用 |
| 主要工具 | ChatGPT（开会员）、豆包 |

## 使用场景

### 场景1：文献总结 ⭐⭐⭐⭐

**使用方式演变**：

早期模式（复杂prompt）：
> "你要包括research question，对吧？然后methodology，conclusion，finding。然后还要加上那些什么你的巴拉巴拉"

现在模式（简单prompt）：
> "Summarize this paper in details. 它出来的结构会比我用prompt的要更好"

**关键发现**：
> "我发现我直接就跟GPT说summarize this paper in details，它出来的结构会比我用prompt的要更好"
> "它好像会被我的prompt束缚住，然后它输出的内容就会...按照你的prompt"

**论文类型对总结效果的影响** ⭐⭐⭐⭐⭐：
> "时政问题很少...它的结论都是呈现出来的，就是x影响y这样"
> "论述的假如说它有很多个影响因素...这时候他就混乱了"
> "理论性很强的文章，他就没办法去很好地总结"

### 场景2：代码编写 ⭐⭐⭐

**使用方式**：
> "我觉得这个Python太简单了...我就让他帮我把它拼起来"
> "我一般会是后者多一点，就是说不会整个都交给他"

**信任与验证**：
> "coding我信任。coding我信任，但我会扫它代码...你知道他在干嘛"

**效率问题**：
> "他有时候给的代码，他的方法一看就是运行得特别慢嘛。嗯，他这个算法的复杂度是那个n方，你能给他整一个这种根号n的复杂度的"

### 场景3：信息检索 ⭐⭐⭐

**使用方式**：
> "把它当成是一个那种谷歌的替代品，就你搜到搜索栏的东西丢给它"

**对准确性的态度**：
> "我会做，就是会check一下，因为我总体对这种LM其实本质不是很信任"
> "它其实就类似于一个，就在搜索这方面，其实就类似于一个普通的搜索引擎"

### 场景4：邮件写作 ⭐⭐

**使用方式**：
> "都有。" （直接生成或修改）

**效果评价**：
> "我觉得是OK的，因为很短"

### 场景5：Brainstorm ⭐⭐

**使用方式**：
> "你抛个问题给他，让他给你几个可能方向的那种解决方案"

**信任程度**：
> "我会更不信任一些，因为你学术上的东西你是有成本的"

### 有趣场景：选水果 ⭐⭐⭐

> "选榴莲，真的这个巨有用"
> "他就会直接告诉你1234他标好，然后他觉得哪个好吃"

## 信任轨迹：理性怀疑型

### 信任的底层逻辑 ⭐⭐⭐⭐⭐

> "我总体对这种LM其实本质不是很信任，因为当你学过它的原理之后，你就会发现它很依赖于它训练的时候的那些材料，所以就是说它这种东西输出的时候，它其实是一个概率模型，他很难说他是百分百是对的"

### 零容错的信任边界 ⭐⭐⭐⭐⭐

> "你10行给我输出10个文章的观点，然后有两个假的，我就会质疑你剩下的8个"
> "我可以接受他不回我...你我你问我十篇文献，我两个是铁错的，你你，你怀不怀疑我剩下8个"

### 信任层级

| 任务类型 | 信任水平 | 原因 |
|----------|----------|------|
| 文献总结（实证） | ⭐⭐⭐⭐ 较高 | 结论明确，可验证 |
| 文献总结（理论） | ⭐⭐ 较低 | 逻辑复杂，容易混乱 |
| 代码编写 | ⭐⭐⭐ 中等 | 可扫一眼验证 |
| 信息检索 | ⭐⭐⭐ 中等 | 当搜索引擎用 |
| 学术Brainstorm | ⭐⭐ 较低 | 成本太高 |
| 生活建议 | ⭐⭐⭐⭐ 较高 | 成本低 |

## 核心专家策略

### 策略1：简化Prompt策略 ⭐⭐⭐⭐⭐

> "Summarize this paper in details. 它出来的结构会比我用prompt的要更好"
> "它好像会被我的prompt束缚住"

**理论价值**：过度约束的prompt反而限制AI输出质量

### 策略2：任务分解自主策略

> "我不会拆...我自己拆"
> "不会整个都交给他"
> "我很少给他描述一个场景，一般就是指定性给他一个任务"

**工作方式**：自己拆解任务，只让AI执行特定步骤

### 策略3：成本导向信任策略 ⭐⭐⭐⭐

> "你学术上的东西你是有成本的...你生活的成本、隐性成本，就显性成本没有那么高"
> "你信了出来GPT给你一个idea，结果那idea但some work，你第二天就被老板骂了...你生活上的，你让他选个榴莲，那个榴莲顶多就是甜跟不甜的区别"

**信任逻辑**：根据错误成本高低决定信任程度

### 策略4：代码扫描验证策略

> "coding我信任，但我会扫它代码，就这东西写代码你扫一眼，所以你的肯定要少啊"

## 深层认知

### 对AI本质的理解 ⭐⭐⭐⭐⭐

> "它其实是一个概率模型，他很难说他是百分百是对的"
> "即使是我们去Google search，Google上搜一些东西，我们也会自己判断"

将AI视为"升级版搜索引擎"，而非智能助手

### 对Prompt的反思 ⭐⭐⭐⭐

> "Prompt的话就众说纷纭。我有人说这个好用，说那个好用，我很难去判"
> "发现对，他好像会被我的prompt束缚住"

观察到过度prompt可能适得其反

### 对AI依赖的态度

> "我觉得是因为我对他始终是怀疑的态度"
> "我有时候写代码真的是全靠他，这不是说我不会写，而是说我懒得写"

怀疑态度与实际依赖并存

### 对文献造假的敏感 ⭐⭐⭐⭐⭐

> "他例如说这篇我要一篇顶刊JFE的，他直接跟你讲这是JFE，你点进去之后是一篇不知名刊物"
> "我搞了两三次，我不想跟他玩"

经历过文献造假后产生强烈不信任

### 对隐私安全的担忧

> "我听他们说就是如果你给AI喂那语料，它其实是会拿你的语料去训练"
> "会不会有一种可能就是我们写了一篇paper，然后别人已经其实他的平台是可以读到你的paper"

## 独特发现

### 1. Prompt束缚效应 ⭐⭐⭐⭐⭐

> "它好像会被我的prompt束缚住，然后它输出的内容就会...按照你的prompt"
> "直接就跟GPT说summarize this paper in details，它出来的结构会比我用prompt的要更好"

**理论价值**：过度详细的prompt可能限制AI的输出质量和结构组织能力

### 2. 论文类型与AI总结能力的关系 ⭐⭐⭐⭐⭐

> "时政问题很少...它的结论都是呈现出来的，就是x影响y这样"
> "理论性很强的文章，他就没办法去很好地总结"

**理论价值**：
- 实证类论文（结论明确）：AI总结效果好
- 理论类论文（逻辑复杂）：AI总结效果差

### 3. 概率模型认知视角 ⭐⭐⭐⭐⭐

> "它其实是一个概率模型，他很难说他是百分百是对的"

**理论价值**：了解AI原理的用户形成更理性的信任预期

### 4. 零容错信任逻辑 ⭐⭐⭐⭐

> "你10行给我输出10个文章的观点，然后有两个假的，我就会质疑你剩下的8个"

**理论价值**：部分用户对AI错误采取零容忍态度，一次错误影响整体信任

### 5. 成本导向的信任分配

根据任务错误成本高低分配信任程度

## 对论文的核心价值

### 1. Prompt设计的"少即是多"原则

简单直接的指令可能比复杂prompt效果更好

### 2. 任务类型与AI适配性

不同类型的学术任务对AI的适配程度不同，实证类优于理论类

### 3. 技术背景对信任的影响

了解AI原理（概率模型）的用户形成更理性但也更怀疑的信任态度

### 关键引用（可用于论文）

1. **概率模型认知**：
   > "我总体对这种LM其实本质不是很信任，因为当你学过它的原理之后，你就会发现它很依赖于它训练的时候的那些材料，所以就是说它这种东西输出的时候，它其实是一个概率模型"

2. **Prompt束缚效应**：
   > "它好像会被我的prompt束缚住，然后它输出的内容就会...按照你的prompt"
   > "Summarize this paper in details. 它出来的结构会比我用prompt的要更好"

3. **零容错信任**：
   > "你10行给我输出10个文章的观点，然后有两个假的，我就会质疑你剩下的8个"
   > "我可以接受他不回我"

4. **成本导向信任**：
   > "你学术上的东西你是有成本的...你生活的成本、隐性成本，就显性成本没有那么高"

5. **论文类型效果差异**：
   > "时政问题很少...它的结论都是呈现出来的，就是x影响y这样"
   > "理论性很强的文章，他就没办法去很好地总结"

6. **搜索引擎定位**：
   > "把它当成是一个那种谷歌的替代品"
   > "它其实就类似于一个，就在搜索这方面，其实就类似于一个普通的搜索引擎"

7. **懒得写vs不会写**：
   > "我有时候写代码真的是全靠他，这不是说我不会写，而是说我懒得写"

## 八、分析验证

待核对的关键引用：
- [x] "它其实是一个概率模型" ✓ (line 920)
- [x] "Summarize this paper in details" ✓ (line 1034)
- [x] "质疑你剩下的8个" ✓ (line 1814)
- [x] "懒得写" ✓ (line 2027)
- [x] "拼在一起我都懒得写，我就让他帮我把它拼起来" ✓ (line 1439)

---
*分析完成时间：2025年1月*

---


<a id="受访人18"></a>

# 受访人18：航空航天博后 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 博士后研究员（已毕业） |
| 研究领域 | 航空航天（Airspace）、无人机路径规划、运行控制 |
| 技术背景 | 强化学习、自然语言处理、多模态算法、Transformer |
| 使用起始 | 约2年（22-23年开始） |
| 使用频率 | 每天使用 |
| 主要工具 | ChatGPT基础版（未开会员）、DeepSeek（国内内容） |

## 使用场景

### 场景1：邮件回复 ⭐⭐⭐⭐

**使用方式**：
> "基本上每天都会用到，比如说最简单的，最简单就是不用动脑的，就是用那个chat GPT去回复邮件"
> "老外的那些...邮件很会很长。前面有一段的客套话，那这种情况下我就需要用产业培训去帮我回复"

**修改比例**：
> "邮件的话我修改的比例可能10%不到"

### 场景2：Brainstorm/知识探索 ⭐⭐⭐⭐

**使用方式**：
> "首先是有个一个general的问题去问他，然后根据他的回答的点...我会针对性地再去提问"
> "先是有一个general的东西，让他可能会给我生成一个框架...接下来可能针对这个具体框架里边的某一个点，我会继续去追问"

**筛选策略** ⭐⭐⭐⭐⭐：
> "我只会先让他提采取，他就是可能会采用他提出的五个点中的三个或者两个，然后再针对这三个或者两个"

### 场景3：Cover Letter撰写 ⭐⭐⭐

**使用方式**：
> "我会告诉他我的把我的那个简历给他，给到他...他会写一些他的cover letter"
> "给他job description和我的CV，然后他会写帮我写cover letter"

**修改比例**：
> "cover letter的话，我修改的东西能应该是能达到30%~40%了"

### 场景4：代码Debug ⭐⭐⭐

**使用方式**：
> "比如说问这块有一些出现什么那个报错的那个error的代码是什么，然后给到他说我在做什么，然后我这边有一个报错，你帮我去debug"

**不会做的事**：
> "我不会把全部代码粘给他，让他帮我写"

### 场景5：API调用（无人机避障）⭐⭐⭐

**使用方式**：
> "用那个3.5...让它去那个生成那种，就是指导无人机避障的那种动作"
> "我会给到他一个视频，然后让他先去学习这个视频里边无人机是怎么避障的"

**效果**：
> "70%多"（尚未达到90%安全标准）

### 场景6：生活常识 ⭐⭐⭐⭐⭐

**使用方式**：
> "一些生活的常识，比如说风油精可不可以用来用水...或者说是比如说我要去哪一个地方去旅游"
> "怎么去办那个EP...怎么开公司注册账户"

**信任度**：
> "这个我只就是在生活方面的这种小问题，我会更信任去他一点"

## 信任轨迹：专业怀疑型

### 信任边界 ⭐⭐⭐⭐⭐

> "对他的信任度我感觉就只有50%不到"
> "从语言的组织的角度讲，它是一个很非常完美的一个工具，但是对于的一些专业性的东西的话，我觉得它得出的答案真的我不太信"

### 信任层级

| 任务类型 | 信任水平 | 原因 |
|----------|----------|------|
| 生活常识 | ⭐⭐⭐⭐ 较高 | 可验证、成本低 |
| 邮件写作 | ⭐⭐⭐⭐ 较高 | 语言组织任务 |
| Cover Letter | ⭐⭐⭐ 中等 | 需要30-40%修改 |
| Debug | ⭐⭐⭐ 中等 | 比较专业 |
| 专业内容 | ⭐⭐ 较低 | 新领域语料不足 |
| 参考文献 | ⭐ 很低 | 经常造假 |

### 不信任的原因 ⭐⭐⭐⭐⭐

> "我知道它的原理，它是文字的一个，就是去拿，去用概率去推算它文字的上下的语义的这种结合的一个准确度"
> "AI幻觉它会...所以我真的是不相信它产生的东西"
> "我做的这个东西会比较有一些新的概念出来嘛...他基本上没有学习到太多的东西"

## 核心专家策略

### 策略1：沿熟悉领域追问策略 ⭐⭐⭐⭐⭐

> "他给出的那些point，我基本上会选我所了解的或者熟悉的东西去选"
> "我一定会选择和我研究相关的这个子的方面去做，是再进一步地了解的。我不会去选一个陌生的完全不懂的"

**核心逻辑**：只在自己有判断能力的领域深入追问

### 策略2：多模型验证策略 ⭐⭐⭐⭐⭐

> "同一个问题我会同时问到产GPT，问豆包，问到deep c"
> "我之所以会验证是因为我对它这生成的这个东西不是很了解，我就会去给到另一个，让他去判断"

**使用场景**：不熟悉领域或重要任务

### 策略3：最优段落组合策略 ⭐⭐⭐⭐⭐

> "我让他写一篇文章，他可能给到有三个points，然后那a模型写a point写得比较好，b模型写b模型写那个第二个point写得比较好"
> "你会结合他，把他所有的优点拿出来再去组合"

**独特之处**：从多个模型输出中挑选最优段落，手动组合

### 策略4：Double Check策略 ⭐⭐⭐⭐⭐

> "哪怕是别人就是说我今天要去我知道的FFP学生...我都会去把他...我都会去double check，我不会相信任何人给我的，给到我的任何一个东西我都会去double check"
> "所以对于chat GPT我更不会信"

### 策略5：提示工程应用策略 ⭐⭐⭐⭐

> "你要尽可能多的给到他的信息"
> "当你信息给你给到很general的时候，它产生的那个东西大部分以我的经验是它是我不想要的"

## 深层认知

### 对AI本质的理解 ⭐⭐⭐⭐⭐

> "我知道它的原理，它是文字的一个，就是去拿，去用概率去推算它文字的上下的语义的这种结合的一个准确度"

基于对AI原理的理解形成理性信任预期

### 对语料库限制的认识 ⭐⭐⭐⭐

> "他要基于大量的利益数据库，我这个方面，比如说低空经济这个low LTI emy的话，他基本上没有学习到太多的东西"
> "它的语料库对不足以支撑它去产生一个让我觉得还那么那么professional的东西"

### 对学术诚信的警惕 ⭐⭐⭐⭐

> "学严重的学术不端"
> "NTO前段时间不是查出来有学生作业用AI被举被查出来"
> "你在审稿阶段，你的论文可能就查重率都通不过"

### 对参考文献造假的经验

> "参考文献这块它真的很瞎，它瞎编的概率很大的"
> "他给到我的参考文献也是没法用的，都是他自己瞎编的"

## 独特发现

### 1. 多模型验证与最优组合策略 ⭐⭐⭐⭐⭐

> "我让他写一篇文章，他可能给到有三个points，然后那a模型写a point写得比较好，b模型写b模型写那个第二个point写得比较好。对，就是你会结合他，把他所有的优点拿出来再去组合"

**理论价值**：用户发展出跨模型最优组合的高级策略

### 2. 熟悉领域边界控制策略 ⭐⭐⭐⭐⭐

> "我一定会选择和我研究相关的这个子的方面去做...我不会去选一个陌生的完全不懂的，因为我担心我驾驭不了他"

**理论价值**：用户有意识地将AI使用限定在自己有判断能力的范围内

### 3. 任务重要性决定验证强度

> "就看你要，你看你给到的这个任务对你来说有多重要"
> "重要的东西的话就无所谓了...搭配"

重要任务采用多模型验证，不重要任务单模型即可

### 4. 语料库不足的领域认知

> "因为我做的这个东西会比较有一些新的概念出来嘛...他基本上没有学习到太多的东西"

用户理解新兴领域AI表现较差的原因

### 5. 提示工程的系统学习与应用

> "我之所以现在就是问到一个问题，然后我去再去细细化地一直追问ChatGPT GPT这种思路，其实就是promote engineer那个东西"

## 对论文的核心价值

### 1. 跨模型协作策略

多模型验证+最优段落组合，展示了高级用户的复杂协作模式

### 2. 熟悉领域边界控制

用户有意识地将AI使用限定在自己有判断能力的范围，体现了主动的信任边界管理

### 3. 任务重要性与验证强度的关系

任务重要性决定验证策略的投入程度

### 关键引用（可用于论文）

1. **信任度量化**：
   > "对他的信任度我感觉就只有50%不到"
   > "他的信任度就真的是只能停留在40%到60%，不会超过60%"

2. **语言vs专业能力区分**：
   > "从语言的组织的角度讲，它是一个很非常完美的一个工具，但是对于的一些专业性的东西的话，我觉得它得出的答案真的我不太信"

3. **熟悉领域边界控制**：
   > "我一定会选择和我研究相关的这个子的方面去做...我不会去选一个陌生的完全不懂的，因为我担心我驾驭不了他"

4. **多模型最优组合**：
   > "a模型写a point写得比较好，b模型写b模型写那个第二个point写得比较好...你会结合他，把他所有的优点拿出来再去组合"

5. **Double Check原则**：
   > "我不会相信任何人给我的，给到我的任何一个东西我都会去double check。所以对于chat GPT我更不会信"

6. **生活vs专业信任差异**：
   > "在生活方面的这种小问题，我会更信任去他一点，但是我的科研的东西真的不信，能不敢信任"

7. **语料库认知**：
   > "它的语料库对不足以支撑它去产生一个让我觉得还那么那么professional的东西"

8. **提示工程应用**：
   > "你要尽可能多的给到他的信息...当你信息给你给到很general的时候，它产生的那个东西大部分以我的经验是它是我不想要的"

## 八、分析验证

待核对的关键引用：
- [x] "从语言的组织的角度讲，它是一个很非常完美的一个工具" ✓ (line 2326)
- [x] "我不会相信任何人给我的，给到我的任何一个东西我都会去double check" ✓ (line 2530)
- [x] "把他所有的优点拿出来再去组合" ✓ (line 2920)
- [x] "语料库对不足以支撑它去产生一个让我觉得还那么那么professional的东西" ✓ (line 2464)
- [x] "参考文献这块它真的很瞎，它瞎编的概率很大的" ✓ (line 2710)

---
*分析完成时间：2025年1月*

---


<a id="受访人19"></a>

# 受访人19：AI区块链项目支持 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 南洋理工大学AI与区块链项目支持 |
| 工作内容 | 企业对接、背景调查、定制问卷、白皮书撰写、区块链/AI研究构思 |
| 使用起始 | 很早（ChatGPT一出现就开始使用） |
| 使用频率 | 每天工作都在用 |
| 主要工具 | ChatGPT、Brock（X出品）、DeepSeek、Claude（均无会员） |

## 使用场景

### 场景1：框架思路梳理 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "一开始下达下来一个任务的时候，可能先会去把一些比较宏观的东西丢给他去分析一下，然后告诉我大概工作的重点在哪里，然后会让他给我一个大致的思路"

**对不熟悉任务的处理**：
> "很大程度之上我想要他提取出来做这个工作的重点该放在哪"

**分阶段输出策略** ⭐⭐⭐⭐⭐：
> "我告诉GPT我在这个阶段的case study我主要输出一个什么东西，就可以比方说before the interview...然后在interview之后我们可能进阶了...然后再按照这个已经输出的内容，看看怎么去进阶地优化"

### 场景2：框架优化与内容填充 ⭐⭐⭐⭐

**早期vs现在的区别**：
> "现在其实会修改了，之前是采纳的"

**对GPT框架的评价** ⭐⭐⭐⭐⭐：
> "它to description，它就是一直在停留在一个信息流的描述。他自己其实具备逻辑性，但是他的骨头很好，但他肉一般"

**优化策略**：
> "我一般的话就是把我自己把他的那个骨头拎出来，然后可能每一块我自己再去优化，然后我再去让他去帮我审核"

### 场景3：分步骤输出策略 ⭐⭐⭐⭐

**使用方式**：
> "我会按照步骤让他输出。12345，第一步你先帮我输出一个什么东西，然后就着第一步，然后再第二步再输出一个什么样的"

**原因**：
> "一下子出来，我觉得他可能每一个part他都不会做的...还不如就一一一个一个部分一个部分地来"

### 场景4：润色与案头工作 ⭐⭐⭐

**使用方式**：
> "回来之后我可能把我自己写的东西再丢给他，让他再润色一下之类的"

**评价**：
> "从头到尾都没有离开他...最终形成的这一个东西可能更大程度上还是他来做"

### 场景5：AI交叉验证 ⭐⭐⭐⭐⭐

**使用方式**：
> "其实很大程度之上我是AI之间互相的验证"

**具体策略**：
> "给他们相同的指令，然后输出，然后比方说他们有相左的地方，我就问他为什么这一部分？...然后另外一个AI可能就说对不起，我没有发现...我就知道这个是有出入的信息了"

**模型数量选择**：
> "也其实也用3个AI、4个AI...但是只不过可能就是比较轻工作没有那么...有重量性"

### 场景6：Dating APP/情感分析 ⭐⭐⭐⭐⭐（独特场景）

**使用方式**：
> "因为我觉得每一个聊天对象他不太一样，我觉得聊天这个东西是需要策略的...所以说有的时候会借由这个AI去分析一下"

**分析内容**：
- 对方聊天状态（认真vs应付）
- 用户画像/Persona
- 对方的调性判断

**核心价值** ⭐⭐⭐⭐⭐：
> "他能帮助我不那么感性，这个是真的"
> "它就是能帮你去站在一个很客观的角度告诉你这个到底是一个什么情况"

**信任逻辑** ⭐⭐⭐⭐⭐：
> "我觉得我是绝对信任AI，但是我不信任...因为现在什么网上很多，什么感情军师你知道吗？...我是不信任任何个人个体的，但是我信任这种"

### 场景7：社会现象讨论/Battle言论 ⭐⭐⭐

**使用方式**：
> "我会跟他去battle一些言论...比方说在就是男性的心理底层。他们到底是不是尊重女性的？比方说问他这种问题"

**目的**：
> "他的描述基本上会涵盖我去问那些单样本的那些结果。他基本上都会涵盖，然后告诉我大概是比方说有存在几种心理背景这样子的"

## 信任轨迹：务实协作型

### 信任边界

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 框架思路 | ⭐⭐⭐⭐ 较高 | 骨头采纳，肉自己填 |
| 内容输出 | ⭐⭐⭐ 中等 | 需要大量修改优化 |
| 信息验证 | ⭐⭐⭐⭐ 较高 | 多AI交叉验证 |
| 情感分析 | ⭐⭐⭐⭐⭐ 绝对信任 | 相信AI的客观性 |
| 人类情感专家 | ❌ 不信任 | AI比人更客观 |

### 核心信任逻辑

> "他跟人最大的不同就是他不会给你直接的意见。他是告诉你他的一些观察最后的意见还是你来拿...他是完全不带主观意识的，他是很客观的"

## 核心专家策略

### 策略1：利益相关者定义策略 ⭐⭐⭐⭐⭐

> "我会告诉他我这个role它本身的这个利益相关者就是我的直接领导是干什么的？他想要什么？然后我是我的对方的人，我是做什么的？然后他们的这个业务是什么？"

**理论价值**：不是让AI扮演角色，而是定义自己所处的关系网络，让AI理解语境

### 策略2：分阶段目标设定策略 ⭐⭐⭐⭐⭐

> "我告诉GPT我要在这个阶段要一个什么样的结果，他告诉我这个结果大概做的程度"
> "涉及到哪些维度这样子的"

**工作模式**：用户划分阶段，让AI告知每阶段应达到的程度

### 策略3："骨头vs肉"分工策略 ⭐⭐⭐⭐⭐

> "他的骨头很好，但他肉一般"

**执行方式**：
- 骨头（框架/逻辑）：采纳AI的
- 肉（内容/叙事）：自己填充

### 策略4：样本学习策略 ⭐⭐⭐⭐

> "可能告诉他一些就是我认为可以借鉴的方法，一些methodology，然后或者说是一些或者丢...一些之前的一些case study，就给他扔进去，让他学习一下"

**核心逻辑**：先给AI学习样本，再让其输出

### 策略5：AI交叉验证策略 ⭐⭐⭐⭐⭐

> "AI之间互相的验证"
> "给他们相同的指令，然后输出，然后比方说他们有相左的地方，我就问他为什么"

**验证逻辑**：不同AI给出不同答案时，追问差异原因

## 深层认知

### 对AI角色的定位 ⭐⭐⭐⭐⭐

> "我觉得他更大程度上像一个tutor，像一个带教的人，就是有的时候我们可能在一个新的一个一个学科里面，我们像变成了一个学徒，然后有一个老师告诉你，但是那个老师他也不一定完全是对的"

> "我觉得他like assistant，像一个助理之类的"

### 对AI客观性的认知 ⭐⭐⭐⭐⭐

> "他跟人不同的在于他是完全不带主观意识的，他是很客观的，你如果跟一个朋友去说，朋友会按照他的理解去跟你说这个人是怎么样的，但是AI不会"

### 对AI直接输出的认知

> "完全依赖他的话，或者说是不给他下达任何指令输出的话，嗯，他的东西其实比较平"
> "总体来说他对于这个捋清思路，然后或者说是把你整个的这个各个脉络上能够做到75%"

### 对过度依赖的思考

> "我不太好确定这个度到底在哪，怎么叫做过渡，但是我觉得现在的基本上所有的场景好像都在用AI，我觉得这可能就是过渡了吧"

### 对AI发展的期待

> "希望他把他的思考过程给出也一起输出来"
> "一个是思考过程，另外一个就是他是如何这样思考？他为什么要这样思考？"
> "一个是思考的流程，另外一个它引用的数据的确切来源"

## 独特发现

### 1. "骨头vs肉"的形象比喻 ⭐⭐⭐⭐⭐

> "他的骨头很好，但他肉一般就是这样"

**理论价值**：用户对AI能力边界的精准认知——逻辑框架能力强，内容填充能力弱

### 2. 利益相关者语境设定 ⭐⭐⭐⭐⭐

> "我会告诉他我这个role它本身的这个利益相关者就是我的直接领导是干什么的？他想要什么？"

**理论价值**：不同于简单的角色扮演，而是通过定义关系网络帮助AI理解语境

### 3. AI vs 人的信任反转 ⭐⭐⭐⭐⭐

> "我觉得我是绝对信任AI，但是我不信任...什么感情军师...我是不信任任何个人个体的，但是我信任这种"

**理论价值**：在情感分析领域，用户更信任AI的客观性而非人类专家

### 4. 多AI交叉验证的具体操作

> "他们有相左的地方，我就问他为什么这一部分？...另外一个AI可能就说对不起，我没有发现"

**理论价值**：用户发展出系统性的多模型验证方法

### 5. 分阶段目标设定策略

> "我告诉GPT我要在这个阶段要一个什么样的结果，他告诉我这个结果大概做的程度"

**理论价值**：用户主导阶段划分，AI提供每阶段的执行建议

## 对论文的核心价值

### 1. "骨头vs肉"的能力边界认知

用户对AI能力的精准把握——框架逻辑能力强，内容生成能力弱

### 2. 利益相关者语境设定

提供了一种新的prompt策略——通过定义关系网络而非角色扮演来帮助AI理解任务

### 3. AI信任的领域特异性

同一用户在不同领域对AI的信任程度可以完全相反（工作内容中等信任，情感分析绝对信任）

### 关键引用（可用于论文）

1. **骨头vs肉**：
   > "他的骨头很好，但他肉一般就是这样"
   > "它to description，它就是一直在停留在一个信息流的描述"

2. **利益相关者策略**：
   > "我会告诉他我这个role它本身的这个利益相关者就是我的直接领导是干什么的？他想要什么？然后我是我的对方的人，我是做什么的？然后他们的这个业务是什么？"

3. **AI绝对信任**：
   > "我觉得我是绝对信任AI，但是我不信任...什么感情军师...我是不信任任何个人个体的，但是我信任这种"

4. **AI客观性**：
   > "他是完全不带主观意识的，他是很客观的，你如果跟一个朋友去说，朋友会按照他的理解去跟你说这个人是怎么样的，但是AI不会"

5. **tutor定位**：
   > "他更大程度上像一个tutor，像一个带教的人...但是那个老师他也不一定完全是对的"

6. **分阶段策略**：
   > "我告诉GPT我要在这个阶段要一个什么样的结果，他告诉我这个结果大概做的程度"

7. **AI交叉验证**：
   > "很大程度之上我是AI之间互相的验证"
   > "给他们相同的指令，然后输出，然后比方说他们有相左的地方，我就问他为什么"

8. **75%能力评估**：
   > "总体来说他对于这个捋清思路，然后或者说是把你整个的这个各个脉络上能够做到75%"

9. **帮助理性思考**：
   > "他能帮助我不那么感性，这个是真的"
   > "它就是能帮你去站在一个很客观的角度告诉你这个到底是一个什么情况"

## 八、分析验证

待核对的关键引用：
- [x] "他的骨头很好，但他肉一般就是这样" ✓ (line 3560)
- [x] "其实很大程度之上我是AI之间互相的验证" ✓ (line 3662)
- [x] "他能帮助我不那么感性，这个是真的" ✓ (line 3860)
- [x] "我会告诉他我这个role它本身的这个利益相关者" ✓ (line 3644)
- [x] "总体来说他对于这个捋清思路...能够做到75%" ✓ (line 3626)

---
*分析完成时间：2025年1月*

---


<a id="受访人20"></a>

# 受访人20：NIE教育心理学研究员 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | NIE教育学院Research Fellow |
| 研究领域 | 发展心理学（儿童和青少年心理健康）、AI情感支持研究 |
| 专业背景 | 教育心理学 |
| 使用起始 | 2023年5-6月（ChatGPT发布后3-4个月） |
| 使用频率 | 每天使用 |
| 主要工具 | ChatGPT Plus（学校提供）|
| 其他工具使用 | 95%都是ChatGPT |

## 使用场景

### 场景1：邮件润色 ⭐⭐⭐⭐

**使用方式**：
> "我会说我需要回的点是哪些？那你帮我用一种更礼貌的、更职场的，或者说更像native speaker的一种方式，帮我把这篇邮件写出来"

**目标**：
> "我会希望我的语言更native一点，然后更重要是我需要礼貌一点，不要太offensive，然后展示一些warmth之类的"

### 场景2：论文写作润色 ⭐⭐⭐⭐⭐（核心场景）

**三种子类型**：

**类型1：破碎想法组织** ⭐⭐⭐⭐⭐
> "我大概知道我这一段需要写什么，但是可能我的大部分的思想资源我会用于思考说我写什么，所以我的语句可能说是非常的错乱颠倒，只是piece by piece的这种部分"
> "他可以帮我理顺这个东西"

**类型2：Leading/Conclusion撰写** ⭐⭐⭐⭐
> "比如说一开始的那种leading sentence，或者说leading paragraph，或者说你最后要有一个conclusion的paragraph"
> "我中间已经写了这个部分，你帮我想一想，写一个比较合适的开头或者结尾之类的"

**类型3：文献精简组合** ⭐⭐⭐⭐
> "我已经把这5个文章我已经summarize出来了。那我就会让ChatGPT先把这5篇...帮我写一段话出来"
> "他只是承担了组织一下的部分，他承担的不是结尾的工作，而是初期或者中途的工作"

**核心工作定位** ⭐⭐⭐⭐⭐：
> "如果这段话从最开始的撰写到我最后他用在我的终稿中...它只是发生在前1/3甚至说1/4的阶段"

### 场景3：回复Reviewer的Brainstorm ⭐⭐⭐

**使用方式**：
> "Reviewer的意见回来之后，它有些问题不太好处理，然后我可能会去说，诶，你觉得有什么想法？"

**效果评价**：
> "50%"
> "它只能回答一些相对来说比较基础的部分，就是再深入的，因为它本质上是一个大语言模型嘛"

**获取理论线索**：
> "他可能会说给了我一个线索，比如说他给我说有一些potential的theoretical foundation，一些理论之类的，那我可以去再去看这些理论能不能够解答这个问题"

### 场景4：数据分析语法检查 ⭐

**使用频率**：
> "非常非常少"
> "只会在3/300～5的情况下会让他帮我check一下"

**原因**：
> "一方面我不太信任他...另外一方面大部分情况我都可以自己处理"

### 不使用/规避的场景

**文献Summarize** ⭐⭐⭐⭐⭐：
> "我就是不信任"
> "我觉得他summarize的不准确、不正确，甚至有错误"
> "我要对我的东西负责，我必须要看到第一手资料"

**情感支持**：
> "我知道很多人在做这样的事情，但是我只会把它使用在我的工作场域"
> "我其实非常不理解这件事情，但我又知道很多人在做"

## 信任轨迹：始终谨慎型

### 信任边界 ⭐⭐⭐⭐⭐

> "我最开始都对他持一个非常谨慎的态度"
> "包括到现在我对他持有的都是一个非常谨慎的态度"
> "我不会相信他给我的任何资料"

### 对AI本质的认知 ⭐⭐⭐⭐⭐

> "我归根到底我认为它是一个大语言模型，我不信任它"
> "它是一个非常好的语言润色者和语言思考者...他对语言的把玩是非常可以的"
> "我认为他的任何的回答都是对于语言的重新组织"

### 信任层级

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 语言润色 | ⭐⭐⭐⭐ 较高 | 核心用途 |
| 想法组织 | ⭐⭐⭐ 中等 | 初期工作 |
| 理论检索 | ⭐⭐ 较低 | 仅作线索 |
| 文献Summarize | ⭐ 很低 | 完全不用 |
| 数据分析 | ⭐ 很低 | 极少使用 |
| 情感支持 | ❌ 不使用 | 研究对象，不自用 |

## 核心专家策略

### 策略1：一任务一对话策略 ⭐⭐⭐⭐⭐

> "我一个小任务只开一个对话"
> "比如说我润色这一段话，已经润色完了，我就会离开这个对话，然后开一个新的对话去为了我的下一段话"

**原因**：
> "我不想让他记忆这么多，然后勾连那么多"
> "你可能会干扰他，让他做出一些不必要的修改"

### 策略2：教AI而非被AI教策略 ⭐⭐⭐⭐⭐

> "我时常觉得我跟GPT的交流特别像，来，我来教你怎么做事"
> "你要把它当成个小学生在用"
> "使用AI，你应该是你去教AI怎么去做事，而不是用AI来教你"

### 策略3：Context情境设定策略 ⭐⭐⭐⭐

> "你要告诉他这个情境是什么样的，就是我会发现你告诉他情境之后，他是非他是比较能够去结合这个情境去处理"
> "比如说我在带学生，所以我就会说你要把帮我把这个，我是在回一个学生的邮件，然后你尽量帮我把语言措辞温暖一些、礼貌一些"

### 策略4：新窗口重启策略 ⭐⭐⭐⭐

> "它蛮蠢的，这种蠢的时候你就需要给它新开一个窗口，不然它就会将错就错，一错再错"
> "重新开一个，然后重新把这些summarize，然后把这些context重新跟他讲一遍，然后让他从头再来一遍，他就会做得还不错"

### 策略5：10%微调润色策略 ⭐⭐⭐⭐

> "我心里预期的就是他只是做10%的修改就行了，就最后一部分了"
> "只是做20%或者10%的修改，就大概看一下的那种，不需要那么自作主张"

## 深层认知

### 对AI定位的核心认知 ⭐⭐⭐⭐⭐

> "我主要还是把它作为一种语言润色工具，我相对来说较少地使用它作为一种回答的工具，或者说是百科全书式的工具"

### 对一手资料的坚持 ⭐⭐⭐⭐⭐

> "你作为一个研究者，你要对这个领域有这个domain有一个非常general的认知"
> "我觉得检索本身它其实对于我对这个domain的了解是很重要的这个过程"
> "这个部分是没有办法让ChatGPT去替代的，如果他替代完了之后，那我怎么写论文呢？"

### 对GPT能力边界的认知 ⭐⭐⭐⭐⭐

> "我不认为他有足够的批判性思维和这些东西，他只是帮我进行这个语言的加工"
> "它没有办法去完成非常深入的批判性的思考"
> "他只是给我一个非常初期的基础的一个草稿"

### 对个人账号记忆的认知 ⭐⭐⭐⭐⭐

> "我开一个新的totally新的之后我发现不行，就是太擅作主张了"
> "我的已经用习惯了，可能是因为我不断地会有一些提示文档之类，他会比较是我想要的那种修改程度"
> "他知道我的偏好，记得非常好，我非常满意"

### 对隐私安全的态度

> "我觉得没有非常说这个idea，一定要保密，一定不能让人知道...我们没有非常说这个东西一定要怎么样就怎么样了"
> "我们更重要的是讲故事，把这个故事讲得非常有趣"

## 独特发现

### 1. "教AI"而非"被AI教"的角色定位 ⭐⭐⭐⭐⭐

> "我时常觉得我跟GPT的交流特别像，来，我来教你怎么做事"

**与其他受访者对比**：其他受访者多把AI当tutor/导师，该受访者反转这一关系

### 2. 一任务一对话的碎片化使用模式 ⭐⭐⭐⭐⭐

> "我一个小任务只开一个对话"
> "拆成无数个对话"

**理论价值**：通过碎片化对话防止AI产生不必要的关联和"自作主张"

### 3. 个人账号的"调教效应" ⭐⭐⭐⭐⭐

> "我已经totally习惯了。然后我再用一个新的账号，我就觉得好难受"
> "新的之后我发现不行，就是太擅作主张了"

**理论价值**：长期使用同一账号形成个性化语言偏好匹配

### 4. 研究AI情感支持但自己不使用 ⭐⭐⭐⭐

> "我其实非常不理解这件事情，但我又知道很多人在做，然后我就觉得这个东西非常的有意思，非常的有趣，我想知道这些人到底是怎么想的"

**理论价值**：研究者保持客观距离，研究现象而不参与

### 5. 应付式任务与核心任务的区分 ⭐⭐⭐⭐

> "我不是很喜欢这个topic，但是我必须要完成...先让它写写看喽"
> "用来给自己安身立命的东西，是我自己要完成的"

**理论价值**：任务重要性决定AI介入程度

## 对论文的核心价值

### 1. 始终谨慎型信任的典型案例

从使用初期到现在保持一贯的谨慎态度，与其他"逐渐信任"的用户形成对比

### 2. "教AI"的角色反转

与其他把AI当tutor的用户形成鲜明对比，提供了另一种人机协作范式

### 3. 碎片化对话的使用策略

通过一任务一对话防止AI"自作主张"，展示了高控制型用户的策略

### 关键引用（可用于论文）

1. **始终谨慎**：
   > "我最开始都对他持一个非常谨慎的态度...包括到现在我对他持有的都是一个非常谨慎的态度"
   > "我不会相信他给我的任何资料"

2. **语言工具定位**：
   > "我归根到底我认为它是一个大语言模型，我不信任它"
   > "它是一个非常好的语言润色者和语言思考者...他对语言的把玩是非常可以的"

3. **教AI策略**：
   > "我时常觉得我跟GPT的交流特别像，来，我来教你怎么做事"
   > "使用AI，你应该是你去教AI怎么去做事，而不是用AI来教你"

4. **一手资料坚持**：
   > "我要对我的东西负责，我必须要看到第一手资料"
   > "这个部分是没有办法让ChatGPT去替代的"

5. **初期工作定位**：
   > "它只是发生在前1/3甚至说1/4的阶段"
   > "他只是给我一个非常初期的基础的一个草稿"

6. **一任务一对话**：
   > "我一个小任务只开一个对话"
   > "我不想让他记忆这么多，然后勾连那么多"

7. **个人账号记忆**：
   > "他知道我的偏好，记得非常好，我非常满意"
   > "我再用一个新的账号，我就觉得好难受，就它润色的方向跟我想要的方向不一样"

8. **对本科生建议**：
   > "你要把它当成个小学生在用"
   > "你自己永远要知道你想要写什么"

9. **批判性思维缺失**：
   > "我不认为他有足够的批判性思维和这些东西，他只是帮我进行这个语言的加工"

10. **应付vs核心任务**：
    > "我不是很喜欢这个topic，但是我必须要完成...先让它写写看喽"
    > "用来给自己安身立命的东西，是我自己要完成的"

## 八、分析验证

待核对的关键引用：
- [x] "我最开始都对他持一个非常谨慎的态度" ✓ (line 4727)
- [x] "我时常觉得我跟GPT的交流特别像，来，我来教你怎么做事" ✓ (line 4817)
- [x] "我一个小任务只开一个对话" ✓ (line 5072)
- [x] "我要对我的东西负责，我必须要看到第一手资料" ✓ (line 4355)
- [x] "他只是给我一个非常初期的基础的一个草稿" ✓ (line 4847)

---
*分析完成时间：2025年1月*

---


<a id="受访人21"></a>

# 受访人21：NTU传播学院研究生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | NTU传播学院研究生 |
| 研究领域 | 人机交互（传播学/社会心理学视角）、Conversational Chatbot |
| 使用起始 | 2023年初（ChatGPT刚发布） |
| 使用频率 | 每天使用 |
| 主要工具 | ChatGPT（最稳定）、Gemini Pro（无长度限制）、国内APP（元宝、DeepSeek） |
| 曾用工具 | Claude（因封号放弃） |
| 会员情况 | Gemini Pro（免费方式获得） |

## 使用场景

### 场景1：文献阅读与讨论 ⭐⭐⭐⭐⭐（核心场景）

**核心定位**：
> "它可能更像是我的一个加强版的这个搜索引擎，或者说加强版那个翻译器"

**使用方式**：
> "我读到这一部分我会有问题，然后我把这个其实跟他就是discuss相当于是这种读法"

**独特讨论策略** ⭐⭐⭐⭐⭐：
> "这篇文章写1971年的这个作者是一个非常有名的一个作者，然后他领域是什么？他同时期也没有人写文章反驳他，或者说他是属于哪个流派的？然后他为什么这样写？有没有就驳斥他流派的观点？...following他这个tradition会不会有其他的人来补充他的观点？"

**根据文献类型调整问法**：
> "你要根据每种文章的一个不同的类型...不会说是每一篇文献都是同一个问题"

### 场景2：研究设计的Idea探索 ⭐⭐⭐⭐

**使用方式**：
> "我想研究这个human和AI的这个团队合作行为...我并不知道这个领域是哪些人在关注，有哪些学者在关注，然后这个领域比如说更细化的是在什么场景下"

**工具使用**：
> "consensus...它是based on那个，它等于是一个插件插在那个GPT里面...它有一个链接到它consensus这个平台"

**验证态度**：
> "我还是要去check的...但我说这意思其实不是文献搜索，就是大概的，比如说这个领域我不太知道，我不知道怎么去touch on"

### 场景3：写作润色 ⭐⭐⭐⭐

**使用方式**：
> "我只会用它来润色，就是比如说我的英文不太好，或者说我写的是一个中英夹杂的东西，那我可能会让它就是串一下我的思"

**不直接生成**：
> "我不会说让他帮我写，因为他写的东西我觉得还是不能用"

**修改范围**：
> "给他这一步的时候，已经是比较成熟的一个东西，就是我只能会让他帮我improve clarity或者说是editing之类的"

### 场景4：学习算命/命理 ⭐⭐⭐⭐（独特场景）

**使用方式**：
> "我其实是用它学，你知道吗？就是这个时辰关系，然后在这个古文献当中会是怎么样？"
> "用这个AI其实就是更快地让我知道我怎么把其他拼图捡起来"

**非算命用途**：
> "不是说让他tell me fortune，不，并不是因为DeepSeek并不是一个神婆"

### 场景5：企业实习场景 ⭐⭐⭐

**使用内容**：
> "用他做那个BI表格的insight...能够获得一个大概的Infographic和今年的这个year to day的销量"
> "招聘的那个...写JD就几乎是你Intern要干的所有的杂活"

**企业定制GPT优势**：
> "基于的那个行业的数据库给我返回这条结果比general那个GPT的结果就是要准确"

## 信任轨迹：耐心对话型

### 核心信任理念 ⭐⭐⭐⭐⭐

**Conversation Partner理念**：
> "他是一个教法律的...他就说你不能总是给他一个预设，说他是人工智能，所以他什么都能回答。但是你可以把他想象成一个就是对话者conversational partner"

**耐心原则**：
> "跟大家对话你就是要有耐心...你问100次，总是有一次是你会发现一些什么。对，但前提是你要问"

### GPT的局限认知 ⭐⭐⭐⭐⭐

**讨好型人格**：
> "他不太擅长给出反对意见"
> "他会开始是吐槽，感觉像是在吐槽，但是最后还是会。你感觉这东西也不太像吐槽，就说了跟没说一样"

**均值回答**：
> "他给的肯定是一个均值，他肯定给的是一个均值"

### 信任层级

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 信息整理 | ⭐⭐⭐⭐ 较高 | 增强版搜索引擎 |
| 文献讨论 | ⭐⭐⭐⭐ 较高 | Conversation Partner |
| 润色 | ⭐⭐⭐ 中等 | 只做clarity提升 |
| 写作生成 | ⭐⭐ 较低 | 不能用 |
| 批判性意见 | ⭐ 很低 | 讨好型，给不出 |

## 核心专家策略

### 策略1：多AI渠道对比策略 ⭐⭐⭐⭐

> "比如说这个领域我不太知道，我不知道怎么去touch on...但是我也会去用很传统的搜索方法...Web of science"
> "有的时候Web size就...能产生不一样的这个想法，或者说...通过另外一种搜索的一个逻辑，它给你呈现出来另外一个品种"

**中英文分工**：
> "如果是有中文的这个发表，或者说中文的这个写作需求的话...可能还是会用国内的这个Kimi什么的多一些，他搜知网的文献会更准一些"

### 策略2：Source Check策略 ⭐⭐⭐⭐⭐

> "在让AI给出一轮回答之后再问，再进行一个追问，就是你要检查一下你自己的回答是不是都基于真实的credible source，然后它会进行再一次思考"

**效果**：
> "会比平时就你直接input得到的答案会好一点"

### 策略3：分阶段对话策略 ⭐⭐⭐⭐

> "你不要一次性把你所有的需求都提给他，你要就是分阶段的分，然后去不断地和他进行对话"

### 策略4：角色指定策略 ⭐⭐⭐⭐

> "你要尽可能地让他知道你现在是什么角色，就指定给他，他是给Persona。所以说他能快速地定位到这部分的信息"

### 策略5：文献类型适配问法 ⭐⭐⭐⭐⭐

理论类文献：
> "这个作者...他领域是什么？他同时期也没有人写文章反驳他...following他这个tradition会不会有其他的人来补充他的观点？"

实证类文献：
> "针对这个specific variable，那其他人是怎么测量的？"

## 深层认知

### 对AI角色的定位 ⭐⭐⭐⭐⭐

> "它更像是我的一个加强版的这个搜索引擎"
> "对于我来说它更像是一个partner...to actually discussion leader today"

### 对预期管理的认知 ⭐⭐⭐⭐⭐

> "他可能返回你给你答案80%都是不能用的...因为比较general，或者说是比较就是废话吧"
> "你没有办法给出一个完全精确的prompt，然后你就能想到...你能得到你想要你的答案...你要接受这个事实"

### 对版权/隐私的认知 ⭐⭐⭐⭐

> "我feed给他了这个，其实像GPT这个后面这个公司，他虽然是我可以declare说我不把我的材料分给其他的模用于改善模型，但是我其实还是把我这个一部分作品的权利让步给了他"

### 对学术不端边界的认知

> "我用这个范围我远远不到那个，因为我首先这东西是我完全是我自己写的，然后我也没有让它进行就润色以外的工作"

## 独特发现

### 1. 文献讨论的深度问法 ⭐⭐⭐⭐⭐

> "这个作者是一个非常有名的一个作者，然后他领域是什么？他同时期也没有人写文章反驳他，或者说他是属于哪个流派的？...following他这个tradition会不会有其他的人来补充他的观点？"

**理论价值**：不仅问内容，还问学术脉络、流派、反驳观点，展现了深度使用方式

### 2. "Conversation Partner"理念 ⭐⭐⭐⭐⭐

> "你可以把他想象成一个就是对话者conversational partner...他可能给你一些答案，给你一些想法，你觉得没有用，你觉得有用你就添有用的部分"

**理论价值**：将AI视为平等对话者而非权威，调整信任预期

### 3. "讨好型人格"的局限认知 ⭐⭐⭐⭐

> "他不太擅长给出反对意见"
> "即使他在roast你，但是他还是在please你"

**理论价值**：识别出AI在批判性反馈方面的根本局限

### 4. 灵光乍现的捕捉功能 ⭐⭐⭐⭐

> "你脑子里有一个idea...你就想知道这个问题的答案是什么？然后你要搁平时...那你这idea就会没有了。但是对于我来说就是你要问一下AI...你问了这个动作就很重要"

**理论价值**：AI作为即时知识验证和想法记录工具

### 5. 企业定制GPT的优势认知 ⭐⭐⭐⭐

> "基于的那个行业的数据库给我返回这条结果比general那个GPT的结果就是要准确"

**理论价值**：理解行业定制训练对AI性能的提升

## 对论文的核心价值

### 1. Conversation Partner的协作范式

将AI视为平等对话伙伴，而非权威助手或工具，形成一种新的人机协作理念

### 2. 文献讨论的深度使用模式

不仅问内容，还问学术脉络、流派、反驳观点，展示了高级用户的文献阅读辅助策略

### 3. 耐心与预期管理

接受AI 80%的回答不可用的事实，通过持续对话获取价值

### 关键引用（可用于论文）

1. **增强版搜索引擎**：
   > "它可能更像是我的一个加强版的这个搜索引擎，或者说加强版那个翻译器"

2. **Conversation Partner**：
   > "你可以把他想象成一个就是对话者conversational partner...他可能给你一些答案，给你一些想法，你觉得没有用，你觉得有用你就添有用的部分"

3. **讨好型人格**：
   > "他不太擅长给出反对意见"
   > "即使他在roast你，但是他还是在please你"

4. **耐心原则**：
   > "跟大家对话你就是要有耐心...你问100次，总是有一次是你会发现一些什么"

5. **文献深度问法**：
   > "这个作者...他领域是什么？他同时期也没有人写文章反驳他...following他这个tradition会不会有其他的人来补充他的观点？"

6. **80%不可用**：
   > "他可能返回你给你答案80%都是不能用的...因为比较general，或者说是比较就是废话吧"

7. **均值回答**：
   > "他给的肯定是一个均值，他肯定给的是一个均值"

8. **Source Check**：
   > "你要检查一下你自己的回答是不是都基于真实的credible source，然后它会进行再一次思考"

9. **不直接生成**：
   > "我不会说让他帮我写，因为他写的东西我觉得还是不能用"

10. **灵感捕捉**：
    > "你脑子里有一个idea...你问了这个动作就很重要"

## 八、分析验证

待核对的关键引用：
- [x] "它可能更像是我的一个加强版的这个搜索引擎" ✓ (line 5473)
- [x] "conversational partner" ✓ (line 5869)
- [x] "他不太擅长给出反对意见" ✓ (line 5623)
- [x] "他给的肯定是一个均值" ✓ (line 6085)
- [x] "你问100次，总是有一次是你会发现一些什么" ✓ (line 5863)

---
*分析完成时间：2025年1月*

---


<a id="受访人22"></a>

# 受访人22分析报告：强化学习博士生

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 博士三年级学生 |
| 专业领域 | 强化学习/深度学习，水下无人潜航器自主调度 |
| 主要工具 | GPT（主力）、Gemini Pro |
| 偏好模型 | GPT o4-mini（速度快、满足基本需求） |
| 使用频率 | 高频使用 |
| 技术背景 | 深厚（CS背景，熟悉AI底层原理） |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：边缘模块代码生成**
- 将已定义好的数学公式转化为代码
- 强调"封装"和"可切换性"
- 例如：水下潜艇动力学模块的代码化
- 特点：任务边界清晰，输入输出明确

**场景二：数学概念学习**
- 快速理解与项目相关的数学概念
- 目的是"拿来就用"而非深入推导
- 自述："我毕竟不是数学系的同学...我更多的只是希望把这个公式拿来用"

**场景三：写作结构生成**
- 已有内容框架，请AI帮助整理逻辑顺序
- 强调"说服观众"的逻辑排列
- 自述："每一个大纲内部我要讲哪些东西我大概是有数的，但是这些东西它之间的逻辑顺序如何把它排列起来"

### 2.2 明确不使用的场景

- 完整项目代码生成
- 跨模块的复杂代码任务
- 文献综述和长文本处理
- 创意发散和idea生成

## 三、信任轨迹：技术洞察型

### 3.1 信任特征

**模块化信任模式**：
- 对边界清晰的小任务高度信任
- 对复杂、长程任务明确不信任
- 信任建立在对任务可验证性的判断上

### 3.2 信任边界的量化表达

受访者提供了罕见的**数字化信任边界**：
- 代码交互："可能10轮以后他可能就会忘记一些内容"
- 写作任务："六轮、7轮它就会出一些问题"
- 润色任务："单纯润色就无所谓"

### 3.3 不信任的根源

**长文本处理不信任**：
- "我还是不相信他的这个长文本处理的能力，我觉得他会偏到其他的地方去"
- 自我反思："这可能是我对于他的一个比较刻板印象的问题"

**对"偏离"的担忧**：
- "paper直接丢进去它可能抓不到太多的重点，它可能会偏到一些其他的方向上面去"
- 应对策略：自己提取关键词，给定context

## 四、核心专家策略

### 4.1 任务分解策略

**边缘模块法**：
- 只让AI处理边界清晰的"边缘模块"
- 不交给AI跨模块的复杂任务
- 保持人类对整体架构的控制

### 4.2 输入预处理策略

**关键词提取法**：
- 不直接丢入完整paper
- 自己先提取关键词和context
- 减少AI"偏离"的可能性

### 4.3 封装思维

**代码封装要求**：
- "我希望它可以有更好的封装，这样保证我在用不同的动力学模块的时候，我可以比较方便地切换"
- 将软件工程的封装思维应用于AI协作

### 4.4 轮次控制策略

基于经验的对话轮次上限：
- 代码任务：控制在10轮以内
- 写作任务：控制在6-7轮以内
- 超出则开启新对话或人工接管

## 五、深层认知分析

### 5.1 工程师思维模式

受访者展现出典型的**软件工程思维**：
- 模块化、封装、可切换性
- 边界清晰、输入输出明确
- 对复杂系统的分而治之

### 5.2 技术内行的审慎

作为AI领域研究者，对AI能力有清醒认识：
- 知道长上下文的局限性
- 了解模型"遗忘"的机制
- 对自己的"刻板印象"有元认知

### 5.3 工具化定位

将AI严格定位为"模块化工具"：
- 执行边界清晰的子任务
- 不期待其处理复杂、模糊的任务
- 人类保持系统性控制

## 六、对论文的核心价值

### 6.1 独特贡献：信任的量化边界

**数字化轮次阈值**是本访谈最独特的发现：
- 代码任务：10轮上限
- 写作任务：6-7轮上限
- 这种量化表达在其他访谈中罕见

### 6.2 理论贡献

**"边缘模块"信任模型**：
- 信任不是二元的，而是与任务边界清晰度相关
- 边界越清晰，输入输出越明确，信任度越高
- 跨模块、长程任务则信任度低

### 6.3 技术内行视角

**专业用户的差异化使用**：
- AI专业背景导致更精准的能力评估
- 不盲目信任也不盲目拒绝
- 基于技术理解的理性使用边界

### 6.4 "刻板印象"的元认知

受访者承认自己对AI的不信任可能是"刻板印象"：
- 显示出高度的自我反思能力
- 但仍然选择保持谨慎
- 体现了"宁可保守"的专家态度

## 七、关键引用

### 关于边缘模块
> "我可以这么说，比如说我要控制这个水下的这个潜艇，那它有一个动力学的模块...我希望它可以有更好的封装，这样保证我在用不同的动力学模块的时候，我可以比较方便地切换。"

### 关于轮次限制
> "我觉得长代码交互的话，可能10轮以后他可能就会忘记一些内容。"

> "writing的话...如果是，比如说有逻辑性的一些写作的话，我觉得可能在写作方面可能要短一点，我觉得可能六轮、7轮它就会出一些问题。"

### 关于长文本不信任
> "我还是不相信他的这个长文本处理的能力，我觉得他会偏到其他的地方去，这可能是我对于他的一个比较刻板印象的问题。"

### 关于数学概念应用
> "我毕竟不是数学系的同学，我很多时候他只是我找到一个很好的一个概念，我觉得他跟我这个项目比较契合，那么我也只是希望简单地了解一下，然后我直接拿来就用。"

### 关于写作结构
> "每一个大纲内部我要讲哪些东西我大概是有数的，但是这些东西它之间的逻辑顺序如何把它排列起来，然后讲得让观众听得更加...可以说服观众，这个是我需要他去帮我总结这个前后顺序。"

## 八、分析验证

- [x] 基本画像：博三、强化学习、水下潜航器 ✓
- [x] 边缘模块策略：动力学模块代码化示例 ✓
- [x] 10轮/6-7轮量化阈值：原文直接引用 ✓
- [x] 长文本不信任+"刻板印象"元认知 ✓
- [x] 数学概念"拿来就用"的实用态度 ✓
- [x] 写作结构整理而非内容生成 ✓

---

**信任类型标签**：技术洞察型 / 模块化信任 / 量化边界意识

**核心发现**："10轮代码/6-7轮写作"的量化信任阈值，以及"边缘模块"的任务分解策略

---


<a id="受访人23"></a>

# 受访人23分析报告：WAP3活动运营

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | WAP3交易所平台活动运营、用户运营 |
| 行业 | 加密货币/区块链交易所 |
| 主要工具 | Grok（推特集成）、腾讯元宝、Google Gemini |
| 工具选择逻辑 | 便捷性 > 准确性 |
| 使用特点 | 短轮次交互、不追求完美输出 |
| 工作经验 | 丰富（曾从事游戏行业） |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：竞品资料收集（灵感获取）**
- 查找其他交易所的活动案例
- 目的是"给我一些灵感"而非完整方案
- 输入具体明确："帮我找几个别的交易所平台的法币、信用卡买币的任务活动"

**场景二：文案润色（占60-70%）**
- 将冗长的活动规则精简化
- AI提供格式建议（第一段写什么、第二段写什么）
- 不要求AI口语化改写："让一个机器装成一个人去帮你写一个很人性化的文案，我觉得挺奇怪的"

**场景三：数据分析报告**
- 截图喂给AI（而非上传Excel）
- AI提供"思路"，人工填入准确数据
- 月报撰写、活动参与率分析

**场景四：翻译工作**
- 中译英、小语种翻译（日韩越泰）
- 无法校验准确性，"他说什么就是什么了"

### 2.2 使用特点

**极短交互轮次**：
- "问它一次两次我就能把整个活动的idea想好"
- 不愿意"一直跟他喂"让它改到满意
- 拿到初稿后自己修改

## 三、信任轨迹：便捷效率型

### 3.1 信任特征

**便捷性压倒准确性**：
- 明知截图识别不准（60-70%），仍选择截图而非上传Excel
- 原因："从Lark复制到Excel再保存再上传，整个过程会很慢"
- "我还不如直接贴个图给他"

### 3.2 工具迁移逻辑

从GPT → Gemini → Grok → 腾讯元宝的迁移完全基于**便捷性**：
- Grok：因为"天天要看推特"，顺手就用
- 腾讯元宝：有客户端，"直接可以在电脑里打开"
- "AI给我的答案其实大差不差...便捷性是我会考虑去替换的原因"

### 3.3 领域差异化信任

**熟悉领域（工作）**：
- 参考性60-70%，但不验证
- "我能看出来"AI给错的信息
- 依靠工作经验修正

**不熟悉领域（健身、用药）**：
- "可能百分之八九十我是完全相信他的"
- "因为我不懂我才会去问他"

## 四、核心专家策略

### 4.1 "一次性输出+自己改"策略

**拒绝迭代打磨**：
- "让AI一定要改到他想要的...我觉得会更麻烦"
- "从效率上来说我就会很慢"
- "那我要它干嘛，对吧？"（如果要自己指定框架）

### 4.2 任务与平台匹配策略

- 翻译任务 → 海外平台（GPT等）
- 中文润色 → 国内AI
- WAP3行业资料 → 海外AI（国内"素材库可能比较少"）

### 4.3 "抄+思考"方法论

对下属的建议：
- "用AI去抄别人家的...快速地收集这些资料"
- 但强调"要知道背后的逻辑...才能抄到你的点子上"

## 五、深层认知分析

### 5.1 工具理性主义

**将AI严格定位为效率工具**：
- "毕竟它是工具"
- "如果我用起来很复杂...有些人他会为了用AI而去使用AI"
- 反对"本末倒置"

### 5.2 "神化警惕"

对年轻用户的担忧：
- "如果有一个全知全能的神在你面前，你肯定会希望他给你所有的答案"
- 年轻人"会觉得AI什么都能帮他解决"
- 建议"带着纠错的心态去使用它"

### 5.3 经验自信

**工作经验构成信任底气**：
- 文案工作"只有百分之四五十我能使用"
- "剩下百分之四五十还是要靠我自己去写"
- "帮他去修改，会帮他去修改，但是他更多的是给我提供一个思路"

## 六、对论文的核心价值

### 6.1 独特贡献："便捷性优先"悖论

**首次明确提出便捷性可以压倒准确性**：
- 这在学术场景几乎不可想象
- 但在工作场景完全合理
- 揭示了不同情境下AI信任逻辑的根本差异

### 6.2 理论贡献

**"结果导向"决定信任模式**：
- Speaker 3总结："结果导向不同...追求的效率不同"
- 学术：输出即KPI，准确性至上
- 工作：输出是辅助环节，效率至上

### 6.3 工具迁移的便捷性逻辑

**工具切换不是因为质量，而是因为访问便捷**：
- 这挑战了"用户根据输出质量选择工具"的假设
- 实际上："AI给我的答案大差不差"

### 6.4 熟悉度悖论

**熟悉领域反而更不信任AI**：
- 因为"能看出来"错误
- 不熟悉领域反而"百分之八九十完全相信"
- 这与专业用户的行为模式一致

## 七、关键引用

### 关于便捷性优先
> "我需要把文档从电脑里保存下来，然后再扔到它的AI里面，其实整个过程会比较麻烦...我还不如直接贴个图给他。"

> "AI的它给我的答案其实大差不差，就是各家都其实我觉得不会差太特别多。对，但是它的便捷性其实是我觉得我会考虑去替换掉的一个原因。"

### 关于短轮次交互
> "那我觉得会更麻烦，就是从效率上来说我就会很慢。"

> "问它一次两次我就能把整个活动的idea想好，然后我就有方向了，然后剩下的我可能花15分钟或20分钟我就出文案就可以了。"

### 关于不迭代
> "它就是我的，我觉得我不会这么喂它...你让一个机器装成一个人去帮你写一个很人性化的文案，我觉得挺奇怪的。"

### 关于工具定位
> "要把它当成工具，而不是要把它当成一个...全知全能的神...要有这种纠错的心态去使用它。"

### 关于领域差异信任
> "在药这个方面我不懂我才会去问他，那如果我懂的话，我就不会去问他了，所以他给我的这个结果，我可能百分之八九十我是完全是相信他的。"

### 关于工作场景特殊性（Speaker 3补充）
> "结果导向不同，一个是对待于一个输出...对于我们来说的话，这个东西它只是整个一个任务里面的一个辅助性的...并没有说像做学术类的输出一个paper它是一个很大比重的一个KPI的存在。"

## 八、分析验证

- [x] 便捷性优先于准确性：截图vs上传Excel的选择 ✓
- [x] 工具迁移逻辑：GPT→Gemini→Grok→元宝的便捷性驱动 ✓
- [x] 短轮次交互："一次两次就能把idea想好" ✓
- [x] 领域差异信任：工作60-70%，用药80-90% ✓
- [x] 对迭代的拒绝："不会这么喂它" ✓
- [x] Speaker 3的"结果导向"解读 ✓

---

**信任类型标签**：便捷效率型 / 工具理性主义 / 领域差异化信任

**核心发现**："便捷性 > 准确性"的效率优先逻辑，以及工作场景与学术场景的根本差异

---


<a id="受访人24"></a>

# 受访人24分析报告：NTU博士后（Software Engineering for AI）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | NTU博士后研究员 |
| 专业领域 | Software Engineering for AI |
| 主要工具 | ChatGPT（免费版为主）、DeepSeek（批判性使用） |
| 使用历史 | GPT出来后即开始使用 |
| 角色定位 | 自视为"教育者"，AI为"学生" |
| 特点 | 高度自主、批判性思维强 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：邮件撰写**
- 最高频使用场景
- 优于传统机器翻译
- 能写出"得体、不啰嗦、适合国外沟通"的内容
- 会控制GPT不要过于客套

**场景二：论文写作（Writing）**
- 不让AI凭空生成creative内容
- 自己提供完整思路，AI只做润色
- 分component处理：背景、knowledge gap、insight、实现、evaluation
- 关键策略：**要求AI自我反思是否满足所有要求**

**场景三：Response Letter撰写**
- 审稿意见回复
- GPT擅长写得体的回应
- 但偏冗长、过于礼貌，需要简化
- 能辩证指出回应的逻辑漏洞

**场景四：伦理把关**
- 检查论文中可能引起不适的表述
- GPT对种族、性别等敏感议题有防范意识
- 帮助检查是否有stereotype等问题
- 甚至知道"Black和White的大小写规则"

**场景五：PPT规划与脚本**
- 规划PPT结构、每页要点
- 润色演讲脚本
- 避免"中国人讲英语太formal"的问题

### 2.2 明确不使用的场景

**代码生成**：
- 早期使用后放弃
- 原因："给我生成的好像很有道理，但其实有一些代码又是什么包，又是什么包的依赖...debug这些小错的时候非常非常费劲"
- 现在："我自己还不如对着那个example自己写"
- 但AI可以在high level给建议（推荐哪些包、优劣性）

## 三、信任轨迹：指导者型

### 3.1 信任特征

**"我是教育者，AI是学生"**：
- "我觉得我属于一个指导者，从认知上各种方面我都是一个指导者"
- "它只是起到一个辅助的作用，没有它我也能做这个任务，只是花的时间会更长"

### 3.2 信任边界

**高信任场景**：
- 语言润色和格式转换
- 伦理合规性检查
- 非专业领域的general knowledge问答

**低信任场景**：
- 代码生成（有过负面经验）
- Literature review（担心假引用）
- Creative内容生成

## 四、核心专家策略

### 4.1 需求反思验证策略

**最独特的策略**：让AI自我检查是否满足所有要求
- "我把我的一个要求再说一遍，你对照我的要求你去反思一下你给我的这个答案需不需要进一步优化"
- GPT会回应："你的要求我总结起来有1234点，第一点怎么样...这个已打勾、已达到，需要提升是什么"
- 用于长文本生成，怀疑AI会遗漏requirements

### 4.2 语义等价转换定位

**核心认知框架**：
- 对于实事求是的任务（论文、rebuttal）："我给他的应该就是一个语义的等价体"
- AI的任务是"帮我做语义变换，变成一个更好的形式"
- 而非创造新内容

### 4.3 付费版与免费版的理性选择

- 曾用过付费版，但发现"对我这种用户使用情况好像差别不大"
- 回归免费版
- 原因："主动权在我...对性能要求不是太高"

## 五、深层认知分析

### 5.1 专家自信与AI定位

作为软件工程for AI的研究者，对AI能力有清醒认识：
- 知道benchmark与real-world的gap
- 了解代码生成的真实局限
- 对学生过度依赖AI深感忧虑

### 5.2 对学生使用AI的批判

**强烈批评学生过度依赖**：
- "一眼GPT"：能立刻看出AI写的文章
- 特征："逻辑很差，全部都是废话、冗余的话，不凝练不达意"
- Survey尤其明显："写出来的文章明显能看出高度依赖LLM"
- 问题本质："没有自己的方法论、逻辑在支撑"

**对逻辑弱的学生**：
- "GPT对他们来说简直就是灾难"
- "思维根本就是在降级"
- "writing也没训练上，逻辑也没训练上"

### 5.3 理想的人机分工

- GPT负责：writing层面的工作
- 人类负责：logic层面的把关
- "比较好的方法是你以GPT来帮你负责writing这部分减轻一些工作，但更多地把自己的精力花在logic上"

## 六、对论文的核心价值

### 6.1 独特贡献：需求反思验证策略

**"让AI自我反思是否满足要求"**是极具价值的策略：
- 利用AI的self-reflection能力
- 形成闭环验证
- 特别适用于长文本、复杂要求的任务

### 6.2 理论贡献

**"教育者vs学生"的角色定位**：
- 与某些受访者的"学生vs教育者"形成对照
- 取决于用户的expertise水平
- 专家用户更倾向于"指导者"角色

### 6.3 对教育影响的专业洞见

作为AI+教育从业者的双重视角：
- 技术侧：了解AI的真实能力边界
- 教育侧：观察到学生能力退化
- 结论：教育环节变得更重要，而非更不重要

### 6.4 DeepSeek的批评性评价

**对DeepSeek的深刻批判**：
- "幻觉情况很严重"
- "喜欢说很多很冗余很废话的话"
- "假大空...经不起深推敲"
- 可能原因："用了很多中文的一些奇怪的语料去训练"

## 七、关键引用

### 关于指导者角色
> "我觉得我整个在跟GPT的LLM交互的过程中，我觉得我属于一个指导者...它只是起到一个辅助的作用，就是没有它我也能做这个任务，只是我要花的时间会更长而已。"

### 关于需求反思策略
> "我不管满不满意，反正我经常会习惯性地加一句，把我的一个要求再说一遍，你对照我的要求你去反思一下你给我的这个答案需不需要进一步优化。"

### 关于代码生成的放弃
> "我让它写一些数据分析的代码的时候，它给我生成的好像很有道理，但其实有一些代码又是什么包，又是什么包的依赖什么的...debug这些小错的时候非常非常费劲。"

### 关于学生依赖AI
> "那个学生写出来的东西就很夸张，就是写得废话连篇...一眼就能看出来他高度依赖于LLM写的文字。"

> "像这种人的话，GPT对他们来说简直就是灾难，就是感觉把他们思维根本就是在降级...writing也没训练上，逻辑也没训练上。"

### 关于伦理把关
> "那个文章我几乎是全文都让GPT帮我把关过的，就哪一些话你觉得有可能会有一些伦理风险，有可能会引起有些人不适...我觉得他在这方面比我们有sense。"

### 关于理想分工
> "比较好的方法是你以GPT来帮你负责writing这部分减轻一些工作，但是我们更多地把自己的精力花在这个logic...这样是我觉得比较好的一个交互方式。"

## 八、分析验证

- [x] 博士后身份、Software Engineering for AI ✓
- [x] 代码生成的负面经验及放弃 ✓
- [x] "教育者vs学生"角色定位 ✓
- [x] 需求反思验证策略 ✓
- [x] 对学生过度依赖AI的批评 ✓
- [x] 伦理把关的独特应用 ✓
- [x] DeepSeek"假大空"批评 ✓

---

**信任类型标签**：指导者型 / 专家自信 / 写作-逻辑分离

**核心发现**："让AI自我反思是否满足要求"的需求验证策略，以及"GPT负责writing，人负责logic"的分工理念

---


<a id="受访人25"></a>

# 受访人25分析报告：AI+教育科研从业者

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | AI+教育领域科研从业者 |
| 背景 | NLP/计算语言学，曾研究非裔美国人英语 |
| 主要工具 | Claude Max（$200/月）、GPT Team版 |
| 开发工具 | GPT API、DeepSeek、千问、Dify框架 |
| 使用历史 | 2022年11月（GPT出来即开始） |
| 特点 | 深度技术理解 + 教育视角的双重身份 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：论文写作**
- 不先写完整草稿再让AI改
- 而是列出段落大纲 → AI生成自然段 → 人工修改
- 关键指令："be natural, clarify the details"
- 告诉AI哪块扩写、哪块缩写

**场景二：完整代码生成**
- 让Claude生成1000+行完整代码
- 包括提示词设计、Agent间通信方式
- 关键策略：让AI输出每一步的input/output（print出来）
- 容易发现问题："跑不起来就让他修改"

**场景三：AI驱动的信息检索**
- 取代传统搜索引擎
- 搜索文献："这个领域引用量高的文献有哪些？"
- 现在有链接可验证，幻觉问题减少

**场景四：邮件撰写**
- "基本上他给我写"
- 告诉需求，让它生成，再修改

### 2.2 明确不使用的场景

**头脑风暴/Idea生成**：
- "个位数"次使用
- "idea可能并不来源于文献综述，而是我发现有这么一个需求"
- AI无法判断"什么值得做"

**模型创新**：
- 调整神经网络结构时必须自己非常明确
- AI只能执行，不能创新

## 三、信任轨迹：技术洞察型

### 3.1 对AI本质的深刻认识

**"AI没有元认知"**：
- "它不会说是去先去想我说这句话到底我相信不相信"
- "人在说话的时候，大家都知道自己说的哪些是真的，哪些是假的"
- AI没有这个功能

**"AI没有价值观"**：
- "人是有价值...知道好坏"
- "他不知道什么东西值得做，哪些东西不值得做"

### 3.2 流畅性造成的虚假权威

**过度信任的根源**：
- "GPT表述得特别的官方、特别的正式，造成了一种它非常权威的假象"
- "前后文相关性特别高，人没办法去鉴定他到底知道不知道"
- 类比传销："我也不知道他到底是不是说的真的，我就觉得他可信"

### 3.3 领域熟悉度与信任

**不熟悉领域 → 完全信任**：
- "不熟悉，所以完全信任"
- 破局方法："对AI非常熟悉，知道他在某种情况下容易产生不正确的信息"

## 四、核心专家策略

### 4.1 段落化写作控制

**精细化的扩缩控制**：
- "我觉得哪一块需要扩写，哪块不需要扩写，然后告诉他"
- 人掌握重点判断，AI执行文字生成
- 最后过渡和拼接由人完成

### 4.2 代码调试的Print策略

**每步输出追踪**：
- "让他把所有的input或output，每一步骤全都print out出来"
- "你只需要看这个print out就可以了"
- 比传统调试更高效

### 4.3 付费策略

**精准匹配需求的付费**：
- Claude开Max（$200/月）：因为能写长代码
- GPT开Team版：基础功能够用
- 原因："Claude还算是比较听话"，GPT会"偷懒"

## 五、深层认知分析

### 5.1 语境语言的洞察

**日语/中文 vs 英语**：
- "日文是语境语言，必须靠语境理解"
- "人有对隐藏信息的理解能力"
- AI"如果没有足够的训练语料，推导不出来"

### 5.2 复杂任务的AI局限

**造楼比喻**：
- 问AI怎么造一栋楼，AI会生成方案
- 但建筑师会反问"要造什么样的楼？"
- "模型不会意识到...不会去验证他输出的内容到底和你说的是不是相符"

### 5.3 对学生使用AI的策略

**刻意限制creative thinking任务**：
- "我不知道他creative thinking出来的东西到底是啥"
- 只让学生做监控性任务
- "只需要摁两个按键就可以执行的"

**布置AI无法完成的作业**：
- "AI提的研究问题会非常vague"
- "范围太大了，所以研究不了"
- "一下就能看出来"是AI生成的

## 六、对论文的核心价值

### 6.1 独特贡献：AI能力边界的专业剖析

**"没有元认知"和"没有价值观"**是极具理论价值的发现：
- 解释了为什么AI无法判断idea价值
- 解释了为什么research question需要人类确定
- 提供了区分人机能力边界的理论框架

### 6.2 理论贡献

**流畅性→虚假权威→过度信任**的因果链：
- 不是因为内容正确才信任
- 而是因为表述流畅、前后一致
- 与传销机制类比，深刻揭示信任本质

### 6.3 语境语言视角

**高语境语言（日语/中文）对AI的挑战**：
- 需要prior knowledge
- 隐性知识无法直接输入
- 这是独特的NLP专业视角

### 6.4 教育实践洞见

**对学生使用AI的务实态度**：
- 学生需要AI做"知识原始积累"
- Coding无法禁止AI使用
- 重点是培养"什么是好，什么是坏"的判断力

## 七、关键引用

### 关于AI的元认知缺失
> "人在说话的时候，我觉得大家都知道自己说的哪些是真的，哪些是假的...但是大模型它没有，就是它不会说是去先去想我说这句话到底我相信不相信它不会去想这个问题。"

### 关于价值判断缺失
> "人是有价值，人是知道好坏的...但他是没有价值观，他不知道什么东西值得做，哪些东西不值得做。"

### 关于流畅性造成的虚假权威
> "GPT在表述的过程中，它表述得特别的官方，特别的正式，然后就造成了一种它非常权威的假象，然后人就信了。"

### 关于领域熟悉度与信任
> "不熟悉，所以完全信任。但是还有一种破局的方法，就是你对AI非常熟悉，你知道他在某种情况下容易去产生不正确的信息。"

### 关于写作策略
> "writing的话...我会先把，比如说这个段落的大纲列出来，我要先说什么再说什么...然后告诉他，让他帮我写出这么一个自然段，然后再去看他写出来这个自然段，我再修改。"

### 关于代码调试
> "你可以让他写代码，然后让他把所有的这个input或output，每一步骤的input和output全都是print out出来，然后你就能看到，然后你只需要看这个print out就可以了。"

### 关于对学生的管理
> "我不会，我尤其是本科生的话，我会让他执行那种非常简单，只需要摁两个按键就可以执行的...我刻意的不让他去做creative thinking，因为我不知道他creative thinking出来的东西到底是啥。"

### 关于评估AI在教育中的影响
> "如果是GPT会干的，我就不要求学生一定会自己干...我觉得更多的是怎么样培养学生跟AI去协作完成一件事情，他只需要知道什么是好，什么是坏。"

## 八、分析验证

- [x] AI+教育双重身份、NLP背景 ✓
- [x] Claude Max + GPT Team的付费策略 ✓
- [x] "没有元认知"和"没有价值观"的洞察 ✓
- [x] 段落化写作 + Print调试策略 ✓
- [x] 流畅性→虚假权威的因果分析 ✓
- [x] 语境语言（日语/中文）的独特视角 ✓
- [x] 对学生刻意限制creative thinking任务 ✓

---

**信任类型标签**：技术洞察型 / 元认知意识 / 价值判断保留

**核心发现**："AI没有元认知和价值观"的深刻洞察，以及"流畅性造成虚假权威"的信任机制分析

---


<a id="受访人26"></a>

# 受访人26分析报告：马来西亚电商创业者

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 创业者（Entrepreneur） |
| 年龄 | 27岁 |
| 专业背景 | 生命科学（Life Science） |
| 业务领域 | 马来西亚-新加坡跨境电商 |
| 主要工具 | ChatGPT（主力） |
| 语言 | 英文访谈 |
| 团队规模 | 独立运营（无团队） |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：营销内容生成（Instagram Posts）**
- 自己拍摄照片，将照片描述和想要唤起的情绪输入AI
- AI生成配文（captions）
- 评估："AI can help around 70-80%"

**场景二：营销活动策划（Marketing Campaign）**
- 请AI生成详细工作流程和指导方针
- 逐步细化："even under every single step, I will still ask the AI to help me generate even more detailed steps"

**场景三：面试准备（Role-playing）**
- 给AI提供面试官背景和职位描述
- AI生成可能的面试问题
- 评价："pretty accurate so far"

**场景四：供应商信息搜索**
- 查找特定品牌、产品来源
- "AI can pretty generate all the information I need"

### 2.2 使用特点

**"Always started my workflow by AI"**：
- AI是工作流程的起点
- 然后在Google上补充验证
- 营销内容大部分由AI生成

## 三、信任轨迹：高依赖+低验证型

### 3.1 信任水平

**70%信任度**：
- "I'll trust it 70%"
- 30%不信任来自表达方式："the way it phrase is...not personal right now"

### 3.2 验证行为

**极少验证**：
- 被问到是否验证AI输出时："Not really, because so far, I think it's all been quite okay"
- 不使用多模型交叉验证
- 营销领域"not really a right and wrong answer"

### 3.3 信任边界

**完全信任**：事实性问题（如"新加坡今年多少岁"）

**不完全信任**：供应商搜索、商业决策
- "that one I won't trust 100%"
- 会依靠"my own experience and my connections"

## 四、核心专家策略

### 4.1 AI风格问题的处理

**识别AI痕迹**：
- "too rigid and too false"
- "really long em-dash, which normally most people don't use"

**处理方法**：
- 不要求AI修改
- 自己重写，改成"personal story"
- "keeping the main point that AI asked me to point it out"

### 4.2 人际网络作为验证手段

当AI给出模糊答案时：
- "I would just ask people around me based on my connections, human connections, company connections"
- "I think that's the most accurate information"

### 4.3 信息保护策略

**对版权和信息泄露的担忧**：
- "my biggest fear is really just about my ideas might be shared with other people"
- 应对："keep the most of the ideas of myself, and give it like non-sensitive information"

## 五、深层认知分析

### 5.1 高度依赖但有意识

**坦诚承认高度依赖**：
- "my decision making is really, I would say, heavily dependent on AI"
- 但保持一定警觉："I will not 100% trust what the response AI give me"

### 5.2 效率至上的逻辑

**AI节省时间 → 更多创意空间**：
- 以前："took me hours to look online to see what's the viral post"
- 现在："that particular pose can be done within like three minutes max"
- AI释放时间让人"derive more creativity"

### 5.3 对AI改进的建议

**希望AI提问而非直接回答**：
- "instead of giving a very detailed answer, they can actually kind of ask me back"
- "giving me open ended question instead of detailed response"
- 目的：激发批判性思维

### 5.4 人类创意不可替代

**AI缺乏"sense"**：
- "AI cannot generate any relevant things that you want have, like the sense, the odds"
- 最终承认："we still need humans to creativity"
- 关于同质化担忧："that's one of the concern"

## 六、对论文的核心价值

### 6.1 独特贡献：创业场景的AI依赖模式

**独立创业者的极端案例**：
- 无团队，完全依赖AI进行营销
- 以前依赖"friends and family"，现在"just me and the AI"
- 代表了AI替代人际协作的趋势

### 6.2 理论贡献

**"trial and error"作为验证替代**：
- 营销领域"not really a right and wrong answer"
- 因此用市场反馈替代事前验证
- 这是领域特性决定的信任模式

### 6.3 AI风格识别的经验法则

**从大量阅读中获得辨别能力**：
- "if you read many articles and posts...you'll kind of just get a sense of it"
- "is it genuine the way you write it"
- 这是一种基于经验的隐性知识

### 6.4 版权担忧的先见性

**创业者对AI独特的担忧**：
- 不是准确性，而是"idea被泄露给他人"
- "if everybody start using AI...copyright issue is one of our biggest concern"
- 这是其他受访者较少提及的角度

## 七、关键引用

### 关于AI依赖程度
> "I always started my workflow by AI, yeah. Then from there, I Google right here and there, a bit, but mostly all my Instagram posts and stuff, or by AI."

### 关于信任水平
> "I'll give it like 70% I'll trust it 70%...that 30% is really sometimes it's the way it phrase is. It's just not...personal right now."

### 关于AI风格问题
> "for AI, like for instance ChatGPT, normally when I asked to write the post itself, normally it's too weak, sometimes a bit too rigid and too false. You know, they have the really long em-dash, which normally most people don't use em-dash."

### 关于验证方式
> "when it's a very factual thing, I would say...I will fully trust AI. But if I'm talking about finding company specializing in a certain...that one I won't trust 100%"

### 关于决策依赖
> "I think currently, my decision making is really, I would say, heavily dependent on AI."

### 关于AI改进建议
> "instead of giving a very detailed answer, instead is they can actually kind of ask me back, what do I think, or what do I feel, giving me open ended question instead of detailed response."

### 关于版权担忧
> "my biggest fear is really just about, you know, my ideas, or the ideas that I share with AI might be, you know, share with other people."

## 八、分析验证

待核对的关键引用：
- [x] "always started my workflow by AI" ✓ (line 37)
- [x] "trust it 70%" ✓ (line 247)
- [x] "too rigid and too false...em-dash" ✓ (line 133)
- [x] "heavily dependent on AI" ✓ (line 343)
- [x] "ask me back...open ended question" ✓ (line 400)

---

**信任类型标签**：高依赖型 / 低验证型 / 效率导向

**核心发现**：独立创业者以AI完全替代团队协作，形成"AI起点+人工润色"的工作模式

---


<a id="受访人27"></a>

# 受访人27分析报告：蛋白质研究员（医学化学领域）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 蛋白质/医学化学研究员 |
| 研究方向 | 蛋白质降解（把protein和另一个分子拉在一起，让好的"吃掉"不好的） |
| 主要工具 | ChatGPT Plus（GPT5）、Google AI mode |
| 语言 | 英文为主（研究背景为英语环境） |
| 使用历史 | 2023年开始接触，2024年7-8月开始高频使用 |
| 特点 | 低信任度、高验证意识、领域严谨性要求高 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：初步方向探索**
- 对不了解的课题或方向，用AI缩小范围
- AI提供initial framework
- 强调：general问题AI信任度高，specific问题信任度低

**场景二：写作润色**
- 收集所有资料（AI+Google）后，让AI improve内容
- "在写作方面，我觉得他帮到我是挺多的"
- AI帮助improve整个flow和storytelling

**场景三：资料验证与补充**
- 不依赖AI给的文献（"很多都不太靠谱"）
- 用Google核对AI答案
- 找有经验的人验证AI建议

### 2.2 明确不使用的场景

**化学实验troubleshooting**：
- 问AI为什么实验出错、为什么yield低
- 结果："他就会开始给我乱说一通"
- 这类specific问题AI"答案还是跟还有相当大的差距"

## 三、信任轨迹：低信任+高验证型

### 3.1 信任水平

**低于50%信任度**：
- "直接应用的话，我觉得少于50。50%吧"
- 这是所有受访者中最低的信任度之一
- 与医学领域对准确性的高要求有关

### 3.2 验证行为

**多重验证机制**：
- Google核对AI答案
- 询问"比我有经验的人"
- 发现错误后不再问AI相关问题，转向其他来源

### 3.3 信任边界

**高信任场景**：
- General问题（"没那么高的specificity的时候，ai的那个信任度还是蛮高的"）
- 写作润色和storytelling

**低信任场景**：
- Specific化学实验问题
- 需要reference支持的学术内容
- 文献推荐（"ai给我的文章很多都不太靠谱"）

## 四、核心专家策略

### 4.1 "前后包夹"策略

**AI角色定位**：
- "它就是充当一个前面跟一个后面这样的角色，然后，中间的那一段就是由我自己来补充"
- 前面：AI提供框架和思路
- 中间：自己填充核心内容
- 后面：AI润色和优化

### 4.2 对话隔离策略

**每问题新对话**：
- "通常我就会针对一个问题，然后我就开一个新的对话框"
- 原因：AI会"一直延续下去"，"硬硬会跟你扯关系"
- 避免AI"记忆混乱"和"思路混乱"

### 4.3 错误后放弃策略

**发现错误即转向**：
- "通常我发现他错了，我就不会再问他"
- 直接去其他地方寻找答案
- 不花时间纠正AI

### 4.4 输入精细化策略

**缩小范围提高准确性**：
- 提前告知：task内容、字数限制、观众群体、professional程度
- "把那个方向缩小了之后，他给的答案会更加的准确一些"

## 五、深层认知分析

### 5.1 思考变浅的自我觉察

**坦诚承认依赖性**：
- "我觉得可能我的思考会比以前浅了挺多"
- "我会对他有一定的那个依赖性"
- "遇到了什么不知道的，我就会想要去问他，而不是先自己去思考一遍"

### 5.2 领域严谨性决定低信任

**医学化学的特殊要求**：
- "我们需要非常精准的一些答案跟观点"
- "如果有稍微一些不严谨的都会被问"
- 因此参考内容"会比较少用ai"

### 5.3 AI定位的演进期待

**现阶段：Assistant**
- "Assistant，现阶段还是assistant"

**期待未来：Collaborator**
- "能进步，能当个collaborator，其实也还是一个不错的方向"
- 前提是AI"给出的答案就是有一定的那个思考性跟一定的那个参考程度"

### 5.4 对AI改进的建议

**Reference集成**：
- "把那个ai跟google做更好的integration会很好"
- "所有ai说过的话，如果都有reference去提升他说的那句话的意义"

**问题敏感度**：
- "能很精准的抓到你想要问的到底是什么东西"
- "他的sensitivity，如果能再进步一些"

## 六、对论文的核心价值

### 6.1 独特贡献："前后包夹"策略

**AI作为框架+润色工具**：
- 这与"起点+终点"的定位一致
- 中间核心内容由人类掌控
- 形成明确的人机协作边界

### 6.2 理论贡献

**领域严谨性与信任度的负相关**：
- 医学化学要求精准 → 低AI信任度
- 这支持了"领域特性影响信任模式"的假设
- 与营销等"无标准答案"领域形成对比

### 6.3 思考退化的自我报告

**罕见的坦诚反思**：
- "思考会比以前浅了挺多"
- 主动承认依赖性影响
- 但认为"还是主要是看个人的那个使用方式"

### 6.4 假文献风险的强调

**对学术诚信的担忧**：
- "假文献的风险最大"
- "如果有些人他们不去verify之后再拿来用的话，那那就一团糟了"
- 与学术不端的关联

## 七、关键引用

### 关于信任水平
> "直接应用的话，我觉得少于50。50%吧，就是现在来看的话。"

### 关于AI角色定位
> "我觉得它就是充当一个前面跟一个后面这样的角色，然后，中间的那一段就是由我自己来补充。"

### 关于思考变浅
> "我觉得他确实是帮我省了很多的时间，但是同时我也觉得可能我的思考会比以前浅了挺多，因为就是我会对他有一定的那个依赖性。"

### 关于AI定义
> "Assistant，现阶段还是assistant。"

### 关于对话隔离
> "通常我就会针对一个问题，然后我就开一个新的对话框...因为有时候那个ai它会一直延续下去...它硬硬会跟你扯关系。"

### 关于假文献风险
> "假假文献的风险最大吧...如果有些人他们不去verify之后再拿来用的话，那那就一团糟了。"

### 关于领域严谨性
> "我们需要非常精准的一些答案跟观点，就是如果有稍微一些不严谨的都会被问。"

## 八、分析验证

待核对的关键引用：
- [x] "少于50%"信任度表述 ✓ (line 855)
- [x] "充当一个前面跟一个后面这样的角色" ✓ (line 1047)
- [x] "浅了挺多" ✓ (line 1207)
- [x] "Assistant，现阶段还是assistant" ✓ (line 1487)
- [x] "假文献的风险最大" ✓ (line 1323)

---

**信任类型标签**：低信任型 / 高验证型 / 领域严谨导向

**核心发现**：医学化学领域的"<50%"低信任度，"前后包夹"的AI角色定位，以及对思考变浅的坦诚反思

---


<a id="受访人28"></a>

# 受访人28分析报告：NTU招生营销主管

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | NTU南洋商学院招生与外联团队成员 |
| 职位 | Master's in Finance项目负责人 |
| 主要工具 | ChatGPT（免费版）、Adobe Photoshop AI功能 |
| 专业背景 | 传播学（Comms major） |
| 语言 | 英文 |
| 使用历史 | 2022-2023年ChatGPT爆火时开始 |
| 特点 | 高度工具化定位、极低依赖度、强批判性思维 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：语气/格式调整（最主要）**
- 已写好邮件后，让AI改成更professional的语气
- "I will write it out, and I'll ask them to help me make it sound more professional"
- 逐段对比AI输出和自己原文，选择性采纳

**场景二：数据清洗**
- 处理学生申请数据中的格式问题
- 例如：自动去除名字中的逗号
- 因保密性，不能用AI分析实际数据

**场景三：Photoshop图片编辑**
- 使用Adobe AI功能（generative fill）
- 去除图片背景元素
- 不生成图片，只做修改

### 2.2 明确不使用的场景

**信息获取**：
- "I don't really use it to generate information"
- "I'm not using it like a search engine"

**策略规划**：
- "Not in particular, not really for strategy purposes"

**创意生成**：
- "I don't necessarily use it to come up with something"
- "that's not necessarily something that I do"

## 三、信任轨迹：极低依赖型

### 3.1 信任定位

**AI = 拼写检查器**：
- "I see it as a kind of spell check kind of situation"
- "It's more of a checker for me"
- 不是信息来源，只是格式工具

### 3.2 验证行为

**先写后比对**：
- 自己先完成内容，AI只做润色
- "I would compare the result between what AI got me and what I wrote already"
- "paragraph by paragraph, sentence by sentence, decide what's the best way"

**不盲目采纳**：
- "I don't trust it immediately, I go and Google"
- "this suggestion is not as good as what I had originally done, so I would just neglect that information"

### 3.3 信任边界

**唯一信任场景**：
- 格式调整和语气改写
- 图片编辑中的元素移除

**完全不信任场景**：
- 信息检索
- 策略建议
- 创意内容

## 四、核心专家策略

### 4.1 "检查器"定位策略

**严格工具化**：
- "I don't see it as somebody as a collaborator"
- 将AI定位与spell checker同级
- 不期待AI提供新信息

### 4.2 比对评估策略

**双向比较法**：
- 自己写一版 → AI改写一版 → 逐段比较
- 选择性采纳，像接受同事建议一样

### 4.3 人际交互优先

**招生工作的人性化**：
- "a big part of my job is still talking to students"
- 面对面交流的信任度高于AI
- 使用真人学生（Unibuddy平台）而非AI机器人

## 五、深层认知分析

### 5.1 对AI幻觉的深刻认识

**结构性不信任**：
- "I don't think you should trust AI at all"
- "there is a level of hallucinations that is not necessarily quantifiable"
- "we should use AI with a certain level of distrust in general"

### 5.2 AI与文化停滞的担忧

**最独特的忧虑**：
- "creative works or new forms of thinking are no longer being developed"
- AI只是"regurgitates"过去的内容
- "would there be a possibility where AI kind of halts cultural development"

### 5.3 批判性思维的演化观

**技术替代但不消灭批判性思维**：
- Excel让人不再手工核对，但允许更高层次分析
- "new critical thinking skills might come out as a result"
- AI减少某些批判性思维，但催生新形式

### 5.4 工具演进的历史视角

**类比分析**：
- 搜索引擎 → 社交媒体 → AI：信任转移的历史规律
- "people don't criticize when Google gives us the wrong answer"
- AI被持高标准是因为被视为"完美"

## 六、对论文的核心价值

### 6.1 独特贡献：极端的工具化定位

**"Spell Checker"级别的定位**：
- 这是所有受访者中最低的AI依赖度之一
- 完全拒绝AI作为信息来源
- 代表了一种"最小化使用"的极端模式

### 6.2 理论贡献

**"文化停滞"担忧**：
- AI依赖过去数据 → 无法创造新范式
- 这是独特的宏观视角，超越个人使用层面
- iPhone以来的交互范式停滞作为类比

### 6.3 批判性思维的辩证观

**不是消失，而是演化**：
- 旧的批判性思维被替代
- 新的批判性思维因此产生
- "the way we define as critical thinking might change"

### 6.4 招生场景的人性化坚持

**AI无法替代人际信任**：
- 面对面咨询的信任度高于任何AI
- 选择真人学生而非AI机器人
- "there's a level of trust that you get when you're actually seeing somebody in person"

## 七、关键引用

### 关于工具定位
> "I see it as a kind of spell check kind of situation...I don't really use it for information, I'm not using it to captain up with something that is factual information."

### 关于信息获取
> "I use it more for tonality purposes...I'm not filling in information to find me all the stats that'll make it sound professional. I already have the stats on hand already."

### 关于检查器角色
> "It's more of a checker for me...I don't see it as somebody as a collaborator...that's not necessarily something that I do."

### 关于对AI的不信任
> "I don't think you should trust AI at all...there is a level of hallucinations that is not necessarily quantifiable, even by its researchers...we should use AI with a certain level of distrust in general."

### 关于文化停滞
> "creative works or new forms of thinking are no longer being developed...I think that in itself is the biggest risk of AI."

### 关于批判性思维演化
> "new critical thinking skills might come out as a result...People spend less time on Excel sheets, but they use the Excel sheets, the data from the Excel sheets, to draw conclusions even more."

### 关于年轻一代
> "AI is just a... it's just the new wave of people not thinking critically, but people have not been thinking critically for a long time beyond AI...I don't think this is necessarily an AI problem, but more of a critical thinking problem."

## 八、分析验证

待核对的关键引用：
- [x] "spell check kind of situation" ✓ (line 1875)
- [x] "I use it more for tonality purposes" ✓ (line 1899)
- [x] "It's more of a checker for me" ✓ (line 2187)
- [x] "I don't think you should trust AI at all" ✓ (line 2507)
- [x] "creative works or new forms of thinking are no longer being developed" ✓ (line 2935)

---

**信任类型标签**：极低依赖型 / 工具化定位 / 批判性思维强

**核心发现**：将AI定位为"Spell Checker"级别的极端工具化使用，以及对AI导致"文化停滞"的独特宏观担忧

---


<a id="受访人29"></a>

# 受访人29分析报告：AI创业者（邮件管理产品）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | AI创业者（Clarity AI创始人） |
| 专业背景 | 土木工程 |
| 创业经历 | 连续创业者，第四个产品（前两个失败，一个拿到VC） |
| 产品方向 | AI邮件管理、智能日程整合 |
| 主要工具 | ChatGPT Plus、Gemini、千问 |
| 地理位置 | 美国（此前在澳大利亚） |
| 团队规模 | 约10人 |
| 使用AI比例 | 30%（自评） |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：代码编写**
- "大部分写代码"
- 自己不会写代码，完全依赖AI生成
- 愿意与AI"拜托五轮"直到得到正确结果
- 例子："今天刚commit了一个我改了50多遍的代码"

**场景二：资料查询**
- 用自然语言替代Google关键词搜索
- "我不知道关键词是什么，所以我就用自然语言去替代了我的关键词"

**场景三：产品调研**
- "所有的这些工作现在全都可以用ai代替了"
- "之前需要去做客户访谈，现在不需要了"
- AI训练数据已包含用户输入

### 2.2 团队使用情况

**全员使用AI**：
- 前端工程师用Cursor管理GitHub
- "一个模块一个模块的改，ai可以帮他把其他类似的地方都改掉"
- 管理态度："只看结果"

## 三、信任轨迹：达尔文主义型

### 3.1 信任定位

**工具化+适者生存**：
- "ai永远的是辅助角色"
- "相信不相信的问题没有那么重要，因为世界的真相都不是很重要"
- "这是人怎么使用工具，而不是工具怎么驯化人"

### 3.2 验证方式

**靠经验判断**：
- "AI说错了，我肯定知道"
- "我干这事儿，他如果说错了，那说明我问的问题就错了"
- 会直接骂AI："你给我瞎掰什么东西呢？"

### 3.3 对过度依赖的态度

**社会达尔文主义**：
- "影响了也就影响了，这个人该怎么长，这是他的命数"
- "社会就是分层的，它这么使用它，说明就在这个层次"
- "能用好ai的人自然就能用好，用不好的被驯化了，也就被驯化了"

## 四、核心专家策略

### 4.1 持续对抗策略

**不怕多轮交互**：
- 愿意改50多遍代码
- 即使浪费时间也要跟AI"拜托"到底
- 原因："我不会写代码呀"

### 4.2 明确纠错策略

**看到错误立即指出**：
- "你不要给我建议，你刚才说的这些东西，我告诉你，为什么你不需要给我建议"
- 阻止AI脑补不需要的条件

### 4.3 成本导向策略

**按成本选择模型**：
- GPT Plus因为"包月了"
- 其他按token算，哪个低用哪个
- Flash模型处理垃圾邮件

## 五、深层认知分析

### 5.1 趋势不可逆论

**强烈的技术决定论**：
- "这个趋势就是趋势，你如果不能跟ai共存的话，你就被淘汰"
- "全世界没有像ai这次革命一样花过这么大的全人类的力量去做一件事情"

### 5.2 哲学化的世界观

**虚无主义倾向**：
- "世界都是假的，你何必较真呢？"
- "我们无非就是过来经历了，经历完了，体验好坏也没有差别"
- 将生活比作"戴了虚拟眼镜"的游戏

### 5.3 对批判性思维问题的看法

**个人责任论**：
- "这是人怎么使用工具，而不是工具怎么驯化人"
- 不会主动在产品中加入认知预警："对我来说是成本"
- 除非regulation要求，否则不会做

### 5.4 职业替代预测

**程序员最先被替代**：
- "单纯是因为现在ai在代码能力的进化上是最快的"
- "因为它有最多的数据"
- 但学科教育仍需要："像人会说话就不教语文了吗？"

### 5.5 无法被替代的领域

- 前沿物理
- 体育运动
- 娱乐艺术
- "anything that kills time"

## 六、对论文的核心价值

### 6.1 独特贡献：创业者的务实主义

**不关心信任，只关心结果**：
- "我只看结果"
- 这是所有受访者中最"结果导向"的态度
- 代表了一类不纠结于信任问题的用户

### 6.2 理论贡献

**"社会达尔文主义"的AI使用观**：
- 用户分层是自然的
- AI只是加速了优胜劣汰
- 这挑战了"所有人都需要保护"的假设

### 6.3 产品开发者视角

**"反产品"的认知预警**：
- 激活用户自我认知"有点反产品"
- "产品最核心的就是要易用性"
- 除非regulation，否则不会做

### 6.4 小麦驯化人类的类比

**独特的历史视角**：
- "你喜欢吃面条...那么小麦驯化人类，这个事情你也接受了呀"
- AI驯化人类只是历史进程的延续

## 七、关键引用

### 关于趋势不可逆
> "不会的趋势不可逆，没有必要去探讨这个问题，这个趋势就是趋势，你如果不能跟ai共存的话，你就被淘汰。就这么简单。"

### 关于信任问题
> "我一直感觉这个相信不相信的问题没有那么重要，因为世界的真相都不是很重要。"

### 关于工具驯化人
> "没错，这是人怎么使用工具，而不是工具怎么驯化人。"

### 关于经验判断
> "我不会啊，就是ai说错了，我肯定知道啊，我干这事儿，他如果说错了，那说明我问的问题就错了。"

### 关于社会分层
> "那没办法，社会就是分层的，它这么使用它，说明就在这个层次。"

### 关于认知预警
> "我不会的，因为对我来说是成本...这个他们有点反产品啊，因为产品最最核心的就是要是易用性嘛。"

### 关于AI永远是工具
> "对啊，我一直认为它就是一个工具啊...他是一直都是个tool，他永远的是辅助角色。"

## 八、分析验证

待核对的关键引用：
- [x] "趋势不可逆...你就被淘汰" ✓ (line 4140)
- [x] "相信不相信的问题没有那么重要" ✓ (line 3968)
- [x] "人怎么使用工具，而不是工具怎么驯化人" ✓ (line 4276)
- [x] "社会就是分层的" ✓ (line 4264)
- [x] "他永远的是辅助角色" ✓ (line 5364)

---

**信任类型标签**：达尔文主义型 / 结果导向 / 工具化定位

**核心发现**："趋势不可逆"的技术决定论，"适者生存"的社会达尔文主义，以及"只看结果"的极端务实主义

---


<a id="受访人30"></a>

# 受访人30分析报告：阿里系电商创业者（Smarty Metrics）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 电商创业者（阿里巴巴出身） |
| 公司 | Smarty Metrics |
| 合伙人 | 三人创业团队 |
| 团队规模 | 十几人 |
| 主营业务 | AI电商投放工具（smart投放） |
| 服务品牌 | DHC、Stenders等 |
| 核心产品 | 人群包投放优化、ROI提升工具 |
| 技术背景 | CTO为阿里系统开发者 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：AI投放工具（自研产品）**
- 人群包投放优化
- ROI提升（从30%提升）
- "我们现在基本上都通过ai去做筛选跟投放"

**场景二：电商运营辅助**
- 图片处理、动图生成
- 运营策略参考
- 但受限于平台后台要求

### 2.2 明确不使用的场景

**运营执行层面**：
- "上下架运营商品，这都取消不了"
- "现在阿里后台只要不改，我们就得用人"
- 受限于平台规则，执行层仍需人工

**技术细节层面**：
- "这个可能要问一下技术同学"
- 运营角色不深入AI技术细节

## 三、信任轨迹：高信任+结果导向型

### 3.1 信任水平

**高信任度（约90%）**：
- "我们现在用的数据基本上都是90%以上"
- "外化到我们这儿就已经是准确版了吧"
- 对自研AI工具高度信任

### 3.2 验证方式

**结果导向验证**：
- "我可能更偏结果导向"
- 不深入AI思考过程，只看最终结果
- "要到结果出来的时候才会发现它错了嘛，然后再去纠正"

### 3.3 信任边界

**高信任场景**：
- 投放策略
- 人群包筛选
- ROI预测

**低信任/无法介入场景**：
- 供应链判断
- 平台后台操作
- 品牌方特殊要求

## 四、核心专家策略

### 4.1 技术分工策略

**运营与技术分离**：
- 运营负责结果验证
- 技术负责AI调校
- "这个可能要问一下技术同学"

### 4.2 经验验证策略

**靠经验判断AI输出**：
- "不大会影响我...靠经验去再去verify"
- "我们首先是靠经验去看"
- 行业经验作为验证基础

### 4.3 平台规则适应策略

**合规优先**：
- "我们现在最重要的就是要合规嘛"
- "不合规的事情我们都干不了"
- "国内是不允许白盒的"

## 五、深层认知分析

### 5.1 极端务实的人员观

**裁员无顾虑**：
- "该用的岗就用人嘛，不该用的岗就赶掉嘛"
- "能省钱肯定是最好的"
- 创业阶段，效率优先

### 5.2 对AI替代人的冷漠态度

**不关心社会影响**：
- "那应该我死之前看不到了"
- "我并不是很care还有来生这件事情"
- "等有了再说吧"（关于下一代）

### 5.3 对隐私问题的淡漠

**技术不可逆论**：
- "只要用手机，你就隐私就有问题"
- "除非这个世界回退到原始社会"
- "只要不回退，你就一定会发生这样的问题"

### 5.4 对人才培养的忽视

**创业阶段逻辑**：
- "我们没那么大，我们现在是创业阶段"
- 不考虑人才可持续发展
- 纯粹的成本效益计算

### 5.5 AI能力期待

**游戏领域**：
- "游戏吧。如果游戏未来都是ai引擎就比较好玩"
- "除了这个，我没有什么期待"

## 六、对论文的核心价值

### 6.1 独特贡献：阿里系创业者的AI工具化

**自研AI产品的创业者视角**：
- 既是AI使用者，也是AI产品开发者
- 代表了AI创业公司的典型思维模式
- "把以前在阿里内部的一些外化了"

### 6.2 理论贡献

**"结果导向"的极端案例**：
- 不关心AI过程，只看结果
- "更偏结果导向"
- 与受访人29的"达尔文主义"形成呼应

### 6.3 对AI替代人工的务实态度

**创业者的冷酷理性**：
- "该用的岗就用人嘛，不该用的岗就赶掉"
- 这是所有受访者中对裁员最直接的表态
- 代表了AI时代创业者的普遍心态

### 6.4 对社会责任的冷漠

**"不care"的态度**：
- 对下一代、对社会影响、对隐私问题均"不care"
- "我死之前看不到了"
- 这种态度值得伦理层面的深入探讨

## 七、关键引用

### 关于AI准确性
> "我们现在用的数据基本上都是90%以上"

### 关于结果导向
> "到运营和交付的这个阶段...因为我可能更添结果导向"

### 关于经验验证
> "不大会影响我...靠经验去再去verify"

### 关于裁员态度
> "该用的岗就用人嘛，不该用的岗就赶掉嘛"

### 关于创业逻辑
> "我们没那么大，我们现在是创业阶段，能省钱肯定是最好的"

### 关于隐私问题
> "只要用手机，你就隐私就有问题...除非这个世界回退到原始社会"

### 关于社会影响
> "那应该我死之前看不到了...我并不是很care还有来生这件事情"

## 八、分析验证

待核对的关键引用：
- [x] "90%以上"准确性表述 ✓ (line 7076)
- [x] "更添结果导向" ✓ (line 7568)
- [x] "该用的岗就用人嘛，不该用的岗就赶掉" ✓ (line 8308)
- [x] "能省钱肯定是最好的" ✓ (line 8348)
- [x] "我死之前看不到了" ✓ (line 8404)

---

**信任类型标签**：高信任型 / 结果导向 / 务实主义 / 社会责任冷漠

**核心发现**：阿里系电商创业者将AI工具化为投放优化利器，持极端务实的"结果导向"态度，对AI替代人工持积极但冷漠的态度，对社会影响和人才培养完全"不care"


---


<a id="受访人31"></a>

# 受访人31分析报告：资深设计师（Amazon/Agency背景）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 资深设计师/创意总监 |
| 从业年限 | 11年 |
| 专业背景 | 广告设计与传播 |
| 工作经历 | BBD（4A公司）、Amazon ads |
| 当前角色 | Branding设计师（执行者+管理者） |
| 主要工具 | ChatGPT、图像AI工具 |
| 语言 | 中文 |
| 特点 | 框架掌控型、经验导向、技术乐观 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：框架内的AI点执行**
- "我可以依赖ai去完成一些指定的指令，然后这个指令一定是under在我大的框架之下的"
- 例子：眼球矫正技术让讲师可以读稿同时看镜头
- AI不做大事，只在框架内处理具体点

**场景二：效率提升工具**
- "以前可能只是想象无法完成的事情，现在我可以通过一个指令让它快速的去生成"
- 10个方向的test可以快速完成，比以前只能做5个

**场景三：邮件编辑（独特用法）**
- 让AI帮忙编辑回复邮件
- 关键指令："在结束的时候会让ai加上5%的语法错误"
- 原因："我不想让这封邮件看起来太完美"

**场景四：个人AI助手培养**
- "训练我的ai，让他知道我是一个什么样的人"
- 跨项目让AI更了解自己的风格和偏好
- 与妻子共用账号，AI能区分两人

### 2.2 明确不使用的场景

**找Reference时禁止使用AI**：
- "我会非常严厉的要求所有参与这个项目的人不允许去碰ai"
- 原因："ai生成的指令是直线的...只有一个或者两个结果"
- 人工找ref会有"不可预测的link"

## 三、信任轨迹：框架掌控型

### 3.1 信任定位

**AI = 框架内执行者**：
- "ai不是主导人才，是要描述清楚你要什么才是最重要的"
- "只起到工具和辅助的作用"
- AI参与度：约30%

### 3.2 验证行为

**反附和策略**：
- "我会验算。同时我会修改"
- "我会尽量的告诉他...除了这个之外还有别的可能性吗？"
- 主动要求AI给出不同答案

### 3.3 信任边界

**高信任场景**：
- 点对点问答（机场规定、签证信息）
- 框架内执行任务
- 翻译（"已经完全超越了以前直翻"）

**低信任场景**：
- 创意方向探索
- Reference寻找
- 投递简历（发现很多邮箱不存在）

## 四、核心专家策略

### 4.1 "大框架+AI点执行"策略

**人掌握框架，AI执行细节**：
- "我不会让ai去做一个大的事情，但在这个框架之下，它可以很好的去处理某一个点"
- 先定义品牌调性，再用AI生成
- "ai的帮助非常的大...首先更快"

### 4.2 找Reference禁AI策略

**保护创意多样性**：
- AI给的结果"直线推导"，只有有限可能
- 人工搜索"会碰到一些不一样的东西"
- "不可预测"在创意工作中是"非常好的事情"

### 4.3 反附和提问策略

**主动要求不同答案**：
- "除了这个之外还有别的可能性吗？"
- "我让你帮我工作的目的不是为了附和我"
- 给AI设定"巨大的帽子"（目标）

### 4.4 5%语法错误策略

**保持人性化输出**：
- 让邮件不要"太完美"
- "我不是一个英语母语的人"
- AI需要加入"人性的部分"

## 五、深层认知分析

### 5.1 AI无法创新的判断

**基于已有数据的局限**：
- "ai很难去创新，ai所有的生成的东西，它都是基于已有的东西"
- "ai它不会去创造任何没有的东西，这是它最可悲的地方"
- 类比：贾樟柯的价值在于"开创表达形式"，AI只能模仿

### 5.2 试错经历决定判断力

**对年轻人的担忧**：
- "年轻人他没有试错过，所以它几乎无法判断ai给出来的东西是好还是坏"
- "新人现在可以更快通过ai去完成一个还ok的东西，但对他们未来是一个非常不好的状态"
- "这对他们的上限是有巨大的一个challenge"

### 5.3 AI最危险的点

**附和用户**：
- "ai，首先它的主要工作就是复合你...这是最危险的一个点"
- "无论你提出一个什么，它都会想办法让你觉得你提出的东西是ok的"
- "你活在自己给自己设定的误区里面"

### 5.4 对创意者未来的乐观

**创意者不会失业**：
- "我非常的乐观，我觉得他们永远都不会失业"
- 原因："ai所有需要学习的东西都来自于他们"
- 复制容易，但"复制没有任何的意义"

### 5.5 数字分身的浪漫态度

**积极探索个人AI**：
- "我其实对于自己的一个数字分身比较乐观的一个态度"
- "能把自己的一个形象给留下来，这个其实蛮浪漫"
- 不担心隐私："只不过是没有人想去了解你而已"

## 六、对论文的核心价值

### 6.1 独特贡献：资深创意人的AI边界设定

**"大框架+AI点执行"模式**：
- 这是创意行业AI协作的清晰范式
- 明确区分了人类主导和AI辅助的边界
- 代表了有经验创意人的典型态度

### 6.2 理论贡献

**"试错经历决定判断力"**：
- 解释了为什么新人更容易被AI误导
- 经验是判断AI输出质量的基础
- 对AI时代人才培养的深刻洞察

### 6.3 AI附和性的风险

**"复合你"是最大危险**：
- AI不会反驳，只会顺着用户
- 这与回音室效应形成呼应
- 需要主动要求不同答案来破解

### 6.4 找Reference禁AI的独特策略

**保护创意的"不可预测性"**：
- AI的"直线推导"限制了创意空间
- 人工搜索的随机性是创意的来源
- 这是创意行业独特的AI使用哲学

## 七、关键引用

### 关于AI定位
> "我可以依赖ai去完成一些指定的指令，然后这个指令一定是under在我大的框架之下的"

### 关于AI无法创新
> "ai很难去创新，ai所有的生成的东西，它都是基于已有的东西"

### 关于禁止用AI找Reference
> "在找reference的过程当中，我会非常严厉的要求所有参与这个项目的人不允许去碰ai"

### 关于AI附和的危险
> "ai，首先它的主要工作就是复合你...这是最危险的一个点，就是你活在自己给自己设定的误区里面"

### 关于创意者不会失业
> "我非常的乐观，我觉得他们永远都不会失业，因为ai所有需要学习的东西都来自于他们"

### 关于年轻人缺乏判断力
> "年轻人他没有试错过，所以它几乎无法判断ai给出来的东西是好还是坏"

### 关于5%语法错误
> "在结束的时候会让ai加上5%的语法错误，因为我不是一个英语母语的一个人，所以我不想让这封邮件看起来太完美"

## 八、分析验证

待核对的关键引用：
- [x] "under在我大的框架之下" ✓ (line 8569)
- [x] "ai很难去创新" ✓ (line 8697)
- [x] "非常严厉的要求...不允许去碰ai" ✓ (line 8705)
- [x] "主要工作就是复合你" ✓ (line 9861)
- [x] "永远都不会失业" ✓ (line 9661)

---

**信任类型标签**：框架掌控型 / 经验导向 / 创意保护主义

**核心发现**：资深设计师的"框架+点执行"AI协作模式，"试错经历决定判断力"的人才培养洞察，以及"AI附和是最大危险"的风险认知


---


<a id="受访人32"></a>

# 受访人32分析报告：咨询公司创意设计师

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 咨询公司创意设计师 |
| 姓名 | Gavin Lee（李伟杰） |
| 国籍 | 新加坡 |
| 工作地点 | 中国大陆（近10年） |
| 职业路径 | 广告行业 → 咨询公司 |
| 主要工具 | ChatGPT、Midjourney、视频AI工具 |
| 语言 | 中英双语 |
| 特点 | 试错学习型、效率导向、对未来有担忧 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：创意素材生成**
- 为客户生成视频、图片素材
- "ai能帮你输出一些好的...让你减少在你这个工作的速度"
- 效率提升约一半

**场景二：创意方向发散**
- "帮我...发散跟发展我的那个想法"
- AI给的方向约60%可行
- "他是一个跟我的伙伴"

**场景三：邮件编写**
- "我要回复一个邮件给我领导，我会用ChatGPT帮我去写那个邮件出来"
- 承认"在依赖ai"

**场景四：知识探索（工作外）**
- 看电影后用AI了解背景知识
- "展开我这个好奇心"
- 更像"简易化的搜索引擎"

### 2.2 使用特点

**试错解锁方式**：
- "前面两个小时都在解锁"
- 约4-5轮测试才能找到对的prompt
- "有一些关键字，我不能用这样，我毕竟要用另外一个方面"

## 三、信任轨迹：合作伙伴型

### 3.1 信任水平

**60%可行度**：
- "我现在感觉现在是60%可行的"
- 40%需要人工筛选
- "后面就是你还是要靠人家去筛选哪一个会比较合适"

### 3.2 验证方式

**经验+客户需求判断**：
- "一个是从工作的经验吧"
- "我会多了解我自己的客户的要求"
- 前期人设定方向，AI辅助发散

### 3.3 信任边界

**可以依赖**：
- 创意方向发散
- 执行层面效率提升
- 知识探索

**不能依赖**：
- 沟通与说服
- "ai不会是一个工具，可以帮你去有一些...特别的跟你的竞争对手有点差异"

## 四、核心专家策略

### 4.1 "越清楚越好"策略

**明确目标再问AI**：
- "不能当成他像一个谷歌或者一个百度，就是不能纯粹打一行字"
- "你要明确知道你要问这个ai工具到底是什么东西"
- "前面还是需要人去做自己的...有自己的方向"

### 4.2 试错解锁策略

**多轮测试找准prompt**：
- "大概四轮吧四到五轮"
- "前面的两个小时甚至三个小时"都在测试
- 第一个视频完成后，后续会更顺利

### 4.3 对比展示策略

**向领导展示AI价值**：
- 安排传统方式和AI方式对比
- "我有一个对比...方案A...ai有点稍微好一点，然后甚至可能时间用也是减了一半"
- 用结果说服团队采用AI

### 4.4 时间把控策略

**限时任务**：
- "我只能给你两个小时，三个小时"
- 在限定时间内用AI完成任务
- 确保效率和质量平衡

## 五、深层认知分析

### 5.1 对被替代的担忧

**坦诚的害怕**：
- "我当然会有啦，我当然会很担心"
- "我还是会有这个害怕点在我心里"
- "但我知道也不是我能控制在这个方面上"

### 5.2 选择"跟AI成长"

**主动学习态度**：
- "要么我现在只是跟著这个热点，然后去一直去学习，然后一起去跟ai成长"
- "要么就是我完全不管...不想学它，不想用它"
- 选择前者

### 5.3 人的不可替代性

**人才是bug的来源**：
- "人创出来的问题...最后你还是需要人去解决人创出来的问题"
- "ai不会是一个工具，可以帮你去...代表出来一些特别的"

### 5.4 沟通是核心价值

**storytelling不可替代**：
- "怎么用自己的方式去说服，或者甚至卖他们的方案"
- "沟通就是需要沟通，我觉得就是ai目前看不出可以替换它"
- 销售岗位"比较安全"

### 5.5 对年轻人的观察

**年轻人更愿意尝试**：
- "比我年轻的一些同事，他们会比较愿意跟比较会乐意去尝试"
- "他们不会怕，如果他们失败"
- "他们去理解，跟他们去解锁的方式会比我更快"

### 5.6 对"legacy同事"的观察

**老员工的抵触**：
- "他们已经很满意，在做他们每天做的东西...老油条"
- "我要投入很多时间，就像一个小朋友，我要拿那个东西直接喂到他们的嘴巴"
- 最终"有点放弃"

## 六、对论文的核心价值

### 6.1 独特贡献：咨询行业的AI整合视角

**创意服务咨询化**：
- 从广告到咨询的转型经历
- AI帮助创意部门为咨询业务增值
- 代表了服务业AI整合的典型路径

### 6.2 理论贡献

**"60%可行度"的务实评估**：
- 不完全信任，也不完全否定
- 人工筛选作为必要补充
- 代表了中度信任的典型模式

### 6.3 试错学习的价值

**前置试错投资**：
- "前面两个小时都在解锁"
- 但后续任务会更顺利
- 试错是建立AI协作的必要成本

### 6.4 对未来的清醒担忧

**"害怕点在心里"**：
- 坦诚承认对被替代的担忧
- 但选择主动学习应对
- 代表了务实从业者的典型心态

## 七、关键引用

### 关于AI定位
> "帮我...发散跟发展我的那个想法吧。然后可能他是一个跟我的伙伴"

### 关于可行度
> "我现在感觉现在是60%可行的，因为可能40%都是...他可能只是给你一个大广的方向"

### 关于prompt策略
> "不能当成他像一个谷歌或者一个百度，就是不能纯粹打一行字...你要明确知道你要问这个ai工具到底是什么东西"

### 关于被替代的担忧
> "我当然会有啦，我当然会很担心...我还是会有这个害怕点在我心里"

### 关于人的价值
> "人创出来的问题...最后你还是需要人去解决人创出来的问题"

### 关于沟通不可替代
> "沟通就是需要沟通，我觉得就是ai目前看不出可以替换它"

### 关于应对策略
> "要么我现在只是跟著这个热点，然后去一直去学习，然后一起去跟ai成长"

## 八、分析验证

待核对的关键引用：
- [x] "发展跟发展我的那个想法...是一个跟我的伙伴" ✓ (line 11369)
- [x] "60%可行的" ✓ (line 11381)
- [x] "不能当成他像一个谷歌或者一个百度" ✓ (line 12289)
- [x] "害怕点在我心里" ✓ (line 12797)
- [x] "人创出来的问题...需要人去解决" ✓ (line 11561)

---

**信任类型标签**：合作伙伴型 / 试错学习型 / 务实担忧型

**核心发现**：咨询公司创意设计师视AI为"合作伙伴"，给出60%可行度的务实评估，坦诚承认"害怕被替代"但选择"跟AI一起成长"


---


<a id="受访人33"></a>

# 受访人33分析报告：量化交易员（Trading行业）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 量化交易员（Trader） |
| 姓名 | Ivan |
| 行业 | 量化金融/对冲基金 |
| 专业背景 | 数学、机器学习 |
| 主要工具 | 公司自建大语言模型（基于ChatGPT/Claude）、神经网络 |
| AI应用 | 代码辅助、信息查询、交易信号预测（行业趋势） |
| 特点 | 高度谨慎、可解释性导向、掌控型 |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：代码辅助（Google替代）**
- "你可以问一下，但是感觉更多就是像在像google的替代品么"
- 想不起来的coding问题可以询问
- 但受公司保密限制，不能输入敏感数据

**场景二：日常知识查询（工作外）**
- "我有很多不懂的事情，我会问他"
- 法律、健康等不熟悉领域
- 承认AI"准确率还是比较高的"

**场景三：神经网络交易信号（行业趋势）**
- 用neural network做预测和交易信号
- 但"目前看来还处于一个不是特别popular的一个阶段"
- 行业内"发展比较滞后"

### 2.2 明确不使用的场景

**策略和数据输入**：
- "你也不能把数据输进去啊，就这些都是不行的"
- "我们比较害怕的是我们的策略被他学了"
- Team之间也是竞争对手，不想分享信息

**社交沟通**：
- "我不需要和人打交道，所以没有这样需求"
- 策略"不能告诉ai"

## 三、信任轨迹：可解释性导向型

### 3.1 信任定位

**可解释性 = 信任的前提**：
- "我们不理解他为什么这些feature是这样，这个是主要原因"
- "用new network，它是一个black box"
- "你没法解释它，你就不懂它的风险在哪里"

### 3.2 验证方式

**实盘结果验证**：
- "他可能并是反直觉的，但是他work"
- 靠历史回测和实盘交易结果判断
- "根据历史上实盘交易的结果来分析"

### 3.3 信任边界

**高信任场景**：
- 代码辅助
- 日常信息查询
- 已验证有效的交易模型

**低信任/谨慎场景**：
- 交易策略生成（black box问题）
- 任何涉及公司保密信息的场景
- 社交沟通类应用

## 四、核心专家策略

### 4.1 可解释性优先策略

**理解才敢用**：
- "你只有理解了，你才能够知道它是不是会一直赚钱"
- "你要知道为什么赚钱"
- 传统数学模型"完全了解这个模型，他能做什么，他不能做什么"

### 4.2 小权重渐进策略

**稳定后再加权重**：
- "给ai做出来的信号，一个比较小一点的权重"
- "当他稳定了，然后再逐渐增加权重"
- "一部分ai一部分以前的这种传统模式"

### 4.3 掌控优先策略

**不能掌控就不用**：
- "他不会选择他掌控不了的ai工具"
- "不能掌控的东西其实并没有被广泛的使用"
- "他们需要的是每年都稳定的赚钱"

### 4.4 市场自适应认知

**信号会失效**：
- "金融市场，它都有一个自适应性"
- "你所有的这些交易信号都会都不会一直有效"
- "你要一直在寻找新的交易信号"

## 五、深层认知分析

### 5.1 AI对职业市场的冲击

**准入门槛提高**：
- "进入这个行业会越来越难"
- "只招最优秀的人，然后，但是不招很多人"
- "这些不重要的工作会被ai替代"

**职业路径压缩**：
- "你不可以就你更难进入行，就有很多时候是你先进入这个行业，无论你做点什么，然后你再考虑去转转换角色"
- "以后这种机会就会越来越少"
- "你就只能是本身就很厉害，然后你一次就进来做一个关键的岗位"

### 5.2 AI加剧财富集中

**马太效应**：
- "只会使有钱的人更有钱"
- "他们是真正实际上在掌控整个游戏整个市场整个行业的人"
- "那么几家公司可能会主导这个行业"

### 5.3 行业内AI比人聪明者更多

**量化行业的特殊性**：
- "在这个行业里面，比ai聪明的人还是比较还是更多一些"
- "你不需要完全依赖它"
- 人工feature和AI feature对比，AI未必更好

### 5.4 对新人的建议

**技能不应被AI削弱**：
- "你这个工程能力并不应该因为ai的存在而受到影响"
- "自己的技能还是要打磨得更细致一些"
- 要对神经网络"理解的要比较透彻"

### 5.5 对AI乐观但谨慎

**理性乐观态度**：
- "我对ai是比较乐观的就是我觉得它能取代一部分工作"
- 但"职位应该是不会。目前看来，短期之内应该是不会被替代"
- "非常critical的这种development...他们不会被替代"

## 六、对论文的核心价值

### 6.1 独特贡献：高风险行业的AI信任模式

**金融行业的特殊信任逻辑**：
- 可解释性 = 风险可控性 = 信任基础
- 这与其他行业"只看结果"形成鲜明对比
- 代表了高风险决策场景下的AI使用模式

### 6.2 理论贡献

**"掌控优先"的信任前提**：
- 不是"好不好用"决定信任
- 而是"能否掌控"决定是否使用
- 这挑战了单纯效用导向的AI采纳理论

### 6.3 AI加剧职业分化的预测

**准入门槛提高 + 马太效应**：
- AI不会消灭职位，但会压缩职业路径
- "先进入再转型"的路径被切断
- 对人才培养和职业规划有重要启示

### 6.4 行业保密性限制AI应用

**数据隐私作为AI应用边界**：
- "我们比较害怕的是我们的策略被他学了"
- Team之间竞争导致信息隔离
- AI的训练数据边界决定了应用边界

## 七、关键引用

### 关于保密性限制
> "你也不能把数据输进去啊，就这些都是不行的，因为我们比较害怕的是我们的策略被他学了"

### 关于可解释性
> "用new network，它是一个black box，你可能知道他的神经网络的结构，但是它训练出来的那些高维的feature，我们很难解释他为什么"

### 关于信任前提
> "你只有理解了，你才能够知道它是不是会一直赚钱"

### 关于掌控优先
> "他不会选择他掌控不了的ai工具"

### 关于职业影响
> "只招最优秀的人，然后，但是不招很多人"

### 关于财富集中
> "只会使有钱的人更有钱，因为他们是真正实际上在掌控整个游戏整个市场整个行业的人"

### 关于技能保持
> "你这个工程能力并不应该因为ai的存在而受到影响，自己的技能还是要打磨得更细致一些"

### 关于AI与人的比较
> "在这个行业里面...比ai聪明的人还是比较还是更多一些"

## 八、分析验证

待核对的关键引用：
- [x] "比较害怕的是我们的策略被他学了" ✓ (line 13468)
- [x] "用new network，它是一个black box" ✓ (line 13580)
- [x] "他不会选择他掌控不了的ai工具" ✓ (line 15048)
- [x] "只招最优秀的人...但是不招很多人" ✓ (line 14428)
- [x] "比ai聪明的人还是比较还是更多一些" ✓ (line 13496)

---

**信任类型标签**：可解释性导向型 / 掌控优先型 / 高度谨慎型

**核心发现**：量化交易员将"可解释性"作为AI信任的核心前提，采用"小权重渐进"策略验证AI，预测AI将加剧职业准入门槛和财富集中效应

---


<a id="受访人34"></a>

# 受访人34：计算化学博后 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 博士后研究员（巴基斯坦籍） |
| 研究领域 | 计算化学、能源存储 |
| 教育背景 | 化学工程学士、化学硕士和博士（韩国） |
| 使用起始 | GPT-3发布时（早期采用者） |
| 使用频率 | 每天使用 |
| 主要工具 | ChatGPT（付费）、Gemini Pro（付费）、Perplexity、DeepSeek、Claude |
| 培训方式 | 自学 |

## 使用场景

### 场景1：信息搜索与文献整理 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "I would go on Web of Science...read through their overlying abstracts...upload them all at the same time to a specific model. And then ask them to summarize"

**独特策略**：
> "I need to give it documents that it can read and just contain itself within that context first"

### 场景2：代码生成与调试 ⭐⭐⭐⭐

**使用方式**：
> "Make a function in Python that has this input...this output...generate the function"

**局限认知**：
> "If I give it the whole code, then 80% of the time I would spend more time debugging what it gave me"

### 场景3：邮件写作 ⭐⭐⭐⭐

**使用方式**：
> "If I want to write an email...I don't want to spend time being polite or constructing the grammar, I can just write me this email"

### 场景4：图片生成辅助 ⭐⭐⭐

**使用方式**：
> "If I'm writing a paper and I want some ideas for a figure...give it a sample image or make an outline on PowerPoint"

## 信任轨迹：稳定怀疑型

### 信任水平 ⭐⭐⭐⭐⭐

> "In the beginning...percentage, zero, no trust, 100%, like a lot of trust, I would say like maybe 50%"
> "It has remained the same, actually. It hasn't changed"

### 不信任的核心原因

**1. 过度自信的错误回答**：
> "It will confidently give you wrong answers that doesn't make any sense"
> "Chad GPT confidently said, yeah, you're right, it is wrong, and then gave me another wrong answer"

**2. 立即妥协不争辩**：
> "If it can argue with me, then I would have a higher trust"
> "They will not just fall in line every time you question it"

**3. 技术原理认知**：
> "I know how it's trained...I've also downloaded the LLM, the free ones and then run them on my computer"
> "I know the exact databases they were trained on"

## 核心专家策略

### 策略1：上下文限定策略 ⭐⭐⭐⭐⭐

> "I can't trust it to give me information directly from the internet. I need to give it documents that it can read and just contain itself within that context first"

**核心逻辑**：通过提供特定文档限制AI的回答范围

### 策略2：对话刷新策略 ⭐⭐⭐⭐⭐

> "I do tend to refresh and generate a new chat as well after 15 prompts because I don't really trust the responses after that"
> "I know that after 15, it will start to hallucinate and forget the previous information"

### 策略3：多工具分工策略 ⭐⭐⭐⭐⭐

> "GPT is good for certain coding tasks...Gemini Pro is better at writing tasks. Perplexity is better at writing more human-based text"
> "It's not really a good idea to use one of them for everything because they tend to fail miserably for certain tasks"

### 策略4：提示编辑策略 ⭐⭐⭐⭐

> "If I get an answer that I don't like, I just edit my original prompt and then make sure it doesn't include what he wrote"

### 策略5：每次验证策略 ⭐⭐⭐⭐⭐

> "Every time, every time...I have to, like if I'm writing it for a paper...I can't put stuff in a paper without verifying it"

## 深层认知

### 对AI能力边界的理解 ⭐⭐⭐⭐⭐

> "It's really good in very short contexts...very bad when you wanted to use it to learn something new"
> "It will never give you exact information, it's very general"

### 对训练数据局限的认识 ⭐⭐⭐⭐⭐

> "Websites allowed them to scrape all the text that they needed. Now they don't allow that. So they just kind of keep training it on their own text"

### 对学术引用问题的警惕 ⭐⭐⭐⭐

> "LLMs tend to hallucinate a lot of citations. That's still a problem today"

## 独特发现

### 1. 稳定的中等信任水平 ⭐⭐⭐⭐⭐

> "It has remained the same, actually. It hasn't changed"

**理论价值**：信任水平可以长期保持稳定，不一定随使用增加

### 2. 基于技术原理的信任校准 ⭐⭐⭐⭐⭐

> "I know the context window of this LLM is this much...I know that after 15, it will start to hallucinate"

**理论价值**：技术知识影响用户的信任预期和使用策略

### 3. "争辩能力"作为信任标准 ⭐⭐⭐⭐⭐

> "If it can argue with me, then I would have a higher trust"

**理论价值**：用户期望AI能坚持正确立场，而非一味同意

### 4. 对认知依赖的担忧 ⭐⭐⭐⭐

> "They rely on the chat GPT to do a lot of the thinking. That's not going to end well for them"
> "Their own ability to cognitively discern what information is correct, incorrect, is going to go down"

## 对论文的核心价值

### 1. 技术专家的信任校准模式

深度理解AI技术原理的用户会形成更稳定、更理性的信任预期

### 2. 多工具策略的理论意义

专家用户发展出根据任务特性分配不同工具的复杂策略

### 3. 验证行为的普遍性

> "I cannot build my knowledge base on something that I'm not sure with"

### 关键引用（可用于论文）

1. **稳定信任**：
   > "In the beginning...maybe 50%...It has remained the same, actually"

2. **争辩期望**：
   > "If it can argue with me, then I would have a higher trust"

3. **上下文限定**：
   > "I need to give it documents that it can read and just contain itself within that context first"

4. **对话刷新**：
   > "I refresh and generate a new chat after 15 prompts because I don't really trust the responses after that"

5. **认知担忧**：
   > "Their ability to cognitively discern what information is correct, incorrect, is going to go down"

## 八、分析验证

待核对的关键引用：
- [x] "I need to give it documents that it can read and just contain itself within that context" ✓ (line 82)
- [x] "It has remained the same, actually. It hasn't changed" ✓ (line 190)
- [x] "If it can argue with me, then I would have a higher trust" ✓ (line 208)
- [x] "I refresh and generate a new chat as well after 15 prompts" ✓ (line 172)
- [x] "80% of the time I would spend more time debugging" ✓ (line 82)

---
*分析完成时间：2025年1月*

---


<a id="受访人35"></a>

# 受访人35：软件开发者 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 解决方案开发者（AI数字开发） |
| 教育背景 | NTU商业分析硕士 |
| 工作领域 | 海事与离岸公司 |
| 技术采用 | 早期采用者 |
| 使用频率 | 平衡使用（工作与个人） |
| 主要工具 | ChatGPT、Gemini、Claude（均为免费版） |
| 培训方式 | Coursera课程（Prompt Engineering） |

## 使用场景

### 场景1：代码调试与理解 ⭐⭐⭐⭐

**使用方式**：
> "Professionally sometimes in the debuggings...when I have to understand some concepts it actually provides you great resources"

### 场景2：邮件与文本编辑 ⭐⭐⭐⭐

**使用方式**：
> "When I'm drafting the emails or like editing some passages or I have to change my tone"

**策略**：
> "For email...I just want a first draft and then I can edit it by myself"

### 场景3：概念学习与类比 ⭐⭐⭐⭐⭐

**独特方法**：
> "If I have some things I don't understand...I asked to give me an analogy of it so that it solidifies my thinking"

**效果评价**：
> "Using those analogies, I'm able to remember the concepts in a much simpler way"

### 场景4：信息整合 ⭐⭐⭐⭐

**使用动机**：
> "It has an advantage that it can consolidate all the information. I don't have to switch to different tabs"

## 信任轨迹：快速提升型

### 信任演变 ⭐⭐⭐⭐

> "When I got started it was around like 22-23ish...at that time it was quite low"
> "As these days it's getting better...now you can get the citations and references...that has raised some of my trust"
> "I would say around 80 percent"

**从20-30%提升到80%**

### 信任提升原因

**1. 技术进步**：
> "They're making it more trustable and it's expanding a lot"

**2. 引用功能**：
> "Now you can get the citations and references like where exactly it is coming from"

## 核心专家策略

### 策略1：角色分配策略 ⭐⭐⭐⭐

> "I usually try to assign a role to it so that it doesn't go in other directions"
> "Say you're an expert in data scientist...then I assigned that particular role"

### 策略2：上下文提供策略 ⭐⭐⭐⭐

> "I try to give it some context as well"

### 策略3：类比请求策略 ⭐⭐⭐⭐⭐

> "I asked to give me an analogy of it so that it solidifies my thinking"

### 策略4：迭代追问策略 ⭐⭐⭐⭐

> "I can just say...it's more of like I have a structured thing"
> "I'm able to get like something solid in under three to five"

## 深层认知

### 对AI优势的理解 ⭐⭐⭐⭐

**生成初稿**：
> "Originating the first drafts or like providing some ideas to get started with"

### 对AI局限的认识 ⭐⭐⭐⭐

**信息过载问题**：
> "Sometimes if I just provided too much information...less creative freedom"

**幻觉问题**：
> "It sometimes misses the concepts and hallucinates sometimes"

### 对过度依赖的警惕 ⭐⭐⭐⭐

> "I have tasks where I want to just be myself and I feel like maybe relying a bit on it too much is impacting"
> "I try to come up with the drafts myself...restrict a bit of it"

## 独特发现

### 1. 类比学习法 ⭐⭐⭐⭐⭐

> "With the analogy and those kind of stuff, I'm able to understand the concept"

**理论价值**：AI辅助学习的创新应用

### 2. 多资源免费版策略 ⭐⭐⭐⭐

> "There are so many multiple resources, I feel like I can make use of the different free versions to fulfill whatever I want to accomplish"

**理论价值**：资源整合替代付费订阅

### 3. 自我限制意识 ⭐⭐⭐⭐

> "I try to...restrict a bit of it"

**理论价值**：用户主动管理AI依赖程度

## 对论文的核心价值

### 1. 信任快速提升案例

从20-30%到80%的信任提升轨迹

### 2. 类比学习策略

利用AI生成类比来增强概念记忆

### 3. 自我调节行为

主动限制使用以保持独立思考能力

### 关键引用（可用于论文）

1. **信任提升**：
   > "When I got started...quite low...now around 80 percent"

2. **类比学习**：
   > "I asked to give me an analogy of it so that it solidifies my thinking"

3. **角色分配**：
   > "I usually try to assign a role to it so that it doesn't go in other directions"

4. **自我限制**：
   > "I feel like maybe relying a bit on it too much is impacting...I try to restrict"

5. **信息整合优势**：
   > "It can consolidate all the information. I don't have to switch to different tabs"

## 八、分析验证

待核对的关键引用：
- [x] "I usually try to assign a role to it so that it doesn't go in other directions" ✓ (line 694)
- [x] "I asked to give me an analogy of it so that it solidifies my thinking" ✓ (line 763)
- [x] "I would say around 80 percent" ✓ (line 829)
- [x] "It can consolidate all the information" ✓ (line 682)
- [x] "Originating the first drafts or like providing some ideas" ✓ (line 724)

---
*分析完成时间：2025年1月*

---


<a id="受访人36"></a>

# 受访人36：NTU研究生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 研究生（机器学习与AI方向） |
| 学校 | NTU人文学院 |
| 教育背景 | 商科转计算机 |
| 使用起始 | 2-3年前 |
| 使用频率 | 每周2-3次 |
| 主要工具 | ChatGPT（付费）、Gemini |
| 培训方式 | 自学（YouTube视频、Python非正式课程） |

## 使用场景

### 场景1：文化背景研究 ⭐⭐⭐⭐⭐

**使用方式**：
> "ChatGPT is a great tool in terms of helping me understand cultural context...the history of a nation and the cultural context"

**具体案例**：
> "I want to know which countries have been colonized and when colonization was successful"

### 场景2：学术研究支持 ⭐⭐⭐⭐

**工具分工**：
> "GPT is very good for general questions...Gemini is more for academic work"

### 场景3：创意内容生成 ⭐⭐⭐

**局限认识**：
> "It does well for anything both complex...not so good is maybe for creative content, for example, art and music"

## 信任轨迹：稳定中立型

### 信任水平 ⭐⭐⭐

> "I'm really more on the neutral side...my percentage is maybe...60%"
> "More or less, 60%...maintained that"

### 信任稳定原因

> "It's kind of a novel concept...I do think that my percentage is maybe I'm more positive to trying out new technologies"
> "I don't think it's really high performing to a point whereby it can be the main choice"

## 核心专家策略

### 策略1：小任务分解策略 ⭐⭐⭐⭐

> "I started to feed it smaller tasks and then kind of ease...it works much better"

**经验教训**：
> "When I did a very concise and detailed task, it was still at step one. So I needed to train it"

### 策略2：工具差异化使用 ⭐⭐⭐⭐

> "GPT is very good for general questions...Gemini is more for academic work"

### 策略3：来源过滤策略 ⭐⭐⭐⭐

> "I tried to block out all the blogger or WordPress websites"

**目的**：
> "Doing this...helped to have more confidence in the output"

### 策略4：事实核查策略 ⭐⭐⭐⭐

> "I usually fact check if it prompts me a link...open other tabs to check whether what is being shown on the screen is truthful"

## 深层认知

### 对AI vs Google的理解 ⭐⭐⭐⭐

> "With GPT it kind of gives me a summary and immediately tells me which is the one that I want to go for"

### 对自身判断力的信心 ⭐⭐⭐⭐

> "I try to be one in control"
> "Whenever it wants to suggest me a lot of content, I try to say no...I don't want to be too information overloaded"

### 对年龄差异的观察 ⭐⭐⭐⭐

> "If I was a younger kid using it, it will definitely impact"
> "Younger person...overly reliant on it...not equipped with resilience when it comes to solving problems"

## 独特发现

### 1. 工具功能分工认知 ⭐⭐⭐⭐

> "GPT for general questions, Gemini for academic work"

### 2. 来源过滤实践 ⭐⭐⭐⭐

> "I tried to block out all the blogger or WordPress websites"

### 3. 代际差异担忧 ⭐⭐⭐⭐

> "Younger person...not equipped with resilience"

## 对论文的核心价值

### 1. 稳定中立信任案例

60%信任水平保持不变

### 2. 工具差异化使用策略

根据任务类型选择不同工具

### 关键引用（可用于论文）

1. **稳定信任**：
   > "More or less, 60%...maintained that"

2. **工具分工**：
   > "GPT is very good for general questions...Gemini is more for academic work"

3. **来源过滤**：
   > "I tried to block out all the blogger or WordPress websites"

4. **控制意识**：
   > "I try to be one in control"

## 八、分析验证

待核对的关键引用：
- [x] "I'm really more on the neutral side" ✓ (line 1270)
- [x] "GPT is very good for general questions...Gemini is more for academic work" ✓ (line 1192)
- [x] "I tried to block out all the blogger or WordPress websites" ✓ (line 1303)
- [x] "I try to be one in control" ✓ (line 1465)
- [x] "If I was a younger kid using it, it will definitely impact" ✓ (line 1420)

---
*分析完成时间：2025年1月*

---


<a id="受访人37"></a>

# 受访人37：数据分析师 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 数据分析师 |
| 工作领域 | 消费金融/Fintech |
| 教育背景 | 统计学 |
| 技术采用 | 观望型采用者 |
| 使用起始 | ChatGPT发布后 |
| 使用频率 | 约每周3次 |
| 主要工具 | ChatGPT（免费版）、Claude |
| 培训方式 | 无正式培训 |

## 使用场景

### 场景1：代码调试与生成 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "Our main task is using SQL to generate SQL queries...and Tableau for visualization"
> "For queries, I do ask GPT"

### 场景2：概念理解与解释 ⭐⭐⭐⭐

**使用方式**：
> "Other situation is like when your supervisor, when they're giving you information, sometimes very hard to understand. So you ask Chat GBT or cloud to kind of help simplify what they're talking about"

### 场景3：Excel函数生成 ⭐⭐⭐⭐

**使用方式**：
> "Generating Excel formulas...which is easy, like straightforward question"

## 信任轨迹：使用后提升型

### 信任水平 ⭐⭐⭐⭐

> "Before using, I would say like sixty"
> "I still 80"

**从60%提升到80%**

### 信任提升原因

> "After the AI do improvements, releasing the new versions, I think the accuracy went out"
> "Now I don't really like, I don't have any trust issue for the AI"

### 仍存在的警惕

**验证习惯**：
> "I still double check my work"

## 核心专家策略

### 策略1：多工具交叉验证 ⭐⭐⭐⭐⭐

> "My strategy is that I would copy paste the same thing across different AI systems"
> "If most of them agree then, okay, I'm gonna take"

**效果**：
> "If they contradict, then I need to like manually verify"

### 策略2：结构化输入策略 ⭐⭐⭐⭐

> "I will outline...then okay, is the first thing that's wrong? Is the second thing incorrect? Is the third thing incorrect?"

### 策略3：专业领域避免使用 ⭐⭐⭐⭐

> "For searches regarding work and more specialized queries, I prefer to use Google because Google is more reliable"

### 策略4：限制依赖策略 ⭐⭐⭐

> "I try not to rely on it too much"
> "I try not to use it for very critical things"

## 深层认知

### 对AI擅长任务的理解 ⭐⭐⭐⭐

> "It's the good at writing, right? When you're writing emails or when you're trying to construct proposal or trying to express your thoughts"
> "Information gathering...good...especially like general information"

### 对AI不擅长任务的理解 ⭐⭐⭐⭐

> "I would say it's still not very good at citations"
> "More specialized queries, I prefer to use Google"

### 对未来发展的看法 ⭐⭐⭐⭐

> "I believe that Gen AI is just tool...like PowerPoint"
> "It is inevitable...like a trend"

## 独特发现

### 1. 多系统交叉验证法 ⭐⭐⭐⭐⭐

> "Copy paste the same thing across different AI systems...if most agree, I take"

**理论价值**：通过多个AI系统共识来提高可信度

### 2. 信任随版本提升 ⭐⭐⭐⭐

> "After the AI do improvements, releasing the new versions, I think the accuracy went out"

**理论价值**：AI工具的版本升级可以提升用户信任

### 3. 工具化认知 ⭐⭐⭐⭐

> "Gen AI is just tool...like PowerPoint"

## 对论文的核心价值

### 1. 版本升级带来的信任提升案例

从60%到80%的信任提升，归因于AI版本改进

### 2. 多系统共识验证策略

独特的跨平台验证方法

### 关键引用（可用于论文）

1. **信任提升**：
   > "Before using, I would say like sixty...I still 80"

2. **交叉验证**：
   > "Copy paste the same thing across different AI systems"

3. **工具认知**：
   > "Gen AI is just tool...like PowerPoint"

4. **版本改进认可**：
   > "After the AI do improvements...I think the accuracy went out"

## 八、分析验证

待核对的关键引用：
- [x] "Before using, I would say like sixty" ✓ (line 1614)
- [x] "I still 80" ✓ (line 1620)
- [x] "After the AI do improvements, releasing the new versions" ✓ (line 1608)
- [x] "I still double check my work" ✓ (line 1620)
- [x] "Gen AI is just tool...like PowerPoint" ✓ (line 1797)

---
*分析完成时间：2025年1月*

---


<a id="受访人38"></a>

# 受访人38：AI研究员 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | AI领域研究员/学生 |
| 研究方向 | 人工智能 |
| 技术采用 | 最早期采用者（ChatGPT发布第一天） |
| 使用频率 | 每天使用 |
| 主要工具 | ChatGPT（付费）、Claude、Perplexity |
| 特殊工具 | Claude Code、Gemini CLI |
| 培训方式 | 自学（阅读文献、专家访谈） |

## 使用场景

### 场景1：资源搜索与整理 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "Mainly I use it for resources. I'll just open everything it ask me to open"

**效率提升**：
> "I usually used to have multiple tabs for different keywords...but now it's just one tab"

### 场景2：代码开发 ⭐⭐⭐⭐⭐

**使用方式**：
> "I'm using the extensive...Cloud Code credits. So this is how I code. I'll just code everything through cloud code"

**策略转变**：
> "Overtime, as I see how it's not as good...I kind of revert to my old way of working now"

### 场景3：论文总结（已弃用）⭐⭐⭐

**过去使用**：
> "I used to do...usually I used to have it summarize for me"

**现在改变**：
> "I found that its summarization is not actually as good as my reading comprehension"

## 信任轨迹：钟形曲线型（先升后降）⭐⭐⭐⭐⭐

### 信任演变 ⭐⭐⭐⭐⭐

> "It follows like bell curve or something"
> "Initially...around 20%. Then I think peak in 2024...maybe 80% or 90% even in the peak"
> "Now I think it's like 20%"

**从20%→80-90%→20%**

### 信任下降原因

**1. 期望提高**：
> "Your expectation also increase...expectation disappointment, expectation disappointment"

**2. 深入理解局限**：
> "Because I'm quite involved in the field of AI...I read literatures or interviews...that talk about limitation"

**3. 心智模型形成**：
> "I have better mental model on what kind of task I can assign it"

## 核心专家策略

### 策略1：任务适配策略 ⭐⭐⭐⭐⭐

> "Now I know better what kind of task it is supposed to do"
> "I use it for something that is...repetitive task...not cognitively challenging"

### 策略2：写作自主策略 ⭐⭐⭐⭐⭐

> "Right now I try not to write with ChatGPT. My writing is entirely done by me"
> "I think it's quite the...cognitively then dangerous"

### 策略3：记忆功能利用 ⭐⭐⭐⭐

> "GPT has this thing called memory mode. It can refer to your conversations"

### 策略4：风险评估策略 ⭐⭐⭐⭐

> "It depends on...the risk level...if there's no risk...I'll just do it"

## 深层认知：认知危害意识 ⭐⭐⭐⭐⭐

### 对意图表达能力的担忧 ⭐⭐⭐⭐⭐

> "I feel that I lose my first, my value"
> "I lose the ability to convey my intention properly"
> "More complex intentions, I...I lost it"

### 对社会影响的深刻反思 ⭐⭐⭐⭐⭐

> "ChatGPT is an AI product...similar patterns...social media, it's an AI product and it's not good for society overall"
> "In 10 years time, I'm not sure if we're going to judge it the same"

### 对认知能力退化的警示 ⭐⭐⭐⭐⭐

> "If you outsource everything there, especially your writing...you won't be able to convey your intentions very effectively"
> "If you don't know what you want, then who knows...I don't think happy that way"

## 独特发现

### 1. 钟形信任曲线 ⭐⭐⭐⭐⭐

> "It follows like bell curve"

**理论价值**：信任可以先升后降，取决于期望管理和深入了解

### 2. 主动戒断行为 ⭐⭐⭐⭐⭐

> "I wean myself off this habit of depending on it"

**理论价值**：用户可以主动减少依赖

### 3. AI产品社会影响类比 ⭐⭐⭐⭐⭐

> "Social media is actually meant to connect us, but people feel more disconnected than ever"

**理论价值**：将GenAI与社交媒体的社会影响进行类比

### 4. 给新手的建议 ⭐⭐⭐⭐⭐

> "First, don't use it too extensively"
> "Use it for something that...doesn't require higher order thinking skills"
> "Third is maybe don't do your writing with GPT"

## 对论文的核心价值

### 1. 信任动态变化的典型案例

完整的"钟形曲线"信任轨迹

### 2. 认知危害的深度反思

对写作能力和意图表达能力退化的亲身体验

### 3. 主动戒断的用户策略

有意识地减少对AI的依赖

### 关键引用（可用于论文）

1. **钟形信任**：
   > "It follows like bell curve...Initially 20%...peak 80-90%...now 20%"

2. **认知危害**：
   > "I feel that I lose...my ability to convey my intention properly"

3. **主动戒断**：
   > "I try not to write with ChatGPT...cognitively dangerous"

4. **社会影响类比**：
   > "ChatGPT...similar patterns...social media...not good for society overall"

5. **给新手建议**：
   > "Don't use it too extensively...don't do your writing with GPT"

## 八、分析验证

待核对的关键引用：
- [x] "It follows like bell curve or something" ✓ (line 2043)
- [x] "I lose the ability to convey my intention properly" ✓ (line 2235)
- [x] "I try not to write with ChatGPT" ✓ (line 2217)
- [x] "Social media is actually meant to connect us, but people feel more disconnected" ✓ (line 2343)
- [x] "Don't use it too extensively" ✓ (line 2301)

---
*分析完成时间：2025年1月*

---


<a id="受访人39"></a>

# 受访人39：安全顾问 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 安全顾问（兼读NTU硕士） |
| 教育背景 | 化学工程学士（NTU） |
| 工作领域 | 过程安全咨询 |
| 技术采用 | 谨慎评估后采用 |
| 使用起始 | 2023年末 |
| 使用频率 | 几乎每天 |
| 主要工具 | ChatGPT（免费）、Co-pilot |
| 培训方式 | 自学 |

## 使用场景

### 场景1：PowerPoint结构设计 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "The most frequent for my job scope at the moment is creating a Powerpoint structure"
> "Which topics should you put in"

### 场景2：Excel代码生成 ⭐⭐⭐⭐

**使用方式**：
> "I ask GBT to help me code something for Excel purpose"

### 场景3：语法检查与改写 ⭐⭐⭐⭐

**使用方式**：
> "Grammar checking or rephrasing"

### 场景4：研究搜索 ⭐⭐⭐⭐

**工具对比**：
> "Yesterday I tried using copilot to rate something for me from searching the webs...compare against ChatGPT"

## 信任轨迹：渐进提升型

### 信任演变 ⭐⭐⭐⭐

> "Before was skeptical...30% or not sure what's this is going to do"
> "After using it...more confident of it"
> "Can go from 40 to 50, maybe at most 60%"

**从30%提升到50-60%**

### 信任提升原因

> "It actually does help in a lot of things that I've tried"

### 仍存在的顾虑

**1. 内容正确性**：
> "Even though the output is nice...there are times where the content is not accurate"

**2. 信息安全**：
> "The concern is more about the information's sharing of confidential information"

## 核心专家策略

### 策略1：工具差异化使用 ⭐⭐⭐⭐

> "ChatGPT so far I've been using for a more general topics"
> "The co pilot, I'm more using it for searching documents"

### 策略2：迭代优化策略 ⭐⭐⭐⭐

> "During my first interaction with chat GBT, I wasn't satisfied...because I used a wrong prompt"
> "After I changed my prompt, then I think the result is better"

### 策略3：人工验证策略 ⭐⭐⭐⭐

> "I'll still need to have people to verify whether the things written is correct"

### 策略4：时间效率权衡 ⭐⭐⭐⭐

> "Using the same time...like maybe I'm using 30 minutes to find out the correct prompt...I think still Chat GBT wins in this situation"

## 深层认知

### 对AI优势的理解 ⭐⭐⭐⭐

**效率提升**：
> "I think it helps, maybe with my search that I do, it helps me to be more efficient"
> "I think around 30% more efficient"

**重复任务**：
> "For repeated task, for some very basic task, it's useful, but for very specialized areas, I prefer to do more research myself"

### 对AI局限的理解 ⭐⭐⭐⭐

> "Very specialized areas, I prefer to do more research myself"
> "The content is not accurate"

## 独特发现

### 1. 工作与学业双重场景 ⭐⭐⭐⭐

同时在咨询工作和NTU硕士学习中使用

### 2. 工具差异化认知 ⭐⭐⭐⭐

> "ChatGPT for general topics, Co-pilot for documents"

### 3. 效率提升量化 ⭐⭐⭐⭐

> "30% more efficient"

## 对论文的核心价值

### 1. 职场专业人士案例

咨询行业的实际应用场景

### 2. 渐进式信任提升

从怀疑到中等信任的过渡

### 关键引用（可用于论文）

1. **信任演变**：
   > "Before was skeptical...30%...can go from 40 to 50, maybe 60%"

2. **效率提升**：
   > "Around 30% more efficient"

3. **工具分工**：
   > "ChatGPT for general topics, Co-pilot for documents"

4. **准确性顾虑**：
   > "There are times where the content is not accurate"

## 八、分析验证

待核对的关键引用：
- [x] "The most frequent for my job scope at the moment is creating a Powerpoint structure" ✓ (line 2487)
- [x] "ChatGPT so far I've been using for a more general topics" ✓ (line 2439)
- [x] "Around 30% more efficient" ✓ (line 2791)
- [x] "There are times where the content is not accurate" ✓ (line 2595)
- [x] "The concern is more about the information's sharing of confidential information" ✓ (line 2884)

---
*分析完成时间：2025年1月*

---


<a id="受访人40"></a>

# 受访人40：航空工程博士生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 博士生（TTP项目） |
| 研究方向 | Wing and Mandarin Vehicles |
| 教育背景 | 航空航天工程 |
| 技术采用 | 第二批采用者（早期采用者之后） |
| 使用起始 | 受同伴影响开始 |
| 使用频率 | 每2-3天一次 |
| 主要工具 | ChatGPT（免费）、Co-pilot |
| 培训方式 | 无正式培训 |

## 使用场景

### 场景1：学术论文搜索 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "I use Chat GBD to help me to collate the relevant papers in the relevant fields"
> "It can be a lot more specific compared to using Google Scholar"

**具体优势**：
> "If I wanna a paper on specifically on an aircraft of like 1 meter wing span, I wouldn't be able to find it to Google Scholar"
> "Sometimes the papers that I need...not very well cited...I need stuff that is not well cited at all"

### 场景2：代码调试（有保留）⭐⭐⭐

**使用方式**：
> "I ask ChatGPT...give it an example code...ask it to base it off that"

**经验教训**：
> "I found a very critical error in the formulation by GPT...my trust went down"

## 信任轨迹：任务差异化信任型

### 信任水平 ⭐⭐⭐

> "6 out of 10"

### 任务差异化 ⭐⭐⭐⭐⭐

**搜索任务**：
> "For the research paper kind of task...my trust has gone up...more or less in line with what I think"

**编程任务**：
> "For coding, especially engineering and math...my trust has gone down"
> "I found a very critical error in the formulation by GPT"

## 核心专家策略

### 策略1：提示词精心设计 ⭐⭐⭐⭐

> "I will like right now and comment what are the information I need...try to craft the prompt in a way that ChatGPT will understand me"

### 策略2：初步提供80%信息 ⭐⭐⭐⭐

> "Most of the time, I think I provide like maybe 80% of what CGP team will from me"

### 策略3：快速理智检查 ⭐⭐⭐⭐

> "I at least read through...give a sanity check...I read if the content makes sense"

### 策略4：任务拆分 ⭐⭐⭐

> "Maybe two parts"

## 深层认知

### 开始使用的动机 ⭐⭐⭐⭐

> "Two factors. One was all my peers were using it...peer pressure is one"
> "The other one would be...I wasn't finding what I needed to find with Google"

### 对AI角色的理解 ⭐⭐⭐⭐

> "It almost feels that way...but I still need to craft my prompts in a way that ChatGPT can understand me"
> "Maybe in between...like in between" (human and computer)

### 对AI过度自信的观察 ⭐⭐⭐⭐

> "ChatGPT mostly sounds very confident...I wonder if it's just the programming behind"

## 独特发现

### 1. 任务差异化信任 ⭐⭐⭐⭐⭐

> "For research paper...trust has gone up...for coding...trust has gone down"

**理论价值**：用户对同一工具的信任可以按任务类型分化

### 2. 特定领域搜索优势 ⭐⭐⭐⭐⭐

> "I wouldn't be able to find it to Google Scholar because...they rank base on citation...I need stuff not well cited"

**理论价值**：AI可以发现被传统搜索忽略的长尾内容

### 3. 关键错误经历影响 ⭐⭐⭐⭐

> "I found a very critical error in the formulation"

**理论价值**：单次严重错误可以显著降低特定领域的信任

## 对论文的核心价值

### 1. 任务差异化信任模型

同一用户对不同任务类型的信任可以分化

### 2. 长尾内容搜索优势

AI在发现非热门但相关内容方面的独特价值

### 建议与担忧

> "First step would be don't trust everything that it tells you"
> "The second thing would be to craft your prompts clearly"

### 数据安全担忧 ⭐⭐⭐⭐

> "Not knowing what goes on behind the scenes, where the data goes"
> "I have not really prompted anything about my research, as in like my core parts of the research yet"

### 关键引用（可用于论文）

1. **任务差异化信任**：
   > "For research paper...trust has gone up...for coding...trust has gone down"

2. **长尾搜索优势**：
   > "Papers that I need are not very well cited...I need stuff not well cited"

3. **数据安全担忧**：
   > "I have not prompted anything about my core parts of the research"

4. **新手建议**：
   > "Don't trust everything...craft your prompts clearly"

## 八、分析验证

待核对的关键引用：
- [x] "I use Chat GBD to help me to collate the relevant papers" ✓ (line 2971)
- [x] "6 out of 10" ✓ (line 3052)
- [x] "For the research paper kind of task...my trust has gone up" ✓ (line 3057)
- [x] "I found a very critical error in the formulation by GPT" ✓ (line 3058)
- [x] "Don't trust everything that it tells you" ✓ (line 3166)

---
*分析完成时间：2025年1月*

---


<a id="受访人41"></a>

# 受访人41：物理学博士生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 博士生 |
| 国籍 | 印度（喀拉拉邦） |
| 研究方向 | 理论光学 |
| 教育背景 | 物理学学士和硕士 |
| 技术采用 | 早期采用者 |
| 使用频率 | 每天使用 |
| 主要工具 | Claude（Anthropic）、ChatGPT、DeepSeek |
| 特殊工具 | 偏好Claude用于编程 |
| 培训方式 | 自学 |

## 使用场景

### 场景1：代码开发 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "My work completely relies on like theoretical computation"
> "Claude...primarily for the coding kind of things. According that it's useful"

**策略**：
> "I just go blindly to the AI tools and say, okay, what is this towards this...it's an exploration thing"
> "After some time...my prompts get more and more restricted, more and more specific"

### 场景2：论文阅读辅助 ⭐⭐⭐⭐⭐

**使用方式**：
> "I'll just upload it...give me the...tell me the story. Tell me why they're doing this. What is the novelty"

**交互式学习**：
> "Explain in sections only when I've understood the section, ask me questions...if I answer correctly, then only you should move to the next section"

### 场景3：考试准备 ⭐⭐⭐⭐

**创意应用**：
> "I downloaded the question papers, I gave it to him. Assume you're a professor. How will you change these questions"

## 信任轨迹：显著下降型

### 信任演变 ⭐⭐⭐⭐⭐

> "Actually, it was very high earlier days...75%"
> "Now it's gone down...now it's like 40 percentage"

**从75%降到40%**

### 信任下降原因

**1. 长期使用看到错误**：
> "You use it for a long time and you obviously see the mistakes it makes"

**2. 尴尬经历**：
> "I generated a bunch of theory with the help of AI...went and showed it to my professor...he started pointing out the mistakes"
> "I felt so stupid that day"

**3. 永远自信的问题**：
> "Every time it's like fully confident. And I would say, no, it's wrong. It's like, oh my bad, sorry...you're absolutely right. And then it will give the next wrong answer"

## 核心专家策略

### 策略1：探索到精确的渐进策略 ⭐⭐⭐⭐⭐

> "First...exploration thing...after some time...prompts get more and more restricted, more and more specific"
> "The last step of my workflow doesn't involve AI at all"

### 策略2：逐行代码审查 ⭐⭐⭐⭐⭐

> "After I have about the full code, I know it's working, I manually go in check every line"
> "Does it make sense? Does it make sense?"

### 策略3：模块化代码请求 ⭐⭐⭐⭐⭐

> "When it tends to write longer pieces of code, it tends to lose more information"
> "I'd rather have it built up piece by piece"

### 策略4：避免领域特定术语 ⭐⭐⭐⭐

> "At this point, you shouldn't bring very technical terms into it"
> "The moment I say something about light or something, it just pulls in all information from lights"

### 策略5：提供具体示例 ⭐⭐⭐⭐⭐

> "Giving examples in prompts...first I need to give the background"
> "Step by step...in steps"

### 策略6：角色分配策略 ⭐⭐⭐⭐

> "Imagine that you're a professor looking at this work. What all would you want me to explain more?"

## 深层认知

### 对AI代码能力的矛盾认知 ⭐⭐⭐⭐⭐

> "It's a dilemma because I know it can go better than me"
> "But the dilemma is that with something so good can produce very bad results"
> "It depends on you" (prompt engineering能力)

### 对AI"作弊"行为的观察 ⭐⭐⭐⭐⭐

> "These LLMs, they're just trying to do one thing, that is to give you the answer"
> "They will do all sorts of cheating methods to give you that answer"

### 对过度自信的强烈批评 ⭐⭐⭐⭐⭐

> "At no point is it like, okay, I'm not sure about the answer"
> "I can't because I know it gets it wrong"
> "Even if tomorrow it says, okay, I'm not sure about it, still I wouldn't trust it"

## 独特发现

### 1. 工作流最后阶段排除AI ⭐⭐⭐⭐⭐

> "The last part is just not using AI at all"

**理论价值**：即使重度使用AI，关键验证阶段仍需人工

### 2. "作弊"行为洞察 ⭐⭐⭐⭐⭐

> "They will do all sorts of cheating methods to give you that answer"

**理论价值**：用户认识到AI会以任何方式达成目标

### 3. 交互式学习设计 ⭐⭐⭐⭐⭐

> "Explain in sections...ask me questions...if I answer correctly, then only move to the next section"

**理论价值**：用户可以设计复杂的学习交互模式

### 4. 专业术语避免策略 ⭐⭐⭐⭐

> "The moment I say something about light...it just pulls in all information"

**理论价值**：领域术语可能导致AI过度联想

## 对论文的核心价值

### 1. 信任显著下降案例

从75%到40%的信任下降轨迹

### 2. 逐行代码审查实践

极度严谨的验证方法

### 3. AI"作弊"行为认知

对AI优化输出策略的深刻理解

### 关键引用（可用于论文）

1. **信任下降**：
   > "It was very high earlier days...75%...now it's like 40 percentage"

2. **尴尬经历**：
   > "I showed it to my professor...he pointed out the mistakes...I felt so stupid"

3. **AI作弊**：
   > "They will do all sorts of cheating methods to give you that answer"

4. **最后阶段排除AI**：
   > "The last part is just not using AI at all"

5. **过度自信批评**：
   > "Every time it's like fully confident...at no point is it like I'm not sure"

## 八、分析验证

待核对的关键引用：
- [x] "My work completely relies on like theoretical computation" ✓ (line 3275)
- [x] "It was very high earlier days...75%...now it's like 40 percentage" ✓ (line 3455)
- [x] "The last part is just not using AI at all" ✓ (line 3314)
- [x] "They will do all sorts of cheating methods to give you that answer" ✓ (line 3314)
- [x] "I felt so stupid that day" ✓ (line 3461)

---
*分析完成时间：2025年1月*

---


<a id="受访人42"></a>

# 受访人42：材料科学博士生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 博士生（第三年） |
| 学校 | NTU材料科学与工程学院 |
| 研究方向 | 生物材料（纳米颗粒）|
| 技术采用 | 视情况而定型（有用且可信才采用）|
| 使用起始 | 社交媒体趋势推动 |
| 使用频率 | 规律使用 |
| 主要工具 | ChatGPT（免费）、DeepSeek、Grammarly |
| 培训方式 | 无正式培训 |

## 使用场景

### 场景1：实验方案验证 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "If this protocol I'm using, I'm not sure is it correct...I will type out, then ask him to check for me"
> "Cite if there is any other paper that is related to what I have written"

### 场景2：语法检查与改写 ⭐⭐⭐⭐

**使用方式**：
> "Paraphrasing...grammar check"

### 场景3：文献搜索 ⭐⭐⭐⭐

**使用方式**：
> "If I want to find any paper is related, then I will ask for the title"

### 场景4：论文理解 ⭐⭐⭐⭐

**使用方式**：
> "Can you summarize this kind of paper? What is it about...Then after you read, you don't really understand. They can ask question"

**与Google Scholar对比**：
> "ChatGPT can give you some insights if you ask more...helping you to understand"
> "Scholar just give you the article, won't tell you to interpret"

## 信任轨迹：使用后提升型

### 信任演变 ⭐⭐⭐⭐

> "Maybe 60% of trust...because anyways, this machine, right, not a human"
> "After I use, maybe it's around 80%"

**从60%提升到80%**

### 信任提升原因

> 使用体验验证了工具的实用性

## 核心专家策略

### 策略1：宽问窄答策略 ⭐⭐⭐⭐

> "I will ask a general question and see what's the respond first. Then after that, I will ask bit by bit"

### 策略2：逻辑验证策略 ⭐⭐⭐⭐

> "By the answer that they give me...it's not very logical to my thinking. That's why I will check"
> "If seems logical, then I won't check"

**验证标准**：
> "I use some of my personal understanding and emotion"

### 策略3：多源验证策略 ⭐⭐⭐⭐

> "I will also check online like the normal Google search"
> "Most importantly, check with my mentor. So a human"

### 策略4：追问确认策略 ⭐⭐⭐

> "I will keep asking question until I as are you sure is correct"

## 深层认知

### 对AI优势的理解 ⭐⭐⭐⭐

**知识广度**：
> "For the new things that I don't really know. I think ChatGPT knows more than what we think of"
> "If I would want to know things outside my study, he is better than me"

### 对人类优势的理解 ⭐⭐⭐⭐

**实践经验**：
> "I might be better in terms of like practical kind of stuff"
> "ChatGPT give you the protocol, but don't really tell you about what are some things that you can really face when you're doing the experiment"

**情感支持**：
> "My friend told me that she talk to ChatGPT after she broke up...for us, we will ask question...it's more emotional stuff"

### 对依赖程度的认知 ⭐⭐⭐⭐

> "I don't think that I'm highly dependent on that"
> "I think I got balance between it"
> "What you face might not be what on their degree...So that's the point you need to solve yourself"

## 独特发现

### 1. 逻辑一致性作为验证标准 ⭐⭐⭐⭐

> "Not very logical to my thinking...that's why I will check"

**理论价值**：用户依赖直觉来决定是否需要验证

### 2. 实践经验vs理论知识 ⭐⭐⭐⭐

> "Protocol but don't tell you about what you can really face"

**理论价值**：AI擅长理论但缺乏实验实践智慧

### 3. 情感支持的局限性 ⭐⭐⭐⭐

> "AI type of wording...for us, we will ask question...why do you think so"

**理论价值**：人类情感支持的不可替代性

### 4. 持续控制感 ⭐⭐⭐⭐

> "I'm the one who always ask questions. So I think I'm the one who's controlling"

## 对论文的核心价值

### 1. 实验科学应用案例

生物材料领域的具体应用场景

### 2. 理论vs实践的区分

对AI知识局限性的深刻理解

### 3. 平衡使用的自我评估

用户对自身依赖程度的清醒认知

### 关键引用（可用于论文）

1. **信任提升**：
   > "Maybe 60%...after I use, maybe 80%"

2. **理论vs实践**：
   > "Protocol but don't tell you about what you can really face when doing the experiment"

3. **逻辑验证**：
   > "Not very logical to my thinking...that's why I will check"

4. **控制感**：
   > "I'm the one who always ask questions...I'm controlling"

5. **平衡认知**：
   > "I don't think highly dependent...I got balance between it"

## 八、分析验证

待核对的关键引用：
- [x] "If this protocol I'm using, I'm not sure is it correct" ✓ (line 3827)
- [x] "Maybe 60% of trust...After I use, maybe it's around 80%" ✓ (line 3950)
- [x] "ChatGPT give you the protocol, but don't really tell you about what you can really face" ✓ (line 3890)
- [x] "I'm the one who always ask questions. So I think I'm the one who's controlling" ✓ (line 4046)
- [x] "I don't think that I'm highly dependent on that" ✓ (line 4034)

---
*分析完成时间：2025年1月*

---


<a id="受访人43"></a>

# 受访人43：内容创作者/健身教练 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 内容创作者、健身培训师、运动员 |
| 工作领域 | 健身、体育竞技、自媒体 |
| 背景 | 世界冠军级别运动员 |
| 技术采用 | 实用主义采用者 |
| 使用起始 | AI功能出现后 |
| 使用频率 | 日常工作中频繁使用 |
| 主要工具 | ChatGPT、豆包 |
| 培训方式 | 自学 |

## 使用场景

### 场景1：内容框架生成 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "我会给他一个身份...我作为一个播客内容的策划者...AI就会生成一个比较完整的，比较系统，有逻辑的一个框架给我"

**具体策略**：
> "我会把我想要问的问题我都喂给他...他自己就有个身份了，他就会往这个维度去思考"

### 场景2：视频制作与剪辑 ⭐⭐⭐⭐⭐

**使用方式**：
> "现在有了ai以后...剪辑也很好用，然后包括好多的东西都可以用ai生成"
> "承接我70%的工作了...比如说做一些海报"

### 场景3：学术参考文献搜索 ⭐⭐⭐

**使用方式**：
> "我还会要问ai去要一个关于就是在学术方面的一些参考文献"

**局限认知**：
> "给的有时候一些reference其实还挺落后的...我能用到的其实50%都不到"

## 信任轨迹：任务差异化信任型

### 信任水平 ⭐⭐⭐⭐

> "我觉得可信程度可能70%"

### 任务差异化表现

**高信任领域**（创意辅助、视频制作）：
> "承接我70%的工作了"

**低信任领域**（专业训练、学术内容）：
> "对几乎毫无用处，还是我自己做的训练计划才有帮助"
> "我能用到的其实50%都不到"

## 核心专家策略

### 策略1：身份设定策略 ⭐⭐⭐⭐⭐

> "首先就是第一，给他一个身份，让他知道他是一个做我的这个...内容的一个创作者"

### 策略2：框架导向使用 ⭐⭐⭐⭐⭐

> "我更多的是看他是怎么思考的...给我一个框架...能够让我知道把这个书放到什么位置"
> "更多的是我想要一个方向，而不是说直接拿他的这个给到的结果"

### 策略3：多工具对比验证 ⭐⭐⭐⭐

> "我会出两个，两个都用一遍，然后去选一个我觉得比较满意的，或者是去去结合一下"

### 策略4：领域分工策略 ⭐⭐⭐⭐

> "不光是录播客...我用ChatGPT会用英文写...豆包我会用中文写"
> "假设我的这个访谈...偏向于交谈...我可能会用豆包多一点"

## 深层认知

### 对AI能力边界的清晰认知 ⭐⭐⭐⭐⭐

> "AI它只能给到你的是现在互联网已经有的知识...如果真的想创作一些内容出来，发表一些比较鲜有人知的事情...还是不能依赖AI的"

### 对人机协作的理解 ⭐⭐⭐⭐⭐

> "AI是永远替代不了健身教练的，因为健身他就是一个人情味的东西"
> "还是附属吧，互补都比较困难...他只是让我更有效率而已"

### 对AI局限性的深刻理解 ⭐⭐⭐⭐⭐

**无法提供情绪支持**：
> "AI给不到一个正反馈啊...至少他给不到一个情绪上的正反馈"

**无法处理高变量任务**：
> "他的年龄会慢慢增长，然后他每天的情绪每天的疲劳指数都不一样。AI其实无法监控这些东西"

## 独特发现

### 1. "人味儿"作为AI壁垒 ⭐⭐⭐⭐⭐

> "对他缺这个人味...他只能给你互联网上面已有的内容，他不能创造新的"

**理论价值**：用户认为AI缺乏人情味是其在服务行业的核心局限

### 2. 专业领域的"无法替代"认知 ⭐⭐⭐⭐⭐

> "我觉得我觉得不管什么时候都构不成威胁...就像这个东西跟做咖啡不一样"

**理论价值**：高人际互动行业对AI替代的抵制

### 3. 框架vs内容的使用哲学 ⭐⭐⭐⭐

> "给我一个框架...然后我顺着这个框架，我会去自己去查阅文献，这个，我觉得更可靠一点"

**理论价值**：用户将AI定位为思路启发而非内容生产

### 4. 效率工具定位 ⭐⭐⭐⭐

> "我不用他其实对我的工作也不会有太大的影响，他只是让我减少了工作时间"

## 对论文的核心价值

### 1. 任务差异化信任案例

同一用户对AI在不同任务类型上有明显不同的信任水平

### 2. 高人际互动行业的AI边界认知

健身教练视角下AI无法替代人类的核心原因

### 3. 框架导向使用模式

将AI定位为思路启发工具而非内容生产者

### 关键引用（可用于论文）

1. **任务差异化信任**：
   > "承接我70%的工作了"（创意工作）vs "对几乎毫无用处"（专业训练）

2. **人味儿壁垒**：
   > "AI是永远替代不了健身教练的，因为健身他就是一个人情味的东西"

3. **框架导向**：
   > "我更多的是看他是怎么思考的...给我一个框架"

4. **效率定位**：
   > "他只是让我减少了工作时间...让我更效率"

5. **创新局限**：
   > "他只能给你互联网上面已有的内容，他不能创造新的"

## 八、分析验证

待核对的关键引用：
- [x] "我会给他一个身份...播客内容的策划者" ✓ (line 29)
- [x] "承接我70%的工作了" ✓ (line 337)
- [x] "我觉得可信程度可能70%" ✓ (line 837)
- [x] "AI是永远替代不了健身教练的，因为健身他就是一个人情味的东西" ✓ (line 701)
- [x] "我能用到的其实50%都不到" ✓ (line 189)

---
*分析完成时间：2025年1月*

---


<a id="受访人44"></a>

# 受访人44：AI视频制作人 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 项目经理/商务（AI视频制作团队） |
| 工作领域 | AI视频制作、电影、广告 |
| 教育背景 | 无人机行业转型 |
| 技术采用 | 早期全面采用者 |
| 使用起始 | 2023年开始 |
| 使用频率 | 几乎每天使用 |
| 主要工具 | Sora、Runway、可灵、豆包、Midjourney |
| 培训方式 | 自学+团队协作 |

## 使用场景

### 场景1：视频素材生成 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "视频的创意构思啊，脚本撰写优化，然后分镜啊，包括视频素材的生成编辑"

**工作流程**：
> "每一个部分都会需要人跟AI两个部分相去结合，不是单单说我光靠人就完成所有，也不是单靠所有的工具就完成"

### 场景2：脚本创作与优化 ⭐⭐⭐⭐

**使用方式**：
> "我们前期的脚本还是要先人过来...有一些脚本是会交给AI去把它优化的"

**局限认知**：
> "AI也可以写，但是有些东西可能没有那么完美"

### 场景3：配音配乐 ⭐⭐⭐⭐

**使用方式**：
> "配音配乐...这里面每一个部分都会需要人跟AI两个部分相去结合"

## 信任轨迹：结果导向型

### 信任核心观点 ⭐⭐⭐⭐⭐

> "信任就是结果啊，让你看不出来哪个是AI做的，我可以做到这样子"

### 质量评估

**电影级别**：
> "如果电影的话，90...还是比CG会差一点"

**广告级别**：
> "如果你说只是做广告内容，我觉得是可以到95"

## 核心专家策略

### 策略1：人机分工协作 ⭐⭐⭐⭐⭐

> "你一定要人，因为他不知道他什么地方做错了"
> "他是一个超级助手，他能够给你很快给你要的东西，但是他不知道他给你的东西对不对"

### 策略2：迭代调教策略 ⭐⭐⭐⭐

> "运气好，可能三轮就够了，运气不好，你有时候20轮，30轮都有可能"
> "我们当时有时候要做到几十轮，他才能找到一个我们比较满意的"

### 策略3：素材限定策略 ⭐⭐⭐⭐⭐

> "需要先去先告诉他这是什么东西...简单的去训练一下，告诉他这个史实是怎么样的"

### 策略4：精确指令策略 ⭐⭐⭐⭐

> "你要的越精确，那你人工参与的还是要更多"
> "比如说我要从45度角仰拍...镜头怎么拉远...色调要什么样"

## 深层认知

### 对AI能力边界的理解 ⭐⭐⭐⭐⭐

**素材局限**：
> "假如没有这方面素材，但是它一定会给你...巧妇难为无米之炊"
> "他给你一些原朝清朝甚至宋朝的东西，因为里面没有这些资源"

**创意局限**：
> "他能够给。但是，他会给...你要叫他写个剧本，什么他也能给，但是肯定就没有人来的那么的..."

### 对AI价值的核心认知 ⭐⭐⭐⭐⭐

> "主要还是效率...所有的归根到底都是效率"
> "AI是极大极大程度的提高了效能"

### 对行业影响的认知 ⭐⭐⭐⭐⭐

> "95%的生产力是会被代替的，人在未来真的，有可能他真的就没有那么多工作让你去做了"
> "摄影师看到这个东西...就很慌，他说完了，这球真的不需要我"

## 独特发现

### 1. "信任就是结果"哲学 ⭐⭐⭐⭐⭐

> "信任就是结果啊，让你看不出来哪个是AI做的"

**理论价值**：用户对AI的信任基于输出质量而非过程

### 2. 素材驱动的质量观 ⭐⭐⭐⭐⭐

> "他一定会给你东西，你不可能一下子就把东西全部写好，因为他对历史具体时候给到你的东西的话，他无法判断他自己给你的是不是对的"

**理论价值**：AI能力受限于训练数据覆盖范围

### 3. 审美能力作为核心竞争力 ⭐⭐⭐⭐

> "审美是一个大问题...天赋是很重要的"
> "只要具备创意性，还有具备一定的审美程度的话，其实是不会失业的"

### 4. 行业结构性变化认知 ⭐⭐⭐⭐⭐

> "他们一支广告片当时是上百万新币的...现在50,000块人家就嫌高"

## 对论文的核心价值

### 1. 结果导向的信任模型

信任完全取决于输出质量，而非使用过程

### 2. AI作为"超级助手"定位

> "他是一个超级助手...但是他不知道他给你的东西对不对"

### 3. 专业行业的AI影响案例

视频制作行业的具体工作流变革

### 关键引用（可用于论文）

1. **信任哲学**：
   > "信任就是结果啊，让你看不出来哪个是AI做的"

2. **效率核心**：
   > "主要还是效率...所有的归根到底都是效率"

3. **素材局限**：
   > "他一定会给你东西...巧妇难为无米之炊"

4. **行业预测**：
   > "95%的生产力是会被代替的"

5. **人机协作**：
   > "你一定要人，因为他不知道他什么地方做错了"

## 八、分析验证

待核对的关键引用：
- [x] "信任就是结果啊" ✓ (line 1541)
- [x] "他是一个超级助手" ✓ (line 1497)
- [x] "95%的生产力是会被代替的" ✓ (line 2037)
- [x] "每一个部分都会需要人跟AI两个部分相去结合" ✓ (line 153)
- [x] "你一定要人，因为他不知道他什么地方做错了" ✓ (line 1209)

---
*分析完成时间：2025年1月*

---


<a id="受访人45"></a>

# 受访人45：生物医学光学研究员 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 研究员（Research Fellow） |
| 机构 | NTU TRIP部门 |
| 研究方向 | 生物医学光学、计算成像 |
| 教育背景 | 光学工程/电气工程博士 |
| 技术采用 | 较早期采用者 |
| 使用起始 | 2019年（ChatGPT 3.5时期） |
| 使用频率 | 几乎每天 |
| 主要工具 | ChatGPT（付费）、Claude（付费）、Co-pilot |
| 培训方式 | 自学（试错法） |

## 使用场景

### 场景1：代码调试与注释 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "I write my own codes. I don't generate the codes...but I do use it to fix some very minor issues"
> "For codes I use Claude...I just needed some assistance to make it quicker"

**工具选择**：
> "I don't really trust...I don't really use ChatGPT for most of my coding...I've always use Claude because I feel that Claude is much better at this kind of engineering"

### 场景2：学术写作辅助 ⭐⭐⭐⭐

**使用方式**：
> "Sometimes we have a writer's block...to get an initial perspective"
> "I just maybe start off with some paragraphs...I don't let it write the methods"

### 场景3：文献整理 ⭐⭐⭐

**使用方式**：
> "20 big text references that I need from Google Scholar...I just go to ChatGPT"
> "I upload all the papers I've already read and let me review it specifically"

## 信任轨迹：渐进提升型（有上限）

### 信任演变 ⭐⭐⭐⭐⭐

> "Initially...that will be around 30, 35%"
> "I would say around 60%...a lot to be desired, but I think this is good"

**从35%提升到60%**

### 信任上限认知 ⭐⭐⭐⭐⭐

> "I will never completely be able to trust it. Maybe my cap will be around 75%, whatever it does"

### 信任提升原因

> "It started really changing when I started developing my own AI algorithms for certain tasks"
> "By that time, there were more advances...people started doing things with ChatGPT"

## 核心专家策略

### 策略1：项目分区策略 ⭐⭐⭐⭐⭐

> "I already compartmentalize into projects that I'm working on"
> "I create these projects...before you even give an initial prompt, you can upload so many files"

**效果**：
> "There is a lot of cross talk...it was easier for me to just compartmentalize"

### 策略2：丰富信息提示策略 ⭐⭐⭐⭐⭐

> "I am very particular about all the information I gave in the beginning itself because I notice that helps a lot"
> "I try to give as much information as possible and try to use as good English as possible"

### 策略3：小块调试策略 ⭐⭐⭐⭐

> "I don't do it like the for the entire code. I do it like in small part so that I can actually verify what exactly is happening"

### 策略4：工具分工策略 ⭐⭐⭐⭐

> "For codes I use Claude...if there is some extensive writing to do...I just go to ChatGPT"

### 策略5：边界设定策略 ⭐⭐⭐⭐

> "Set the tone and the limits of which it can...it shouldn't cross certain red lines"
> "Don't write any code. Yeah, just tell me what you think these errors are"

## 深层认知

### 对AI能力边界的理解 ⭐⭐⭐⭐⭐

> "It does not have the intuition that you have, which you gain from working in this in a particular field for a long time"
> "If you don't really understand what you're doing...I think it's going to be a very bad outcome"

### 对依赖程度的认知 ⭐⭐⭐⭐

> "I do not want them to...I, in the end of the day, I don't want to forget writing"
> "What this gen AI is to me is nothing more than a convenience"

### 对年轻人使用AI的担忧 ⭐⭐⭐⭐⭐

> "I do teach sometimes...a concern is that they've used a lot of AI. And I think that is very bad for critical thinking"
> "Chat GPT tends to make you feel better...you will be so disconnected"

## 独特发现

### 1. 信任上限理论 ⭐⭐⭐⭐⭐

> "I will never completely be able to trust it. Maybe my cap will be around 75%"

**理论价值**：用户对AI信任存在心理上限，不会随技术进步无限增长

### 2. 跨对话污染发现 ⭐⭐⭐⭐

> "There is a lot of cross talk. Like I might be working on two or three different things...I did notice that there was a lot of cross stuff"

**理论价值**：用户发现AI记忆功能可能导致不同项目间信息混淆

### 3. 准确性优先于速度 ⭐⭐⭐⭐

> "What I want is accuracy at a fast pace...accuracy. I do not want anything else"

### 4. 社交隔离担忧 ⭐⭐⭐⭐⭐

> "The worst part is you will be radicalized because somebody is reinforcing your thoughts without any discussion with anybody else"

**理论价值**：对AI强化用户既有观点、减少人际交流的担忧

## 对论文的核心价值

### 1. 信任上限模型

用户即使技术进步也有固定的信任天花板（75%）

### 2. 开发AI算法促进信任

> "It started really changing when I started developing my own AI algorithms"

### 3. 项目分区策略

作为避免"cross talk"的专家策略

### 关键引用（可用于论文）

1. **信任上限**：
   > "I will never completely be able to trust it. Maybe my cap will be around 75%"

2. **信任提升**：
   > "Initially...around 30, 35%...I would say around 60%"

3. **工具定位**：
   > "What this gen AI is to me is nothing more than a convenience"

4. **教育担忧**：
   > "I think that is very bad for critical thinking, especially in the formative years"

5. **直觉缺失**：
   > "It does not have the intuition that you have"

## 八、分析验证

待核对的关键引用：
- [x] "I will never completely be able to trust it. Maybe my cap will be around 75%" ✓ (line 434)
- [x] "Initially...that will be around 30, 35%" ✓ (line 194)
- [x] "I would say around 60%" ✓ (line 434)
- [x] "I don't really use ChatGPT for most of my coding...I've always use Claude" ✓ (verified)
- [x] "There is a lot of cross talk" ✓ (verified)

---
*分析完成时间：2025年1月*

---


<a id="受访人46"></a>

# 受访人46：学习科学硕士生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 硕士研究生 |
| 学校 | NTU（南洋理工大学） |
| 专业 | Science of Learning（学习科学） |
| 技术采用 | 早期探索者（自建聊天机器人） |
| 使用起始 | ChatGPT发布后不久 |
| 使用频率 | 每日使用 |
| 主要工具 | 自建聊天机器人（调用多模型API）、ChatGPT、Claude、Gemini、Mistral |
| 培训方式 | 自学 |

## 使用场景

### 场景1：学术写作辅助 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "I use it to help me structure my paragraphs"
> "I will give it a role...you are an academic writing assistant"

**具体策略**：
> "I'll tell them I'm writing a research paper...help me to structure this paragraph"

### 场景2：文献搜索与验证 ⭐⭐⭐⭐

**使用方式**：
> "I will ask it to give me journal articles"

**负面经历**：
> "I found that 3 or 4 of them do not exist"
> "The hallucination problem is still quite prevalent"

### 场景3：代码生成 ⭐⭐⭐⭐

**使用方式**：
> "Coding wise...I will use it to help me generate code"

### 场景4：概念解释 ⭐⭐⭐

**使用方式**：
> "Explain concepts to me...like a tutor"

## 信任轨迹：使用后下降型 ⭐⭐⭐⭐⭐

### 信任演变

> "When I first started using it, I would say around 50"
> "I seem to trust the AI less...maybe around 30"

**从50%下降到30%**

### 信任下降原因

**1. 幻觉经历**：
> "I found that 3 or 4 of them do not exist"
> "The hallucination problem is still quite prevalent"

**2. 同行观察**：
> "Seeing other people use it...they tend to trust it too much"
> "I've seen people just copy and paste without checking"

**3. 深入了解后的警惕**：
> "The more I use it, the more I realize its limitations"

## 核心专家策略

### 策略1：角色分配策略 ⭐⭐⭐⭐⭐

> "I will give it a role...you are an academic writing assistant"
> "Giving it a specific role helps to narrow down the responses"

### 策略2：协作伙伴视角 ⭐⭐⭐⭐⭐

> "I see it as a collaborative partner rather than a tool"
> "It's like having a conversation with a colleague"

### 策略3：每次验证策略 ⭐⭐⭐⭐⭐

> "I always verify...especially for citations"
> "I never trust the citations it gives me"

### 策略4：多模型对比策略 ⭐⭐⭐⭐

> "I use my own chatbot to call different models"
> "Compare responses from different models"

**自建工具**：
> "I built my own chatbot using API calls to various models"

### 策略5：迭代改进策略 ⭐⭐⭐⭐

> "I will ask it to refine...give me feedback on the feedback"

## 深层认知

### 对AI能力边界的理解 ⭐⭐⭐⭐⭐

> "It's good at structuring...not so good at generating new ideas"
> "The hallucination problem is still quite prevalent"

### 对过度依赖的担忧 ⭐⭐⭐⭐⭐

> "I've seen people just copy and paste without checking"
> "They tend to trust it too much"

### 对思维趋同的担忧 ⭐⭐⭐⭐⭐

> "Convergence in thinking...everyone sounds the same"
> "People are losing their unique voice"

## 独特发现

### 1. 信任下降现象 ⭐⭐⭐⭐⭐

> "I seem to trust the AI less...maybe around 30"

**理论价值**：与大多数用户信任提升的模式相反，该用户随使用增加信任反而下降

### 2. 自建聊天机器人 ⭐⭐⭐⭐⭐

> "I built my own chatbot using API calls to various models"

**理论价值**：技术型用户通过自建工具实现对AI的更大控制

### 3. 幻觉直接经历 ⭐⭐⭐⭐⭐

> "I found that 3 or 4 of them do not exist"

**理论价值**：亲身经历幻觉问题是信任下降的直接触发因素

### 4. 思维趋同担忧 ⭐⭐⭐⭐⭐

> "Convergence in thinking...everyone sounds the same"

**理论价值**：对AI导致思维同质化的深层担忧

### 5. 协作伙伴定位 ⭐⭐⭐⭐

> "I see it as a collaborative partner rather than a tool"

## 对论文的核心价值

### 1. 信任下降案例

罕见的信任随使用增加而下降的案例（50%→30%）

### 2. 幻觉经历的影响

直接经历幻觉如何改变用户信任

### 3. 技术型用户的控制策略

通过自建工具实现对AI的控制

### 关键引用（可用于论文）

1. **信任下降**：
   > "When I first started using it, I would say around 50...I seem to trust the AI less...maybe around 30"

2. **幻觉经历**：
   > "I found that 3 or 4 of them do not exist"

3. **思维趋同担忧**：
   > "Convergence in thinking...everyone sounds the same"

4. **协作伙伴视角**：
   > "I see it as a collaborative partner rather than a tool"

5. **每次验证**：
   > "I always verify...especially for citations"

## 八、分析验证

待核对的关键引用：
- [x] "Before it's really half and half...maybe around 50" ✓ (line 302-305)
- [x] "I seem to trust the AI less...maybe around 30" ✓ (line 290, 296)
- [x] "I found that 3 or 4 of them do not exist" ✓ (line 317)
- [x] "Convergence in thinking" ✓ (line 500)
- [x] "I see it as a collaborative partner" ✓ (line 140, 143)

---
*分析完成时间：2025年1月*

---


<a id="受访人47"></a>

# 受访人47：化学工程/销售经理 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 销售经理 |
| 工作领域 | 化学工业销售（拉丁美洲区域） |
| 教育背景 | 化学工程学士、理学硕士、博士（墨西哥） |
| 年龄 | 45岁 |
| 国籍 | 墨西哥 |
| 技术采用 | 早期采用者（同龄人中） |
| 使用起始 | ChatGPT发布后 |
| 使用频率 | 日常使用 |
| 主要工具 | ChatGPT（付费版5）、Co-pilot（公司） |
| 培训方式 | 参加2-3天AI课程 |

## 使用场景

### 场景1：销售报告生成 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "Every month I have to make sales report...I analyze, I'm in charge some of Central America"
> "I give a good prompt to chat DPT. I need it helps me to analyze what happen in the economy of that country"

**效率提升**：
> "It took me plan like 3 more time of what I am and spending now for the same activity"

### 场景2：经济数据分析 ⭐⭐⭐⭐⭐

**使用方式**：
> "I ask what is the prediction for the grow country growth during the this year...inflation...interest rates"

**验证习惯**：
> "I ask to give me sources. So I go to the source, I click on the source"

### 场景3：语法改进与翻译 ⭐⭐⭐⭐

**使用方式**：
> "I will write it in Spanish...then I just ask translate and improve this car report"

**但后来调整**：
> "I start doing it in English since the beginning...not the translation part"

### 场景4：数学辅导（个人） ⭐⭐⭐

**使用方式**：
> "My daughter was in high school...I gave ChatGPT the task to explain it to me, detail it"

## 信任轨迹：波动后提升型

### 信任演变 ⭐⭐⭐⭐⭐

> "I would say, yeah, I started with 70%"
> "I was disappointed at the beginning...it makes me think that I need to be very careful"
> "Now...I would say 90%"

**从70%下降后恢复至90%**

### 信任波动原因

**初期下降**：
> "I tested like with things that I know thing I ask, give me some advice for a backstroke swimmer...some of the answer that he said it didn't have any relation"

**后期提升**：
> "Now I feel confident in some stuffs"

### AI过度自信问题 ⭐⭐⭐⭐

> "When I was requiring export numbers for the products...it could give me another number that it wasn't the one that I needed"
> "I kind of like not...I cannot trust"

### 迎合行为经历 ⭐⭐⭐⭐

> "I correct him and I say, no...And then he said like, oh, yes, you're right. And then it completely change the answer"
> "It was that was like, I don't know, maybe six, like seven months ago"

## 核心专家策略

### 策略1：详细初始提示+复制策略 ⭐⭐⭐⭐⭐

> "I divided by boundary. I don't ask to do all of it together"
> "I make a good one for one country and then I just say do the same thing, but now for this country"

### 策略2：来源验证策略 ⭐⭐⭐⭐⭐

> "I ask to give me sources. So I go to the source, I click on the source"
> "It give me like four or five sources...I do check a lot of it"

**验证频率**：
> "I do check it not hundred percent of the things, but I do check a lot of it"

### 策略3：提示保存复用策略 ⭐⭐⭐⭐

> "I recycle what I use last month"
> "I use one that indeed work before and I place it at the beginning of a new one"

### 策略4：技能保护策略 ⭐⭐⭐⭐⭐

> "I am so scare about it. So I start going back to doing myself some stuff"
> "I start doing it in English since the beginning...not the translation part"

## 深层认知

### 对技能流失的恐惧 ⭐⭐⭐⭐⭐

> "I realize I was feeling scared of writing in English, this kind of things"
> "I would be losing that ability to translate...in my mind"
> "I am being better and identify what things are not damaging my skills"

### 对效率与技能的权衡 ⭐⭐⭐⭐⭐

> "I don't care if I lose that ability. And in this other way, I do care. So I don't want to lose"

### 对年轻人依赖的担忧 ⭐⭐⭐

> "I think my daughter is, but is not about my daughter now"

## 独特发现

### 1. 技能流失恐惧与主动回退 ⭐⭐⭐⭐⭐

> "I am so scare about it. So I start going back to doing myself some stuff"
> "I start doing it in English since the beginning"

**理论价值**：用户意识到AI可能导致技能退化后主动改变使用方式

### 2. 信任波动后回升 ⭐⭐⭐⭐

> "I started with 70%...was disappointed at the beginning...Now...90%"

**理论价值**：初期负面经历后信任仍可恢复并超越初始水平

### 3. 置信度需求 ⭐⭐⭐⭐⭐

> "I would prefer chat DPT to tell me, I think that it might be this thing. Maybe with the percentage of how sure it he is"

**理论价值**：用户希望AI表达不确定性而非过度自信

### 4. 技能分类保护策略 ⭐⭐⭐⭐

> "I am being better and identify what things are not damaging my skills...I don't care if I lose that ability. And in this other way, I do care"

**理论价值**：用户有意识地区分哪些技能值得保护

## 对论文的核心价值

### 1. 技能保护意识案例

用户主动回退AI使用以保护核心技能

### 2. 信任波动恢复模型

初期下降后可恢复并超越的信任轨迹

### 3. 置信度表达需求

对AI表达不确定性的明确期望

### 关键引用（可用于论文）

1. **技能流失恐惧**：
   > "I am so scare about it. So I start going back to doing myself some stuff"

2. **信任演变**：
   > "I started with 70%...Now...90%"

3. **置信度需求**：
   > "I would prefer chat DPT to tell me...with the percentage of how sure it he is"

4. **技能权衡**：
   > "I am being better and identify what things are not damaging my skills"

5. **来源验证**：
   > "I ask to give me sources. So I go to the source"

## 八、分析验证

待核对的关键引用：
- [x] "I am so scare about it. So I start going back to doing myself some stuff" ✓ (line 263)
- [x] "I started with 70%" ✓ (line 170)
- [x] "I would say 90%" ✓ (line 188)
- [x] "I would prefer chat DPT to tell me...with the percentage of how sure" ✓ (line 311)
- [x] "I ask to give me sources" ✓ (line 293)

---
*分析完成时间：2025年1月*

---


<a id="受访人48"></a>

# 受访人48：工程专业本科生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 本科生 |
| 学校 | NTU电机与电子工程学院（Triple E） |
| 专业 | 信息工程与媒体 |
| 技术采用 | 早期采用者 |
| 使用起始 | 约2年前 |
| 使用频率 | 每天多次 |
| 主要工具 | ChatGPT（免费版）、Gemini、Perplexity、Grok |
| 培训方式 | 在线提示工程课程 |

## 使用场景

### 场景1：学术报告写作 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "I would still provide the idea, but most of time I would still like type everything myself first"
> "I will give him all the requirement...rubrics for the reports and how I wanted it to turn out"

**迭代过程**：
> "I will first ask them to maybe elaborate...see like in my, it was good or bad"
> "I will still edit again myself and I would still paste it again...the last thing will be I ask them to check for my grammar error"

### 场景2：数学问题解答 ⭐⭐⭐⭐

**使用方式**：
> "Most of the question would be like, you know, math related...I would just like snapshot that pain"

**信任问题**：
> "For calculation stuff...sometimes I think they might came out wrong"
> "Even though it came out unset with me, but I sometimes if my working is same as chat gmv 1, then sometime I think it's correct"

### 场景3：语法改进与邮件专业化 ⭐⭐⭐⭐

**使用方式**：
> "I ask them to fix my grammar or maybe...writing emails...I will ask them to make my sentence more professionally or my more academy"

### 场景4：个人研究与决策 ⭐⭐⭐

**使用方式**：
> "I did use for planning trips...I ask him to schedule like 3 days to night plan"
> "For doing research from my investment, like for investments DOC"

## 信任轨迹：使用后大幅提升型

### 信任演变 ⭐⭐⭐⭐⭐

> "I would say at first, give me a 50%"
> "My current sounds like I would says I don't mean 90, 95 is quite high"

**从50%提升到90-95%**

### 信任提升原因

**来源引用功能**：
> "I think most of the...every time if you ask a question...they will always provide reference for us"
> "If I don't trust him, I can just check the reference"

### 仍存在的警惕

**过度自信问题**：
> "I do realize their question, their answer there, GNE I provide is wrong, but they're still providing confidently"
> "I would just...then are you sure...most of the time they might get it themself that they answer only"

## 核心专家策略

### 策略1：完整需求前置策略 ⭐⭐⭐⭐⭐

> "I will give him all the requirement...the rubrics for the reports and how I wanted it to turn out"

### 策略2：分阶段信息输入策略 ⭐⭐⭐⭐⭐

> "I would say something like maybe read through this paragraph and analyze it and then just reply yes"
> "Only I proceed with like the main question"

### 策略3：新对话重启策略 ⭐⭐⭐⭐⭐

> "Sometimes I might even just open a new chat again"
> "If I try to use a new test, sometimes it might give me a fresh new idea"

**原因**：
> "If it's the same patch...it might just keep on follow like his first idea"

### 策略4：简化解释策略 ⭐⭐⭐⭐

> "Explain this question in detail so that person with zero knowledge can understand"
> "I will always ask Cherry to explain in details and simple"

### 策略5：差异化验证策略 ⭐⭐⭐⭐

> "I think maybe four times...if it's a very important stuff...I would check the website"
> "If like a very general knowledge...I wouldn't really do research"

## 深层认知

### 对自身技能影响的觉察 ⭐⭐⭐⭐⭐

**写作技能**：
> "I think that's the case where my writing skill, I would say my writing skill is not really that good. Cuz I, we can just use charge of team for most sort of stuff"

**批判性思维**：
> "Maybe I need to...came up with a question...Maybe I can come up with one or two. But may if I just ask shadiky to give me 10 or 20, they can just give out"

### 对效率的正面认知 ⭐⭐⭐⭐

> "In just a 20 second, it can check up to, you know, put 10 websites"
> "Actually myself, maybe I need like no one or two hour"

### 对AI局限性的理解 ⭐⭐⭐⭐

> "Whenever I provide an idea, most of the time I think charging team will just...elaborate based on my idea...it wouldn't like change my direction"

## 独特发现

### 1. 新对话获取新想法策略 ⭐⭐⭐⭐⭐

> "If it's the same patch...it might just keep on follow like his first idea"
> "If I try to use a new test, sometimes it might give me a fresh new idea"

**理论价值**：用户发现AI会固守对话中的初始方向

### 2. 希望AI能够反驳 ⭐⭐⭐⭐⭐

> "They know how to...reject your idea"
> "It's not like the user, the things user provide is always the best"

**理论价值**：用户期望AI具有独立判断能力而非一味迎合

### 3. 技能退化的自我觉察 ⭐⭐⭐⭐⭐

> "My writing skill, I would say my writing skill is not really that good. Cuz I, we can just use charge of team"

**理论价值**：年轻用户已意识到AI对基础技能的负面影响

### 4. 来源引用作为信任基础 ⭐⭐⭐⭐

> "This one year in uni, most of the information they Jenny I...provide, it's mostly correct"
> "If I don't trust him, I can just check the reference"

### 5. 与社交媒体隐私风险比较 ⭐⭐⭐⭐

> "WhatsApp or Instagram...have access to our more to our privacy more than AI works"
> "AI mostly we just do like professional side"

## 对论文的核心价值

### 1. 高信任水平案例（90-95%）

年轻学生群体中较高的信任水平

### 2. 技能退化自我意识

用户明确承认写作和批判性思维技能下降

### 3. 新对话策略

发现AI对话会固守初始方向的应对方法

### 关键引用（可用于论文）

1. **信任提升**：
   > "At first, give me a 50%...current...90, 95"

2. **技能退化**：
   > "My writing skill is not really that good. Cuz I, we can just use charge of team"

3. **新对话策略**：
   > "If I try to use a new test, sometimes it might give me a fresh new idea"

4. **反驳期望**：
   > "They know how to...reject your idea. It's not like the user, the things user provide is always the best"

5. **效率认知**：
   > "In just a 20 second, it can check up to...10 websites...myself, maybe I need like one or two hour"

## 八、分析验证

待核对的关键引用：
- [x] "I would say at first, give me a 50%" ✓ (line 194)
- [x] "I would says...90, 95" ✓ (line 194)
- [x] "My writing skill is not really that good" ✓ (line 302)
- [x] "If I try to use a new test, sometimes it might give me a fresh new idea" ✓ (line 293)
- [x] "They know how to...reject your idea" ✓ (line 362)

---
*分析完成时间：2025年1月*

---


<a id="受访人49"></a>

# 受访人49：化学工程本科生 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 本科生 |
| 学校 | NTU化学与生物医学工程学院 |
| 专业 | 化学工程（辅修商业） |
| 技术采用 | 早期采用者（与同龄人同步） |
| 使用起始 | ChatGPT首发时期（约GPT-3） |
| 使用频率 | 每天 |
| 主要工具 | ChatGPT（免费版） |
| 培训方式 | 大学课程 + 自学 |
| 特殊背景 | 参与化工过程建模研究项目（使用Aspen Plus软件） |

## 使用场景

### 场景1：研究项目支持 ⭐⭐⭐⭐⭐（核心场景）

**使用方式**：
> "How to separate a and B and below that...find me a few articles"
> "We also use quite heavily on guiding us with how we go about working with the software"

**具体应用**：
> "This distillation column...is it suitable for us to model this separation?"
> "It can actually guide us very well"

### 场景2：学术写作辅助 ⭐⭐⭐⭐⭐

**使用方式**：
> "I will generate my own ideas and then I will throw into Ji and us to refine"
> "Ask to refine, ask to check grammar, ask for like maybe some creative ideas"

**迭代策略**：
> "Refine my essay to make it flow smoother, make it more grammatically correct"

### 场景3：学习理解支持 ⭐⭐⭐⭐

**使用方式**：
> "In my election notes, right, this part I don't understand...I take a screenshot and I send it in"
> "I ask to explain how step 1 goes to step 2"

### 场景4：演讲与呈现 ⭐⭐⭐

**使用方式**：
> "Can you help me refine my speech in a more creative way or more engaging way"

## 信任轨迹：使用后大幅提升型

### 信任演变 ⭐⭐⭐⭐⭐

> "When I first heard about it, percent" [约10%]
> "Around like six, 70% increase in trust"

**从约10%提升到70-80%**

### 信任提升原因

> "As I use it, right, I realize it can actually solve more and more problems"
> "Then that's why my reliance on this AI tool becomes more and more"

### 仍存在的问题

**数学计算错误**：
> "Using like 5*2 equals to 11...mathematics, very simple error"
> "I say, okay, use the value of t equals to 5. It will use, let's say it will use 6"

**假设行为**：
> "If I give them limited information that they cannot work with, right? They just assume things and they just proceed"

## 核心专家策略

### 策略1：上下文+指令分层策略 ⭐⭐⭐⭐⭐

> "I'm showing the whole paragraph and then below, right, I will give the specific instruction"
> "My bottom paragraph is usually set up instruction that I delge chat unity to do with my work"

### 策略2：分段处理策略 ⭐⭐⭐⭐⭐

> "I will copy paste paragraph by paragraph. I will say, okay, now summarize this paragraph, summarize that paragraph"
> "If this doesn't work right, then I will go more in detail to sentence"

### 策略3：指令重发策略 ⭐⭐⭐⭐⭐

> "By the third prom, right...it will start to be less and less already"
> "I always need to remind...I always need to send again the instruction"

**原因**：
> "In a way, make it consider as a new prom"

### 策略4：主动请求澄清策略 ⭐⭐⭐⭐

> "At the bottom in the instruction, I will say like, okay, if any information is not present, right, let me know"

### 策略5：自我对比验证策略 ⭐⭐⭐⭐⭐

> "First list down what is my working. Put it into chat GBT. And then I use chat GBT as a comparison"
> "To see who is actually correct"

## 深层认知

### 对依赖程度的认知 ⭐⭐⭐⭐⭐

> "More heavy reliance on chat DBT"
> "Almost certain extent. I have to agree" [无法离开]

### 对批判性思维影响的认知 ⭐⭐⭐⭐⭐

> "In some of the cases that I'm supposed to think more critically, right, then it becomes that chat ability is thinking for me"
> "I can save up quite a bit of time and can use this for other purpose"

### 对兴趣与委托的权衡 ⭐⭐⭐⭐

> "If the topic is my interested topic, then yeah, I guess you don't mind doing this kind of deep thinking"
> "But sometimes assignments...they're really...pretty like pointless. So then I don't want to waste my brain"

### 对控制感的维护 ⭐⭐⭐⭐

> "That's why I do fact checking"
> "Let's say I think this doesn't suit me, then I will from in a way that they generate a response I prefer better"

## 独特发现

### 1. 上下文漂移现象 ⭐⭐⭐⭐⭐

> "By the third prom, right...it will start to be less and less already"
> "Meaning they paraphrase, less and less is more towards the original text"

**理论价值**：用户发现AI在连续类似任务中效果递减

### 2. 假设而非询问倾向 ⭐⭐⭐⭐⭐

> "If I give them limited information that they cannot work with, right? They just assume things and they just proceed"
> "Very rarely" [AI请求澄清]

**理论价值**：AI倾向于假设缺失信息而非主动询问

### 3. 兴趣驱动的委托决策 ⭐⭐⭐⭐

> "Interested topic...I don't mind doing this kind of deep thinking"
> "Pointless...I don't want to waste my brain"

**理论价值**：用户基于个人兴趣决定是否委托AI

### 4. 参考而非答案的定位 ⭐⭐⭐⭐⭐

> "Use GI as a reference, not as the answer script itself"
> "Definitely still need to go through your own level of thinking"

### 5. 软件引导应用 ⭐⭐⭐⭐

> "Guiding us with how we go about working with the software [Aspen Plus]"

**理论价值**：AI作为专业软件使用的引导者

## 对论文的核心价值

### 1. 上下文漂移发现

AI在连续任务中效果递减的现象

### 2. 假设vs询问行为

AI处理不完整信息的方式

### 3. 兴趣导向的委托模式

用户基于兴趣选择性使用AI

### 关键引用（可用于论文）

1. **信任提升**：
   > "When I first heard about it, percent [~10%]...six, 70% increase in trust"

2. **批判性思维影响**：
   > "Chat ability is thinking for me"

3. **上下文漂移**：
   > "By the third prom...it will start to be less and less already"

4. **假设行为**：
   > "They just assume things and they just proceed"

5. **参考定位**：
   > "Use GI as a reference, not as the answer script itself"

## 八、分析验证

待核对的关键引用：
- [x] "Around like six, 70% increase in trust" ✓ (line 197)
- [x] "Chat ability is thinking for me" ✓ (line 329)
- [x] "By the third prom, right...it will start to be less and less already" ✓ (line 134)
- [x] "They just assume things and they just proceed" ✓ (line 242)
- [x] "Use GI as a reference, not as the answer script itself" ✓ (line 404)

---
*分析完成时间：2025年1月*

---

