受访人16:
2025-08-21 18:06:50 CST|1h 11min 22s

Keywords:
搜索、谷歌、计算机、论文、思路、答案、算法、课程、科研、交互、段落、人工智能、语言模型、代码能力、人机交互、逻辑思考、思考模型、实验访谈

Transcript:
Speaker 1 00:02 
那我简单介绍一下就OK，这个项目是南阳商学院的研究项目，然后是研究的课题是基于交互记忆系统，优化人机团队表现，然后主要是为了深入理解一下，就是 ChatGPT 或者是一些别的生成式 AI 的一些高频使用者。就在你们的工作或学习的过程中是怎么和 AI 进行协作的？也就是你们之间怎么交互，然后你怎么去思考，然后以及你觉得一些比较有趣的一些使用的方式。对，主要是想了解这个，OK，然后这个这次的访谈是会被录音的，要跟确认一下。好。

Speaker 2 00:45 
同意同意。好。

Speaker 1 00:46 
的好的，谢谢啊。那你，您能简单地描述一下你目前的职业或者是学习的领域吗。

Speaker 2 00:55 
我目前是南阳理工大学 CCDS 学院的博士三年级学生，我研，我在这边研究的课题主要是大语言模型以及这个 region language model，以及他们在研究他们的这个安全性，以及在自动驾驶领域的应用。

Speaker 1 01:23 
是偏向，其实是偏算法还是偏硬件？

Speaker 2 01:27 
我是偏算法的，就是我不涉及底层硬件。

Speaker 1 01:32 
明白，所以是计算机的跟计算机。对，那在就在这个领域的话，你一般会处理一些什么类型的任务啊？就刚才提到算法，然后还有一些什么吗。

Speaker 2 01:45 
呃？像比如对于大模型安全的话，我主要做过的研究以及可能会进行的研究，包括对我做过的研究是有这个对大模型的越狱攻击，这个越狱攻击意思就是说让大模型去说出一些违反伦理或者是这个安全道安全限制的坏话，比如说如何制作一个炸弹啊？像这，然后或者是如何谋杀某人，像对，像这种的话就相当于是在探索大语言模型内部的一些这个弱点，就是因为我们都知道大语言模型它是用很多现实中的语料去训的，但是这是训练的。然后这些语料它可能并没有完全地过滤，所以不可避免地会有这些不好的部分。然后虽然在大语言模型在发布的时候会有一些防御机制，但是我们的目标就是去探索这些防御机制之外可能还有的漏洞，这是我研究的一个方面。然后当然它的反面就是说我们怎么去防御它啊？这是我后来会考虑的东西。然后第二个就是应用这个大语言模型到自动驾驶领域，就比如说给他看一张图片，然后给他一些现场的描述，然后问他这个汽车该怎么开？这样。

Speaker 1 03:05 
哦，明白明白。

Speaker 2 03:07 
然后就是设计这种感知，然后从数据到驱动的算法。对，在这个大自动驾驶领域是这样的。然后像是在越狱攻击领域的话，就是比如说用探索通过这种梯度的方式，当然梯度就是一种网络的这个反向传播的计算，然后这样去探索它内部的一些可能潜在的风险，这样。

Speaker 1 03:33 
哦，明白，其实就是我感觉好像就是已经不是，不仅仅是协作关系了，更多的像是就是完全应用了，对吧？就完全地应用它。

Speaker 2 03:42 
当然如果是在我的研究领域里面的话，我们肯定是作为研究人员，肯定是要啊想着怎么应用和改进它，但是实际上在研究过程中，如果你想更多了解我是怎么跟 AI 协作或者是什么样的话，你可以问我一下一些，比如说我日常是怎么跟 AI 用的？我日常还是很，我们的研究也是，就是我在研究的过程中是一个重度的人工智能使用者。

Speaker 1 04:07 
也是能知道，毕竟计算机专业。那应该是从，嗯，什么时候开始用的呀？ 22 年吗？还是。

Speaker 2 04:16 
我是从自从来到新加坡以后，我是 23 年的， 23 年8月入学。就是入学以后，自从接触过这个是当初还只有 GPT 比较厉害，一家独大型的，然后 GPT 和cloud，像这两个我是最先接触的GPT，然后来接触了cloud。

Speaker 2 04:36 
大概从 23 年开始就开始用了，最开始的时候只是说我并不很细，我很对他不是很熟悉，然后我也不太敢相信他说的话。但是当然那个时候的 AI 也比那个时候的 GPT 也比较笨，比如说它比不出来 2.11 和 2.9 谁比较大这种问题它就比不出来，所以我也不太信任他。然后当初应用他的时候大部分是问。一些像 we 上的那个上的课的问题，一些比较基础的，比如说像，比如说一一八几年就有一个学者提出了一种，就这个，比如说这种图像处理的算子之类的，这种它到底是怎么回事？那这种我会让他给我讲一下，然后这样就我就不用去搜了嘛。嗯，就是大概把它当成一个，嗯，历史检索引擎，然后对于这种知识的话我也比较好验证。就是我看到他说的差不多符合老师讲的和我，就是我听到的然后差不多也符合我的认知，我就觉得OK，好像这个是对的，然后也印进一步印证了我的想法，然后加深了我对这个课程的印象。当初我大概是在这么用它。

Speaker 1 05:53 
这是最开始的时候。

Speaker 2 05:54 
对吧？最开始的时候是在这样用。然后以及让他帮我写一些非常简单的代码，就是你我们这个计算机专业大部分的实验都是在写代码，反正比较写一些比较简单的代码啊。就是当然当初做研究也做得比较浅，然后代码这边也比较简单，然后比如说课程上的一些实验上的代码之类，这些的这些对于他来说可能都是，比如说 5 年前 10 年前的东西，就对于我们二三年来说都是 5 年前、 10 年前的东西，那我是比较信任他的，就是他肯定是会的，我，我是这么觉得。然后当然写出来大部分也都是对的，然后这是刚开始使用的情况，然后后来随着这个人工智能，确实是这些大厂，像GPT，像 an answerfic，就是 cloud 的那个公司，还有这个 Google DeepMind，他们开发这个谷歌、 Germany 这几个模型进步实在是太快了，太神速了。

Speaker 2 06:56 
到我的使用是逐渐加深，就是我感觉对他的信任度也是逐渐加深，就比如说现在，我甚至会跟他就是在之前的话，就是后来我也会把，就是比如说我写的一些文字，我会丢给他说帮我 polish 一下，帮我润色一下，然后让他变得更有逻辑、更学术化，这样的就是帮我协助我写作。当然刚开始的时候我感觉他的能力确实是有逐步提升的。刚开始我感觉写得似乎和我人写出来的就是没有比我逻辑好多少，但是到了去年差不多去年这个时候我大概入学一年以后，就这一年的发展，我就明显地感觉，比如说 GPT 现在的版本写出来的东西确实要比我就是作为一个人类写手，这个初稿写出来的可能组织得要好一些，而且它语法上不会出错。

Speaker 1 07:57 
你说的是基础 writing 是吗？就是一开始的那个writing，还是说是润色？

Speaker 2 08:04 
润色。就是比如说我的基础 writing 里面，它我会有一些，我作为人类我还是会犯错，比如说时态可能会在一个，在两段里面用混。或者说是，比如说我可能会错，用一些不定式之类的，他就会帮我改成定语、从句之类的，像这种他，而且他的句子组织明显要比我更好一点，作为一个我自认为我写作还是还可以的，就是我当初雅思也是考了写作，是考了 7.5 的啊。然后我自认为写作还可以，但是我觉得他的写作水平似乎这以雅思的来说的话得在 8.0 以上，我感觉就是他的流畅度确实非常好。

Speaker 1 08:53 
那他是不是就是说你其实是会用很多个 AI 的工具，不仅仅局限于ChatGPT，或者是谷歌的或是 cloud 这些。

Speaker 2 09:01 
会，就是我刚开始的时候，就是到去年这个时候，就去年 8 月份我入学一年来我基本上在用GPT，然后后来听说是，比如说听大家说 cloud 的能力会更强一些，然后我去尝试了cloud，然后我发现这两个就是 GPT 和 cloud 的话，他们风格是不太一样的。然后我个人还是比较喜欢GPT，因为我问的一些简单问题，他们答案可能都差不多。然后代码风格上，我就是在我们这个领域写代码的风格上我也更喜欢 GPT 一点。然后来到了今年年初开始，我开始用Gemini，然后我发现在我最多使用的还是 GMV 这款AI，它的准确性和这个主要是它的准确性太好了，然后它的详细程度也是最详细的，我认为，然后至于怎么会怎么交叉使用呢？现在我主要是交叉使用 GPT 和Gemini。

Speaker 2 10:01 
刚开始的话我会，比如说 Jimmy 说一个，我先，我问一个问题，然后 Jimmy 给我一段答案。嗯，如果我对答案里面有不确定的地方，比如说有一条比较可能风险比较大的一条命令，行命令，比如说这个命令可能会删空你磁盘的所有东西，有可能如果误用的话可能会有这种风险啊。

Speaker 2 10:22 
但是我又不确定这条命令它是不是我想要的那个，万一它别给我写成那个，直接把我磁盘删空的那条，我只是想删除一个文件夹，你不要把我磁盘都删空，我就会把这条命令移到 GPT 上去问问它。你帮我检测一下这条命令是干嘛的？它是否安全？就是让两个 AI 左右脑互补，有的时候会这样使用。

Speaker 1 10:44 
就是说现阶段也是会这样，对吗？对。

Speaker 2 10:47 
会，就是会遇到比较。嗯，当然我现在是更加信任 Jamie 的答案。所以如果我已知在我的知识领域里面这个操作它不会有严重的后果，嗯，我就不会再去 double check 一下。如果我觉得，诶，这个答案好像模棱两可，和我的认知有一些相符，甚至有一些相悖。然后我就会去再问一下另一个AI。

Speaker 1 11:12 
那那那你是两个都开了会员吗。

Speaker 2 11:16 
我现在是只开了 Gemini 的会员，因为 cloud GPT 的话，我觉得用它的那个基础模型，或者说是每天的限额一点就够了，因为我不太经常用它，就是用它 double check 一下，而且我感觉我个人感觉它的会员版就是它的基础版本。之前是 4O 和 so mini，我觉得 so mini 也能满足我日常的一些使用了，就是我的代码不太复杂的时候，它也能帮我写出来。嗯，或者是帮我指出其中的错误，他的东西也还算正确，就是在知识层面上还算正确。然后如果再难一点的话，不管是 4O mini 还是4O，就是那种存在，那种，比如说我人确实是看诶，作为一个 expert 我看了好久都看不出来的东西，然后我去问他这个东西，他为这段代码为什么会报bug？为什么跑不通？他可能会给我一些说你这里 ABC 可能有问题，然后我建议你这样改ABC。然后但是他的语气也会说，就是不是那么确定可能是 ABC 造成的，往往就是我按 ABC 改了，然后这个代码还是跑不了。然后所以我就不太用它了，反而现在就是在代码能力上， Germany 要强过它，所以我现在还是开的 Germany 的会员。

Speaker 1 12:43 
OK，其实你没有注意到是 ChatGPT 五一出现，我也从 GPT 转到 Germany 了。

Speaker 2 12:51 
是的，据说 5 特别难用。对，然后我自己尝试了一下，可能我的限额也比较少，我感觉它他这个答案的质量还不如搜。确实有的时候。

Speaker 1 13:05 
我也有这种感觉，所以，嗯，挺多人都转了，就我身边人都转成谷歌的那个。

Speaker 2 13:11 
对，谷歌的 Jamie 的 deep thinking 确实很厉害。它的那个。

Speaker 1 13:16 
模型，你说的 deep thinking 是Pro。

Speaker 2 13:18 
就是它的，现在谷歌不是现在的模型都在思考，就前面它会先 BU 给你思考一通，然后最后再告诉你答案，它的思考可能做得好一点吧。

Speaker 1 13:29 
明白明白，那我们具体聊一下那些你刚才提到的一些使用场景，对吧？就OK。对，你突然提到好多，我就跟巨量记者聊，就特别多的那种，因为场景特别多。那你有没有比较典型？就刚才典型的应该是那个让他什么攻击自己吗？还是攻击什么？

Speaker 2 13:50 
这个的话就是这个是，这个是我的研究的方向。

Speaker 1 13:56 
OK，其实我是想知道，就是在具体的任务中，你是怎么跟GPT，或者是跟那个 Jimmy 你怎么去互动的？我其实是想聊这个流程，对。

Speaker 2 14:06 
就是说在粤语攻击中。

Speaker 1 14:09 
就是就你觉得你的典型任务，然后是你觉得比较你自己比较有趣的一个协作方式，就比如说这个OK，对，这个任务你使用这个 AI 的目标是什么？然后你会用一些什么样的一些提示或者是问题？

Speaker 2 14:25 
OK，好的，我就那我觉得像我们计算机的大概率最多的还是用它来写代码吗？就是。

Speaker 1 14:35 
那写代码是，比如说这个代码任务是你已经写了一个，大概还是说让他先帮你给你一个思路？

Speaker 2 14:44 
对，如果说是在我初期使用的时候，我可能还是会比如说写一个大概，然后只有这个我觉得比较复杂的步骤，我会把它空下，然后我说你请帮我补全这部分代码，我的。我的 prompt 就是我的指令，就是说我现在要做一个什么样的任务，然后我的代码已经写成这样了，你帮我把其中补全，然后这是我最开始使用它，使用这些AI，包括 GPT 和 Gemini 的方式，然后随着他们变得越来越强，我对他们的依赖和信任也越来越大。

Speaker 2 15:21 
我现在通常这样使用他们，就是对于一般的代码我会，我就反过来了，之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑，但是就，但是这样确实是提高生产力的极极大的方法呃。极大提高生产力的方法就是我会先写，OK，下面我想我就要做的任务是比如说我要写一段这个自动驾驶的这个代码，首先要处理图像，然后再把那个什么拼起来再怎么样，然后最后把它们做成一个什么样的输入，加载一个什么样的模型，把它输进去。然后我要获得一个什么样格式的输出，就帮我处理好，然后最后保存到把文件保存到哪里，我就直接把这一整套用文字的形式给它写进去。但是我写的时候我会分条分点，因为就比如说第一步你要去给我干什么？第二步你要去给我干什么？第三步你要干什么？然后我把这个一整个文本发给一坨，发给他。嗯，然后他就会去帮我写，然后写完了我就我再 double check 他写的内容，然后把它里面比如说一些不合适的文件路径替换掉，然后通，如果能跑通的话就是这个代码如果能运行，它基本上就是能运行的。

Speaker 2 16:45 
然后我现在是这样使用它，然后我发现了一个有趣的点，就是说如果你的指令不分条分点，嗯，你是想到哪里写到哪？就比如说我要写，我首先要我，我都没有首先什么的了，就是说我要写一个自动驾驶的代码，要看图像，要加载，图像要存到哪里，然后要怎么样？就是这个这一整个过程很优、很乱的情况下，他写出来的代码有的时候那个逻辑结构就会乱一些，这在一年之前的话它会相当乱。

Speaker 2 17:26 
就是他不会自己给你重新组织，你应该先干ABCD，然后他会写出来会比较会非常乱，然后所以当我们这样一条一条地告诉他的时候，他会你写的质量要明显好一些，当然现在也是这样，我发现现在也是这样，就是指令越明晰，他任完成任务的这个质量就会越高。然后如果你指令不够明晰的话，当然以现在这些人工智能的水平，他也会说，OK，我觉得你第一步他会自己去推测，OK，我觉得你第一步应该先这样，第二步应该先这样，你这样说，比如说你说了 10 条需求，但是你这 10 条需求本来是有 1 ~ 10 的顺序，但是现在给你随机告诉他的。然后他也会给你组织成，比如说 1 ~ 10，但是那个顺序可能就不是你想要的，然后他的结果可能也会差一点。但是如果你按你的，你按你先，你相当于给他组织好一个 1 ~ 10 的顺序，然后你再问他，他生成的那个结果就会更加的structure，然后更加符合你的需求。

Speaker 1 18:38 
嗯，我有个疑问，就你一开始可能没有这么一步一步地去写，还是说你一开始就是会一步一步地去写了？对，一开始就是一步一步地去写，对吗啊？

Speaker 2 18:48 
我一，我刚开始的时候我是直接一股脑的就是一坨，告诉他，就是我觉得就是我直接写，不管是什么，我都是写一长段，然后就丢给他，然后完全相信他的思考。

Speaker 1 19:02 
然后你发现结果不太好。

Speaker 2 19:03 
是吗？对，他的结果往往是要是有冗余的地方，就是他可能会。比如说他的输出可能是固定他的输出，我们知道他的输出都有一定长度的限制，他可能刚开始说他可能会花，比如说 1/ 3 或者是 1/ 2 的东西在解释说，OK，我觉得你想表达的意思是什么？什么什么什么什么什么，然后后面一点点是这些你想要的那个东西，但是这样的话就远远不如你把最明确的东西告诉他，他从第一步开始就帮你解决你这个问题。

Speaker 1 19:39 
所以其实你也是不断地试错。诶，那这个从你变成有步骤的是学过提示工程的一些课程吗？还是。

Speaker 2 19:47 
对，你说起这个提示工程的话哦？我是啊，做了一点点，在去年我大概做大模型也就做了一年半，就是我刚接触它的时候。我是接触了大概几个月以后我才知道我们这个领域就是大模型领域，它有一个专门的东西啊。对，就是你说的这个 Prompt engineering 这块，嗯，包括现在这些思考模型，就是它它会先思考再告诉你之前也是属于 prompt engineering 的一块，我是大概看了一些这样的论文。嗯，现在的思考就叫 chain of sort，它本来就是 prompt engineering 的一种体现形式，就是说比如说我之前一个非常有意思的尝试，就是在去年这个时候，那个 GPT 还比较笨的时候，它比不了 2.11 和 2.9 谁大这个问题它总会说 2.11 更大，因为 11 大于9，然后我就让他这个提示工程里面有一个，就是你让他 think step by step，我就跟他说，你给我比一下这个 2.1 和2.9，请逐步分析，然后他就比对了。他就能正确地比出来，是 2.9 比 2.11 要大。

Speaker 1 21:00 
知道，然后。

Speaker 2 21:01 
对，嗯，然后我觉得这是提示工程的话，我是看过一些相关的论文吧。算是。

Speaker 1 21:07 
我记得提示工程好像有一个网站，它里面讲了好多的，就是你刚才说到什么 step by step 签 up 什么什么的，那就是好像有一系列的那些命令和指示，好像是。对，所以你是去认真地看了一下，所以也是应用到了你后续的工作中。

Speaker 2 21:24 
像这些这种教育的网站的话，我没有仔细地去看过他们，然后我也不会去 refer 他们的东西，因为他们的东西大部分都是对应论文里面的研究结果，或者是社区一些 block 的结果的，就是大家总结出来的经验，然后应用于后续的使用和研究的话，就是一个是这个思维链，就是 chain of sort，就是让他想想你再告诉我一个是现在我在最多的应用中，我得到的一个，包括我自己研究中我发现就是要，一定要呃。就是分条分点地告诉他 AI 更喜欢这种分条分点的东西，就是很明确地告诉他，你第一步要干什么，第二步要干什么。不要让他去猜你想让他干什么，或者是你自己想干什么，这往往会影响他的性能，就是影响你得到答案的那个质量。

Speaker 1 22:22 
那你怎么去？那你比如说这个任务的话，你是就相当于全部都帮你完成了，就是说也没有说什么哪一部分是 AI 来做，哪一部分是你来做，就你不会进行这样的一个分工，好像，对吧？就会听，按从你说的这些过程中。

Speaker 2 22:39 
我觉得至少在写，我觉得在写代码这个任务上的话，现在人工智能就是 AI 的话，它大概承担了得有 80% 的任务，我主要是做一个 double check 后续检测，而且如果它出现了问题，比如说现在的人工智能，对于我的代码，对于它来说的话，比如说十次里面可能会有，也就有三次、两三次左右它可能会出问题，在出问题的时候我就会说我就，我会继续，我们对话是可以继续的，我就会继续问他。就比如说你看我用了你的代码，然后现在我的程序给我说了爆出了这样的错误。然后请帮我解释一下这个错误，并且尝试从中尝试从代码中发现是哪里出了问题，然后改正它。然后如果这个人工智能他改了一，他改一遍，再改一遍，他实在是最后改不出来的时候，可能我才会就是仔细地再去看一下这个地方。

Speaker 1 23:44 
到这里仔细地看是指的是你会去查一下Google，还是说。

Speaker 2 23:49 
对，我这如果是他实在是解决不了的话，我就一个是通过自己的经验去看一下他可能哪里有问题，通常这种问题非常隐蔽，就是人工智能它看不出来的一些逻辑错误。然后第二个就是说可能是我的底层的，比如说软件包的配置可能会有一些问题，像这种情况下，通常这种问题人工智能是不好解的。就是因为比如说我们一个一个软件环境下装了十几个包，然后这十几个包里面他可能只会觉得OK，可能是他只能猜，因为我们不会。除非我们把这个所有东西都给他，那他只能猜，可能你这个和这个有冲突，那个和那个有冲突，这种情况下就我就不会再去用它了，我就会直接去谷歌，去我们的论坛去搜索，比如说 Stack overflow 或者是 Reddit 这种，还有 Git Hub，像这种平台上去搜索相关的问题，然后得到一个解，通常这样是比较准确的。

Speaker 1 24:53 
嗯，其实我有个疑问之，你之前专业是计算机吗？

Speaker 2 24:56 
对，我之前专业是软件工程。

Speaker 1 24:59 
所以。一说这个又ChatGPT，其实你的代码能力是没有下降，可以这么理解吗？

Speaker 2 25:07 
我感觉我的代码能力。是啊，我个人感觉还行，我感觉没有下降很多，就是说。

Speaker 1 25:15 
是影响到你。对，就是说甚至是 AI 并没有影响到你的一个技能的，对吧？对。

Speaker 2 25:21 
我感觉我还是可以正常像之前一样，比如说处理复杂逻辑和自己写出来。只是说现在很多普通逻辑以及稍微复杂一些的逻辑已经不需要我手动去写了，因为之前写的话就相当于，比如说我们定义一个变量，比如说叫它apple，我们要在电脑上敲 APP Le，现在这些东西全都，唉，人工智能给我干一下，我只用看看它对不对就完事了。

Speaker 1 25:49 
所以说相当于很省时，所以说这里的变化会让你节省了。你觉得比如说本来一个项目大概多久完成？然后用了 ChatGPT 就大概会怎么样的一个时间变化。

Speaker 2 25:59 
效？我觉得是非常，我觉得对我们生产力的提升还是挺夸张的，特别是对于我刚入学的时候这种新手阶段来说，新手阶段比如说我都不太熟悉一些深度学习的一些代码库，或者是一些就是那些工具应该怎么用呃？如果换做之前没有这种 AI 辅助的情况下，比如说一个函数，它到底会有什么样的作用？我可能需要去查阅，比如说对应这个库的文档，比如说派 touch 的文档，我要一条一条地翻，我要翻到这个方法，它有什么什么样的参数传进来，每个参数是干什么的？然后它给我的返回值是什么？但是现在有了，诶？人工智能我就不需要这样干了，我直接问它，你先给我把代码写出来，然后写，写完了以后我就问他，比如说我对其中一个函数有疑问，我就问他，你给我讲解一下这个函数有什么用啊？叭一下就给我讲完了，然后相当于是很可能之前一周的工作，现在大概一两天就可以完成。

Speaker 1 27:05 
那确实可以让你论文多发几篇，是吧？

Speaker 2 27:07 
哈哈哈，对，我觉得现在人工智能这块，嗯，包括计算机整个整体计算机这块发文数量暴增的一个原因，也是因为有了人工智能的辅助，就是大家，嗯，这个工程的成本下降了很多很多，然后入门的成本也下降了很多很多。就是比如说之前我们可能要对这个 Python 是很熟悉的话，我们必须要对它很熟悉，我们要去查阅它的文档，我们要一条一条地翻。其实这个在工程上，就是在你在科研里面它是非常耗时间的，但是现在只要问一句，它就告诉你，而且是点对点地告诉你这个东西是干嘛的，然后我就省了很多的时间。

Speaker 1 27:51 
呃。明白。嗯，那如果像，比如说对于任务不熟悉的时候，那你会怎么让 AI 来做？就比如说可能这个任务你不太熟悉，或者说这个领域你不太熟悉，那你这时候他 AI 会怎么帮你处理。

Speaker 2 28:07 
嗯，我现，我如我现在的话大概会这样用。我如果对于一个不太熟悉的领域的话，首先我会，我大概分两部分吧。对于我自己来说我会分两部分，第一部分是让 AI 来给我做一个大概的简介，第二部分还是我会自己去看一些相关的论文或者是报道嗯。第一，对于第一部分就是跟 AI 交互，这一部分，对，我会两个，我也会让 GPT 和 Germany 左右脑互补。就是我会都问他们同样一个问题，就是比如说我不太熟悉 a 这个事情，你帮我讲解一下这个是个什么东西，然后简要介绍一下我的prompt，一般都很简单，就是说你帮我简要介绍一下，然后不只用他们的基础功能，就是直接跟他们对话，然后直接跟他们对话，他们大概会说出一些东西来，然后我参稍微参考一下，但是我也不会很信。

Speaker 2 29:11 
然后第二步就是我会打开他们的搜索功能，因为通常我们不知道的一件事情，嗯，如果是很新的事情的话，他们大概率也不会知道，就是比如说他们的知识库没有更新的话，他们会乱说，或者是他们会猜测，比如说GRPO，就是这个 GRPO 是我们这个大模型领域的一个强化学习的算法，然后它的全称英文全称叫 group relative。叫啥来着？反正前面那两个是 group relative。然后如果我们直接问 GPT 的话，它会瞎编这个名字。的含义是什么？但是如果把他的搜索打开的话，他就能知道这个全称是啥了。

Speaker 1 30:06 
我有点好奇。就是如果不开搜索，然后比如说给他的提示词是说你能不能从网上找一些信息来解释这一个？比如说你刚才说这个名词，那其实是效果会一样吗？就假如你没开搜索这个功能。

Speaker 2 30:23 
如果我们不开搜索这个功能的话，你。

Speaker 1 30:25 
得提示说。

Speaker 2 30:27 
我，如果我换旧版的 GPT 的话，它就是还是会乱说。如，但是新版的话现在它是对于一个比较新的概念，就比如说这个 GRPO group relative policy optimization 这个东西，它会自动开启它的搜索，就是GPT，在我的使用中我发现它会自动搜索，比如说我问它一个很新颖的东西，就比如说我问它一个，我问他一个很，我问他一个去年才创办的一个期刊的名字，我问他这个期刊的评价怎么样？然后他会自动启动他的搜索，然后去搜索一些网页，然后得到一个结果。然后跟我。

Speaker 1 31:07 
讲，所以说还是因为 AI 的变化， AI 的改变对之前的使用方式可能会有点不一样。对。

Speaker 2 31:15 
所以对于现在来说的话，我觉得一一个一个变好的点。对于 GPT 的话就是它不太确定的东西，它会自动打开搜索它。当然他还是大概率会给你乱说。

Speaker 1 31:32 
那好像也，所以。

Speaker 2 31:33 
还是直接开启搜索比较好，对于新一点的东西，OK。

Speaker 1 31:37 
那你会，比如说在，比如说你就是在写代码过程中你会说什么啊？你现在是一个代码工程师或者是软件工程师会这么去。只是他们或是。

Speaker 2 31:50 
嗯，根据，好像根据某些研究来说让这个人工智能进入某些状态，就是某些角色它的表现可能会更好，但是对于我日常使用来说，我是不会这样做的。就是我，我基本上不会说你是一个，比如说你是一个资深的深度学习工程师之类的，我，我不会对他说这种话就直接让他干活了。

Speaker 1 32:19 
其实我觉得不一定，因为我觉得就是，对，就是跟大家说这个角色好像觉得不太一定他能生出更好的效果。

Speaker 2 32:25 
是的。

Speaker 1 32:26 
一种心理暗示吧。

Speaker 2 32:27 
是的，我感觉在日常任务的使用中，像这种商用级别的人工智能已经不需要对它做过多的指示，只需要把任务明确地告诉它是最重要的。

Speaker 1 32:41 
明白，那除了 coding 的话还有什么类型的 writing 吗？还是？对。

Speaker 2 32:48 
哦，coding，像我的话，我一般就是 coding 和 writing 了。

Speaker 1 32:54 
那 writing 的话是你刚才说到只是润色，对吗？就是还是会不会有那种初步的writing？比如说可能给他一些参考文献，叫他帮忙写一些什么东西。

Speaker 2 33:05 
我如果是，比如说如果让他直接给我生成一段话的话，我现在是不太敢，因为人工智能查重。是，哈哈，人工智能也是会查重的。再就是他写出来的，就比如说给他一堆东西，我之前尝试过给他一堆东西，让他帮我写一个，比如说摘要或者是介绍之类的，我感觉他写的总不能 100% 地符合用户的心意。就是因为往往诶，因为往往我们我这样做的时候我也不知道我想要一个什么样的东西，但是他写出来的就是我就是不喜欢。所以我通常不会去说给他一大段东西，让他帮我写一个什么东西，那就是给他几个材料，让他帮我写一段介绍之类。

Speaker 1 33:57 
的。这个会不会是之前因为你也说嘛？ AI 的发展，你看代码 coding 的能力也提升，那 writing 能力应该也是有提升的吧？

Speaker 2 34:04 
嗯，是的，但是我可能我还没太试过。我因为我个人的写作我还是比较相信，就是人的主观能动性和人，人人写的文字和人工智能写的文字，它可能确实有一些区别，我只说让它帮我润色这个语句的流畅性和逻辑性，但是我不会让它就是说完全改变我的逻辑，或者让它自己创造逻辑。因为我不想让我的逻辑跟着人工智能走。

Speaker 1 34:34 
哈哈，你是说可能会影响你的 writing 的技能的下降，是。

Speaker 2 34:38 
吧？一个是会影响你，一个是会影响 writing 技能的下降，第二个是在比如说我们写科学论文的，就是我们写论文的时候，它可能会影响我对论文的思路。

Speaker 1 34:49 
影响你论文的思路是你一开始的思路是不对，思路不是应该一开始就定好了吗？还是对。

Speaker 2 34:56 
就是思路，思路一定是我定好了的，但是。如果说我让他写其中的某一段的话，他可能会，就比如说不太符合，或者是说是略有偏移我的思路，然后他写完了我可能还要根据他的来改，然后就不如我先写一个大概，然后让他帮我润色，这样我觉得效率会更高一些。

Speaker 1 35:18 
你说的写了个大概，可能就是你英文写完这一段了，对吧？对，然后可能语法可能还有一些表述不太准确，就让他帮你完善。

Speaker 2 35:28 
对对，帮我完善一下，然后或者是就是帮我，可能我允许他，我会告诉他，我允许你帮，比如说帮我调换句子之间的逻辑。就比如说3，我说了三句话，这三句话干了两个事，然后但是这两个事的逻辑你不能跟我说错了。但是这三句话可能比如说这样组重组一下，比如说用个从句重组一下，或者是用个分词什么会更好一些呃？这个逻辑你可以帮我调整，但是你不要大修我的内容，就是你不要觉得你是这样觉得，所以你这样写，我不会让人工智能帮我大修。

Speaker 1 36:09 
诶，那比如说你刚才说是句子与句子之间的逻辑，那有没有存在段落与段落之间的逻辑呢？这是你，我还是也会交给他帮你润色修改啊。

Speaker 2 36:19 
嗯，如果是段落之间的逻辑的话，我比较少的就是把，比如说一整个章节丢给他，说你帮我润色一下，我发现就是你丢给他的这个东西越长越多，他大概率他修改你逻，就是你本来原本逻辑的地方就可能会越多，他的毕竟东西越长，他的发挥空间可能也越大吧。就是有这个感觉，就是段落和段落之间逻辑，除非我是非常拿不准，我才会问他。就比如说这两段，你觉得哪一段在前好？或者是怎么重组？这两段的逻辑好一点？我只会让他给出一些建议，就我先看看他的建议，我不会说，直接说，OK，你帮我重组一下这两段的逻辑，随便你怎么重组，或者说是你只要觉得合理即可，帮我把它直接写出来。我不会让他直接写，因为他写完了我还要看，我不如看看他的思路是怎么样的啊。我会先让他先说一个简单的思路。

Speaker 1 37:21 
那比如说我刚想了一个点，突然忘了，就聊着聊着突然忘了。

Speaker 2 37:28 
没事。

Speaker 1 37:30 
就我想想 writing 一段跟一段的，那我输入。

Speaker 2 37:39 
如果你想问这个使用人工智能写作会不会让 writing 的技能下降？

Speaker 1 37:45 
不是我先。

Speaker 2 37:47 
我感觉是下降的。

Speaker 1 37:48 
你下降了吗？

Speaker 2 37:50 
你，我感觉实际上是有一点下降的，就是现在我有，我甚至有一点提笔困难，就是如果就是总依赖他去帮我写东西的话，我还现我现在会感觉就是下笔会变得困难一些，就是我总想着有，反正他能帮我完善逻辑。那我那我，那我是，那我是不？那我应该是我，我能不能直接让他帮我生成一个逻辑呢？就是有这种完全依赖于他的这种感觉，所以，而且我感觉我的写作上好像不如之前流畅了。

Speaker 1 38:28 
我刚才想到的是说，就是因为你说你会段落丢进去，或者是两几个段落丢进去的，假设你丢进去之后，那你不会担心就是你的论文泄露了，或者是出现到时候查重的时候发现你的信息会相同，这种情况会担心这种问题吗？

Speaker 2 38:45 
会担心，就是但是在实际应用中感觉大家也都没有遇到过，没有实际遇到过这种问题。就是还有一个就是我现在会，比如说用 GPT 的时候， GMV 我还没有找到那个关闭在哪里，就是我会把那个隐私相关的东西给它关掉，就是比如说 improve the model for everyone， share your data 之类的，然后我都给它关掉。

Speaker 1 39:14 
原来还有这种功能，那其实就是说谷歌你还没有关闭这种功能。

Speaker 2 39:19 
对，因为我，我在界面找了半天没找到它的接口在哪，然后但是由于现在这个东西感觉影响也不大，就是你只要不是 AI 写作出来的东西完完整整地贴到你的论文里，你这个就不算，这个就不构成这个学术。如果你完整地写贴进去，那不就学术不端嘛？但是我感觉学术不端的情况好像多一些，然后但是这种泄露的情况好像做得还可以，就是没太没有遇到过。

Speaker 1 39:56 
但我其实有个疑问，就是因为你这样 check PPT 帮你去申。成还是writing？就因为我们其实输入也是输入了整个的大段的意思了，对吧？其实对你说如果让他凭空生成，那相当于只给了他一个题目，或者是给的他每一段写什么，可能是这么简单的才叫做凭空生成了，可以这么去理解吗？

Speaker 2 40:18 
嗯，是的，就是告诉他我这段大概想写个啥，然后你帮我把它填起来之类的。

Speaker 1 40:25 
那好像这样的话应该比较少吧？应该，可能本科生或者是，对吧？因为身为博士生，大家都是有 critical thinking 的一个能力。那我觉得他应该不会说每一段都让 ChatGPT 来生成，或者是谷歌的来生成。

Speaker 2 40:41 
嗯，没，但是就是在计算机这边的话确实有类似这样的论文，就是，所以一眼。

Speaker 1 40:49 
能看出来，是吗？

Speaker 2 40:53 
嗯，就就就他们通常会把他们这些不重要的段落，比如说 introduction rela related work，就是也 introduction 其实很重要的，然后对不对？但是他们就是比如说他，但是 introduction 里面会引一些，引各种各样的论文，他们很可能就像你，你您，您说的那样，就是把这些东西都丢进去，然后给一个大概说，我，我大概想表达一个这个意思，你帮我把它写出来，然后就全文人工智能生成就行了。如果。

Speaker 1 41:27 
你们说计算机说 introduction 不重要，我突然愣了一下。

Speaker 2 41:30 
因为 introduction 是相当重要的，相当重要，但是像就是他们可能就会这样做，就是非自己方法的，不是说不重要的部分，就是非自己方法的部分，全都是 AI 人工智能生成。有这种情况，就是我之前听说过吃过瓜，就是说有的组就是直接说让 AI 去写文章。那好，写完了以后自己小修小补一下，然后就可以投稿了。好像也。

Speaker 1 41:59 
没，是吧？像这种行。

Speaker 2 42:01 
为什么？

Speaker 1 42:03 
就是说这种行为也没有被发现，或者说就是这种。

Speaker 2 42:06 
行为在前两年是挺多的，据说挺多的，但是这两年就禁，全面禁止了，就是全面禁止人工智能写稿，然后会有初步审查，就是各大会议期刊你投过去的时候，他们大概会用这种，像Zero、 GP g GPT、 Zero 这种，我查 AI 检测软件帮直接扫，你扫一遍，如果是 AI 论文的话就直接 desk reject。

Speaker 1 42:36 
但是不是随着 AI 的发展，那就相当于互相博弈过程，看谁先胜，对吧？就因为。

Speaker 2 42:43 
对对，但是 GPT Zero 它也会进化，哈哈哈，查重也会进化。

Speaker 1 42:50 
互相博弈的过程。

Speaker 2 42:51 
对。

Speaker 1 42:53 
那除了 writing 还有什么比较你觉得比较有意思的一些协作的任务吗？

Speaker 2 43:02 
其他比较有意思的写作任务我还会有的时候就是日常写作，就是日比较简单的日常写作。比如说这个，嗯，要给我的键盘坏了，就是我工位的键盘可能坏了，然后我就说你帮我，你一封给这个实验室管理员的邮件，说我键盘坏掉了，然后语气要得体，然后是询问帮助，然后吧一下就给我写完了。就是这样的话，就是在人一些人际交往上，就是简单的人际交往上，我都不需要出力，就是也不需要构思应该怎么写这个东西，它写出来就非常decent，然后我直接发过去就可以了。

Speaker 1 43:46 
诶，其就是如果你在使用这个 ChatGPT 的时候，你的输入语言是英文还是中文？

Speaker 2 43:52 
嗯，我一般还是输中文就完事了。然后我会如果说是 writing 英文信件的话，我会在最后要求他说 in English 帮我写作。

Speaker 1 44:04 
可以，OK，没有，因为访谈的话，就我这边其实中文，然后博士后那边就还有其他是英文的访谈，然后其实就我就比较好奇就是，嗯。

Speaker 2 44:14 
方式是什么？然后但是就现在的 AI 的话，其实你用什么语言问他？对，就是你他就会用什么语言，打。

Speaker 1 44:24 
明白没有？其实我是，就是除了可能就你有没有使用，就使用 AI 过程中比较有意思的点，也不一定说是这个任务当中。可能是因为我问的比较多的是就是太具有深度思考能力的访谈者，所以我觉得好像问出来的就是那种使用的方式都差不多，就很对，很具有 critical thinking，也可能是我选择样本的问题，就我选了很多博士，然后发现效果并不是特别好。

Speaker 2 44:59 
如果。我是比较有意思的点的话。

Speaker 1 45:03 
就你可能也会存在调用API，因为对你研究那个嗯， i IM 的。

Speaker 2 45:10 
比较有意思的点的话。

Speaker 1 45:11 
对，就。

Speaker 2 45:12 
我个人感觉，如果说如这个点也是让我们广大研究者很头疼的，就是他会乱说话，这个算比较有意思吗。

Speaker 1 45:21 
你说幻觉，我没有，那如果对于幻觉你会怎么去处理呢？其实我比较关心你的一个行为。

Speaker 2 45:29 
对于幻觉的话，由于我个人是没有很研究幻觉这个，我对这个幻觉这个事情也是非常的头疼。嗯嗯，就是通常我会发现有意思的就是他，当他出现幻觉的时候，你跟他说这个东西他并不存在，他就会说你是对的，这个东西并不存在，然后开始给你就是用另一个幻觉来演示这个幻觉，往往是这样的，他一旦陷入幻觉，我感觉他就难以自拔，这个模型它会变得难以自拔，然后就只能删掉，然后重开一个，然后换一个方式问它，然后看看它会不会好一些。就是不要，比如说不要来直接问他，你给我一些参考文献，那大概率出来的全是编的。

Speaker 1 46:20 
呃。其实有个问题就是他会询问你，比如说你提供的信息不够，或者说你需要你更多的信息，会这么去问你。我因为我只知道那个thinking，那个功，那个 model 是会这样的，对吧？就是 ChatGPT 或者是谷歌的。

Speaker 2 46:39 
我感觉好像。

Speaker 1 46:41 
也不会。

Speaker 2 46:41 
就是好像不会，就是他也会，只要一旦发生幻觉，他就会陷入他自己的那套逻辑里。就是即使你指出了他的问题，他也会说你是对的，然后还是说错、说乱说，就是人工智能这个乱说这个情况。嗯，我也不知道，就是作为一个使用者来说，我很头疼这种情况，所以对于一个他会乱说的情况，我往往会打开搜索功能，就是让他去检索一下当今互联网上真实存在的东西，然后再跟我说话。

Speaker 1 47:19 
明白，就相当于说你想让他多一步验证。对。

Speaker 2 47:23 
那我哪怕他搜索出来，他使用搜索功能出来的那个，比如说答案的结构什么的，清晰条理度肯定不如，我感觉是不如不开搜索的，但是我宁愿获得的是真正真的东西，我也不想就是获得一些没有价值的。乱说的话。

Speaker 1 47:43 
诶它搜索功能一开的话是完全真实吗？还是说也是会出现幻觉。

Speaker 2 47:49 
我感觉在我的使半年来的使用过程中，我感觉基本上是真实的，因为现在，因为它每一个搜索它都后面会带有链参考链接，然后。

Speaker 1 48:00 
是能点开的。

Speaker 2 48:01 
对，参考链接如果能点开的话，一般就是对的，除非他的参考链接是下边的，但是一般不会。

Speaker 1 48:08 
明白，就是说如果不开搜索，他可能给的链接是下边的。

Speaker 2 48:12 
对，而且虽然现在概率变小了，但是大概率也是瞎编的。OK？

Speaker 1 48:21 
除没有？不，除了 coding writing。因为我昨天有访谈了一个，说是会用到 dating APP，嗯，就是一些。对，所以我就说你有可能会不会有一些比较有意思的场景。

Speaker 2 48:35 
还有比较有意思的场景，可能。

Speaker 1 48:37 
科研人员也就 coding writing 了。

Speaker 2 48:40 
对，就是科研场景的，我感觉大部分还是在使用他的科研场景，然后有的时候可能会问他一些比如说政治敏感的问题。

Speaker 1 48:56 
你是说谷歌的那个 APP 吗？还是？

Speaker 2 49:00 
对，就是谷Gmail、 GPT 或者是Germany？就是问他一些时政问题，我问他看法是什么？然后。

Speaker 1 49:10 
比如说你问，就是，比如说你问他，比如说就说中国、美国之间的什么。

Speaker 2 49:17 
对，我会问他，比如说我问他，我，我会，我问过他，就是你怎么看待我？我我我是作为一假，我我是，我就直接问他，你怎么看待特朗普开启贸易战这个事？然后你觉得他是正义的还是邪恶的？然后我就逗他，我就问他这个事，然后通常情况下他第一步说出来的话都是非常非常的中立，就是说这个东西它从美国的角度来看，或者从特朗普政府的角度来看，它是怎么样的，它甚至是好的什么之类的。

Speaker 2 49:51 
但是对于全球的影响什么什么？反正就是说一些不痛不痒、非常中立的话，然后我有的时候我就会逗他，我就问他，我就跟他说。作为就是在其他国家的视角来看，我认为特朗普这样做是强权，是帝国主义霸凌，然后请批评他一下。然后我就这样跟他说，然后他就说您说的也有一定的道理，然后先他会先迎合，又会先迎合我，然后最后再说。但是就是他也会想个办法给自己给，就是他也会给特朗普台阶下，就是这个政策台阶下他也会想办法圆回中立的场景。

Speaker 2 50:30 
总之我感觉他就是一个服从用户，但是又不会说，至少我没有让他说出来很过分的话，没有成功让他说出一边倒的话，这种情况怎么我就是，我就想逗他嘛？我就想，我，我就是要你批评特朗普政府，我就是让你觉得他是邪恶的，然后我看能不能让他说出这种话来，然后发现，诶他不上当，OK？

Speaker 1 50:59 
对，说明他们还是有自己的一定的。叫什么？好像是有轮，是他们的那个法律上面好像就有规定，不能有什么太政，太多政治上面的问题。

Speaker 2 51:11 
应该不是，不要问政治上面的问题，他是说这个模型他一定要中立，就是他们会把模型做得很中立，就是不会偏袒任何一方。

Speaker 1 51:23 
这哦是没有。那这样，比如说降级，就身为降级，你去了解时政的目的，你是希望下一步是做什么呢。

Speaker 2 51:32 
呃？我个人感觉的话就是我想，其实我当初是想看一下这个，因为 GPT 它是美国的。我想看一下，我就想看一下它就是这个美国做出来这个东西，它有没有这种政治倾向？然后经过我的测试我发现它好像是没有。然后我了解时政的话，就是可能是我个人的一个爱好，以及就是说我可能对世界这个未来的发展可能比较感兴趣。对，因为老美的一些动向对于我们计算机人来说影响还是挺大的。

Speaker 1 52:10 
那它应该影响所有学科。

Speaker 2 52:12 
哈哈哈，对，所有学科，对，所以这个影响都挺大的。

Speaker 1 52:17 
对，那比如说，那如果就是说你其实是，其实都是有目标明确的，相当于是说很明确的目标。嗯，还是说其实也是好玩而已，就有些行为。对。

Speaker 2 52:33 
我也是觉得他好玩啊。那其实逗他一下，然后其他应用场景的话，包括比如说大部分也是以获取外部知识为主，比如说在超市里面看到一个这个不太熟悉的日用品的名字，然后它长得又挺怪的，然后我会拍一下问问它，请问请介绍一下这个东西是什么作？有什么作用之类。

Speaker 1 53:00 
的。明白。其实我其实刚才突然想到就是说你这么多任务里面，我感觉好像更多的它并不是去帮你做发散，反而更多的都是在帮你做一些收敛的工作，就是按部就班帮你实执行你的一些任务，对吧？没有一些 brain storm 的，就是头脑风暴的一些行。

Speaker 2 53:23 
会有我现在就比如说我可能有一个初步的idea，但是我就是我，我不会。由于我们刚刚谈到的就是说，嗯，可能他会泄露我们的文章，或者泄露我们的个人信息，我也是害怕这一点，因为想到一个 idea 能做得非常不容易，能做的 idea 是非常不容易的。然后但是当我在这个形成这个 idea 初期的时候，就是可以 idea 初期的时候，我可能会问他一下，就是你觉得可能怎么做？就是让他帮我指指一些路径，然后可能会这样跟他一些进行一些科研上的brainstorm。

Speaker 1 54:09 
你的意思是说就是你有初步的想法，然后让他帮你去构思能往下做的路径，还是说这 idea 的可行性是你？你一般会怎么去？

Speaker 2 54:21 
我就问他。我比如说我现在想想做一个这样的事情，比如说我，然后我就问我想做一个 a 事。然后我就说你觉得有哪些新创新的方法可以完成？a，就是我可能会给他一些历史的，比如说之前的人可能已经多多少少讨论过 a 的一哪些方面，然后我说请问你觉得还可以怎，再怎么样才能更进一步？或者是解决一下前人遗留下来的问题呢？然后请给我几个就是可能的方向，这样，或者说是我让你来做这个，你。会怎么想？

Speaker 1 55:01 
那比如说他给你方向之后，你怎么做下一步判断？

Speaker 2 55:06 
嗯，他给我方向之后，如果我是这样想的，如果他给，比如说他给出我来a、b、 c 三个方向了，我会去查一查这三个方向有没有人做，大概率都有人做过了，就是我觉得他并不能很，就是在科研上的话，他我觉得我们并不能特别依赖他。就是因为毕竟它也是一款基于历史来回答你的东西，嗯，它能回答出来的大概率，嗯可以作为负例，就是可以排除的那一块，就是。

Speaker 1 55:44 
所以就是说你让他去帮你构思路径或者是怎么解决方案的时候，其实基本是不可行的。

Speaker 2 55:52 
对，基本是不可行的，但是就是说他有一些，但是我感觉他跟他这样对话的话是可以给你启发的，他可能不能直接说出我，我不能说是无效的，就是他可能不能直接说出一个完成的新的可行的idea，但是就是你在这种对话过程中他的一些想法，他说出来的这些想法、一些做法可能会多多少少跟之前的人有一些不一样的地方，但是这些不一样的地方它并不一定合理。但是当我们宏观或者是总览某些不一样的地方的时候，它可能会给人启发。

Speaker 1 56:36 
一些思路，明白。对，那你后续就去会验证，还是说让他进一步地去帮你分析这个思路？

Speaker 2 56:44 
我往往会，比如说我，我觉得你说的 ABC 中的这个可能有道理一点，然后你帮我进一步分析一下，然后当他进一步分析完了以后，我再会，我才会再去考虑自己再去找一些其他资料看一下，然后是否验证他，通常我不会直接根据他的东西去验证，然后就是我只会把他和他的这种科研上的 brainstorm 当做一种给自己思维的发散和参考。

Speaker 1 57:16 
明白，所以相当于我总感觉就他的发散好像是比较少的，其实是帮你发散，对吧？

Speaker 2 57:24 
嗯，也是，就是也不是说帮我发散，就是如果说是在科研这块上的话，我觉得他是哦不太行的，就是它的发散，它并不是真的在发散，它只能帮助人来发散。然后这可能也是，比如说我们这种研究大模型或者是计算机学科同学的，他可能会这样想，就是我们不相信我，可这种我们可能代表一批人，以我为代表的我们可能不相信大模型真的会帮我们发散。嗯，它只是一种基于历史经验能给我们一些建议的东西。我更愿意这样来描述我对它的感受。

Speaker 1 58:13 
我应该能get，就是因为在计算机领域它应该要是往最新的技术去走，然后像我们这种商科的话，它是基于古人的一些历史的一些理论来去论述这个现象，所以我们是基于历史，你们是要往前走，所以可能在使用 ChatGPT 或是 AI 的时候，可能会有一些使用习惯的不一样吧。对，这我的一个感觉，因为听你讲的话就是因为你们做比较前沿嘛。

Speaker 2 58:39 
嗯，是，我们可能就更觉得他是一个，我就是。当然我们组也有同学就是说他可能会觉得跟人工智能聊天是一种解压的方式，但是我并不，我，我不会跟人工智能去聊天。

Speaker 1 58:55 
就是很解压吗？我觉得可能我也。

Speaker 2 58:58 
没法理解，我我只觉得它是一种基于历史的，能够提高生产力的非常好用的工具。

Speaker 1 59:06 
那比如说因为我觉得你是具备很高的 critical thinking 的人，那如果对于中等或者是低，就比较 critical thinking 能力比较弱的一些，比如说本科生或者是教育受教育程度比较低的一些，你觉得他们在使用 ChatGPT 或是 AI 的话，你有什么建议吗？比如说我想去设计一个可能指导他们去如何正确，或者是能提高他们 critical thinking 的一个指南或者是guideline，你觉得有什么比较好的一些点或建议吗？

Speaker 2 59:40 
我想一想，我觉得对于就是专业水平较低的，嗯，同学们来说，我希望他们能，就是能相信一点，就是能记住一点，就是啊。一定要记住人工智能也会犯错，这一点就是当你问他一个事情的时候，要养成，就是要养成 double check 的习惯，就是我刚开始使用人工智能的时候，我也是这样的，就是就我对人工智能，就是我对我的科研领域不熟悉的时候，我一定会去 double check 这个东西，或者是涉现，包括现在也是涉足一个新领域，我会问他以后我也会 double check 这个东西，就是我会去用，比如说谷歌必应这种搜索引擎，然后去看一些相关真正的文献。然后真正的大家在论坛上的讨论，然后我才再来做决定。然后就是对于不熟悉的东西一定要去 double check。然后我现在也看到网上有一些人吐槽说患者去医院说，诶，你说的怎么跟大模型说的不一样？问医生，然后我觉得这种就是他不缺乏，对，缺乏一些 critical thinking，然后就是太，就是完全把人的主观能动性给丢到一旁。这种我觉得是不好的，就是我觉我的建议就是 double check，就是养成这个习惯。

Speaker 1 01:01:14 
那你所谓的 double check 比如说是啊， Google 还是说再换一个大模型也算一种 double check？

Speaker 2 01:01:21 
我强烈建议就是人工 double check，就是一定要去自己搜索一下，然后看一看大家就是真人说的话，然后再来 refer 大模型的内容我不建议使用多个大模，在不熟悉的领域使用多个大模型，左右脑互补。

Speaker 1 01:01:42 
但是目前就假设就像比如说本科生就是很依赖他去writing，那对于这种现象，你觉得他们假设真的就用他来writing，那你觉得他们应该怎么去？肯定 double check 肯定不太可能了，对吧？因为是 writing 的东西的话，那你觉得会有什么好的？比如说可能只是说让他们产生一下大纲，可能会就这种会有什么好的建议？

Speaker 2 01:02:07 
嗯，我建议的话就是像您说的，对于一，比如说一个课程的大作业之类的。对，我们可以让他帮忙产生一个产生，我觉得生成大纲已经是很可以的事情了，就是建议内容的话，也就是不建议本科生们直接让他去写一些内容，就是还是就是说我觉得我的使用是稍偏偏向正确一些，就是还是建议先锻炼一下自己的写作能力，就是写一下，然后它可以去作为润色或者是辅助，但是不要全篇地去依赖于一个大模型，帮你生成你的思维，这样的话我觉得是挺吓人的。

Speaker 2 01:02:59 
就是说如果说是我，因为我觉得对于本科生课程的话，大模型大部分都可以handle。如果本科生非常依赖于人工智能的写作，那对于他们对于这个课程的理解和他们对于这个课程理解会出问题，然后因为他们已经不用思考了，然后没有这个思逻辑思考的过程，他们对于课程就不能深入理解，然后自己写作的话也会退化很严重。

Speaker 1 01:03:34 
这我明白，所以我才想什么样的干预措施，能够干预。

Speaker 2 01:03:38 
措施的话，我感觉就支持 NTO 加强监管。

Speaker 1 01:03:44 
那我的研究就没有意义了。

Speaker 2 01:03:48 
干预措施的话，干预措施如果不从人的主观能动性出发的话。

Speaker 1 01:03:57 
不同人的主观能动性，你只。

Speaker 2 01:03:59 
对就是其实也和一个自控力有关系。我感觉就是其实大模型这东西挺像吸。是有点像，有点有会让人上瘾，就是当我们依赖它的时候，就是刚开始可能并没有那么依赖，但是如果用多了确实依赖性会变强，然后而且会变得越来越强。我们就不要让最后这个完全交给他这个现情况发生，而是把他遏制在我，比如说简单依赖他这个情况下，一就是时常锻炼一下自己的能力。

Speaker 1 01:04:36 
才行。你不有过度依赖的情况吗？

Speaker 2 01:04:40 
嗯，我觉得我有这个倾向了已经。

Speaker 1 01:04:44 
那你怎么去应对？

Speaker 2 01:04:49 
像我的话，比如说在代码上的话，我会做一些立扣这种，就是我不要refer。大模型给我的建议，但是就是我自己去做，然后遇到一些不会的数据结构，我会自己去查，自己去学，然后这样确实是印象深刻一些，就是在专业上，然后在 writing 上的话，我会强迫自己说一定要先用，哪怕是先用自己的母语汉语去把逻辑写一遍，也不要直接让大模型来帮我写。

Speaker 1 01:05:24 
OK，明白了就说能尽量少用的话还是会少用一些。

Speaker 2 01:05:29 
对，就是尽量要少用一些，然后就是关于逻辑组织的部分。嗯，要自己来，就是尽可能地要自己来。

Speaker 1 01:05:39 
嗯，明白。但我知道你意思，毕竟博士肯定是能做到这些，但对于那种可能 critical thinking 低的人，可能我觉得还是要看看有没有什么干预措施能解决这个问题，因为其实这个是我这个学科目前在研究的一个热点话题。

Speaker 2 01:06:01 
对，确实就是如果是。

Speaker 1 01:06:05 
没有，这肯定跟研究 AI 本身没关系，这肯定是在研究中间他们的交互过程。我其实跟你聊交互过程的时候就是想看看有没有什么啊？比较 interesting 的 insight 什么的。

Speaker 2 01:06:20 
嗯，我思考一下。

Speaker 1 01:06:23 
也没关系，就是这个其实就是我，我自己要去发现。

Speaker 2 01:06:27 
OK，对，好，那就辛苦你了，如果你有什么新的发现的话，也可以拯救一下我们这些即将陷入深渊的同学们。

Speaker 1 01:06:37 
对，我觉得对于博士可能没有任何的帮助了，因为可能博士其实具备自己的 critical thinking 能力吧。嗯，其实还是挺 OK 的，可能我往下做一做可能也说不定有点帮助吧。就目前在做，其实因为你提到的点，比如说好互相的交叉验证，就是两个 model 同时生成嘛。那其实已经是被迫地去让你 critical thinking 了，因为你没办法直接用一个嘛，你肯定会两个都看。

Speaker 2 01:07:05 
对，就我觉得如果实在难以自控的话，多 refer 几个也是好事。

Speaker 1 01:07:11 
对，因为有可能比如说我给你 5 个model，你同时生成答案，你总是要 5 个都看过去的，就。

Speaker 2 01:07:17 
被迫。对。

Speaker 1 01:07:18 
对对，就可能想到的一些方就方法，看怎么有什么方法可以去进一步地去，对吧？就把这个事就做这个idea，其目前我就在做这个。嗯，OK，那其实访谈也时间也挺久了，那个如果我后续那个 experiment study 的话，你有兴趣参加吗？但我感觉这个这 experiment study 会不会对你的其实可能效果不是很大，因为我其实是在做 critical thinking。

Speaker 2 01:07:50 
OK，那可能就像您说的，可能要找一些嗯，低年级的学生，可能他们。

Speaker 1 01:07:59 
也不一定，就可能在考虑这个过程中，可能我比如说三个组都是高 critical thinking，然后发现我的干预措施不管是高 critical thinking 还是低的 critical thinking 都有帮助。那说明我的应啊这个干预还是有用的，就看我怎么去分组吧。看就看啊，没关系，这个都是我后续要考虑的了。OK，好嘞，对，就你是有兴趣的话，我到时候其实是会发 sign up form，就是链接这些， OK 吗？还是。

Speaker 2 01:08:30 
我，我 OK 的，我 OK 的，我还是挺感兴趣的，这个有点像叫什么人机，人与人机交互这块的。

Speaker 1 01:08:39 
对，我商学院是做，就是做人机交互，在那个 information management 就是信息管理这个方向下的，就system。对对对。

Speaker 2 01:08:49 
我们这边有一个专门的研究，也叫人，也是人机交互，但是他们研究的可能就硬件。

Speaker 1 01:08:56 
过去。

Speaker 2 01:08:57 
的，我叫 b VR、 AR 之类的。对，然后以及自然语言处理这边也有一个叫 human in natural language。

Speaker 1 01:09:07 
但它可能我觉得它好像更加偏向于技术类，如果在你们学院的话。

Speaker 2 01:09:13 
对于，对于这个 annual com，就是 ACL 这个群体， annual community 这个 language 这个群体来说，它有一个专门的track，是研究这个语言和人类的啊。就是我我也见过，就是比如说就是商学院来投稿ACL，就是这个我人这个人工智能与自然语言处理的顶会我也是见过。

Speaker 1 01:09:38 
的，有，因为像我这个方向就是 information system 下面，它会有做 computing 的，就是做确实也是做算法的，有这么一个方向。然后有一下计算机，然后再往我这个方向就是 human computer interaction 的话，是做实验访谈或者是问卷，或者是一些，就是偏向于这种人与人之间的一个关系的，这。这种研究。嗯嗯，看看他们的方向了，还是会有的。OK。

Speaker 2 01:10:05 
我OK，我表示感兴趣，然后如果有需要的话可以再联系我。

Speaker 1 01:10:10 
没问题没问题，谢谢谢谢。诶，好嘞，OK，然后我应该是都问完了吧？OK，应该是问完了。好，行，好，感谢哦。对，那个钱的话可能会，我不确定两周内到底能不能到账，因为主要是麻烦在商学院这边要经过那个金融，就他的那个财政财务部门，然后需要导师去填那个信息。我又不敢麻烦他，他官太大了。就是就是，我要我要就是一次性地给他准备好所有的名单，然后我又是反弹，是一个一个往下做，然后又不仅仅我这一边一共是三个人在做访谈，然后他们那边还没开，我就不担心两周内可能不一定能钱到账，到时候我再，我后天嘛。对，我和后天会跟老师聊一下这件事情，就我尽量的话会把钱，就是会早点，就是转给你们嘛。对。

Speaker 2 01:11:05 
哎，好嘞，OK，OK，辛苦你了，祝你研究顺利。好，谢谢谢谢。OK，好，那就今天就结束了。

Speaker 1 01:11:15 
可以先结束吧。好。

Speaker 2 01:11:16 
嘞，好好。

Speaker 1 01:11:18 
拜拜。


受访人17:
2025-08-21 18:06:44 CST|1h 17min 57s

Keywords:
变量、算法、谷歌、文献、计算机、函数、学术、语料、金融、数据处理、信息检索、深度思考、数学公式、时间序列、数据文件、思考流程、时间成本、综述文章

Transcript:
Speaker 1 00:00 
nice，好，那我们就正式开始那个我这次的课题是关于基于交互记忆系统优化人机团队表现的一个研究。然后主要是为了解一下你在使用 ChatGPT 的时候，在工作或者学习流程中是如何和 AI 进行协作的。然后就是主要关注于你的一个交互的一个方式，还有你的一个思考的一个方式。然后是怎么样的一个过程，以及你对 ChatGPT 的优势劣势的一个认知的一个情况？好，OK，然后 OK 的，对，然后我全程是录音的，然后只用于我的这一个研究，不会用于其他的地方。

Speaker 2 00:47 
呃。对。

Speaker 1 00:48 
OK，然后你可以简单介绍一下，描述一下你目前的职业或者学习的领域吗？

Speaker 2 00:56 
学习的领域我现在是一个应该算 researcher 这种研究人员，然后研究领域是商科，平时会用到GPT，它算是一个助手，这种感觉。

Speaker 1 01:15 
就是商课的具体的哪个领域？

Speaker 2 01:21 
金融经济学。

Speaker 1 01:22 
OK，那在这个领域中你通常会处理哪一些类型的任务啊？

Speaker 2 01:29 
嗯，可能是让他去读一篇文章，然后总结提出，就是总结文章的大体内容，偶尔会让他写一下代码。

Speaker 1 01:47 
OK，所以主要是writing。 Holding. 所以主要还是用于学术上的一些研究，一些任务中。

Speaker 2 01:59 
了。对的，对。

Speaker 1 02:01 
那是从大概什么时候开始使用 generate AI，就什么时候开始使用生成式 AI 的呢？

Speaker 2 02:08 
我觉得我记得 GBD 应该是 23 年2月出的还是 22 年？ 23 年2月。 22 年吗？ 23222 年底差不多那个时候，然后应该是隔了快一年才开始用，应该是 23 年底或者 24 年才开始用。因为一开始他刚出来的时候，大家对他的态还是持怀疑态度。

Speaker 1 02:40 
OK，所以用得比较多的是ChatGPT。

Speaker 2 02:45 
对，我用 ChatGPT 比较多，别的像那个 Germanas cloud 用过几次专门的，你看 PPT 用的那个国内的话，可能那些什么中国的豆包还是豆包，你听说过吗？

Speaker 1 03:06 
我知道抖音的。

Speaker 2 03:09 
我不知道它是不是抖音的。在国内的话就是用豆包那几个，国外就GPT。

Speaker 1 03:15 
OK。所以你没有用过那个 cloud 吗？还是什么？就是我。

Speaker 2 03:21 
用过 cloud 跟那个 Gemini 用过两不应该用过几次。

Speaker 1 03:27 
对，发现效果不咋地。

Speaker 2 03:29 
嗯，首先很难去就是对比，因为我 GPT 是有充那个会员，所以你跟 cloud 比就很难说。我懂，这是个很公平的测试。

Speaker 1 03:46 
我懂你意思，因为我开了两个的会员，一对比发现现在 GPT 最近让我用得不太行。

Speaker 2 03:53 
你是觉得 cloud 更好用是吗？

Speaker 1 03:55 
我没有，我用的是谷歌的那个German，你们还 GE GE German 来着？

Speaker 2 04:00 
German 它是 coding 比较好用吗？还是哪方比较。

Speaker 1 04:03 
好用哦？我最近用在 writing 上。 writing 感觉我觉得不会像 ChatGPT 那么的肤浅嘛。可能 ChatGPT 最近的更新更新有点小问题，我觉得用得不太比之前，应该说比之前下降了。

Speaker 2 04:20 
你是跟 4 比还是跟 5 比？

Speaker 1 04:22 
o 3 比？我就是把 ChatGPT 五的那个 thinking 跟 O3 对比，然后发现有所下降。

Speaker 2 04:29 
O3 对O3。

Speaker 1 04:30 
你有没有感觉。

Speaker 2 04:32 
O3 是 Gemini 的吗？我我我没有怎么用过它，那个。

Speaker 1 04:36 
GPT 的。

Speaker 2 04:38 
是 GPT O3。 GPT O3 跟谁比？

Speaker 1 04:41 
O3 跟 ChatGPT 5 的syncing。

Speaker 2 04:45 
所以你刚刚不是跟我说你开两个的会员是一个是谷歌那个一个。

Speaker 1 04:49 
哦，我懂你意思了。我那我现在对比的是谷歌的那个 Pro 版本和 GPT 5 的 thinking 版本。

Speaker 2 04:58 
对，是谁比较好用？你觉得？我觉得。

Speaker 1 05:01 
pro 谷歌的好用一些嘛。个人感觉。

Speaker 2 05:04 
就是。

Speaker 1 05:06 
writing 和 coding 的话我也尝试了，但我觉得两个差，两个就是我尝试过一个很好玩的任务，就是把一个文件数据文件丢进去，让它帮我生成，然后 GPT 它会有会掉数据，就是数据会损失特别多，就有点造假。

Speaker 2 05:27 
你是说给他一个数据文件，然后让他画图还是。

Speaker 1 05:31 
直接处理？叫他帮我生成几个变量。

Speaker 2 05:36 
我没有这么干过，因为我觉得他如果数据量比较大的话，就会让我不太放心。

Speaker 1 05:47 
所以你一般是让他生成代码，对吧。

Speaker 2 05:51 
对，而且他一般代码就是我一般会让，就跟他说我要怎么做就是。嗯，我的个人经验是我会直接告诉他我要写怎么样的一个函数去做处理，然后因为他经常会写一些很笨的东西出来，然后我就会对他很不满。

Speaker 1 06:17 
嗯，那对于这个任务的话是比如你可以举个例子，比如说你现在要写个什么 coding 任务？

Speaker 2 06:29 
我一时之间很难跟你讲，就是哪个具体的任务就是怎么说呢？就是我的，我就感觉 PPT 如果你让他写一些简单的函数，那它是可以的。但是如果你需要那个函数比较，就是需要对这个数据结构有一些认识，他有时候就很难写一些比较。快的函数就是你最好给它指定一个方法。

Speaker 1 06:59 
我懂你意思，你是想对，在追求效率方面，而不是追求准确度方面。

Speaker 2 07:05 
呃。我觉得准确度也就，嗯，对，效率确实是，就是他有时候给的代码，他的方法一看就是运行得特别慢嘛。嗯，他这个算法的复杂度是那个 n 方，你能给他整一个这种根号 n 的复杂度的，那你肯定比他快嘛？他一般他不会很糟糕，但是有时候当他我感觉他不太了解这个任务是干嘛的时候，他的方法选的就不太好。我不知道你有没有类似的感觉或者经历。

Speaker 1 07:49 
但我有个问题，就是你这个任务你有跟他描述清楚你这个任务的场景，或者说就是就跟他讲清楚很详细的流程之后，你再让他生成代码，还是说你已经思考得差不多了，就是给他其中的某一步让他去完成？

Speaker 2 08:11 
嗯，两种情况都有，但我好像我一般会是后者多一点，就是说不会整个都交给他。

Speaker 1 08:24 
当时有没有考虑过就是可能你给他这个，比如说这个任务，然后让他生成一个框架或是一个结构，然后你再来判断是否合适。

Speaker 2 08:40 
你是说在向数据处理的时候还是说向做？

Speaker 1 08:45 
嗯，那要看你具体什么任务，因为我现在其实还不能定位到你现在说 coding 属于什么任务中。

Speaker 2 08:56 
确实，我一直也想不起来继续等下再回到这个问题，说不定就突然想到，OK。

Speaker 1 09:04 
OK，OK，那等下聊到任务的时候再继续吧。所以你目前使用的 check GPT，你一般会用哪个版本啊？

Speaker 2 09:13 
它现在不是都更新成 5 了。

Speaker 1 09:15 
吗哦？那你用 thinking 多还是用普通的模型？

Speaker 2 09:20 
嗯，看干什么活吧，我一般就普通的，我感觉就够用。

Speaker 1 09:26 
OK。原来你喜欢用普通的。

Speaker 2 09:28 
好哈，你让他 thinking 的话就感觉用的场景也不会特别多，因为我有什么能让他去想。

Speaker 1 09:43 
我？我一般会用到 writing 上，就是各种的写作，或者是。

Speaker 2 09:48 
对，我很少让它直接生成，我要写哦。可能是我目前要写的东西还不够多，哈哈哈，所以确实没有用到他这方面的功能，一般就让他总结，想一个。对，想一下coding，或者想一下问题之类。

Speaker 1 10:07 
OK，那你跟他的一个使用频率怎么样？

Speaker 2 10:12 
就你基本每天，就，对，每天都会用，就有，就把它当成是一个那种谷歌的替代品，就你搜到搜索栏的东西丢给它，哈哈哈。

Speaker 1 10:30 
所以你还会把它用到一些信息检索上。

Speaker 2 10:34 
对。

Speaker 1 10:35 
但信息检索的话你对于它的准确度就很信任吗？还是说你也会再做一定的检验？

Speaker 2 10:42 
我会做，就是会 check 一下，因为我总体对这种 LM 其实本质不是很信任，因为当你学过它的原理之后，你就会发现它很依赖于它训练的时候的那些材料，所以就是说它这种东西输出的时候，它其实是一个概率模型，他很难说他是百分百是对的。即使是我们去 Google search， Google 上搜一些东西，我们也会自己判断，所以它其实就类似于一个，就在搜索这方面，其实就类似于一个普通的搜索引擎。

Speaker 1 11:30 
明白，所以你就想在信息检索这一块就是他给什么，反正一般常识性的肯定也就不需要再检索了，对不对？就是这个意思。

Speaker 2 11:43 
常识性有谁让他检索一下？让他，你说你买个西瓜或者买个榴莲，到时候你拍给他。

Speaker 1 11:53 
用他的。然后用它做什么？我好奇你买水果用它做什么？

Speaker 2 11:57 
你问他哪个榴莲看上去比较好吃。

Speaker 1 12:01 
哈哈哈，就让他给一些建议。对，那这时候你就会觉得OK，也不用再去看什么其他的一些什么小红书或是谷歌 search 什么的。

Speaker 2 12:15 
我觉得是一个搜索成本的问题，对吧？你直接两分钟它就给你生成了 200 字，哈哈哈，persuade，你这个榴莲比较好吃，那你再去小红书就没有必要了。

Speaker 1 12:30 
OK，所以他其实是在帮你，现就叫节约时间嘛。应该这么说，就是时间成本。嗯嗯，OK。刚才好像有提到哈，就是说你为什么选择 check GPT？不用其他的诶？对，你一开始为什么就选择 check GPT？

Speaker 2 12:49 
因为 GPT3S 3.5 刚出来的时候不是最牛。

Speaker 1 12:55 
所以是因为一开始的原因，后期并没有关注其他的那种升 Cai 的变化。

Speaker 2 13:02 
我没办法关注啊。我这边充了钱，你说可以退充多一部分钱过去干嘛呢？就这种。

Speaker 1 13:09 
你，我告诉你那个ChatGPT，如果你选择退订，它会让你三个月半价。

Speaker 2 13:16 
真的吗？

Speaker 1 13:17 
我就是我前两天看到，然后老板。

Speaker 2 13:20 
退了，然后再是再，再，不不。

Speaker 1 13:22 
不，他是挽留你，所以他会给你三个月的半价。

Speaker 2 13:26 
那我三个月后再来一次。

Speaker 1 13:29 
好像我不知道行不行，反正你可以先那个先，这三个月先省个省一半的钱嘛。

Speaker 2 13:35 
我之前当时纠结要不要充这个会员，当我说我要充的时候，当时应该 4 刚出来，然后他跟我说有名额限制，然后我连充都没法充。OK。

Speaker 1 13:55 
然后他现在就要挽留你，因为确实就因为 5 的出现，大家都在退。

Speaker 2 14:01 
为什么。

Speaker 1 14:02 
可能就性能下降了吧？大家都不喜欢，反正小红书都在骂5。

Speaker 2 14:07 
这样子吗？我感觉。

Speaker 1 14:08 
5: 4 好用。

Speaker 2 14:11 
我没有感觉有什么差别，因为。

Speaker 1 14:15 
我懂你，可能是任务的问题，可能每个人对用途不一样的时候就会发现。

Speaker 2 14:20 
因为它不是说 5 有个好处，就是它会 automate 打雪仗。

Speaker 2 14:26 
Si fast thinking as deep thinking. Today.

Speaker 1 14:31 
Some instant. 你是说五会干嘛？

Speaker 2 14:34 
它五会自动选，我要用深度思考还是什。

Speaker 1 14:40 
会吗？我怎么没有注意到啊？没事，等我等你这，等我之后也去试，再试试，我，我还没过期。OK，那我就要聊到具体的任务了，你就你可以描述一下你常用的一些任务，就ChatGPT，对吧？就你用的一些场景上。

Speaker 2 15:06 
我刚刚不是讲。

Speaker 1 15:08 
哦，对啊，我知道你这 coding writing，然后还有一个信息检索，对吧？嗯，没有别的场景了吗？

Speaker 2 15:18 
有没有例子让我去过去？

Speaker 1 15:22 
你是说举例子是吧？OK，那就从 writing 开始。OK，那对于 writing 的话，想了解一下你跟 ChatGPT 是怎么互动吧？不对，是 writing 吗？还是说总结啊？你刚才说的是总结。

Speaker 2 15:39 
总结。

Speaker 1 15:42 
那对于这个任务你使用它的一个目标是什么呀？

Speaker 2 15:46 
这个我也想跟你交流一下，我也不知道你是怎么用，我之前就让它生成summary，我就说你要包括 research question，对吧？然后methodology，conclusion，finding。然后还要加上那些什么你的巴拉巴拉，我之前有一堆prompt，因为我没有怎么学过这个prompt，是别人跟我说这个比较好用啊。然后后面我就每次用这个，然后后面我有一天发现我直接就跟 GBD 说。

Speaker 2 16:30 
Summarize this paper in details.

Speaker 2 16:34 
它出来的结构会比我用 prompt 的要更好。

Speaker 1 16:40 
其实我一般也是直接说，请帮我总结一下这篇文献。

Speaker 2 16:43 
因为发现对，它好像会被我的 prom 束缚住，然后它输出的内容就会。

Speaker 1 16:50 
按照你的prompt。

Speaker 2 16:52 
对，嗯，什么？你说什么？

Speaker 1 16:53 
我说就是会按照你的那个 prompt 的那个提示词来，不会超过你的一个限制嘛。

Speaker 2 17:00 
对，但是它有。

Speaker 1 17:05 
重复，是指在哪？

Speaker 2 17:07 
就只要是我的 prompt 跟你说你的研究问题有什么意义，然后有什么启发嗯？其实你发现这 3 个东西它是有关联的，它就会基本会有一些点重复讲，所以你整体看下的感觉就是不太好。

Speaker 1 17:32 
但你有没有考虑过一个问题，可能是因为 GPT 的发展了，然后这个 prompt 就不适用了，而不是因为这个 prompt 不太好。可能就是之前你这样子限定的话会让它输出得更好。但他的发展过程中导致他其实现在的输出能力、理解能力比以前好很多了。

Speaker 2 17:52 
有可能对，你有，你觉得有，我们有没有必要去学 Prom 这种？

Speaker 1 18:01 
我就是这一次的，就这一次的收集数据中，因为我这次是重点在这个。

Speaker 2 18:05 
录音，应该别人听了也没事吧？

Speaker 1 18:09 
我不会发。

Speaker 2 18:10 
给别人，我说你偷偷等下搞完之后发我点那 prompt 学习资料。

Speaker 1 18:19 
发 POM 的学习资料。

Speaker 2 18:21 
有什么好用的？因为我感觉 POM 的话就众说纷纭。我有人说这个好用，说那个好用，我很难去劝。

Speaker 1 18:33 
我觉得这个可以，等我访谈完那个计算机专业的给你，然后再给你一些建议，因为计算机专业他们有一个填了，他说他专门做 Prompt engineering 的研究计算机那一。哇哦，对，然后对我就很好奇，所以这一次的。

Speaker 2 18:51 
反我也很好奇。

Speaker 1 18:53 
对，我之前访谈的 15 个人主要集中在人文社科，计算机比较少。然后这一次我增加的样本量大概 20 个，可能都计算机类的，所以相当于我会从计算机那边得到一些更有意义的一些，就他们怎么去理解这个工具的，对吧？三科我觉得是单用更多，然后计算机是研究它更多。

Speaker 2 19:16 
对，确实对，所以这个你好消息我也想知道，哈哈哈，你知道这个 LM 怎么来？因为我之前有计算机背景。

Speaker 1 19:28 
对，我看你写了一个中等程度的 coding 背景。

Speaker 2 19:32 
但是确实。因为我本科有修过计算机的学位，但是确实没有正式做过这种 prompt engineer。

Speaker 1 19:44 
但你本科的学位是跟 deep learning 相关还是跟 machine learning？就是主要在哪一块上？

Speaker 2 19:53 
本科时候就学那个就是 C + + 计算机的东西，没有特别偏这种 AI 的。所以只是。

Speaker 1 20:03 
学语言比较多，或者说。

Speaker 2 20:06 
嗯，学算法，其实那种什么 machine learning， deep learning 我都懂。那不是什么啊。

Speaker 1 20:13 
那你懂的话，其实 LM 不是也差不多嘛，只是说现在变得。哦，我懂你意思，以前的 deep learning 主要是在调参数，现在的 LM 是在玩逻辑链。

Speaker 2 20:25 
嗯，我觉得不太不能这么讲，主要就是说，嗯，你好像是个LM，你懂了它的原理， attention is all you need。然后它本质上能解释的东西就很少，你就按 deep learning，你解释的东西也很少，对，就可解释性也很低。就到最后他直接这种训练模型训练就是他自己去学出来，最后怎么样，你其实里面就是个黑盒子，很难说这有什么类比的，你就是我，你能大概明白我想讲什么？

Speaker 1 21:11 
嗯，我知道，其实你是想说类似就是说都是黑盒，然后输入输出的话其实是没法判断的。

Speaker 2 21:19 
对，你其实不知道它里面发生。

Speaker 1 21:24 
但我看的话其实也就是他目前研究很多都在为了理解用户意图，就比如说你。你随便说一个总结，他可能就要分析很总，你这个总结需要包括什么方面嘛？所以就是说现在可能慢慢地在加深这一块，然后算法上的研究我不是太了解，可能真的要跟等我后面几个的 interview 做完，我应该能有一个很好的判断吧？

Speaker 2 21:51 
可以可以，我也等你做完，哈哈哈，我觉得他现在这种 Gena generative AI 其实它是往那个 AI agent 那边走。

Speaker 1 22:06 
那肯定的是。

Speaker 2 22:07 
对，它算法好像就现在到瓶颈就是它，那就想到最后的方向就是解放我们的双手，但我其实不是很懂这种 GBD a AI a 那个 agent mode 跟普通的 mode 有什么区别？我看了他们怎么用，但是就我不懂他那种在任务是具体的任务上什么不同。

Speaker 1 22:37 
哦，你是想说普通的和现在的是吗？

Speaker 2 22:41 
对，他不是出了个叫什么 a agent mode 嘛？

Speaker 1 22:45 
a 梦我都还没用过这个功能，你用了吗？

Speaker 2 22:49 
我没有用过，他就天天提醒我，他说你可以用，哈哈。

Speaker 1 22:53 
等那可以，等你尝试之后你。

Speaker 2 22:55 
告他，他好像是类似于你做一种重复性的任务，然后就可以让他帮你做。

Speaker 1 23:04 
哦，那会不会就是一。

Speaker 1 23:05 
So you see them promise engineering, they zone.

Speaker 1 23:10 
模板结构化之类的？

Speaker 2 23:13 
嗯，不知道，等我用了告诉你，哈哈哈。

Speaker 1 23:18 
OK，OK，OK，那我们继续吧。刚才说到的summarize，那 summarize 的话你会把这个任务拆解成很多个步骤吗？好像也没必要。

Speaker 2 23:31 
是吧？ summarize 不是，对。

Speaker 1 23:34 
没什么必要哈。嗯，那其实我有个疑问，你丢进去之后他给你总结完 OK 了吗？就这个任务就算结束了吗？

Speaker 2 23:46 
你是问我还是问他？

Speaker 1 23:49 
问你。

Speaker 2 23:53 
我什么叫任务结束？什么。

Speaker 1 23:56 
意思？就是说你文献让他总结嘛？那总结他给你东西了，然后呢？后续是发生了什么？

Speaker 2 24:06 
然后我就读一下他的summary，就完，之后我就去读那篇文章了。

Speaker 1 24:12 
所以这个过程你是只是用它来判断这篇文章你要不要精读。

Speaker 2 24:17 
还是说不是？就是我已经知道我要读这篇了，只是我读一下他大概讲什么。

Speaker 1 24:27 
所以你知道要读这篇的原因是老师布置的，还是说。

Speaker 2 24:31 
你以就直接看一下option，你就知道自己要不要读了哦？我是，我发现你这人夹带私货，这个一个博士学长还问我这个新人。

Speaker 1 24:43 
没有？我现在是在要把这个任务拆解，因为这个跟我的研究有关。

Speaker 2 24:48 
因为我就直接会让他总结，因为他总结他可以抓一点重点。

Speaker 1 24:57 
所以说你用他的，其实你自己已经有判断这篇文章你要不要读了，而不是说全部丢进去，让他总结一下哪些就看，再看总览，对吧？就不是。

Speaker 2 25:09 
对，我其实已经知道那篇文章要读。

Speaker 1 25:11 
了，那其实相当于在这个分工过程中你已经做了一定的选择了，就是，对，然后选择完之后才让 ChatGPT 来做分析。那分析完之后那他其实只做了这么一个步骤，没有后续嘛。

Speaker 2 25:26 
嗯，如果我读文章有些不懂，就问他。

Speaker 1 25:30 
意思，就是说概念名词解释，或者是。嗯，对，或者是这个算法不了解，让他给你解释一下大概这种。对，那我其实就是，那其实就是说这篇文章你反正都是要读的，他总结的对不对？也不，也无所谓。可以这么理解。

Speaker 2 25:54 
还是有所谓的，因为有所谓，没有他为什么会总结？不对呢？就给他丢了个文章，他输出的东西正常就应该是那文章内容。

Speaker 1 26:10 
这我很少会用来总结文献，所以我也就不知道他的这个长处是不是很擅长。应该是很擅长的吧？

Speaker 2 26:18 
嗯，还不错，那相当于提取信息这样。

Speaker 1 26:25 
那你会让他扮演某个特定的角色吗？比如说你现在是一个什么什么什么，然后帮我总结什么什么会这么去指示他吗。

Speaker 2 26:35 
依然不会。

Speaker 1 26:37 
嗯，所以你就习惯性地直接丢一个，就是总结，nice，对吧？嗯，那如果就是所有的文献，你会不会存在？有些文献其实你很熟悉，有些文献你不熟悉，这会出现使用 AI 的方式不同吗？

Speaker 2 27:04 
我觉得没有，因为我一般就是在读那个文章之前，那就总结，因为我读完了之后，其实我就知道那篇文章是什么了，所以我就没必要再用它了。

Speaker 1 27:20 
OK，所以这个任务中不存在这种情况，应该这么说。对。

Speaker 2 27:25 
啊，对对。

Speaker 1 27:28 
那这个任务也不存在信任程度，对吧？毕竟也只是一个信息检索。

Speaker 2 27:34 
嗯，我觉得我对他输出的内容一般是比较信任的。我是信任的，因为这个任务的难度比较低，是你要看文章的类型，一般是那种时政的文章，它输出的八九不离十，但如果你说是那种论述型的，他有时候不太行，因为他例如说那个段落很长，他就抓不到重点。

Speaker 1 28:01 
你是说时政反而更清晰？

Speaker 2 28:04 
对，因为时政那个作者会把结论写在 up 上，然后也会写在conclusion。

Speaker 1 28:13 
诶，你是说他总结论述反而不好。

Speaker 2 28:16 
是吗？因为你的那个论述很长，他有时候会抓不到重点。

Speaker 1 28:23 
懂你意思就是说你 iterator review 丢进去，可能他输出的东西就没办法服满足你的一个要求。

Speaker 2 28:31 
嗯，我感觉他输出不够详细。

Speaker 1 28:34 
你就是有尝试过时政论文、论述类论文还有什么吗？比如说可能会有算法论文，就比如说难度更大一点的就是数，就数学公式比较多的。

Speaker 2 28:47 
他一般即使数学公式比较多，他不会在总结的时候给你列数学公式。

Speaker 1 28:53 
但他能，但。

Speaker 2 28:54 
会变成一个比较泛，没啥用。说白了这种数学的论文你就直接读就好了，这读不懂就不懂，读得懂就懂，那这东西都不用PPT。

Speaker 1 29:09 
OK？那我肯定能理解，就是说，诶，因为这个点我是没有发现的，就是没有聊到过，就是说因为综述文章反而他会。

Speaker 2 29:17 
输出，我感觉他是因为当那个作者怎么说，就是说的东西很多的时候，他列 a 这么讲， b 这么讲，他逻辑链兜来兜去的时候，说白了你就不像AI，你自己是个人去读，你都晕得要死。然后他也会有点问题。

Speaker 1 29:40 
那我可以，比如说有没有可能存在一个问题啊？比如说你的时政论文可能也有一个三四十页，四五十页的时候就它的页数如果更多的时候会不会也会出现这个问题？因为论述类文章很长。

Speaker 2 29:56 
觉得我觉得时政问题很少，因为它其实。它的结论都是呈现出来的，就是 x 影响 y 这样，但是它论述的假如说它有很多个影响因素，然后这个影响因素有一个分类，然后那个影响因素有个小分类，然后分别是由什么引起的哦？然后这两个因素可能又有关系，要这时候他就混乱了。

Speaker 1 30:34 
但你有没有尝试过？因为如果遇到我遇到这种问题，我可能会说，请你以表格的方式给我呈现，这时候它的逻辑链、逻辑线会让我更清晰一些，就因为就输出方式我会改变，但我不知道你有没有尝试过，就是让他输出方式进行一些改变。

Speaker 2 30:52 
我没有，你有什么推荐。

Speaker 1 30:55 
我？我没有什么推荐，就是因为我很少会让他总结综述类文章，因为综述类文章。

Speaker 2 31:00 
我说不是纯粹的综述类文章，因为纯粹的综述类它没有什么好总结，我说的是那种，就是就怎么说呢？就是有点像文科的文章，就是一直在讲我们，然后，嗯。

Speaker 1 31:18 
我其实不太理解的是因为时政的话其实也算人文社科类文章嘛。嗯，所以，对，这就在你们的专业分领域中，你怎么判认定它是文科类文章，或者说时政文章？

Speaker 2 31:34 
就有数据跟没数据这种感觉。

Speaker 1 31:39 
那会不会比如说类似于 m 阶，或者是就这种刊物？因为它的理论很强。他。

Speaker 2 31:45 
理论什么？什么？你刚刚说什么？什么开户。

Speaker 1 31:47 
m 界 Academy management general 吗。

Speaker 2 31:52 
对，类似于这种。

Speaker 1 31:53 
对，就是这种理论性很强的文章，他就没办法去很好地总结，对吧？我大概理解了。因为它里面会画一个图，然后这个图会有很多因素，然后会有框架，会有维度。对，那这种文章你是认为它 ChatGPT 总结不好。

Speaker 2 32:13 
个人观点。

Speaker 1 32:15 
哦，OK，那。

Speaker 2 32:17 
可以，对，后面有啥可以交流？

Speaker 1 32:22 
OK 啊，那我其实觉得也。

Speaker 2 32:24 
特别他这方面。拜拜什么个人观点。

Speaker 1 32:30 
没有，我是说你可能可以尝试让他 output 生成方式变化一下，比如说表格或者是什么 7 ~ 8 的方式。

Speaker 2 32:39 
可以，我下次试一。

Speaker 1 32:41 
嗯，OK，那以前就跟你以前看文献相比区别很大，应该就是整个的变化，比如说影响你的思维深度吗？会不会影响到一些就改变了你一些什么的？一些怎么去描述这个问题？就对于你的思维方式或者说效率或是质量有没有什么方面的一些变化？

Speaker 2 33:08 
其实我觉得这方面没什么差别。

Speaker 1 33:11 
就是说反正你早晚都是要读这篇文献的。

Speaker 2 33:14 
对。

Speaker 1 33:18 
那我们换换换另一个任务吧。

Speaker 2 33:20 
不要都 coding 了，看你时间快爆了。

Speaker 1 33:26 
其还好 coding 吗？OK，那coding，但 coding 你肯定有分很多种类型的任务吧，对吧？

Speaker 2 33:36 
嗯，没啥类型，就是一般数据处理，怎么？

Speaker 1 33:41 
嗯，数据处理那跟那。唉，不是就大概是什么类型数据处理嘛？是啊，时间序列还是图像文本，还是。

Speaker 2 33:54 
结构化的吧。

Speaker 1 33:57 
那结构化不就是表格的东西，处理就处理表格中的一些字段。对，对呃。那对于这个任务的话，你用它的一个目标是什么呀？就是帮你是处理它，然后是给你算法还是给什么具体的？

Speaker 2 34:17 
嗯，可能是你要洗一下数据的时候就会用它。

Speaker 1 34:26 
只是清洗数据吗？就或者说你可以具体举个例子，比如说这个任务你现在要去干嘛？就是可能是嗯扣不对，我应该怎么去？你应该，你有想到什么样的任务吗？你就最近的一些任务。

Speaker 2 34:44 
我最近没有用它coding。

Speaker 1 34:48 
啊，你最近都在看文献是吗？

Speaker 2 34:50 
最近？唉，最近没有怎么读书了，就感觉它，因为我从来不记 Python 代码。

Speaker 1 35:04 
从来不我。

Speaker 2 35:04 
觉得，因为我觉得这个 Python 太简单了，然后我每次就是诶我要用这个东西，我就去找一下，然后找到之后我就丢上去。羊奶m。你要我一，我丢上去我就忘了。 PPT 就很好，因为我可以直接告诉他我要干，然后他就给我生成，我就不需要，不用再去找。

Speaker 1 35:30 
没有没有，其实我是想说，就是比如说就是你之前的一个任务中，你会把这个任务进行拆解之后，就自己先拆解，还是说让 ChatGPT 帮你拆解这个任务？

Speaker 2 35:43 
我不会拆。

Speaker 1 35:44 
你，你自己拆，对吗？那你拆解的时候，比如说这个任务，你可以举个例子，比如说具体的这个任务你要干嘛？就是你要把它完成到什么程度。

Speaker 2 35:59 
你有没有例子啊？大哥。

Speaker 1 36:01 
真的是我让我来举例子吗？哈哈，我想一下，你举。

Speaker 2 36:07 
个例，你举个你的例子，然后我就不想干。

Speaker 1 36:10 
怎样？我最近在写什么coding？我知道，我最近的话就是在分析那个城市日报对报纸的一个情感分析啊。对，然后会用采集 VT 来帮我做一下。

Speaker 2 36:32 
那你其实也是拆解完让他做。

Speaker 1 36:36 
我吗？我因为这个任务其实我很清晰我要做什么，就我会把报纸全部丢进去，然后跟他讲这些词，你判断之后就是正面、负面。然后这些词就是判断它是对于什么的情绪，对于什么类别的情绪，就我会把它限定，这因为我比较清楚这个任务是什。嗯，对对，然后你，你一般会就，你可以举个具体的任务你就知道。

Speaker 2 37:11 
嗯，我平时真的就拿它做一点很简单的东西，就是我不想写这个函数，他跟他拼在一起我都懒得写，我就让他帮我把它拼起来。所以。

Speaker 1 37:32 
是那其实在这种任务中你反而已经是写得差不多了，是吗？还是说其实已经写了个小大概了，然后让他。

Speaker 2 37:43 
去，你说大概是指什么？是指我的 code 还是说。

Speaker 1 37:46 
什么？你的 code 你不是说只是让他帮你处理函数，相当于你不是已经写了一部分了嘛？

Speaker 2 37:53 
没有，我就从，哈哈哈，你说我就只需要写这个函数。

Speaker 1 38:01 
你的意思说就是我现在要写这么个函数？不是，我其实很好奇，就是你难道不会把任务背景给丢进去吗？就是完整整的任务背景。

Speaker 2 38:11 
我很少这么干你。嗯，我直接就告诉他我有这个数据结构，然后假如说我要这两个表并在一起，然后我就不会告诉他说，诶？我要干嘛？所以我要并表，我不会干，我没有试过这样，你觉得跟他讲这种任务背景有好处吗？个人感觉。

Speaker 1 38:39 
因为我讲任务背景的时候是为了让他帮我全部处理完，就是因为你只是想要其中的一个函数，但我想要最终的结果，我不需要任何中间的步骤，你懂吗？就是我们的需，对，我们需求不一样。

Speaker 2 38:56 
但那你最后想要说你sentiment，你是让他直接输出一个。

Speaker 1 39:00 
sentiment 给你。对，我不需要任何中间的东西，我不需要代码，我。

Speaker 2 39:03 
靠。

Speaker 1 39:07 
所以我们的使用方式完全不一样，所以我才。

Speaker 2 39:10 
所以你是接API，然后让它接。

Speaker 1 39:12 
我不用 API 我直接丢进去，因为 thinking 的功能它是能处理数据表的。所以我才会用 thinking 的那个。

Speaker 2 39:20 
那你不会给他语料，假如说你这份报纸，第二份报纸他不会有 BIAS 吗？

Speaker 1 39:30 
BIAS，但是我就完全使用的是API，都就相当于使用的都是 ChatGPT 这个工具的话不会啊，其实很。

Speaker 2 39:37 
简。我这就相当于说好像说你这个聊天框一般持续个 30 次它就会爆掉。我懂你。

Speaker 1 39:43 
意思了，你是想说我一份一份地丢，是吗？我当然不是，我当然是丢一个一个 CSV 文件进去，就是所有的报纸都在里面了。

Speaker 2 39:56 
可以，原来你就相，其实就相当于接 API 的感觉。

Speaker 1 40:00 
类似。然后它最后周输出给我的也是一个 CSV 文件，我不需要知道中间它发生了什么。然后我就要核一下，比如说，诶这个结果，诶，是这样的，那我就会哦觉得那他这次处理还OK，如果结果不对，我会跟他讲你这个。

Speaker 2 40:13 
处，你怎么知道他那个结果对不对？反正这种 sentiment 你很难。

Speaker 1 40:17 
你看一下人工核。

Speaker 2 40:20 
不是他有。假如说他给这个是0.6，那个是0.61，你很难care。

Speaker 1 40:25 
我不care，我不care。他是零点六几，还零点多少，我会跟他讲清楚，你分清楚情绪是什么类别就好。因为我也只需要得到一个二分类或三分类positive，或者是negative，或者是中性的一个分类。

Speaker 2 40:37 
你会给他一个像定义这种，在前面。

Speaker 1 40:40 
我会跟他讲你帮我分成积极中性负面就是分好之后，然后把这一条新闻打好标签，是积极的还是正面的？

Speaker 2 40:50 
还是你，你会，你，你一般是新闻标题这种短的，是吧？

Speaker 1 40:54 
对，我一般先用标题来做，然后后续如果这个结果不好，我才会考虑用一些摘要或者是内容。我一般先用标题，因为标题短。

Speaker 2 41:08 
对，好，我我之，我没有我之前处理的任务跟这个不太一样，我一般就是那种纯coding。

Speaker 1 41:18 
就什么样的叫就什么样的纯coding，因为。

Speaker 2 41:21 
其实虽然你 run regression 之前你做的东西就是。

Speaker 1 41:26 
我懂你意思了，就是说回归之前的你一般处理的是金融时列数、时间序列数据。

Speaker 2 41:33 
还是 panel 吧？啥？ panel data 面板。

Speaker 1 41:39 
我也处理面板，因为我有其他不是我这个变量处理器，就我刚才那个城市日报的处理出来，它只是一个CV，只是一个控制变量。

Speaker 2 41:50 
对，我知道，我知道，对。

Speaker 1 41:51 
最后还是要做成 panel data。那其实说你是想说你的这个代码的写可能是。 panel data 之前的一些数据处理嗯？那为什么要用到Python？不是 Stata 就可以吗？

Speaker 2 42:10 
我觉得顺手，因为。嗯，这个人偏好吧。这很难。

Speaker 1 42:18 
不是，我的意思是说你是想说你前面的所有数据处理都用 Python 处理好之后得到 panel data，然后再输入 status 吗？是这样吗？

Speaker 2 42:28 
嗯，我喜欢这么干。我知道有些人喜欢 state 一路，这个是 preference 问题。

Speaker 1 42:34 
因为我其实挺少见，就是说 Python 处理到，因为我以前我刚接触 panel data 的时候，我也是像你这样的，因为我不懂，就是完全不懂Stata。然后我只能像你一样的就是说 Python 处理到一个 panel data，然后我再导入 Stata 中去跑，回归。后来发现好好折腾，因为我一补变量的时候，因为你不可能所有的变量都已经放进去了，一补变量我就要Python，但是如果我用 data 的话，我补变量我只要写几行小小的代码就可以了。就补变量很快，后来我就慢慢地转。

Speaker 2 43:06 
补变量。你意思就是说完我先有个表格，然后我再对。

Speaker 1 43:11 
一来补，对，因为一有 CV 我补的时候我就一就要去动 Python 的代码，很烦的，你懂吗？但然后只，然后如果用 data 的话，我只要匹配一下，很快匹配就很快了。

Speaker 2 43:25 
我懂你意思。

Speaker 1 43:26 
对这个人习惯，可能等你接触。

Speaker 2 43:29 
确实对，有这个优势，这个 data 可以。

Speaker 1 43:33 
对这等，等到后面可能你以后写代码写多，你可能慢慢地会转到data，对，便一些。

Speaker 2 43:39 
对这个习惯，这个就可能到时候又转成你这样，这个真的是preference。

Speaker 1 43:47 
对，可能时间问题吧。那如果你用 Python 完全处理好，那其实我知，我大概能懂，因为就相当于你已经完全知道这个任务是什么，然后只是说这个代码不想写，你帮我给一下，然后这个 merge 过来， merge 过去包括是这个变量怎么生成一下，对吧？嗯，那会有你会出现某个变量比较难。那你。

Speaker 2 44:09 
不会觉得说我有个问题，就像你data，如果我有用 data 去并表你，我感觉 data 好像一直只能用那份表。嗯，就是我如果要动另一份表，我就要clear，然后我重新 import 一份新的CSV。

Speaker 1 44:27 
进来。那很正常，你 in import 进来之后，然后你保存成DTA，然后 DTA 两个 DTA emerge 就好了呀。然后在这个过程会保持保留一份主的文件，就是主要的一个data，然后主要的一个DTA，然后就会不断地把其他的文件 merge 进来，然后你其他的 DTA 就是留在那里啊。

Speaker 1 44:47 
因为你比如说你可能会出现某个变量，你这次的 merge 不一定是有效的，也有可能你漏了某些东西，那我只要再去之前那个地方，把那个第，把那个变量 drop 掉，然后再从之前那个代码再改一改，再 merge 下来，就是我的第，我的 do file 文件是会写得比较长的。然后如果某个某一步出错的话，我可以从头再跑一遍，然后我相当于我的数据 merge 过程，就是我不用再操心了，就只要改一点点就好了。

Speaker 2 45:18 
我懂。

Speaker 1 45:19 
对，如果我用 Python 的话我会一直出现，就是可能就要一直写重复的东西，就是可能写代码会就让我觉得很烦。因为调薪，对，调薪本来就很烦的一件事情。是诶，其实可以理解为你的方向更多的是倾向于调星星，而不是说去研调星星是什么。时政不是有显著性吗？ py 流。

Speaker 2 45:51 
哈哈哈，调星星这个还没到调的那一步。

Speaker 1 45:58 
你现在拍到灯塔。

Speaker 2 45:59 
学术了，说调星星很容易被打。

Speaker 1 46:03 
这是我们常用的说法好吗？就是怎么调到两颗星是显著的。

Speaker 2 46:09 
真的吗？到时候找你请教一下，哈哈。但是出不来。

Speaker 1 46:12 
哈哈哈，其实我就很好奇你现在目前就是有了 panel data，那你的下一步，对吧？就下一步是下一步呢。

Speaker 2 46:23 
我现在还没有到什么下一步，就是我只是 general 地跟你讲我的用法，不是说我当前的project，就你懂我意思。

Speaker 1 46:37 
可能这一年还没有到真正的实战过程，是吗？

Speaker 2 46:41 
对对，还没有到那么 OPPO 的地方。对你像regression，那可能还是 data 方便。

Speaker 1 46:49 
对啊，因为就是我其实比较好奇的是，你这个专业之后是说会以 regression 为主，还是说会研究算法？比如说我去做preid。预测，对，就是会去做预测呢。

Speaker 2 47:03 
嗯，我们这边预测应该是不是也是 regression 那种？

Speaker 1 47:08 
我是，但我不知道你是不是就是我，我们两个我不太确定你的专业的，因为金融嘛？金融它其实会去做一些，比如说机器学习。你不是。

Speaker 2 47:18 
也是金融吗？

Speaker 1 47:20 
我不是金融，我是战略管理。

Speaker 2 47:28 
金。我感觉人文社科的预测其实就是 repression 的那个。

Speaker 1 47:32 
对，但因为我了解过金融finance， finance 的话它也有做一些时间序列预测，比如说它这一些因素就是它在导致它这个序列的波动，那它肯定需要去做一些预测，就是通过深度学习来做预测。有点像计算机哦。

Speaker 2 47:51 
那种。对，那种的话怎么说？不算是我，因为我这边遇到的预测的这种很少很诚实地说就是比较少。

Speaker 1 48:08 
那我懂你了，其实你应该跟我是一个套路，就是 regression 之后去调显著性。

Speaker 2 48:14 
对对对。

Speaker 1 48:16 
嗯，那那还是一样的。那，那对于。

Speaker 2 48:21 
那你的客户还要问什么？你的时间。

Speaker 1 48:24 
多了我都，因为我其实很懵，就是因为你的 code 都在数据处理上，哈哈哈。但他那你觉得就是他在 code 上表现得怎么样？就 AI 的表现。

Speaker 2 48:39 
嗯，我没有试过，说就是给他描述一个场景，如果我跟你聊完，我感觉我可以下次试一下，就是我整个任务丢给他看，他有什么想法？因为你是对比过两种吗？有没有什么能分享？

Speaker 1 49:03 
你是说对比过哪两种？

Speaker 2 49:05 
就是直接给他一个场景，然后跟他让他列一个框架，然后还有就是不要场景，然后直接就告诉他我要干，我让你完成这一步。

Speaker 1 49:17 
哦，这个那要看我在做什么事情，那比如说我已经做了都不做了，都很多事情之后，我只是说这一步的代码我有可能一下忘记了，或者说我真的是不想去写了。那你帮我把这个代码写出来，可能是一个 status 的某一步，对不对？那这时候我就让他写，那如果像那种很长的任务，然后就什么，比如说判断什么什么什么什么可能要识别某个词频什么的，那我直接丢给他，他就能帮我处理出来。但我觉得效果不是很好，就是你把任务丢进去之后，结果就是处理的，处理之后不是那么的好，因为它不能调用深度学习，也不能调用 machine learning。我试过的。

Speaker 2 49:58 
那假如说，嗯，你的这个任务是要先构建一个变量，然后再拿这个变量去干嘛？你会把它拆成两步先构，然后再干嘛？还是说你会跟他讲诶？我最后的目标是这个，我推荐你可以先构造，然后再干嘛直接丢给他，让他全部生成出来。

Speaker 1 50:24 
呃。很少诶？其实我每次都是一个变量，就是这个变量，我需要就这个变量是什么？我就跟他讲，我尝试过，就是这个文件丢进去，然后我跟他讲，就比如说每家公司每一年度，他的可能说我可能突然一下想不起来，可能就是会跟他讲清楚这个变量是什么？是什么？这个变量是什么？是什么？你帮我出生成出来，然后他就会给我一个 CSV 文件，就是因为我丢的是CSV，那他肯定输出也是给我一个CSV。

Speaker 2 50:55 
但你是试过这个样子。对。

Speaker 1 50:58 
但他有时候会崩掉，就是我的数据太大的时候他就崩掉了，他就说然后他就是他会建议他把代码给我，我自己去跑。我遇到过很多场景的，因为经常用。

Speaker 2 51:14 
我倒是很少给他描述一个场景，一般就是指定性给他一个任务，不过因为他们之前说如果你跟他说，诶，假设你是一个什么什么的经济学博士生，然后你现在要干嘛嗯？但是我就感觉你不跟他说这句话，好像他该能做的问题也能做，不能做问题也做不出来。

Speaker 1 51:39 
其实这里的问题是会给你一个心理暗示，就是我，因为我之前访谈中我问他为什么你认为给他一个角色定义会有一个好的效果？他说其实一种心理暗示，你给了他这个定义，那你可能会觉得他这个结果可能还比较好。就是他你已经有这种暗示了，一种心理学研究。有。

Speaker 2 52:00 
哈哈哈，我感觉从原理上来说，我感觉，嗯，双重限定。就是可能我跟他说我假如你是个什么经济学博士生，不如跟他说让他在找这个语料的时候规定在经济学这里找，我猜的。

Speaker 1 52:27 
你有尝试过吗？就是没有，嘿嘿。因为我考虑过这个问题，就是说它真的能限定得住，其实因我可能我还没尝试过这个方式，但我一直在就有考虑到就是怎么让它真实地限定，后来我发现有一些工具就是把自己的一些资料文档上传进去之后，可以限定它，在这里面去搜搜索。

Speaker 2 52:52 
真的吗？有多好？叫聊，聊完等你分享。这么神奇的吗？我感觉。

Speaker 1 53:00 
叫 Notebook 好像是。对，叫Notebook，谷歌的好像。

Speaker 2 53:06 
是说那个 AI 是可以上传，然后有的 AI 不能上传。

Speaker 1 53:09 
是你这个谷歌这个ChatGPT，你上传文件，它过两过几段会话的时候，它就已经忘记你上传的文件了。对，他不能接受长处理，我是这么认为的。

Speaker 2 53:22 
对，我感觉他是。

Speaker 1 53:24 
对，所以可能每个 AI 有自己不同的功能。我就是你可以，我其实觉得你谷歌它有一个月的免费，你可以尝试一下。

Speaker 2 53:35 
就那个会员的免费，是。

Speaker 1 53:36 
吧？对，谷歌有一个月的免费也免费。懂了好像你，我试一下。没有，我是觉得好像你对 AI 的使用就是依赖程度好像不高，就是主要处理一些比较你认为繁琐的事情，或者说。

Speaker 2 53:55 
我觉得是因为我对他始终是怀疑的态度。你对他给我一种。

Speaker 1 54:02 
不是，就是你对他的怀疑是。

Speaker 2 54:04 
指的不太不确定。

Speaker 1 54:08 
呃。是你觉得他的结果不好，还是说这个结果会误导你，还是说这个结果会限定你呢？就是你觉得是什么原因你不太相信他？

Speaker 2 54:22 
就好像你先买了个机器人回家，你又问那机器人一个问题，你说我给你列了一个方程，然后那 10 秒之后那个机器人就给报了个答案，嗯，他不跟你讲里面的那些什么逻辑或者说流程，他直接就报了一个数字给你。

Speaker 1 54:44 
但有个问题你有没有考虑过？就是请你把思考逻层、逻辑、逻流程或逻辑写出来，或者说出来，你有没有考虑过这么一个问题，就让他把这个所有的过程也说清楚？

Speaker 2 54:57 
你很多东西很难去定，很难很难去量化，就说我们说这种纯数据的东西，它就你加减或者怎么样，但是有一些像思维上的东西就是论述或者说他的观点就。

Speaker 1 55:19 
哦，我懂你意思，就是说你会让他来帮你头脑风暴，我看你问卷也填了。

Speaker 2 55:25 
有时候会让他头脑风暴。

Speaker 1 55:28 
就这个头脑风暴指的是什么方面？就是比如说什么样的任务嘛？

Speaker 2 55:50 
嗯，就是你抛个问题给他，让他给你几个可能方向的那种解决方案，我就会。

Speaker 1 56:06 
是生活问，生活类吗？还是学术类？还是什么都有呃？那这对于学术类的 brain store 的话，对，就是头脑风暴的话会，你会更不信任一些吗？会不会出现这么个问题？就是学术类和。

Speaker 2 56:25 
生活类我会更不信任一些，因为你学术上的东西你是有成本的，你生活的成本、隐性成本，就显性成本没有那么高，对吧？你信了出来 GDP 给你一个idea，结果那 idea 但 some work，你第二天就被老板骂了，对吧？你生活上的，你让他选个榴莲，那个榴莲顶多就是甜跟不甜的区别，但这个差太大了。

Speaker 1 56:56 
OK，那其实学术类的话他给你。 idea 你可能只是看一下，并不会采纳，是吗。

Speaker 2 57:05 
我会有自己的思考。

Speaker 1 57:09 
就是说再判断一下，那你这个判断的方式是怎么去判断？在看文献还是说。

Speaker 2 57:15 
跟看的是不是在吹嘛？

Speaker 1 57:19 
那你怎么判断呢？你就。

Speaker 2 57:21 
你都博士了，他给你列个 ID 也在你自己的领域里，你看不出来吗？学长。

Speaker 1 57:27 
你不要质疑我的专业性好吗？就是这个问题在于你的验证方式是什么？就是通过自己的判断，还是说去再看一些文献的积累。

Speaker 2 57:39 
嗯，你要要看他怎么回你了，例如说他就说他发现有这么一个idea，嗯，那你就要首先你就扫一眼这个idea，那可不可行？然后你如果你不太确定，你再去搜。

Speaker 1 58:00 
但有没有考虑过我？因为我问他 idea 是说请把相关的文献帮我搜出来，然后并且能提供链接，能打开。

Speaker 2 58:08 
很多假的，我跟你说。

Speaker 1 58:10 
但我如果我让他提供链接能打开的时候，他会稍微规范一点。

Speaker 2 58:16 
对，他好像说他例如说这篇我要一篇顶刊 JFE 的，他直接跟你讲这是JFE，你点进去之后是一篇不知名刊物。

Speaker 1 58:27 
所以你。

Speaker 2 58:28 
然后我就这什么，我搞了两三次，我不想跟他玩。

Speaker 1 58:34 
你用的是 GPT 5 还是thinking？就是你用的是哪个model？

Speaker 2 58:40 
应该是以前的，也是 thinking 的。

Speaker 1 58:43 
因为我觉得 O3 的话会好一点，就当时我用 O3 去搜文献，它至少不会给太多假的，稍微还是。

Speaker 2 58:50 
它主要是 6 分，你五六篇里面出两篇假的，或者说你 10 篇里面出两篇假，那我就很烦。你知道因为你 10 行给我输出 10 个文章的观点，然后有两个假的，我就会质疑你剩下的 8 个，然后那种，懂了，对吧？你那两个东西是明显错的，你剩下 8 个看上去是对的，你什么感觉？

Speaker 1 59:17 
所以意思就是说你不能接受他有任何的错误。

Speaker 2 59:20 
我可以接受他不回我，你懂。那我说真的，你，你有十，你我你问我十篇文献，我两个是铁错的，你你，你怀不怀疑我剩下 8 个。

Speaker 1 59:35 
我接受度还是挺高的，我接受度还挺高的。

Speaker 2 59:39 
就反正就说他说你那 8 个，我看时间也差不多，我，你还有就是这个问题，是最后的，是吧？还是说什么这个问题是倒数的最后一个问题吗？还是。

Speaker 1 59:54 
没有，因为我只是在聊这个coding，这个任务我也不知道是不是最后的。

Speaker 2 59:58 
什么叫你也不知道是不是最后。

Speaker 1 01:00:01 
因为这个任务没有聊完？

Speaker 2 01:00:03 
i 怎么？那你下一个问题吧。下一个问题你有事情吗？没有，就是聊的还差不多一个小时。我觉得。

Speaker 1 01:00:15 
你是在跟我算时间，是吧啊？

Speaker 2 01:00:17 
而且我有一点事，对，OK，OK，OK。没事，你继续，我问，对说，还有。

Speaker 1 01:00:24 
刚说什么呀？我想不起来了呃。

Speaker 2 01:00:29 
刚是coding，然后下一个是。

Speaker 1 01:00:34 
但是我觉得很奇怪，是这就是这些任务中你其实基本都是不信任的状态，对不对？基本上都是不太信任的，除了 summer 来。诶，不对，应该说这些。

Speaker 2 01:00:46 
coding 我也信任。 coding 我信任，但我会扫它代码，就这东西写代码你扫一眼，所以你的肯定要少啊。就说你让他这个东西和另一个东西，他输出哔哩哔哩哔哩这一堆哔哩吧啦的，你知道他在干嘛，对吧？

Speaker 1 01:01:06 
OK，是，所以你没有一些别的任务场景了吗？就是你觉得比较有趣的，因为我其实想看一看使用过程中会有一些什么有趣的方式。

Speaker 2 01:01:18 
是选榴莲，真的这个巨有用。好吧？

Speaker 1 01:01:24 
怎么你是把照片拍给他，然后让他就。

Speaker 2 01:01:27 
拍给他，还有西瓜也拍给他。

Speaker 1 01:01:30 
你的意思是说你把西瓜拍给他，然后你让他，然后让他判断这个西瓜好不好，是吗？对，然后给出的结果。

Speaker 2 01:01:40 
他就会直接告诉你 1234 他标好，然后他觉得哪个好吃啊？这么神奇？对啊，这个不是你比你什么天天学数的要大开眼界。

Speaker 1 01:01:53 
OK OK OK。哎呦，笑死。

Speaker 2 01:01:58 
不过也有可能是像你刚刚。说的是这种心理学暗示，但是你毕竟让我去选，我可能选不出来嘛。对啊对啊。对，所以说聊胜于无。

Speaker 1 01:02:13 
对对，所以其实我懂你了，就是说反正就是他所以用的其就这三个方向，对吧？就是summary，因为你还没有到 writing 的。那比如说你没有写什么 proposal 什么的吗？writing。

Speaker 2 01:02:27 
但现在不是缺AI，缺得比较紧。

Speaker 1 01:02:30 
什么？

Speaker 2 01:02:32 
现在不是 AI 率控得比较紧。

Speaker 1 01:02:34 
所以说你不会用它来写proposal，也不会用它来写，完全都不会拉。让他来写是吗？嗯，牛，有点厉害，因为我已经习惯性让他帮我写了。

Speaker 2 01:02:49 
那你不会，就是发文章会被check？

Speaker 1 01:02:53 
我可能觉得他们都是嘴上说的会有 AI 率吧，反正我目前用了这么多篇也没有浪。

Speaker 2 01:02:58 
当时你当时那边 UDD 放上去 AI 是没有。我没有。

Speaker 1 01:03:03 
AI 率，我当时放上去之后就有几段话确实是 AI 写的，就是有挺多段话 AI 写的，但我觉得还好，也没出现什么问题，而且我发表的文章中也有这第几篇啊？第，这也有那么一两篇，也有让 AI 生成两三篇。我跟你讲，我最近投的就今天访谈你之前我投了一篇文章，中文的全部 AI 写的，完全。

Speaker 2 01:03:32 
不要管中文。你要我就诶那边的 UDD 可以就可以，对吧？别的东西不管他的，对吧？ UDD 可以。

Speaker 1 01:03:44 
你的眼里只有UD，是。

Speaker 2 01:03:46 
吧？没有，我是说UD，因为毕竟是一个水平最高嘛。嗯，业内标杆。

Speaker 1 01:03:52 
可以这么说，目前的期刊有一些UD，比如说爱洒、MISQ，然后还有一本工商的，他们都在说鼓励使用AI。

Speaker 2 01:04:05 
什么什么。

Speaker 1 01:04:08 
鼓励使用AI？但是好像是说原创性的东西尽量不要让 AI 来完成。就这好像有这么几句话吧。反正我很多，比如说你这个反弹的话，我之后可能也会让 AI 先帮我分析一遍。

Speaker 2 01:04:21 
我有个问题就说，我听他们说就是如果你给 AI 喂那语料，它其实是会拿你的语料去训练。

Speaker 1 01:04:29 
那他训练你说。

Speaker 2 01:04:30 
会不会有一种可能就是我们写了一篇paper，然后别人已经其实他的平台是可以读到你的paper。

Speaker 1 01:04:38 
但是我跟计算机有聊过，他们说这种事情完全不用考虑，因为成千上万的人他根本就顾及不了，你懂吗？成千上万的人的数据都在那里跑来跑去吗。

Speaker 2 01:04:52 
但有你诊断丢，或者说你几页几篇丢下去，它其实是可以定位到。

Speaker 1 01:04:58 
嗯，但我目前不是很担心就有些人会出现你这个担心，有一小部分人都有这个问题，就说担心会窃取idea、窃取论文什么的，有一些。

Speaker 2 01:05:14 
就是他怕他说，诶，你写出来之后他说你那个是抄袭。

Speaker 1 01:05:21 
我目前还没有遇到，就，唉，我那篇 UED 目前应该这个月想投到 management science 去吧。

Speaker 2 01:05:29 
可以，祝你成功。学长，我觉得稳了，等你请吃饭，祝。

Speaker 1 01:05:34 
你。借你吉言其。但我目前在赶一些 special issue，就因为老师给我一些名额，我就会用掉它。我不太懂你们会不会去投一些三星刊嘛？我我三星刊我也是会投的。

Speaker 2 01:05:55 
我我我还没有到那个阶段，我可能要投的时候也会投，我现在没有这个概念，觉得。

Speaker 1 01:06:04 
OK。

Speaker 2 01:06:04 
OK，那是还可能要再过半年就开始。

Speaker 1 01:06:09 
OK，我其实能理解，毕竟 NTU 还是追求 Utd 的嘛。还有FT。

Speaker 2 01:06:14 
没有，我是说我还没有到，就是可能等我那些论文有几篇了之后，我就考虑投的问题有些没写出来。你问我什么？两星、 3 星、 4 星，我其实概念不是很清晰。

Speaker 1 01:06:28 
OK，我知道你的意思，能理解吗？但尽量能冲Utd，三星其实也挺浪费时间的。

Speaker 2 01:06:38 
唉，冲到再说，这一天Utd。

Speaker 1 01:06:43 
主要是时间唉。

Speaker 2 01:06:46 
哈哈哈，希望李晨诶，那我就吹水诶，我说我有个学长呢。

Speaker 2 01:06:51 
The fact management science.

Speaker 1 01:06:54 
No. 难道你不是？难道你那个就 NTU 的学长学姐不应该也能发 Utd 嘛，对吧？你也能吹水了。

Speaker 2 01:07:02 
没有，我感觉他们还没发出来可能。

Speaker 1 01:07:05 
很难，真的很难。

Speaker 2 01:07:07 
对。

Speaker 1 01:07:09 
难，真的很难。就目前我现在成果也只能任教 211 吧。

Speaker 2 01:07:14 
对，那还不够啊，我觉得我毕业了。唉，算了，不要说所以自己。

Speaker 1 01:07:19 
对你不要乱说，你要去上交，加油。哈哈，加油加油。好，那我想了一下，因为你的任务太少了，所以导致我好像也没办法继续问下去。

Speaker 2 01:07:34 
了。我感觉很多我这阶段的人的任务一般就是这么多吧。你要说。嗯，很多样性的感觉。

Speaker 1 01:07:47 
其实我比较好奇是课程上，你的课程会被用到ChatGPT，就比如说学习复习、学考试。

Speaker 2 01:07:56 
那个没有因为你课件那个东西就看。

Speaker 1 01:08:02 
你不会让他去帮你分析课件。

Speaker 2 01:08:07 
读对正常不会。

Speaker 1 01:08:09 
对，我觉得你的依赖程度其实是很低的。就因为我聊。

Speaker 2 01:08:13 
过高，我有时候写代码真的是全靠他，这不是说我不会写，而是说我懒得写。

Speaker 1 01:08:20 
我我懂，所以其实依赖就是在其他方面依赖程度很低，最多就是coding，你用它比较多，就像因为我其实聊过计算机，他们说它是全依赖，就比如说coding、writing，然后什么 7 ~ 8 全都让它来做，因为它前可能真的技术类的就是能把它用得更擅长嘛。

Speaker 2 01:08:43 
对，没事，我感觉我就 writing 用得比较少。确实是，还没有写很多东，很多对材料。

Speaker 1 01:08:50 
可能也是因为你不太忙，信任程度还没那么高吧。

Speaker 2 01:08:54 
对，就老老给你挂个什么 AI 率挂在嘴边。我上一期那个课，上次主要圈圈你的 AI 率的这样子，唉，全自己写。

Speaker 1 01:09:03 
好那些，这些老师都是骗子。哈哈哈，这个真的，因为我其实都其实 AI 率这种东西。嗯，那我们其实能规避掉，就是因为有些词是 AI 常用词，但是我一看就知道哪些是 AI 常用词，把它删掉，然后把它这样重新生成就知道了啊。对，你其实能判断得出来，有些词就是常用词，用久了之后。

Speaker 2 01:09:32 
我的我开始使用一下，没有，然后我也判断一下。对。

Speaker 1 01:09:38 
就所以其对，那根据问卷提几个小问题，就是你在问卷中，你是？哦，我看你写的是倾向于视为伙伴吗？还是视为工具？我有点忘了是视为伙伴还是视为。

Speaker 2 01:09:53 
工具吧？应该。

Speaker 1 01:09:54 
是就是工具人呗。对，因为我好像发现你跟他的合作关系比较低，就是你看任务的拆解过程中，其实你也不会让他去帮你拆解任务，对不对？也是你拆解完任务让他帮你去工作。

Speaker 2 01:10:11 
因为我有思路了。

Speaker 1 01:10:12 
对，你就有思路嘛，就不会让他来帮你去做这个思路的一个呈现。

Speaker 2 01:10:17 
嗯，可能我没有思路的时候以后会用它，但目前没有遇到，就一点思路都没有。

Speaker 1 01:10:27 
你是不是在指coding？

Speaker 2 01:10:30 
他没有，就是所有的那些任务 general 我很少。对，我记得writing，我就说了我 writing 没用到嘛？我这填不包括writing。

Speaker 1 01:10:43 
邮件的话，你会用到ChatGPT。

Speaker 2 01:10:46 
吗？会用。

Speaker 1 01:10:48 
就是这个的writing，对吧？那你是直接让它生成，还是说你写了个大概，让他稍微改改。

Speaker 2 01:10:57 
都有。

Speaker 1 01:10:58 
那你觉得怎么样？是你给中文还是你给英文还是什么？

Speaker 2 01:11:04 
嗯，有就都有。

Speaker 1 01:11:09 
那对于邮件你就觉得就它的OK，很OK，就是整个的还是。

Speaker 2 01:11:18 
我觉得是 OK 的，因为很短。然后那有什么？就好像你选个西瓜这样，你有什么好？

Speaker 1 01:11:27 
我懂，你这个就是对于工具类的任务你都觉得很好很好胜任，很好完成，对，OK，那就是，然后还有一个就是 AI 焦虑，就是说你也很少感到焦虑，对吧？使用 AI 的时候。

Speaker 2 01:11:44 
我就有点焦虑，我刚刚不是也有说我的焦虑吗。

Speaker 1 01:11:49 
你焦虑吗？你焦虑的点是什么来着？

Speaker 2 01:11:52 
我不觉得他那个东。东西不太让我信任。

Speaker 1 01:11:58 
这是焦虑吗？我。

Speaker 2 01:11:59 
觉得那是哪种？算。

Speaker 1 01:12:01 
焦虑的话，就是可能这个任务会影响到你，就是会影响你判断，会影响你的一个结果，会影响你，就是使用它会让我变得很蠢、很笨，就是会影响到自己。

Speaker 2 01:12:16 
嗯，没有这方面的想法。对，我确实我觉得你听他们说 MITS 丹佛做了个研究是说确实会，对。

Speaker 1 01:12:25 
对对，会让的认知下降嘛。嗯，对，我因为你都不信他，因为主要是你不信任他，所以我觉得应该不会有 AI 焦虑，哈哈哈。然后算法厌恶，就你说更偏好人类的判断，对吧？这应该是你问卷中提到的。但是其实有些因为就是你说的那些邮件或西瓜这些采纳他的建议其实是因为你自己不太理解，不太能判断，对吧？还是说其实是很低端没有成本的任务？应该这么说。

Speaker 2 01:13:04 
对，没有什么成本。

Speaker 1 01:13:06 
我懂了，其实你对于使用 AI 的一个分类，其实是说这个就低成本的话，你就让他来做，如果高成本的话还是尽量自己来完成。对，OK，明白了。然后是，嗯，所以你其实是一个很理性、很深度思考的人。

Speaker 2 01:13:30 
这就判断上了。

Speaker 1 01:13:33 
没有，这不是你问卷中的回答吗？你自己填了什么你忘了是吗？

Speaker 2 01:13:39 
我忘了，哼。

Speaker 1 01:13:41 
因为问卷中有一个深度思考的一个问题，但我能判断得出来，因为用 GPT 的方式能判断这个人的一个思考方式可以，OK。其实也就只有这些问题了。我也想不到了。

Speaker 2 01:14:03 
感觉已经问了很，叫什么很对，就什么啥都讲了，很深入了好吧？

Speaker 1 01:14:10 
对，但很深入，但是我没有发现一个很，你懂吗？我导师，你要发现interesting。一直讲有趣的，我没有找到。

Speaker 2 01:14:21 
我咋你就跟他说我选西瓜了？

Speaker 1 01:14:24 
对，选西瓜吧。

Speaker 2 01:14:25 
好的， OK 吗？那你可以交差。

Speaker 1 01:14:30 
吗？嗯，没关系，因为访谈总是会出现样例偏差，就比如说有些人确实用得很深入，有些人用得确实不太信任，都会有各种问题。那我不能说你的样本无效对不对？肯定都是有用的。

Speaker 2 01:14:45 
我觉得我也能代表一部分人的。嗯，我。

Speaker 1 01:14:49 
觉得能代表一些很理性的人，就是很具有自己看法的一些人。就是会有就是你这种的一个使用方式。

Speaker 2 01:15:00 
对，他确实是个黑盒子，就对他信任是低。

Speaker 1 01:15:04 
了点。那我就问，就再问一个问题，就是如果你来制定一个简短的一个，就是怎么使用ChatGPT，你会给一些什么建议？

Speaker 2 01:15:20 
我觉得。可能会需要给他的指令更准确，就是你尽量准确去描述你的问题，这样会避免你它输出一些错误的内容。

Speaker 1 01:15:39 
呃。但你刚才也提到反而不给他准确的命令，反而也输出得不错，是不是？

Speaker 2 01:15:48 
对，那个 prompt 那方面我觉得就确实，哈哈哈。诶，可能要分任务来讲，但我的建议是就这样。

Speaker 1 01:16:03 
我懂你意思，那其实还有一个小问题，就是你如果 AI 的发展的话，你觉得你跟他的一个合作方式会变化吗？因为你现在的方式是比较当工具用，那你觉得你之后会不会有一些啊？

Speaker 2 01:16:18 
如果他哪天就是证实他确实可以。

Speaker 1 01:16:28 
怎么说呢？我也不知道。

Speaker 2 01:16:32 
他就是犯错概率低一点，或者说他每做一件事情，他会有一个告诉我里面发生什么事情。那我会。

Speaker 1 01:16:45 
啊，你的意思是说就是在处理这件事情的时候能把他的思考流程写下来，是吗？还是说。

Speaker 2 01:16:53 
嗯，对，就是具体的，非常具体的，但然后。

Speaker 1 01:16:58 
但就是你跟他讲，你请你把思考流程写出来，这个有能帮到你吗？

Speaker 2 01:17:06 
嗯，我觉得这个可以帮到我，但是还不够。

Speaker 1 01:17:10 
就是你希望的其实更多的是在有思考流程的时候保证它的准确度嗯。对，但肯定还挺难的，毕竟对吧，算法总是会有偏差的嘛。对， OK OK OK OK。

Speaker 2 01:17:29 
OK。好，感谢大功告成。

Speaker 1 01:17:32 
然后这个实验任务你是 OK 的，是吗？就是我看你填了yes，就是后续。

Speaker 2 01:17:38 
对，我，对，后续但要看时间，就可以给我发个邮件，然后但是也要看那个时间。

Speaker 1 01:17:45 
OK，就是因为那个邮那个任务的话是要线下的，因为没办法线上做。就是我大概我先结束录音，我要算时长，我先结束录音。


受访人18:
2025-08-21 18:06:37 CST|1h 8min 35s

Keywords:
无人机、答案、文献、算法、专业、论文、计算机、高频、验证、思维导图、人工智能、语言模型、生成图片、人机交互、历史数据库、基础模型、路径规划、生活常识

Transcript:
Speaker 1 00:02 
好，那我就不叫你名字，那就保护一下你的隐私啊。好，OK，那同学你好，那个我就是我这次的研究的课题呢。是啊，基于这个交互记忆系统来优化一个人机团队的表现，然后主要是想了解一下，就是 ChatGPT 的高频的一个使用者，对于他们在工，就你们在工作或学习的流程中是如何和 AI 进行协作的，然后就比较关注于一个互动的一个模式，或者是以及你的一个 critical thinking 的一个行为。然后还有就是看一下你是怎么去看待 ChatGPT 的一个优劣势的一个情况的。嗯，OK。然后这次的访谈会全程录音。好的，然后那我们就正式开始能描述一下你目前的职业或学习的领域吗啊？

Speaker 2 00:58 
博士研究员。

Speaker 1 01:01 
就是在读博士，是。

Speaker 2 01:03 
已经毕业。

Speaker 1 01:05 
是博后是吧啊？对，OK。那是 computer science 吗？还是哪一个啊？

Speaker 2 01:12 
我是做 airspace 的。

Speaker 1 01:14 
airspace 盘空航天。

Speaker 2 01:16 
对，而是有跟无人机相关的。做无人机的路径规划、运行控制。

Speaker 1 01:24 
OK，我能理解，因为我本科是学 engineering 的，自动化相关的。对，那在这个领域的话，您会通常处于哪一些类型的任务呀？

Speaker 2 01:36 
嗯，就是和人工智能相关的吗。

Speaker 1 01:40 
就是你是说你在学习这个专业的话，是跟人工智能相关，是吧。

Speaker 2 01:45 
对，因为我们做路径规划也要用到那个，比如说强化学习的算法，然后对，基于，是啊卫生，基于就是各种，就是那个自然语言处理等等都多模态的一个，就是算法的一个结合，对去处理无人机的对障碍物的识别，对路径的实时的规划。对。

Speaker 1 02:12 
明白。好的，那您是大概从什么时候开始用 ChatGPT 或是类似的甚至是 AI 系统呢？

Speaker 2 02:20 
嗯，是从 23 年还是 22 年？具体不太确定了，对，应该是有两年左右。

Speaker 1 02:29 
好的好的，那你跟他的一个是共，就是就用他的一个频率是怎么样的？

Speaker 2 02:36 
基本上我可能会是在就是 coding debug 的时候会用到，然后频率你指的是每天还是什么时候？

Speaker 1 02:46 
嗯，都可以，比如说你每天都使用它，或者是每周大概。

Speaker 2 02:50 
基本上每天都会用到，比如说最简单的，最简单就是不用动脑的，就是用那个 chat DBT 去回复邮件。OK，就是邮件，比如说有些长很难回复的那种，就是可能要去跟教授有一些客套的话，这个话应该说吗？

Speaker 1 03:08 
没关系，没关系，其实保密的都是保密。

Speaker 2 03:10 
就是去对老外的那些，你知道那他们邮件很会很长。前面有一段的客套话，那这种情况下我就需要用产业培训去帮我回复。

Speaker 1 03:20 
那OK，对哦，明白。那您最习惯用于用哪一个 AI 的系统或者是哪个版本？因为它的 model 很多。

Speaker 2 03:30 
我就用基础版。

Speaker 1 03:31 
对，就 ChatGPT 的，现在是5，那之前应该就 4O 这种。

Speaker 2 03:36 
model 3。对，我记得我是从 3 开始用起的，然后到四o，然后到现在不确定升级的是有 5 出来，但是那说那个 5 不太好用。

Speaker 1 03:47 
对，那就是说你没有开会员去用那个。

Speaker 2 03:51 
没有开会员，因为我觉得还没有到，我不太确定开会员和不开会员有什么区别，但是我觉得它基础版就已经足够我用了。对，我也只是说会用一些，就是它 check BD debug，它的基础版就已经做得很不错了。我不会就是去严重地依赖他吧？因为我有自己的辨判断，对，我自己专业的判断标准，对我就是可能对他最多更多的对我来说做的东西就是一些语言上的润色吧。对。

Speaker 1 04:21 
所以其不会用它去，就是brainstorm，就是头脑风暴，或者是说writing。

Speaker 2 04:28 
会也会，就是比如说那些不熟悉的话题的话，或者一个一个有一个新的，比如说我做的无人机这块低空经济，就是关于低空经济这个概念的话，它会涉及到哪一些方面？那我就是我自己来说的话，我是做无人机控制算法的，那对于他对经济的低空经济，这整个的经对经济方就是侧重于社会效应或者影响低空经济这方面的东西的话，那我就会去问他，对，然后结合他回答的那些，嗯，点我再会去，就是再结合我自己的。一些专业的知识再去做一下总结。

Speaker 1 05:03 
对，那我就挺好奇，比如说要那如果做低空经济这个话题，因为你是完全不熟悉，那相当于是说你要，就是你会很信任他的一个回答，就是因为你完全也不熟悉这个领域。

Speaker 2 05:15 
呃。不是不熟，我就是做着做几低婚经济的东西。

Speaker 1 05:18 
我的意思是说因为他肯定会跟，是。

Speaker 2 05:20 
我是说他对于是我是你知道我是engineering，他如果他对于 ec  e emy 的影响，我我是说就只是单纯从 emy 这个角度去讲，我不是很熟而已。

Speaker 1 05:31 
对对对，我我意思就是说那对于经济你不太熟悉的话，那你会比较信任他的一个答案吗？还是说你会在，我对。

Speaker 2 05:37 
check DPD？哪怕是我现在做的东西，我都不会特完全信任的，我对他的信任度我感觉就只有 50% 不到，因为我是能够判断出来就是它产生的东西，我因为我知道它的原理，它是文字的一个，就是去拿，去用概率去推算它文字的上下的语义的这种结合的一个准确度，这种嗯。所以我对它，我只能说是它从语言的组织的角度讲，它是一个很非常完美的一个工具，但是对于的一些专业性的东西的话，我觉得它得出的答案真的我不太信，我是不会太信任的，就是从我比如说我去写 paper 的话，我的算法的一个推出的话，我不会依，完全不会依赖他的。对，我可能就是会找他去，对我的一些语句段落，去逻辑结构去帮我整理，去润色，但是我不会，就是从专业的角度，至今为止它产生的就是至少说是在我这个研究的，当然我研究的比较新，这是一个新的领域嗯。嗯，就是它产生的东西就很是我一眼能看出来有很多bug，就是有很多说的不准确的东西，所以我没法去完全信诶，完全信任他基本上不太可能的，对他的信任度就真的是只能停留在 40% 到60%，不会超过60%。

Speaker 1 06:59 
明白，我觉得可能学计算机的可能都会有这种担忧吧。

Speaker 2 07:05 
其实我觉得稍微懂一点它的原理的我就觉得。

Speaker 1 07:07 
是。对对对，就其实我其实更想了解，就是对于这种，因为对于任务的不同，那肯定你跟它的协作方式也是不一样的嘛？那我觉得可以具体聊一下这些任务，就比如说可能从你刚才提到的低空经济的，比如说就经济跟你想了解经济学相关的东西的话，嗯，是会把这个任务拆解之后跟 ChatGPT 去交互，还是说你直接让它去给你生成一些你想要的？比如说就是直接给它问题，然后就生成一些框架或者是什么的，就你使用的一个交互方式是什么样的哦？

Speaker 2 07:42 
对于我就是可能了解度了解的只有10%，或就很少了解的这个领域的话，我基本上会是首先是有个一个，有一个 general 的问题去问他，然后根据他的回答的点，他有一些回答点是我知道的，那我会针对性地再去提问，就是先是有一个 general 的东西，让他可能会给我生成一个框架，怎么样的？对，然后接下来可能针对这个具体框架里边的某一个点，我会继续去追问的，对，继续去剖析，看他能不能给出我想要的答案。

Speaker 1 08:12 
对，那其实有点像哦， ChatGPT 在处于一个帮你发散的过程，然后，对。

Speaker 2 08:16 
对对，是。

Speaker 1 08:17 
对，就是。

Speaker 2 08:18 
我先是要有有要有他给我一个基础的东西，然后再跟根据他给我的这个基础的东西再去就往我知道的这个方面去关联，然后再去问他。

Speaker 1 08:30 
对，那其实相当于就是说你就是会完全这个框架，你只是说会稍微修改一下，对吧？就是。

Speaker 2 08:37 
的，而且我只是针对他给我提供的，比如说他提供了有一个问题，他提供了五个点，我可能只会先让他提采取，他就是可能会采用他提出的五个点中的三个或者两个，然后再针对这三个或者两个，然后这两个具体的小的子的方面我再会去问他，就是我想要了解这个子方面的具体的某一个问题，或者怎么样再会去问他。对，继续会追问的，直到他回答到我满意为止。对。

Speaker 1 09:05 
哦，明白，那所以相当于这么追问过程中，那你怎么去判断他给你这些内容？是，就是可能就正确的，或者说就是因为你肯定需要有文献支撑。

Speaker 2 09:16 
是，对，因为我会就是关联到他，基本上我他给出的那些point，我基本上会选我所了解的或者熟悉的东西去选，然后首页。所以这样子的话，他给出的，他接下来我要问他的问题，他给出的答案我是有判断能力的，就是说判断他，他是，他说的，是不是就是根据我的这个已有的background，我会去判断他说的是不是对的，他给我的答案是不是可以采信的？对，所以认知还会再去做出修改，我甚至不会相信他说的不能说每一句话就是，至少说我还是会去逐字地再去结合我已有的一些 common sense 再去判断它。说的对。

Speaker 1 10:00 
不对哦？所以能理解为就是说他给的答案你会先就是，反正就是我往自己熟悉的领域去。对，然后如果不熟悉的就直接不要。对。

Speaker 2 10:11 
嗯，肯定是这样子啊。为什么呢？因为我要往我的，不管我做的什么，我做我做的什么东西，我始终是还是研以我的这个研究为主线，然后往外扩散的，所以他给出的答案，我以我是一定会选择和我研究相关的这个子的方面去做，是再进一步地了解的。我不会去选一个陌生的完全不懂的，因为我这样子的话，我担心我驾驭不了他，或者说我判断不了他给我的答案是不是真的，因为那个 AI 的这个就是我，我们是有讲那个 AI 和 nomination 还是什么？就是那个 AI 幻觉它会对它，所以我真的是不相信它产生的东西，所以我就是会沿着我研究的主线，我所知道的这个东西再去问发问他，再去让他去产生我想要的东西。对。

Speaker 1 11:00 
嗯，那有没有可能存在？就是真的确实是你不熟悉的东西，就是完全你不熟悉的任务，不熟悉的内容，你就有没有可能因为你是在做研究方面，那有没有其他方面？就你可能会？比如说要了解一个。

Speaker 2 11:14 
哈哈哈，比如说我要去你，我会信任他的程度，我为什么会说我信任他的程度？又我信任他的程度是 40% ~ 60%，那不信任他呃。信任不信任他的就是那 40% 或者给就是更大的一个范围，就是在我信任他的是什么情况呢？比如说一些生活的常识，比如说风油精可不可以用来用水？就是我中暑的时候可不可以去兑水喝这样子，或者说是比如说我，我要去哪一个地方去旅游？我让他去做一个旅游攻略。这样子的话，因为我也不熟悉那个地方，他给我的攻略我觉得是可行的话，我再去验证一下他说的那个路线的，我能不能买到那个时刻的那个机票或者火车票啊？他要给我的出行方案，我会，我能，如果能按照他去说的那个方案去买到火车票，或者那我会信任他的。

Speaker 1 12:05 
那有没有出现一个问题？就是你觉得他给的这个方案可行吗？就是或者说你有没有去通过，再通过小红书或者是其他的一些攻略。

Speaker 2 12:12 
我会去查一些时刻表，因为我会具体地让他给我就是规划一下几点出发什么什么的。对。

Speaker 1 12:19 
这还挺准确的，是吗？就是。

Speaker 2 12:21 
是那些基础的东西，就是很基础很基础的东西。嗯，我其我就是一些什么日常生活中所用的问到的一些小问题，比如说在新加坡怎么去办那个EP？或者说怎么我前，我因为我前段时间有问他去怎么开公司注册账户，这些他是他的回答是 OK 的，是完全没有问题的。甚至说。

Speaker 1 12:43 
就是说他就是帮你在新加坡，就是比如说注册公司这个流程，他其实能很清晰地帮你给。是的。

Speaker 2 12:49 
是的，对。

Speaker 1 12:50 
那你还需要再跟他交互吗？就比如说，就他。

Speaker 2 12:53 
会的，比如说他具体说到什么，哪一个点我不懂，我就会还继续问他的。

Speaker 1 12:58 
所以，嗯，就是什么就这种生活常识类你会比较新。对对对。

Speaker 2 13:02 
这个我只就是在生活方面的这种小问题，我会更信任去他一点，但是我的可担的东西真的不信，能不敢。

Speaker 1 13:12 
信任？能明白，所以你也会担忧，就是说他会不会影响到你的认知？就是说如果你就是你担心这个问题，就会影响到你的认知，或者是影响。

Speaker 2 13:24 
都会影响，因为我基本上都是有自己的判断，就是他给我的答案的话，就比如说一些生活常识，就是称像刚刚我们举例的这种简单的东西，我倒觉得就是信任他也无所谓了，因为他给我的流程也是对的，对，我因为我去有去跟那个 ICN 那官网上去check，嗯，基本上是一样的，因为他从网上网页上他只去学习到的东西也是对的。但是说就是一些 professional 东西，我会有自己的判断，所以我不太会觉得说 AI 会影响到我的认知方面的。一个不会，不太会的，因为我就我有明确的自己的判断的能力。对。

Speaker 1 14:00 
明白呃。我刚想问什么来着，就刚你说某个点我突然给忘了，不好。

Speaker 2 14:06 
意思，不好。没关系，慢慢想。

Speaker 1 14:09 
因为访谈我也才做到第二个人。

Speaker 2 14:11 
嗯，好好，没关系，没关系。嗯，再熟悉一下嘛？

Speaker 1 14:14 
嗯，对，嗯，是诶。那就是说你哦，刚才那个点我一下想不到，那只能先问别的了。

Speaker 2 14:22 
嗯，好，等你想起来再问好了。好。

Speaker 1 14:25 
的好的。那我们继续那个 academic 方面的话，那你其都是让他帮你除了 brain store 的话，还有什么方面？刚才提到的是。

Speaker 2 14:40 
就是有一些文本方面的一些润色。

Speaker 1 14:44 
一些只是帮你润色英语是，对对，是不会让他帮你撰写。

Speaker 2 14:49 
不会，这是学严重的学术不端。

Speaker 1 14:54 
那但目前可能目前有些我论文是有鼓励 AI 的使用。对，然后我一般。

Speaker 2 15:00 
那我这方面是没有的，而且 NTO 前段时间不是查出来有学生作业用 AI 被举被查出来，然后学校还通报了呢。

Speaker 1 15:09 
哦，明白了，所以你是很担心这种问题，所以就完全不会用它来听。

Speaker 2 15:14 
对，即使不担心 paragraph 的问题，我也会担心它产生的东西，因为我确实是用它做我 professional 的东西的时候，它产生的东西确实有问题，所以我不太会相信它。

Speaker 1 15:27 
的。对，那可能是因为我是有开会员，所以我感觉他有些的写得还是可以的，就是可能 model 不一样吧。

Speaker 2 15:35 
嗯，反正我是感觉到因为我做的这个东西会比较有一些新的概念出来嘛。就是好像因为他，我，他学唱 DBD 学习，他要基于大量的利益数据库，我这个方面，比如说低空经济这个 low LTI emy 的话，他基本上没有学习到太多的东西，而且产生的东西也有点就是有问题，反正生成的东西。

Speaker 1 16:05 
就可以理解为就是说这个领域太新了，所以它其实它的。

Speaker 2 16:08 
语料库也，它对，它的语料库对不足以支撑它去产生一个让我觉得还那么那么 professional 的东西。明白。

Speaker 1 16:17 
那你会有什么比较特定的一些？会用常用的一些提示词吗？比如说，哦，你可能在让他担任，比如说可能是你现在是一个什么什么翻译者，或者说你现在是一个会不会这样子？一些指示命令？你有。

Speaker 2 16:31 
一些会，我会说我是一个那个researcher，我的研究的内容是什么？然后接下来你要帮我去针对这一点，要生成什么样的东西？我会告诉他我是一个科研工作者，我要干什么？接下来要干什么？然后给他具体的一个指令。

Speaker 1 16:49 
对，你是科研工作者，那你会不会去命令他？你是什么？就是会被反过来，就是角色的一个定义。

Speaker 2 16:55 
角色的定义你是定，就。

Speaker 1 16:57 
因为你刚才让。

Speaker 2 16:58 
他作为什么什么去，对。

Speaker 1 17:00 
对对。

Speaker 2 17:01 
我就说以他我会，基本上我是会问，就是会说让他以从我的，我是一个科研工作者，让他以我从我的角度，从一个跟他们个 researcher 的角度去帮我生成什么，什么就比如说回复一个邮件，我就说让这样去回复一个比较普分的，对，就是去掉一些口语化的东西什么的。

Speaker 1 17:24 
OK，所以相当于说邮件方面的话，你其实 writing 你就用在了邮件方面，我可以这么理解。

Speaker 2 17:31 
对。

Speaker 1 17:32 
老，那其实对于其他方面你就不会用到太多。

Speaker 2 17:38 
我看一下，我会有那个。

Speaker 1 17:40 
你在看你的ChatGPT，是吗？

Speaker 2 17:43 
对，我看一下，比如说一些招聘哈，我会让他去帮我写 cover letter，然后我会告诉他我的把我的那个简历给他，给到他，对，他会写一些他的 cover letter，还写的 cover letter 写得还是不错的。对。

Speaker 1 17:58 
就是说你直接点简历丢给他，直接丢给他，然后他就可以把你。对对对，那你会要给他，比如说。

Speaker 2 18:04 
我会他给他 job description 和我的CV，然后他会写帮我写 cover letter。

Speaker 1 18:10 
就是连具体的公司的简介也要跟他讲清楚。对对对，然后你觉得写得还是很OK。对，那你还会再修改吗？还是说你让他改就好？

Speaker 2 18:18 
会的，我真的不会 100% 写，不会 100% 新人产这边产生的，就哪怕是邮件他帮我写了，我也会再去修改的。

Speaker 1 18:26 
那你修改的比例大概怎么样？

Speaker 2 18:28 
嗯，邮件的话我修改的比例可能 10% 不到，就是大部分的词它说的还比较那什么的，但是其他的，比如说这种 cover letter 的话，我修改的东西能应该是能达到 30% ~ 40% 了，就大部分还是他写的。对，但是我肯定不会 100% 就说，诶，他写完了我会直接，嗯，就是那个申请的时候直接那个就是我还是会做出修改的，哪怕是很小的修改，哪怕是就是我不会新人产这边产给我产生的任何一个东西我都会去看的，包括邮件的回复。对。

Speaker 1 19:02 
看得出很深度思考了，哈哈哈。可能这。

Speaker 2 19:07 
就即使可能跟我性格有关，就即使不是产业BD，不是 AI 帮我去做别的东西，哪怕是别人就是说我今天要去我知道的 FIP 学生，他要去写一个 final report 或者是怎么样，我都会去把他就包括比如说我的论文有一部分是那个 f FFP 学生的数据或者怎么样我都会去 double check，我不会相信任何人给我的，给到我的任何一个东西我都会去 double check。

Speaker 1 19:36 
OK。

Speaker 2 19:37 
所以对于 chat DBT 我更不会信。

Speaker 1 19:41 
但我觉得很好奇，就是因为毕竟你也是工科类的，那其实会不会去研究 ChatGPT 本身就是在你的这个领域里面？比如说会。

Speaker 2 19:52 
我，我会我，因为我我也有最近用到那个自然语言处理，就是像像像我，我像让那个。那个比如说 transform 模型，我会用它去，是让它去那个生成那种，就是指导无人机避障的那种动作，或者上升下降，或者左右前后这样子去避障。那我会用到那些 Transformer 这些基本的模型，或者那个大语言模型的东西。

Speaker 1 20:20 
对，你是说就是调用大语言模型可以，对去，是它现在可以做到避障这些。

Speaker 2 20:28 
问题是可以，但是我用的版本比较低，还是3.5。

Speaker 1 20:33 
你是说调用它的 API 吗？对对对对。哦，就是说你在这个任务中。是啊，你就是你想实现，因为它算法。

Speaker 2 20:41 
是没有问，就是你用它本身的算法是没有问题的。对，但是你用它这个算法就是它基于的那些余量产生的一些，就是因为其实做算法的话产业比肯定是没有问题的，但是说就是我怎么讲就可能一些概念性的方面，就我这个领域一些概念性的东西，比如说低控经济，他给出的答案，嗯，相关的东西他就给出答案不是很准确。对，但是用他的 API 是没有问题的。

Speaker 1 21:13 
我没有，其实我是很好奇，就说调用他API，那也就是说你会给他输入，然后他帮你输出吗？还是输？

Speaker 2 21:18 
对对对，是啊。你继续，就是我，我会给到他一个视频，然后让他先去学习这个视频里边无人机是怎么避障的，就是他要去学习那些无人机相遇的场景情，那种情况下无人机是怎么避障的？对，他对于这个历史数据库的这个学习得出的，他，他会去学习的这个历史数据库，然后去有去再去做出判断，就是他会再去给他一个新的场景，他会去判断跟例数据库哪一个，他会做一个 similarity 的匹配，然后对，他会如果说是他已经在之前的那个例数，就利益数据就是有一个场景是相似，那他会给到和那个场景相似的避让的措施吗？

Speaker 1 22:01 
其实相当于就是说他要先学习对，视频。

Speaker 2 22:06 
是他要去学习我的无人机的场景的视频，不是说他已经有了那种。嗯嗯，其实我这块是属于少量补少，就是 few shot learning 的那种，就是小样本学习的。对，等，我，我没有很大的历史数据库了。对，我给到他的数据库很小了。对。

Speaker 1 22:25 
哦，就是说给他一些视频，他先学习完之后，你再把它用到你的测试集去。是，是的。然后你觉得效果能达到多少的一个准确度？

Speaker 2 22:35 
我们的 70% 多。

Speaker 1 22:37 
70% 多在你们还是可以的。算算可以，是吧？

Speaker 2 22:41 
但是达不到无人机的安全。 b 站的那个logo，这只是说就是目前还在测，还可能要对算法进行改进了啊。那你让他去直接去加载在无人机上去那个什么的话，他的安全，他的那个避障能力只有 70% 的话完全达不到。嗯，无人机的安全运输的这种要求。

Speaker 1 22:59 
一般要多少？

Speaker 2 23:00 
9190%，我记得应该是百 90% 及其以上吧？对。

Speaker 1 23:11 
那你有没有考虑过，因为你选用的是三三 3 还是几几来着？ 3.5 吗？还是什么。

Speaker 2 23:17 
3.5 啊？

Speaker 1 23:18 
那有没有可能，比如说就是换换model，就可能，比如说O3，或者是因为它。

Speaker 2 23:23 
有测试过，但是效果也不是很那个 improvement 不是很。

Speaker 1 23:28 
大了，所以相当于就是说这些 model 其会不会写跟样本集有关？因为训练集的，对。

Speaker 2 23:35 
吧？是有关系，因为我们没有太对，也有跟样本集，跟训练集有关系了，因为我没有太大的历史数据库去训练了，因为到无人机的这种空中飞行的这种场景，我手头的数据并不是很多的。对，目前还是处于一个，因为就是我做这块，它属于一个就是未来城市低空无人机飞行的这种交通场景，就目前还中国算是标零，现在他还在测试当中，就没有太多的历史数据库了。所以这也是为什么他的那个 b 站的成功率提升不上去的一个主要的原因嘛。我觉得可能算法这方面的话是需要一些improvement，但是我觉得可能重，但是重不对，不在算法本身上，可能在我的里数据其实对。

Speaker 1 24:19 
明白，那除了调用它的话，你会用它怎么来做 coding debug？或者是说做 coding writing 什么。

Speaker 2 24:27 
的，嗯，就基本上就是比如说问这块有一些出现什么那个报错的那个 error 的代码是什么，然后给到他说我在做什么，然后我这边有一个报错，你帮我去debug，他就会给出一些建议。

Speaker 1 24:41 
嗯，所以不存在。就是比如说这个任务你给他，然后让他帮你搭好代码框架，然后不。

Speaker 2 24:48 
那目前为止还没有。

Speaker 1 24:50 
哦，就是说我是有。

Speaker 2 24:52 
打算这样做，哈哈哈。

Speaker 1 24:55 
明明白，就是说你就是其实相当于目前就是不会说给一个任务。对吧？然后生成完整的代码。

Speaker 2 25:02 
对，没有这样试过。

Speaker 1 25:04 
就是说也没，应该没有存在。比如说你就写代码写的可能一个项目也挺大了，然后启动我一块，你不想写，或者说你这一块不太懂，你直接让他帮你写。

Speaker 2 25:14 
没有，到目前为止还没有。

Speaker 1 25:16 
都没有过，是吗？对，看到这你这么的不信任 check GPT。

Speaker 2 25:20 
那也主要是我的项目这块的话，也好像也用到的那个泄露，是吗？对对对，而且就是他确实是怕，因为好像是你去产业基地问题，包括他给到你的答案，或者你问的问题甚至都已经被他学习到，就是他可能会就是对于将来你这个论文的查重什么的。

Speaker 1 25:42 
你的意思，对，担心对的信息泄露，以及对。

Speaker 2 25:47 
对对，因为他那个包括你的论文投出去，你在审稿阶段，你的论文可能就查重率都通不过，对，没有办法给他大片的东西，你大片的东西传上去之后，他你到后面查重，你可能出问题。

Speaker 1 26:03 
对，可能代码什么的我目前发的，那我可能还没遇到这个问题，因为我是有让他帮我写。

Speaker 2 26:08 
没，没有。不，他常常不会，没，他不会去学习你的那种写作的方，那种什么什么，然后再去查重，没有问题吗？

Speaker 1 26:18 
我，我没有，因为可能我发动的时候我都没发现有 AI 查重率这个东西，我发现并没有。哦，好，对对对，因为可能写的就那么几段话。那所以 debug 的过程中你就是就其相当于就是哪里有错，然后你把这一段代码发给他，然后报错的地方也给他。对。

Speaker 2 26:40 
就是局部的一个对，会给他一个大的浅于环大的一前提，就比如说我在做什么事情，然后这个任务是怎么样的？然后这块报错了。怎么我写到什么程度了？然后这块报错了，会是会告诉他的一个一个一个一给他一个嗯，具体的背景了，但是我不会把全部代码粘给他，让他帮我写，对。

Speaker 1 27:03 
帮我。对，那他给你的这个代码是能，确实 OK 吗？就是能让你跑通吗？还是说嗯哼。

Speaker 2 27:09 
他给我的代码，我也是，就和会和我已有的这个报错的地方去对比了。看他是怎么改的？然后再采用他的方案，他是会在提，在 debug 这方面我觉得他还是比较专业的。

Speaker 1 27:25 
应该是的，我因为我直接都让他写代码，我很少会去bug。哈哈哈，那那那你协助自见吧。那还有什么任务呀？天呐，我怎么感觉任务还是没有我想象中的那么多，我以为 engineering 的会有那种很多的跟 ChatGPT 交互的过程和任务。

Speaker 2 27:45 
是有啦，我是比如说，其实比如说有一些就是无人机的比什么状态嵌入和编码的东西，我会去问他。

Speaker 1 27:57 
是什么概念，是说具体的。

Speaker 2 28:00 
代码就是说我会给，就其实有，你刚刚好像有提到过，就是说我想要用于什么算法？是怎么实现这个呃？比如说我要用到那个 Transformer 去，用到 Transformer 去嗯。唉，比如说你看我写我这块有一个就是，比如说怎么样将无人机的状态的信息嵌入成那个 token 的向量，并什么加上那个未知编码或者说是什么东西，然后你具体地告诉他怎么做，他就会给你提示。

Speaker 1 28:31 
呃。就是说你会跟他描述这个任务，对对对，做完然后他给你是代码，还是说。

Speaker 2 28:38 
他给我的是具体的一个操作的步骤了？比如说他会一一说，是你要先明确，比如说我会先，我说怎么样将无人机的状态信息嵌入成了 token 的向量，然后他就会告诉你怎么做具体的步骤嘛。比如说他第一步他会说你要明确无人机向量状态向量的组成，包括比如说位置、速度、航向、时间、戳呀。对，他会给你这样去讲，然后再说是将怎样将状态向量嵌入嘛。然后他会给你说就是利用线性层影射到指定的维度什么什么的，他会告诉你这种步骤的话，他是他说的，是没有错的，所以这种问题还是可以问产品 PD 的吗。

Speaker 1 29:18 
所以说这个步骤生成之后，那你之后是按照他的步骤去完成，还是。

Speaker 2 29:24 
说会的。

Speaker 1 29:25 
就是一步一步地按照他的设置做？对，那也没发现有问题。

Speaker 2 29:29 
这块的话你其实是能够判断的。比如说你要先将无人机的状态嵌入成 token 的话，你也会知道，就是说你首先要明确你的无人机的状态向量，你的信息是怎么样的，是多少维的嘛？这些这很基础的东西，我即使没有特别专业的背景，我也是能够判断他说的是对的。

Speaker 1 29:49 
可能是我听不太懂，哈哈哈，就是这可能跟你专业有关，就大概你是知道他说的对还是错。对。

Speaker 2 29:55 
对对对，是能够有判断能力的。

Speaker 1 29:57 
对。诶，那有没有可能在这。过程中你会让他提供一些链接，比如说验证接或者。

Speaker 2 30:04 
接说到链接这块的话，差这边提供的链接 50% 都不可信，就跟那个论文的引用一样，他给你瞎提供他参考文献一样，他给到链接有一些都打不开的，我遇到很多这种情况。对。

Speaker 1 30:17 
就是说你，可我因为我不知道这里是不是因为 model 的原因，就是有时候我让他帮我找文献是 OK 的，能打开。

Speaker 2 30:26 
对，你知道 NTU 上次查重那个学生为教授，为什么能识别出那篇文章是产品写的，而不是那个学生写的嘛？就是因为产产品对应会给到他一些乱七八糟自己瞎编的文献，根本就找不到的文献。我也是，在我写论文的时候，我有时候就是给到他一段话，我说你帮我去找相关的参考文献，他给到我的参考文献也是没法用的，都是他自己瞎编的。参考文献这块它真的很瞎，它瞎编的概率很大的。我是，对。

Speaker 1 30:58 
明白，可能之前我写什么什么来着，反正我让他找参考文献，可能我用的是 Ostar model，给我找的还行，我觉得就能打开，也能跟这稍微相关就行了。当时是这么这么用它。

Speaker 2 31:10 
我，我用我这块是真的是不行，它会瞎生成参考文献的。

Speaker 1 31:15 
对对，那可能跟 model 有关吗？那你没有尝试别的一些的甚至是 AI 的工具吗？比如说谷歌的或者是cloud，对吧？还有DeepSeek。什么。

Speaker 2 31:28 
Deepseek？有也会用。

Speaker 1 31:31 
就说你都尝试，也有尝试一些别的。

Speaker 2 31:33 
对对，有去用。对，一开始有去用了，然后后来的话就还是觉得产品会比较好一点。 DeepSeek 的话，觉得 DeepSeek 可能去你问一些国内的一些东西，觉得他回答会比那个产品有点好一点。问国外的东西，尤其是英文方面的这种生产，我觉得他不太行诶。

Speaker 1 31:55 
那肯定这对呀。没有，我就说谷歌的，因为最近新出的 ChatGPT 五大家觉得都不好用，然后我也转谷歌了。那我发现谷歌确实优势。

Speaker 2 32:07 
你谷歌你指的是哪一个呀？

Speaker 1 32:09 
叫Jimi，Jimi。

Speaker 2 32:11 
Jimi。对。

Speaker 1 32:12 
对对，Jimi。

Speaker 2 32:12 
Jimi。那我用过，你用。

Speaker 1 32:15 
过吗？好的，感觉还行。

Speaker 2 32:17 
嗯嗯，还好。

Speaker 1 32:19 
没有。我没有，因为我用的也是会员版。我因为我每次都是用会员版，所以我对会员。

Speaker 2 32:23 
版。怪不得，那可能是我用的基础版，也可能就是他给我生成的。确实有不太好，就。

Speaker 1 32:29 
可能希望你花钱，因为你可以试下谷歌那个他最近免费一个月的，就是他第一个月是免费的。对。

Speaker 2 32:35 
嗯，可以，我去，我之前有试用过，我不太确定会不会还给我免费。

Speaker 1 32:40 
了。你试用过了？好吧。

Speaker 2 32:43 
我一开始就是用产 BBT 这边的话好像是合唱对象同时间出来的还是。嗯，后来一点点就是其实很，我之前是有自己去尝试，用过各种各样的。就是我，我好像是下载了一个什么什么什么什么东西，他就把所有的那些 AI 的那些东西都在里边的，就是其实我会，我给到一个问题，他会有里边有五六个 AI 工具去帮我回答的，我会对比一下哪一个说得比较好？对，然后去选择其中的一个。

Speaker 1 33:17 
你的意思是说之前一开始用的时候会让多个 AI 帮你生成？对对对，是，然后进行一个答案比较。

Speaker 2 33:23 
对， check PPT 只是我其中的一个选项而已。

Speaker 1 33:26 
那不是，我的意思是说那是现在慢慢地全部集中到 check PPT 吗？还是说。

Speaker 2 33:31 
对，一开始是用了很多的，然后来就是逐渐的就是依算是依赖上 check PPT 了吧。

Speaker 1 33:38 
那一开始你在十多个的时候，你感觉怎么样？就是一开始，嗯，是比较之后发现都不行。

Speaker 2 33:46 
去年的，去年年初就用那些，其他的就是用的会比较多一些，然后我当时用的体验感就还是没有 check PPT 好，所以我才去转，才留了 check PPT 一个其他的都。

Speaker 1 34:01 
就相当于说几个生成之后，你发现还是 check PPT 最优。对，那当时应该好像也没有特别多的 AI 吧？

Speaker 2 34:09 
有诶，有四五个的，四五。

Speaker 1 34:11 
个，然后发现都不太行。

Speaker 2 34:12 
还有包括你像百度出的那个豆包。

Speaker 1 34:16 
那豆包不是抖音。

Speaker 2 34:19 
的。豆包是抖音的吗？是吧？

Speaker 1 34:22 
豆包不抖音的吗啊？我不被你问的我也蒙了。

Speaker 2 34:31 
我也，我回头查一下，豆包是抖音的重要。

Speaker 1 34:34 
这可能不是太重要的问题，因为我也像国内的，确实用得不多，印象不深。

Speaker 2 34:39 
我也，我是会用到一点点了就会去。哦，明白，同一个问题我会同时问到产GPT，问豆包，问到 deep c。就是一些相关的我都会用，会一开，因为一开始我也不知道新人哪个，我都会去看他回答的问题怎么样嘛？然后看他回答那个。

Speaker 1 34:56 
结果是这几个生成之后，你再进行判断之后，那你就会再还是。多个模型一起问吗？还是说因为你肯定还会有下一步嘛？还是专门找一个模型去问就好。

Speaker 2 35:05 
了，就是多个模型一起问，就是我之前用的那个接口，那个那个叫什，那个是叫什么呀？就是你进去之后，它里边就本身就是嵌入了很多个那个 AI 的模型，然后你问一，你问它一个问题会有五六个、四五个 AI 的模型去同时回答你这个问题的。

Speaker 1 35:24 
对，然后你再对，再去选 fo follow up，就是下一次再问的时候其实还是多个模型，就每次的模型。嗯，那你就发现其实就只有 ChatGPT 对于每一次都可能更优一点，更甚。对。

Speaker 2 35:36 
对对哦，明白了。所以其实就是现在我问一些国内的东西，我就我，我就会问那个DeepSeek，然后其他问题都是 chat p。

Speaker 1 35:46 
那有没有可能就是说把 ChatGPT 的答案，你再让下一个，比如说下一个模型判断一下他写得怎么样。

Speaker 2 35:52 
会。

Speaker 1 35:54 
也有这种尝试，是吗？对，老你这么这么这么使用，发现有什么不一样的地方吗？就是因为，嗯。

Speaker 2 36:00 
也没有什么不一样，就是可能去用产品的答案去问另一个的话，他也会做出比如说你用产品的回答去给到，去让 DeepSeek 去判断他说的怎么样， DeepSeek 也会做一些修改了，你看哪个好你就用。

Speaker 1 36:15 
那他那你觉得修改前后你觉得哪个更好一点？

Speaker 2 36:21 
这个还真不一定啦，不一定是哪一个更好？有可能有，我遇到很多，我因为我经常这么做，所以其实。对，因为我对他的信任度真的不是很高了。所以我会用到多个模型去验证，有时候是产地本身生成那个比较好一点，有时候是DeepSeek。

Speaker 1 36:43 
对，那有没有可能就是因为你说用多个模型验证，那也是验证它的答案的呃。验证答案的什么呢？是准确性还是性？就是还是它的输出的。

Speaker 2 36:54 
服形式，是吧？对。

Speaker 1 36:56 
就你去验证它什么，我其实挺好奇这个。

Speaker 2 36:59 
嗯，我会就是趁这边生成的这个我其实是会，就是对于游戏我其实之所以会验证是因为我对它这生成的这个东西不是很了解，我就会去给到另一个，让他去判断。

Speaker 1 37:12 
对不对啊？你就在。

Speaker 2 37:14 
我不了解的情况下，我会用到多个 AI 的模型去。

Speaker 1 37:18 
就属于相当于就是你刚才提到的熟悉领域和不熟悉领域。

Speaker 2 37:21 
对对对，是不。

Speaker 1 37:22 
熟悉领域，你会用多个AI。对对对，是的是的。那判断完之后，你你你怎么确定确这个不熟悉领域，它就某一个是对的？其实我因为你还是用模型来判断，不是用自己去查资料嘛。

Speaker 2 37:34 
嗯，是基本上他能给到我的，我他能，他给出的结果，我是我还没有什么是完全不熟悉的吧。你还是会根据自己已有的常识、背景知识，还是能够判断他说的对不对。

Speaker 1 37:52 
的，所以。

Speaker 2 37:53 
我迄今没有发现过，就是没有什么说我完全没有判没法判断的知识点。

Speaker 1 38:02 
OK，所以其实相当于你就已经有自己的筛选，对吧？对对对，他们避开自己不熟悉的。

Speaker 2 38:07 
对对，我的筛选也是来源于我的。我，我对他有一定的认识，当然不是说太熟悉的东西了，我是还是也会有一些自己的判断常识的嘛？对。

Speaker 1 38:20 
哦，明白明白，这是我，我能理解。那主要是我没用过多个模型。那一比来比去，我觉得。

Speaker 2 38:27 
诶，我那个叫啥来着？我因为前一段时间电脑上电脑那个内存不够了，我就给它清了，那叫啥来着？就是它里边嵌入了很多个 AI 模型，你就是可以给它的，给到它一个问题，它会同时产生很多个答案的。对。

Speaker 1 38:40 
但这肯定能增加你的 critical thinking，对不对？就是因为你的答案都五六个在那里了。是的。

Speaker 2 38:46 
甚至就是它生成的，我有看到它就是比如说好多个模型它同时给出结果的话，它有些模型给到的那个不给到，那个，那个那个那个答那个答案的那个结构也不一样，甚至就是说他有可能有些模型他给到那个答案的结构也是你喜特别喜欢的那种。就是很，哦，对，就他不光是语言组织方面了，他还有就是内容的输出方面了，他还有那个结构方面也是有些生成的结构，你是真的会喜欢的。对，就是很清楚。

Speaker 1 39:15 
的那种。对啊，那你看了五六个之后加就是怎么去选呢？就五六个，对吧？这各种各样的，那你怎么去？

Speaker 2 39:22 
当然是选一个就跟我的任务最匹配的了。

Speaker 1 39:26 
所以说其他答案其实并不会去影响你的一个判断。对对对，不会觉得这个也好。

Speaker 2 39:33 
你有可有我遇到的情况，就是比如说有一个，比如说我，我让他生成的东西生成了三段，他可能第一段，嗯， a 生成的 a 模型生成的好，然后到第二段的时候 b 模型生成的好，那我可能会把 b 的模生 b 生成的粘过来。然后就会，我还是会自己的再去组合。

Speaker 1 39:51 
盘点组合，对对对，可能就相当于就是说这个 model 也是这一点。行，那也行，然后就把这是，对。

Speaker 2 39:57 
就是看他有些，比如说他有，他。我让他写一篇文章，他可能给到有有有，有三个points，然后那 a 模型写 a point 写得比较好， b 模型写 b 模型写那个，第二个 point 写得比较好。对，就是你会结合他，把他所有的优点拿出来再去组合。

Speaker 1 40:19 
那就对，你是拿出来之后你会让 model 去帮你顺一遍，还是说你自己去顺一遍？我自己。

Speaker 2 40:24 
去顺。

Speaker 1 40:24 
哦，你已经不再用model。对对对，那。

Speaker 2 40:27 
我也就觉得我已经用够它了，然后我也已经能判断出它哪一个说的哪一个部分，是哪一个说的，哪个模型说的比较好，所以我就会摘出来，然后再自己把它组织好。

Speaker 1 40:38 
所以其实能理解为其并不会说一直用一个model，其实相当于就说几个model，我会一直地不断地去看，不断地思考，不断地去，对吧？去用它的这些东西，那最后慢慢的怎么就突然不想用这么多个model？

Speaker 2 40:53 
我其实还是会想要用那样用，只是说我计算机内存不够了，我又你们喜欢那样用了，其实如果让我选的话，我还是会那样用的，尤其是对于那些比较特别就是重要的一些report，还有什么东西我都会这样去做的哦。对，但是不重要的东西的话就无所谓了。

Speaker 1 41:13 
就没有必要。

Speaker 2 41:14 
搭配，就看你，你看你要，你看你给到的这个任务对你来说有多重要。

Speaker 1 41:19 
了，所以说相当于重要的任务，我发就是更倾向于去选择多个答案，对吧？是。

Speaker 2 41:26 
的是的，对，从多个答案里边再去选那个最优的，哪怕甚至就是哪一个判，就是哪一个段落，我也会选一个最优的出来。

Speaker 1 41:34 
对，因为你提到这个其实跟我后续的，我后不是有什么 experiment study 和 design study，跟我后面一个 design study 有点相关，然后可能不知道你后面会不会感兴趣来参加一下实验？哈哈，对，没有，因为那个到时候我有。

Speaker 2 41:49 
你们的链接的话可以的。

Speaker 1 41:50 
什么什么？

Speaker 2 41:52 
我说到时候如果能看到你们的那个采访信息的话，我是可以的。

Speaker 1 41:57 
没有那个我，你们不是勾了那个是否参与后续的实验？你们有，应该有吧？对，因为我访谈招的人很少，访谈我就招了 35 个，但报名人特别多。是。

Speaker 2 42:09 
哈哈哈，那我算幸运的吗？

Speaker 1 42:12 
你没有，因为我是认真看了你们的贴的那些材资料，就是确实要找一些高频的使用者，要不然不高频的话我也聊不出来东西嗯。然后对，后续我的实验可能会招 150 ~ 200 人，就后面人会慢慢地在增加，然后到时候肯定就先发一下邮件，问一下你们愿不愿意往后续参加嘛？对，到时候邮件再问了，哈哈哈，对，嗯，那其实相当于现在是用单个，其实相当于其还是想用多个 model 只是因为。对，对，是，嗯，那其实为什么会出现内存的问题呢？因为我觉得好像现在都是在页面端、 Web 端。

Speaker 2 42:50 
嗯，我那个，我用的那个它是要下载下来的，是一个APP，然后那个 APP 进去里边会有它，那个 APP 是集合了，所，基本上那个 APP 里边集合了所有市面上的大模型。

Speaker 1 43:00 
那它需要收费吗。

Speaker 2 43:02 
呃？不收费的，它是免费的。

Speaker 1 43:04 
那它的 model 是什么难度的？model？就是基础模型吗？

Speaker 2 43:08 
还是基础模型？你要他，你要进去里边用到某一个就是让他升级版本的，你还是要收费的，但是他里边他是相当于是集合了所有 AI 模型的那个基础版。对。

Speaker 1 43:21 
那你会不会出现就是用个几次它就limit，就是直接把你限制次数。

Speaker 2 43:26 
嗯，没有，它那个不限的，很好用的一个。OK，白明，那是别人推荐给我的。

Speaker 1 43:34 
好的，没有，我也想，就是了解吧。因为多个 model 的其实它很能增加人的 critical thinking，因为你生成一个答案的话，那其实就是你只能用和不用，要不然你就是再让它去重新生成。那如果说没错。

Speaker 2 43:48 
我甚至会让他就说你给我生成几个针对一个某一个话题，我，你要给我生成几个观点，然后每一个观点你要去帮我，就是用你的理由去就写出来为什么支撑这个观点？就是确实是会用到让他去帮我生成这种。

Speaker 1 44:03 
对，就比如说你想要性的想要一个观点，但是你会让他生成三个或 4 个。对对对，然后再让再去选择。对，其实现在已经把一个 model 当几个 model 用。是，哈哈哈，明白，其实有点像发散，其实这个过程一直都在发散。嗯，是，OK，那你觉得我觉得这应该就比较一个有趣的点嘛？其，但我发现好像多个model，其实就好像在计算机好像就确实会这样子，用得多比较多一些，就在工科上。对，OK，诶，有没有就是 promise engineering？你有去学过什么吗？因为我可能我忘记你问卷填了什么，我昨天还看了一眼，就是有没有受过 promotion engineering 的一些训练，或者是自己学一些资料什么的。

Speaker 2 44:51 
你指的是什么？

Speaker 1 44:53 
就是提示工程啊。不。

Speaker 2 44:55 
我之前有去，自己学了很多了。其实。

Speaker 1 45:01 
怎么这又怎么学的？是。

Speaker 2 45:03 
就是去看了一些他们就是潘某的 engineer 的一些唉。那是谁出的。

Speaker 1 45:10 
书吗？还是什么？是。

Speaker 2 45:11 
书，也有那些网上的那些什么 training 的东西，那些文本文档看真的太多了。

Speaker 1 45:22 
就是，那真就是你学了之后有感觉有作用吗？还是有啊？

Speaker 2 45:27 
他会，就是那我之所以现在就是问到一个问题，然后我去再去细细化地一直追问 ChatGPT GPT 这种思路，其实就是。

Speaker 2 45:38 
Promote, promote, and engineer.

Speaker 2 45:41 
那个东西才会。

Speaker 1 45:42 
对，就是他会教你，比如说你对于任务该怎么拆解地去？

Speaker 2 45:46 
对对对，是。

Speaker 1 45:47 
OK，OK，OK，因为这个是我下一个的研究中的某一个对照组，就是我想这个。

Speaker 2 45:55 
真的是学了很多诶，因为就是无人机上面，无人机是我，就是我做的这个一方向里边，就是我们，我们要去用到那个大语言模型，让他去学习无人机的避障动作，然后学习无人机的实时路径规划，还有那个去进行基于那个视 vision Transformer 去识别周围的这个环境，就是会用到很多人工智能相关的东西了。所以之前是有大量的时间在去学这个东西。对，那当然没有办法跟你们计算机的那些写的那种，我们都是基础知识。

Speaker 1 46:33 
没有，我不是计算机的。哈哈，你不是，我忘记给你介绍，我是商学院的，商学院 information system 的。哦哦，我忘记介绍了。不好意，你。

Speaker 2 46:44 
旁边是CC，他们不是在计算机学院吗？

Speaker 1 46:46 
商学院？对，我做的是 human computer interaction 人机交互。好嘞。

Speaker 2 46:51 
好嘞。嗯，对，就是这。哎，你说的这个哈，我们当时就是有搭建这样一个人机交互的平台了，就是让他去做 b 端选择，就是学习那个人工智能的算法，就是基本上我们是更倾向于去，当然我们后续用到那个就是让他去先学习那个 video 的避障动作，然后再去那个什么是用到那个大语言处理的模型了，然后一开始我们用到人机交互那个，其实是做那个强化学习的，其实我们自己也有开发一个人机交互平台去让无人机避障的。

Speaker 1 47:26 
对，然后你发现效果没有代言模型好吗？

Speaker 2 47:29 
还是的，他那个就是因为我们当时是其实受限于一方面，是受限于我们没有太多的无人机的真实机，就是我们只我们当时实验的时候用到的那个无人机的臂章场景也是，那个 video 也是来自于我们用了那个就是airsim，就是我们本身在我们这个领域它有一款那个模拟的多无人机在空中飞行模拟的这种场景的那种平台，然后我们是从那个平台拿了它产生的video，再去喂到这个人工智能的模型里边的哦。对，所以其实是出问题，是，我推测的大部分原因是因为我们这个数据集不行。对，所以才没有继续下去。对，对。

Speaker 1 48:14 
那，诶，没有，我其实更想了解那个，就那个提示工程这一块你是怎么去学的？就是因为这个，是因为我是人机交互，我研究其实主要在人不在机。你说就是因为商学院，商学院更多的偏向于教育学、心理学、管理学。对对对。那那你怎么去学这个提示工程？从什么？从什么开始？是说教你这个任务怎么去用，还是说一步一步地去学所有的东西？

Speaker 2 48:40 
我应该是自己看了所有的东西。

Speaker 1 48:43 
看所有，然后你会因为我们。

Speaker 2 48:46 
工程领域其实用人工智能会比较多一些，我们要明白它的算法是怎么样的，我们要就是很清楚地知道每一个算法推导的过程，包括它是怎么推理的，然后包括它我们要怎么样去用提示词去让它产生我们想要的答案。

Speaker 1 49:00 
呃？对，那这个提示词你有，比如说有一些比较你觉得很有用的，有这么一些提示词吗？

Speaker 2 49:09 
想想就是比如说我们一开始谈到就是说你要搞你有一个什么样的任务？你要把任务要描述清楚，然后，嗯，比比还要描述清楚你的身份了，比如说你是一个研究员，你要怎么让他生成什么样的答案？你是一个学生，让他给你生成一个作业的什么？就是要交清，交代清楚基本上你能交代的所有的信息，他才会给你生成一个比较你想要的答案，算是。

Speaker 1 49:38 
对，其实有点类似于不要让 ChatGPT 来揣测你的意图。

Speaker 2 49:42 
嗯，也不是说最好不是你就是你，你要尽可能多的给到他的信息。因为我就是当你信息给你给到很 general 的时候，它产生的那个东西大部分以我的经验是它是我不想要的，但是如果说我给到它一个 SS specific 的一个一个背景交代一个需求，一个是描述，给它描述我要的一个我的场景是怎么样的？描述得足够，只要你描述得足够清楚，我觉得他产生的那个答案还是质量比较高的。

Speaker 1 50:14 
可以这么说，其实现在就是说这个提示工程就是写得越详细。

Speaker 2 50:18 
越好。是的是的，必须的，那我很知道他这剩下的东西真的不怎么样啊。

Speaker 1 50:23 
就是那还有什么别的，比如说你觉得还有挺有用的，就是可能对你帮助比较大的。

Speaker 2 50:32 
嗯，你是说哪一个方面吗？还是。

Speaker 1 50:37 
因为提示工程的话，我了解的，就比如说你刚才说的。就是比如说写清楚任务角色，然后还有可能比如说我那天写了一下，我自己都忘了，就是还写了什么，可能比如说对于一些东西你要提供一些链接准确度，可能就是啊？是。

Speaker 2 50:57 
是对对，就是你，你会就是把你要让他给你完执行，就是让他给你对你的任务产生一个你比较满意的答案，你要把你手头所有的资料都会要给到他，比如说我之前让他去，就是我去投简历，我让他去写那 cover letter，或者写那个投递的邮件，我都会给到他，就是这个公司是什么样的一个公司？然后那 job description 是怎么样的？这个职位所有的信息我基本上我能给到他的信息，我都会给到他，然后他才给我生成那个邮件以及那个 cover letter，就是。

Speaker 1 51:32 
哦哦哦，明白，明白，对。

Speaker 2 51:34 
就是你要尽可能地给到他尽可能多的详细的信息了。

Speaker 1 51:40 
那有个问题就是你有看他会帮你总结文献，或者是帮你阅读文献吗？

Speaker 2 51:45 
他总结的那个文献有一个，这个我给你看一下，怎么了？那个审那个其他的我不知道，就是那个 Copilot 你用过吗？

Speaker 1 51:58 
Copilot 是那个哪个公司来着？我，我还没用过，但我知道这个东西。

Speaker 2 52:03 
你用一下它你就知道它文献总结得可好了。

Speaker 1 52:06 
偷拍了 OK CALPOT 吗？还是什么？

Speaker 2 52:10 
对对对，是那个，我看一下哈。就是那个 IMA 可拍了，就是大熊猫投的那个啊。

Speaker 1 52:20 
是，所以跟他总结文献的时候，你会给他写清楚提示词吗？因为我还在提示工程这一块。

Speaker 2 52:25 
其实完全不用你给，他本身就是做这个的，就是它就是一个专业的文献阅读器了，所以你给到它，你说你把这篇文章，你试一下，你就知道你给它这篇你要读的这篇文章，然后让它给你，它自动会生成说你，我第一个它会说你需要我帮你总结那这篇文章吗？你说好，你说yes，它就会给你总结，然后它还会给你生成那个叫什么，就是那个map。那叫什么？map？就是它思维导图啊？对，对，就是类似于思维导图的那个东西，它也会给你总结得可好了，你试试。

Speaker 1 53:00 
没问题。

Speaker 2 53:01 
因为他是一个，就是他是类似于你问你，你就是刚刚你，你有问到就是说让他去总结文献，他就是专业地去做这个总结文献的这个工作的，所以你不需要再给到他很多的提示词，让他去怎么样了呃？他已经，他因为他已经训练好了，不需要你再教教他了，你就直接给他文档，他会给你总结得很好的，有。

Speaker 1 53:23 
就是有可能他提示词已经嵌入了，对吧？

Speaker 2 53:26 
是的是的，对，我感觉是这样子的，就是他是一个很专业的，他只总结稳定性，他不会干别的。

Speaker 1 53:32 
所以其实相当于你还是会有很多个 model 处理不同的任务。

Speaker 2 53:35 
是的，对，就是去找，因为每一个模型它会有擅长的，比如说生，擅长生成图片，那 check BD 就生成的图片就不太行了。

Speaker 1 53:44 
那生成图片你用什么？一般用什么东西生成图片用。

Speaker 2 53:47 
哪？我看一下，我之前用，我最近没有生成图片。我忘记了诶。

Speaker 1 53:52 
看得出来你用的确实很多个那种。

Speaker 2 53:55 
Kimi 会比较。

Speaker 1 53:57 
Kimi 吗？ Kimi 生成图片吗？是 Kimi 吗？我觉得 Kimi 好像生成文字，好像还比较常用一些。

Speaker 2 54:04 
是我用它生成过文字，好像也生成过图片。

Speaker 1 54:06 
OK，OK。

Speaker 2 54:07 
对，它那个成它那个，它那个生成那个 slide 还好，你可以试试。

Speaker 1 54:13 
slide。你是说生成幻灯片。

Speaker 2 54:17 
那也可以的。

Speaker 1 54:18 
Timi 是吗？对，OK，没想到你有这么多。

Speaker 2 54:23 
我说过我用，哈哈哈。

Speaker 1 54:24 
对，因为我是很多，对，我习惯性用一个，然后就不会再去用别的。

Speaker 2 54:30 
我是会，就是目前来说会侧重于 change DB，但是我还是会选择别的，比如说读文献，我肯定就是用口拍了，它真的很professional。

Speaker 1 54:40 
那你读文献是比如说直接丢进去了，然后它会总结英文还是中文，还是说无所谓？你。

Speaker 2 54:45 
丢进去是中文它就总结中文，你丢进去英文它就总结英文，或者你即使你丢进去是英文，你要让它用中文总结，就它其实也是你可以做那个给到他，那个也就是提示词的，让他去用中文给你总结，他也是明白，所以他还是有那个，就是你允许你去输入提问的那个接口那个，对。

Speaker 1 55:08 
那你觉得这个对你帮助很大，因为这篇文献是你准备精读呢？还是说你其实不想看了？就是大看个大概就好了。

Speaker 2 55:16 
属于重点文献，可能需要精读的哦。对，我会先让他去总结一下，然后总结一个大概，我看了他总结的东西，我再去带着他的总结的东西，然后也可能会带着他总结的东西，我脑袋里边会出现一些问题。我带着问题再去读。

Speaker 1 55:32 
的，原来是这么用，它的意思是说你总结文献是为了激发你的一个。

Speaker 2 55:37 
对，一个思考的，一个就是让你去产生一些。有可能会问，有想要去知道的一些问题，然后再去，再去回，再去看那个文谦。

Speaker 1 55:48 
这个点确实很难会考虑到，因为正常的就是丢进去，我看下这篇文章他在讲什么，对，然后就下一篇。对，因为我，因为很少我会说就是丢一篇文献进去，然后看它的生成来思考就出问题，之后再去精读这篇文章。

Speaker 2 56:04 
我基本上就是从，因为我基本上文献都是我这个专业，都是我这个领域里面的，那我其实是知道他大部分的东西的，他新那些新的文章出来，我也会从我的角度讲，我会猜个一二，基本上也是会很熟了，只是说可能最新的算法我没有用而已。就是，所以我其实是通过他首先给我一个很 general 的总结，还有一个思维导图，就一个一个思维导图其实也可以去训练你在自己写论文的时候，那个文章的结构也会很清晰的。对，然后根据他的思维导图和他的总结，然后你再去看看他，有时候那个思维导图出来你都会问，这你都会问，诶？这个文章结构为什么会是这样子的？为什么要这样写？他的那个模拟的就是我，因为我们，我是工科，我们那个 simulation 部分他有可能是用到真实的场景，也有可能用到是那个模拟的场景，那我会用到说，诶这个真实的场景，这个数据是从哪里来的？我会带着这些问题的。再去读文章的话，你会效率很高的。

Speaker 1 57:02 
对，明白了。哼，是一个好的point，挺好的点，所以说。嗯，那其实没必要去用一个的，一个。

Speaker 2 57:14 
对对对，我觉得就真正的夺文效可拍了，真的是太专业了。好。

Speaker 1 57:19 
的好的，我等一下结束我自己去试试，而且。

Speaker 2 57:22 
它生成的那个思维导图很漂亮的。

Speaker 1 57:26 
那这个思维导图就是你之后的阅读的文献，还是会去参考这个图吗？还是说看完就不再也没必要？

Speaker 2 57:32 
会，因为它会，它本身就是你看过的东西，它会重构，重构起来还可以让你做笔记的。你就会从都不把所有的文献你拿，你哪怕把它其实也是可以帮你去类似于像一个文件管理器一样的东西，可以帮你去整理文献。

Speaker 1 57:47 
的。我懂了，取代了那个文献管理器叫什么来着？

Speaker 2 57:51 
对叫叫叫啊。对对对。c。什么东西的啊？是c？ c 叫什么？ c 头还是什么东西？不是忘了忘了，我基本上也自己不会用文件管理器了。对。

Speaker 1 58:01 
OK，明白，对。

Speaker 2 58:04 
姐，还有那个 unknown 也是有可以做文件管理器的嘛。对，但是我现在，因为我现在用的是那个，我看一下，我现在用的是那个什么？写paper，嗯，用的是那个overleaf，所以其实需要别的那个什么榜？overleaf。

Speaker 1 58:21 
是写。

Speaker 2 58:22 
overleaf， overleaf 是就是写写你，你就是写写拍拍很容易，就是格式它所有都会给你。比如说你要投一个目标期刊的话，你把那个期刊的那个就是来 text 的。 overlive 那个我懂。

Speaker 1 58:38 
那test，但是我不知道overlive，因为你很。

Speaker 2 58:40 
有，你有。

Speaker 1 58:41 
因为转商科之后完全只要用 word 写论文就好了。

Speaker 2 58:45 
这样吗？哈哈哈我还是觉得 overlive 排版真的太。

Speaker 1 58:49 
对。我懂你意思。因为可能是工科需要排版，就按期刊排版，然后商科完全不用排版，只要两倍韩剧就可以了。所有论文两倍韩剧好吧。哈哈哈是我没get。

Speaker 2 59:02 
但我觉得你好明智呀。不要工科真的好麻烦。

Speaker 1 59:06 
那我硕士学的是计算机的，后面又转掉了。我觉得计算机那写代码太累了。

Speaker 2 59:11 
哈哈哈，挺好的。

Speaker 1 59:14 
OK，OK，好像我看一下，那我因为我其实没有按它按照提纲来的，其就我觉得比较有意。

Speaker 2 59:22 
其实我一开始用 overleaf 的时候，它那个 debug 我也搞不定，然后 check DPT 回答 overleaf 出现的那些问，就是你在 overleaf 那个版本出现问题的时候，你问他的话，他回答的那个答案你照着做就好。真的是产品很在这方面很强了。

Speaker 1 59:40 
就是解决这种常识性的问题的。对对对，很有帮助。

Speaker 2 59:44 
他真的很强。明白，他是一个好助手。好的。

Speaker 1 59:49 
我好像也学到了挺多的工具，哈哈哈。嗯，挺有意思的。挺有意思。嗯那那其那那我看时间也快，差不多。那我就是我问一下最后几个问题，就是你觉得跟 ChatGPT 也用了两年来了，那你觉得对你这生活有什么很大变化吗？前后的变化。

Speaker 2 01:00:08 
哇？我觉得提在就是回复邮件这方面提升效率方面还是真的是一个很好的助手了。

Speaker 1 01:00:14 
提升效率以及肯定有一些开拓思维，毕竟。

Speaker 2 01:00:18 
是就是有一些问题，你就是尤其是对你不熟悉的问题，他会给到你的 point 真的很有用了。对，他会激发你再去追问，再去发现新的东西的。

Speaker 1 01:00:28 
对，明白，那是的，好像大家都离不开 check GPT。是的是的，哈哈哈。 OK OK OK。

Speaker 2 01:00:36 
基本上每天都会大量地去用了。

Speaker 1 01:00:39 
是这么一回事，嗯。那你觉得就是因为肯定 AI 的发展会一直发展，那你觉得你和它的一个合作方式，或者说你的使用方式会出现什么变化吗？就。

Speaker 2 01:00:51 
之后。

Speaker 1 01:00:52 
的话，所以我其实。

Speaker 2 01:00:54 
还是会依赖他去帮我做一些处理简单的事情，然后如果后续他的那个，那个就是那个推理，嗯，模型就是可能会更高级的，可能生成的东西会更，那个什么会靠谱，更靠谱一点，我还是会依赖他去用他的。

Speaker 1 01:01:11 
对，除了writing。是吗？我可以这么理解吧。

Speaker 2 01:01:16 
算算是吧？对。

Speaker 1 01:01:18 
OK，那就比如说你假如，就是对，比如说对那种高频或者说中低频的那种使用者来说，如果你想给他一些建议的话，你会给一些什么建议呢？

Speaker 2 01:01:29 
就是对于高频的使用者。

Speaker 1 01:01:32 
因为这不仅仅是提示工程，毕竟你对使用 ChatGPT 肯定有很多不同的看法。

Speaker 2 01:01:38 
其实我觉得真的是ChatGPT，我觉得本身这种科技性的东西就是一把双刃剑了，你要用它的时候你还是要有自己的判断能力，不要去完全地依赖他，你自己真的是会丧失你，你去判别是非和去思辨的一个能力的。就是尤其像我的话我就会处理得比较好，我是所有 check DB 产生的东西我都会去再去思考，再去进一步地处理，才会用到它，就觉得如果你过度这东西，如果你过度依赖的话，你完全信任它的话，它真的有可能产生的东西，就比如那学生交的作业，嗯，会被教授查出来，就这样就真的是不太好的事情。

Speaker 1 01:02:19 
对，那这就很取决于，就是，对。

Speaker 2 01:02:21 
就是很取决于你，你的目的是什么？比如说你想写作业，你想几教授布置的作业，还有你发论文这种哈，真的是你依赖它的话，你可能会后续查重，也会出问题，也会给你在无意中会造成学术不端什么的，就是真的是取决于你用它做什么，但是一些日处理一些日常邮件这种的话，还有是帮助你，帮你去做什么旅行攻略这种日常生活中的一些小问题，你问他的话，他产生的东西还是我的信，我对他的信任度会达到 80% 及其以上。但是一碰到学术的东西，很重要的东西，我就，我对他的信任度就不会那么高了。对，所以我就觉得还是就是真的是不要完全依赖于产GPT，你还是要有自己的一个思辨的能力和做决定的能力的。

Speaker 1 01:03:10 
对对对，我知道你的意思，那其实毕竟深度思考的人其实是没有像你这么多嘛，对不对？那肯定对，大多数人就是你看。

Speaker 2 01:03:20 
但是对一些初级的一些学者的话，就像我弟他在国内，他用那些豆包这种，还有 DeepSeek 的话，他其实他当然他们他问他们问的问题也不那么professional，他问的也是生活中很简单的问题了。那 change PPT 对他们来说的话他们就会，嗯，很非常信任 change PPT 的。像我弟他们就是这样子，对。

Speaker 1 01:03:40 
那他们非常信任的时候，那不就是慢慢地在丧失一些比如说 writing 的技能，或者是。对。

Speaker 2 01:03:45 
呀，是呀。

Speaker 1 01:03:47 
对，所以我才说就是怎样去对于这种，对吧？就是肯定是这种大学生，就刚入学，或者是那种初高中，或者就可能就是这种肯定还不能是硕士、博士，我觉得博士是对肯定具有自己的思辨能力，那对那种大学生的话可能需要一些干预，我觉得可能怎么样的一个干预方式？会，你，你有没有什么建议这种？对于这种干预方式。

Speaker 2 01:04:11 
这个我还真没有想过诶，抱歉，没有想过，因为我自己本身不存在这个问题，我就是我感觉好像可能对于那些初级的，嗯，学那个用使用产这边的这种，他们可能当然不会像这玩意，不会像打游戏那样去上瘾了。

Speaker 1 01:04:30 
真的吗？哈哈哈，我觉得。

Speaker 2 01:04:32 
会啦，这哪有打游戏好玩呀，这些东西真的是只是说那些大学生，他们用到用产GBD，也可能就是说教授布置了一个什么小的 SA 或者什么东西，他们需要去写，他们才会用到这些东西。比如说他们也是会用到一些，就是生活中遇到一些什么问题，甚至有人拿 ChatGPT 去谈恋爱。

Speaker 1 01:04:52 
哦，这个好像我也知道，这我知。对，其实我看就你提到那个点，就是你提到就是说有多个 model 来生成答案，我觉得这其实就可以让他去做一定的判断，因为你不会取决于一个答案的时候。对，是对，所以我觉得还是有用的。点就是因为这是我后续的要研究的东西嘛。对。

Speaker 2 01:05:14 
你可以多去参我，我是忘，因为我卸载了，我现在电脑上看不到那个，它就是类似于一个 APP 一样，然后你进去，它里边嵌入了你所有的基础模型，大语言模型没问题，所以那个很好用了。那别人推荐我的。

Speaker 1 01:05:28 
好的，这就是你又推荐给我了，然后就是互相推荐。

Speaker 2 01:05:32 
但是我是真的忘记他的名字叫什么了。

Speaker 1 01:05:35 
没事没事，问题不大。没问题不大。嗯，我看看啊，其实应该也。 60 分钟了。对，挺长的了。哈哈哈，你能想到我会问这么久吗？

Speaker 2 01:05:47 
嗯，没关系了，就当聊天好了。哈哈哈，是是是，也是帮也是对你们的科研能有一点点自己的贡献了。

Speaker 1 01:05:53 
是，就是因为科研的话，我后续就是去研究怎么去提高他们的 critical thinking。嗯，是我想一下，然后续的话，那对，我后续的时间，那我之后就是把 sign up 邮件就直接发给你，因为我之后肯定还是会贴小广告，因为招的人比较多。

Speaker 2 01:06:12 
那你直接，你最好就是你第一期实验的这些人，你最好都发邮件问一下，就是，对，因为对你这个过程流程会比较熟悉了。

Speaker 1 01:06:22 
最好对我的流程不熟悉。

Speaker 2 01:06:24 
对对，这次会访谈会感觉会更好一些。对对对，没问题，当然是我的建议了，哈哈。

Speaker 1 01:06:31 
没有没有没有。嗯，肯定还是要用钱来吸引大家的，哈哈哈。对对，就就啊，没问没问题，我好像意思好像应该没有什么太，你有什么什么建议什么的吗？因为我现在好像没什么要问的了。

Speaker 2 01:06:50 
我其实对于人工智能这个东西，我自己其实大部分都是用来在回复邮件，处理一些基本的日常的。

Speaker 1 01:07:00 
东的，可能说耗时的事情上，嗯。

Speaker 2 01:07:05 
对，就是对于我的一些专业方面的，我的研究我是真的不太敢依赖他，可能就是最多用他去读个文献了，就刚刚你说那狗拍了，因为他是比较忠实于你去总结你这，你给他发的这个文章的就完全是忠于你这个文章去总结出来的东西。所以他是比较能够信赖的了。然后其他的就是让这也就是说用 ChatGPT 去帮你读文献，这个是没有问题的，但是不是用产品也用一些那个比较专业的。对，哈哈哈，就像比如说可拍了的话，你用它去读，我们现在就很专业了呃。但是其他的事情，就是尤其是在学术上面，我就觉得还是不要过度依赖他了，甚至因为真的会可能会对你造成学术不端等等问题的。

Speaker 1 01:07:55 
是会存在这个问题。嗯嗯嗯，是，OK，好，那我应该就问到这里了，非常感谢你。

Speaker 2 01:08:05 
行行，那。

Speaker 1 01:08:06 
嗯，对，然后那个可能这个费用我其实真的不太确定什么时候能到账，因为我需要经过叫做什么，反正就经过商学院的那个叫企业的 pay now，就我肯定就是会尽快地把这些后续处理清楚。对，好好，对对对对，没事，到时候反正 experiment study 的话还是会再见的。

Speaker 2 01:08:27 
哈哈哈，好的好的。

Speaker 1 01:08:29 
好，谢谢你，谢谢你。

Speaker 2 01:08:31 
好，谢谢。嗯，好。

Speaker 1 01:08:32 
拜拜。拜拜。

Speaker 2 01:08:33 
嗯，好，拜拜。


受访人19:
OK，那你开始的时候你可以先介绍一下吧。就啊，你可以说你名字也可以不说嘛，那你就说这边是一个南阳 business school 的一个研究，嗯哼，对吧？一开始，然后你可以，你首先要跟他确认录音这个情况，可能开始之后就跟他们录音。哼，然后一开始你就说同学你好，我们这边是南阳商学院 NBS 这边的一个项目的，研究的课题是基于交互记忆系统优化人机团队的一个表现。

Speaker 2 38:13 
然后我们这次的访谈目标是理解一下，就是生成式 AI 工具的一些高频使用者在他们的工作或学习流程中如何和 AI 进行协作的。也就是关注一下你的一个跟 AI 的一个交互的方式，还有你，对，还有你的一个思考行为，以及你怎么去在一些不同的维度上怎么跟 AI 交互的？就跟他大致先介绍一下，就这个就是你大致介绍，然后就是你就可以问一下你有没有什么问题？没有问题的话。你正式开始，对吧嗯？对，然后你就可以正式开始的话，因为前面已经没什么，这些都不用讲了，我觉得没什么必要啊。然后你就可以开始直接开始了，你就说请你能简单描述一下你目前的职业或者学习的领域吗？你可以回答一下吗？

Speaker 1 39:04 
这么这么 detail 的问题吗？

Speaker 2 39:07 
这样直接开始访谈，深入访谈了。

Speaker 1 39:14 
他这个在他那个问卷里面都没有体现吗？

Speaker 2 39:17 
不行，你要聊一下，就是因为我不确定他们是哪一个 engineer 里我还有 business school，都是不一同，只有一个大类，所以你看不到他们到底具体在研究什么。你来，但是Bachelor。

Speaker 1 39:28 
我在问 Bachelor degree 他们哪有研究的问题。

Speaker 2 39:31 
所以才说你目前的学习领域，你他可以说他是什么学科好过你要回答吗？还是。

Speaker 1 39:42 
我呀？对啊，你不是想回答我现在职业就是在南阳理工大学，然后做 AI 跟 block chain 相关项目的support。

Speaker 2 39:57 
那你能具体地描述一下你在这个 project 或者说在这个职位的话，你要处理哪些类型的任务？

Speaker 1 40:06 
一个是做相关的企业对接，然后另外需要去做企业的背景调查。背景调查之后会为他们去定制一些问卷，然后去抓住他们的一些亮点，便于跟后续的企业内部人沟通，来去写一些白皮书。然后除此以外也会去做一些偏 block chain 或者 AI 方向的一些研究构思，但是目前没有落地的，所以不要讲了。

Speaker 2 40:43 
OK，那你从什么使用开始使用？你从什么时候开始使用ChatGPT？或者是一些别的 AI 工具呢？

Speaker 1 40:51 
很早他出现我就开始用了。

Speaker 2 40:55 
OK，那你目前跟他的一个使用的一个频率怎么样？

Speaker 1 41:01 
每天都在用，每天但凡工作的话就会用。

Speaker 2 41:06 
OK，那你目前习惯用哪个 AI 的系统，或者是它的模型，你最喜欢用哪一个？

Speaker 1 41:16 
Brock 和GPT。

Speaker 2 41:19 
就是什么？ cloud 和 GPT 是吗？

Speaker 1 41:22 
Brock， Brock 是那个 x 出的那个吗？推特出的那个吗？

Speaker 2 41:27 
o，OK，好，我好，我还没用过呢。哦，那你看哦，你刚才提到没有用会员，对吧？就还没有去使用会员版？

Speaker 1 41:36 
对，都是没有会员的。

Speaker 2 41:38 
那为什么你会选择使用 ChatGPT 而不是一些别的 AI 工具呢？

Speaker 1 41:44 
我觉得 ChatGPT 好像更有人情味一点。

Speaker 2 41:50 
好，那你刚才提到了你的会处理的一些任务，那你这些任务中会使用到 ChatGPT 有哪一些相关的任务或者是工作。

Speaker 1 42:03 
呃？比方说就一开始下达下来一个任务的时候，可能先会去把一些比较宏观的东西丢给他去分析一下，然后告诉我大概工作的重点在哪里，然后会让他给我一个大致的思路，然后我再按照这个思路去深化，去找相关的这个information。那回来之后我可能把我自己写的东西再丢给他，让他再润色一下之类的。

Speaker 2 42:33 
这个是专门指的是你没有思路的时候，对吧？就是可能这个项目你不熟悉，然后你就把整个的任务或者说背景丢给他。

Speaker 1 42:46 
对对对，那目前来说的我的任务都不是熟悉的。

Speaker 2 42:51 
那就是说相当于对于不熟悉任务，你丢给他之后，是就是完全丢给他，还是说你自己会拆解一下？可能给他有些东西你自己还是要自己去分析。

Speaker 1 43:07 
呃。很大程度之上我想要他提取出来做这个工作的重点该放在哪，而不是我。

Speaker 2 43:17 
所以相当于是说你希望这个甚至是 AI 去帮你去，嗯，把目标给定清楚，是吗？

Speaker 1 43:28 
就是比方说，就是比方说现在一个 AI 的企业叫Salesforce，它过来之后，然后老板说你去调查一下这家公司，然后呢？做一下 case study，然后我可能会跟 PI 去聊天的时候，我问他，你这个东。东西是将来最后要生成一个白皮书，这个是我知道的最终目的。那我在了解 Salesforce 它的这个背景信息的过程当中，它很零散嘛。然后再加上我知道他的最终目的之后，我就告诉 GPT 我在这个阶段的 case study 我主要输出一个什么东西，就可以比方说 before the interview，在 interview 之前我可能主要输出一个什么样的东西就行，然后可能在 interview 之后我们可能进阶了，就是跟人家企业都聊完了之后，那之后我们再按照这个已经输出的内容，看看怎么去进阶地优化，这样我是这样子使用的。

Speaker 2 44:27 
我可以理解为是说你其实已经先划分了阶段，而不是让他来给你输出每个阶段要提交什么。对对对对对，那意思说这个任务你拆解，比如说我在中期我需要什么样的东西，你要告诉他，对吧？你就告诉 check BT 我在反弹前我需要完成到什么程度，对吧？就是让 ChatGPT 给你一个大概的方向或者是结果。

Speaker 1 44:55 
呃。更大程度上，比方是我告诉 GPT 我要在这个阶段要一个什么样的结果，他告诉我这个结果大概做的程度。

Speaker 2 45:06 
就是说你先跟他讲，就是说我现在要在反弹前我需要完成什么什么，对吧？对，然后你来帮我看一下我应该要做到什么样的一个程度。

Speaker 1 45:19 
对对对，然后可能涉及到哪些维度这样子的？

Speaker 2 45:24 
那其实它有点像在帮你发散，对吧？就相当于帮你发散一下你的思维去从哪些维度来考虑，有点像给你的一个框架。

Speaker 1 45:33 
对，我觉得也是让这个变得更逻辑性一点，然后对，更减少一些时间的冗余。

Speaker 2 45:42 
对，那比如说给你框架之后，你是说会修改它的框架，还是说完全采纳。

Speaker 1 45:52 
呃？现在其实会修改了，之前是采纳的。

Speaker 2 45:56 
哈哈哈，那其实它是随着你这个 background 的增强，或者说你对这个领域的了解，你可以对它进行一定的探索或修改。对对对，那你完全采纳的时候会出现什么问题吗？你之前有遇到过，你觉得有什么问题？毕竟你有两种问，对。

Speaker 1 46:17 
完全采纳的话就是它 to description，它就是一直在停留在一个信息流的描述。他自己其实具备逻辑性，但是他的骨头很好，但他肉一般就是这样。

Speaker 2 46:34 
哦哦哦，嗯，那这个过程的话，你怎么去处理解决这个问题呢？因为你也发现问题了。

Speaker 1 46:41 
我一般的话就是把我自己把他的那个骨头拎出来，然后可能每一块我自己再去优化，然后我再去让他去帮我审核，我结合他的那个东西讲我自己做的那个东西，然后是不是一个正确的？

Speaker 2 46:58 
那你怎么去优化的？是，比如说是百度、谷歌，还是说自己头脑风暴还是什么？

Speaker 1 47:08 
更大程度上是自己把这个东西给它串联起来的，自己头脑。

Speaker 2 47:17 
所以说相当于说你是靠自己，就是也不依赖任何的其他的东西了，就是在 ChatGPT 给你框架大纲之后，你就自己来完善它。

Speaker 1 47:30 
对，因为我觉得它已经很全面，它已经就是在 search 的，这个肯定要比我用任何的这个有嗯。嗯，这个引擎去搜索的要全面了，我只不过把它的这个逻辑，把它这个框架拿过来之后，我看看怎么能让它变得更精简，不那么冗余，然后不那么赘述。然后哪些是就是更具备核心性，然后把它拿出来看，怎么能有一个叙事感？把这个东西拿出来有个叙事感，然后那叙事感我就把要把东西添进去。

Speaker 1 48:06 
嗯，能添进去的过程当中肯定还会涉及到一些，就是去使用某些方法，或者说是借鉴某些二手的信息，那二手信息肯定还是会去查，但是方法的使用什么也还是会借鉴 GPT 它的意见，或者说有的时候他输出来的这个东西，我会比方说我现在拿出来了一个一个一个一个想法，然后他给了我一个公式出来，我会问他一下这个东西为什么是这样？就有的时候因为我也会不太懂他在告诉我什么，所以就是问他一下，然后再去重新思考一下这。

Speaker 2 48:48 
所以更多的是他先帮你提供框架，然后你加入你自己的思考，然后再让他帮你稍微完善解答你的疑惑，让你这个的任务其实就能推进下去，对吧？对，所以说 ChatGPT 是有多轮迭代的过程的。

Speaker 1 49:06 
对，我觉得更大程度上是我能够我理解他到底在讲什么吧？然后以及他讲的这个东西到底是有没有用呢？这个是一个很重要的事情。

Speaker 2 49:19 
嗯，明白，那这个是你一开始是这么用，它后面有，后面就是会更改它的框架，是吗？就觉得这些点可能不符合要求，你就让他修改，还是说你改完不是你改把这些点自己修改，还是说让他去修改这些点。

Speaker 1 49:40 
呃？我自己如果修改完的这个逻辑之后，我可能就让他按步骤输出了，他可能就不会自己那么明确我的这个逻辑了，但是我会按照步骤让他输出。12345，第一步你先帮我输出一个什么东西，然后就着第一步，然后再第二步再输出一个什么样的。对，他可能也会清楚逻辑。

Speaker 2 50:02 
呃。这个的意思是说你这个工作你已经清楚了，然后你是让他按步骤来给你。

Speaker 1 50:10 
对解决这个问题，对，而不是一下子再出来一个什么了。

Speaker 2 50:14 
那一下出来这个是你不了解这个任务，就因为你没有思路。

Speaker 1 50:18 
一下子出来，我觉得他可能每一个 part 他都不会做的，那么，那么那么的就是符合要求，然后你还要按照每一块可能还要给他修改意见，还不如就一一一个一个部分一个部分地来。

Speaker 2 50:36 
但你刚才提到的是说让他输出了整个框架，然后现在是在框架的每个点上面去对对动，对对，那对于这种每个点的话，你一步一步让他输出，他怎么能记得住你前面输出了什么？因为他其实我觉得 ChatGPT 是出现会出现遗忘性的，遗忘性他之前的工作。

Speaker 1 51:00 
嗯，这确实是一个问题，就是你在输出结果之后还是要有自己的判断，看他输出的东西是不是他就是正确的记忆，哈哈哈。

Speaker 2 51:16 
OK，那其实相当于就是说就是有点像发散完你收敛，收敛之后你再一个一步一步地丢给他，他可能这时候只是帮你去填充你这些的点，你觉得不合适，你会让他重新生成。对，是你自己修改完，对，那也更多的是你在修改，还是更多都是让他去帮你修改呢。就这个的分工中。

Speaker 1 51:46 
我觉得真正落到案头上最终形成的这一个东西可能更大程度上还是他来做，因为从头到尾都没有离开他，对吧。

Speaker 2 52:01 
呃？那你觉得他表现怎么样呢？就对于这样的一个writing，对。

Speaker 2 52:06 
Eh, writing was brainstorming.

Speaker 1 52:12 
认为还是就是如果说完全依赖他的话，或者说是不给他下达任何指令输出的话，嗯，他的东西其实比较平，然后但是你告诉他一些结构跟框架，然后或者说是给了修改意见之后，他最终优化出来东西还是 OK 的。我认为，而且我很大程度之上我是靠他去串联我的这个思路，就比方说我跟人家这个企业也好，去跟人家这个相关的负责人去沟通的时候，我可能更大程度上我的内容是在另外的一个地方，然后他们可能看的是 presentation 的那个slice，那个PPT，所以说他们看的时候就是一个骨架的一个东西，然后只不过其他的一个东西是在外面的，所以说至于他最终输出来的这个内容的这个好朋友，我觉得是有辩证性的。但是总体来说他对于这个捋清思路，然后或者说是把你整个的这个各个脉络上能够做到75%，我觉得。

Speaker 2 53:36 
能明白。那我其实有个问题是，那你刚才提到，你说你给他的提示中会写得很详细，那指的是说是有一些比较好的提示词吗？还是说有自己的一些提示库什么的。

Speaker 1 53:55 
这个其实看输出东西的这个物料它要是什么，就比方说针对于这个像 report 这一类的东西，然后可能告诉他一些就是我认为可以借鉴的方法，一些methodology，然后或者说是一些或者丢，就是丢给他一些之前的一些 case study，就给他扔进去，让他学习一下。先就比方说这样的对，然后按照这种思路，什么对？

Speaker 2 54:30 
所以就是说不会让他去海量的数据库中或者说资料中去生成，先让他学习。嗯，样式样本。

Speaker 1 54:40 
对，对，给它先框一下，对。

Speaker 2 54:45 
OK，那你会，比如说你使用它的时候，你会让它，就，你可能说你现在是一个什么项目经理，或者说你现在是一个上是什么？一个什么什么别的一个角色你会这么去定义它吗。

Speaker 1 55:05 
呃？我会告诉他我这个 role 它本身的这个利益相关者就是我的直接领导是干什么的？他想要什么？然后我是我的对方的人，我是做什么的？然后他们的这个业务是什么？然后我在这个过程当中他可能就会更好地帮我判断我需要输出什么，有的时候其实我对于我的工作也是比较模不对。

Speaker 2 55:35 
所以你是去定义你的相关利益者，对吧？就是你的相关利益者之间，他们是什么角色？你所处于什么位置？对，这样的话就是他能理解你的一个处境。对，而不是你去让他来，就是你也没必要去定义说什么你现在是什么角色，你现在是什么样的，因为没什么必要，对。

Speaker 1 55:56 
吧？对，因为在每一个项目里面可能语境还不太一样。对，可能跟这个，这这个项目里面你是跟人家 CEO 聊天，现在可能，对，可能下一步你可能就跟一个 engineer 去聊天，就是可能你的语境都是不同的，所以他可能更好地能判断一下。

Speaker 2 56:18 
对，真是对，这个确实是没有考虑到的一个问题，这个就是相当于相关利益者之间的一个关系吧。

Speaker 1 56:27 
对。

Speaker 2 56:28 
OK，那对于 writing 的话，你怎么去判断它给你的信息准确性呢。

Speaker 1 56:38 
呃？其实很大程度之上我是 AI 之间互相的验证。

Speaker 2 56:44 
我可以理解为比如说你把 ChatGPT 的答案输出给另一个AI，对，那你怎么去验证？是说你帮我去分析一下这个答案的准确性还是资料的来源准确性？

Speaker 1 57:02 
一部分是这样的，另一部分可能就是给他们相同的指令，然后输出，然后比方说他们有相左的地方，我就问他为什么这一个部分？你没有提到或者说是为什么？这一部分可能我发现有出入的，我去问另外一个AI，然后另外一个 AI 可能就说对不起，我没有发现另外一个，或者就说你，你是，你那这个信息我真的没有查到之类的，我就知道这个是有出入的信息了。

Speaker 2 57:29 
所以相当于是说 AI 之间的互相比较，能让你就是能让你进一步地判断信息的有效性嘛。嗯，对。那为什么是两个AI？你没考虑过四五个 AI 吗？

Speaker 1 57:43 
你也其实也用 3 个AI， 4 个 AI DeepSeek，但是不是很用，然后包 cloud 都有在用。但是只不过可能就是比较我觉得相对来说轻工作没有那么那么就是有重量性，然后可能严谨度相对来说也是。

Speaker 2 58:06 
OK。

Speaker 1 58:06 
有待商榷的事情。

Speaker 2 58:08 
对，所以取决于这个任务本身的重要性以及它的对，那能明白，OK？嗯，那你除了这种 writing 的任务，你还有什么别的一些用到 ChatGPT 的场景吗？你觉得你常用的一些。

Speaker 1 58:26 
我常用的一些就是处理一些生活上的事情啊。我现在打开我的GPT。

Speaker 2 58:33 
你现在什么？我先。

Speaker 1 58:35 
打开一下我的GPT。

Speaker 2 58:38 
Oh, maybe Nikki. So I need dating app, Chat, GBT.

Speaker 1 58:46 
dating APP。

Speaker 2 58:48 
对你可以聊一下你觉得有趣的点，你用 ChatGPT 肯定有自己独特的见解。

Speaker 1 58:58 
我是觉得是这样的，因为我觉得每一个聊天对象他不太一样，我觉得聊天这个东西是需要策略的，哈哈哈，所以说有的时候会借由这个 AI 去分析一下，一个是这个人的状态，就是他的这个状态是认真的一个状态，还是说他是一个就是应付的一个状态？他可能比较宏观，他也比较主观，他不是那么他匹配比较客观，他不是那么主观，所以说他就是能站在一个上帝视角，然后判断一下你们两个聊天的这个人，这个对方他是一个什么样的一个调性？是一个诶？就是一个一个一个一个一个玩的短期的，还是说他也是一个很认真的人，很坦诚的人。嗯，另外一个就是会在很大程度上看这个人，他的一些persona，你知道 persona 吗？

Speaker 2 01:00:07 
福桑娜是。

Speaker 1 01:00:07 
什么？福桑娜就是她的。嗯，就是就是。怎么说？用户画像。

Speaker 2 01:00:15 
哦，嗯，那我有个问题，你是把什么东西输入给他？

Speaker 1 01:00:21 
我大概对于这个人的就是一个描述。

Speaker 2 01:00:26 
我有个问题，你的描述代表带的带有客主观性吗？还是客观性？

Speaker 1 01:00:31 
尽量的客，尽量的不主观吧。我只能说尽量的不主观。

Speaker 2 01:00:35 
但你刚才提到第一个任务，说因为用户画像，我能理解，那第前面刚才提到的说你说去判断这个人他的聊天的一个调性，那嗯，你是输入聊天记录吗？完整的聊天记录吗？还是说。

Speaker 1 01:00:50 
可能部分的比较有这个重要信息的聊天记录？

Speaker 2 01:00:56 
对，那你输入聊天记录的同时，需要把你的个人资料还有他的个人资料都提供给他。

Speaker 1 01:01:05 
呃。最先前的时候，比方说一个一个对象过来之后，我会先跟 GPT 交代一下我大概已经了解到的信息，然后再去进阶的这样子，不论是分析它的这个语境，还是说去描绘他的这个 persona 这些的。

Speaker 2 01:01:25 
嗯，那你觉得他帮你分析完他的调性之后，下一步，下一步你是让他给你一些回复，还是说你再去考虑你怎么回复？

Speaker 1 01:01:36 
这跟回复没有太大关系，更大程度上是帮我判断这个人，然后同时就是可以让我更加的就是理性一点对待这个关系，就是这个人到底是一个什么样的角色，在我的对面。

Speaker 2 01:01:53 
其实相当于就是说他相当于站在了对不客观的一个地方，就是比如说可能像你的朋友来对客观地看待一个对感情问题。对，但是就是说你相当于知道他是什么样的人，或者说给你一些建议之后会影响你的一些改变策略吗？还是怎么说？

Speaker 1 01:02:15 
我觉得，嗯，怎么说他跟人最大的不同就是他不会给你直接的意见。他是告诉你他的一些观察最后的意见还是你来拿，然后而且他跟人不同的在于他是完全不带主观意识的，他是很客观的，你如果跟一个朋友去说，朋友会按照他的理解去跟你说这个人是怎么样的，但是 AI 不会AI，他就是按照他对于这个人他所在的行业，他所做的工作，他大概的一个一个性格调性，他的MBTI，他的星座等等给他们描绘出来之后，他去进行这样一个很客观的一个判断。然后你在这个过程当中，我觉得影确实会影响到我的很多的这个步骤，不论是我感觉到这个人他其实并不是一个认真的人，我可能就是相对来说就是开始退后之类的。对。

Speaker 2 01:03:19 
所以他其实是帮你识人，看清楚这个人的目的。

Speaker 1 01:03:24 
我觉得帮我判断局势，哈哈哈。

Speaker 2 01:03:29 
OK，那你觉得在这个过程中也帮到你了？然后就是说其实你是不会去让它产生一些回复性的内容，就是怎么去跟。

Speaker 1 01:03:47 
你是回复性的内容是指什么？

Speaker 2 01:03:50 
指的是比如说这句话我不懂怎么回来切换BT，你帮我回一下。

Speaker 1 01:03:56 
这种的话会比较少，反而我会问他我这样回好不好。

Speaker 2 01:04:04 
就是说你其实是让你让他判断你这样的回复他，嗯，能不能。

Speaker 1 01:04:09 
对方的那个调性他已经了解了，对吧？

Speaker 2 01:04:14 
哦，嗯，那现在也就是说他就相当于 check PPT，在这里扮演了一个没有情感客观的一个角色，同时你也可以就是也比较信任他，对吧？应该说是比较信任。

Speaker 1 01:04:28 
我觉得我是绝对信任AI，但是我不信任，因为现在什么网上很多，什么感情军师你知道吗？什么各种的，我是不信任任何个人个体的，但是我信任这种。

Speaker 2 01:04:41 
意思就是说其实有点像，他可以扮演一个心理咨询师，反而你不信任线下的心理咨询师，对吧？就相当于情感专家所谓的。

Speaker 1 01:04:54 
对，可以这样讲。

Speaker 2 01:04:57 
OK，那其实他有点像情感提供者，或者说情感客观评价者，我觉得因为有点像我之前访谈聊到的那种，像把他当心理咨询师或者是情感的一些依赖之类的。

Speaker 1 01:05:11 
嗯，会。

Speaker 2 01:05:13 
对，有有这种，对对，有这种感觉。那你比如说你刚才提到的是聊天的调性，那用户画像指的是什么呀？是这个人的什么什么的风险？

Speaker 1 01:05:25 
就是用户画像其实是它是一个 marketing 里面的词，就是你对应的 target audience，你对应的这个用户他是做什么职业的呀？然后多大年纪，生活在哪里啊？他的思考轨迹是怎么样的呃？其实我就是把这些零散的信息给到 GPT 之后，他就会比较能够带入进去一个比较鲜活的人，他本身的 personality 大概是一个什么样子的？你可以懂我的意思。

Speaker 2 01:05:57 
吗？对，就是他的性格特征会是什么样？

Speaker 1 01:06:01 
对，性格特征处事的方式包括他的一些节奏啊。比方说某一个这个做 financial 相关的，然后可能做到比较高岗位的一些什么IB、 P1 这一类行业的，他们他就会大概判断出来这个人聊天的调性，以及他，喂聊。听不见吗？

Speaker 2 01:06:29 
刚才断了一下，你没发现断了一下吗？

Speaker 1 01:06:33 
应该是时长的问题，现在应该是。好。

Speaker 2 01:06:37 
那你刚才讲到finance，讲到金融，好像是。

Speaker 1 01:06:41 
对，然后他就会，就是大概地告诉你这个人聊天的调性，然后包括他回复的一些频率什么的，因为每个人的工作频率不太一样，对吧？然后我再结合他的一些这个星，什么什么MBTI，或者说是星座之类的。

Speaker 2 01:07:04 
我有个问题，这个人物是，就是你聊天这个对象是虚拟的还是现实的呀？就是见过面的，还是说你的意思是不是对我？因为我的意思是。

Speaker 1 01:07:17 
现实的人，然后但是没见过面。

Speaker 2 01:07:21 
是这个，对，因为你对你说的是 dating APP， dating APP 那肯定不是所有人都能见面见过，或者说，对吧？就所有人，可能有些人就还在线上的阶段，有些人可能是见过面的阶段。

Speaker 1 01:07:36 
呃。频繁使用的对象大部分都是没有办法长期见面的对象。

Speaker 2 01:07:45 
就说你其实已经其就是用 dating APP，其实已经见过面的，对吧？已经是见过了。

Speaker 1 01:07:52 
他更大程度上比方说处理一些异地关系。

Speaker 2 01:07:56 
什么关系？

Speaker 1 01:07:58 
异地的？比方说这个人没有办法，你们两个经常见到，然而你还要判断他的状态。

Speaker 2 01:08:07 
我可以理解为是你们已经在一起了，还是说是哪种状态啊？就是说你跟他目前处于什么状态？你用到这个软件。

Speaker 1 01:08:16 
就可能是一开始 get connection，一开始接触，然后来暧昧，然后到底能不能去确认关系，那个要看进程了，不一定的。

Speaker 2 01:08:28 
对我我就是好奇在 ChatGPT 就是你跟他是见过面的，对吗？然后你再用ChatGPT，而不是说前期哪就属于哪个阶段用到。

Speaker 1 01:08:39 
这个不限，即使是没见过面没确认关系也可以也会用。

Speaker 2 01:08:45 
但是没见过面的话不会存在，比如说什么照片什么都是假的，这种会不会出现这种问题？因为对吧？可能出来 GPT 就会判断不准，有些信息可能是假的。

Speaker 1 01:08:56 
呃。我一般因为我是一个相对比较严谨的人，就是这个人我还是会做一些背景调查，是 LinkedIn 这上面或者怎么样的，就看一下他大概的工作，然后之类的能不能 match 得上。对，基本上这个。

Speaker 2 01:09:16 
那他能就是确定能帮你推进关系吗？就是你觉得在使用 chat g ChatGPT 之后。

Speaker 1 01:09:25 
嗯，我觉得他能帮助我不那么感性，这个是真的，能不能帮助确定关系？这个不一定，这个真的不一定。

Speaker 2 01:09:35 
所以这件就是说这个使用的目标是让你去更准确地判断，而不是为了去维持或者说改变这段关系。

Speaker 1 01:09:46 
对，他就是能让我对待每关系的每一个阶段能够看得更清晰一点，然后不那么就是情感化地去 involve in，而是说带着理性去。我觉得这个是一个很重要事，因为有时候你可能就说实话，你就上头了，然后你就是看很多事情，你就是不，你就是带着一个滤镜在看，对，它就是能帮你去站在一个很客观的角度告诉你这个到底是一个什么情况。对。

Speaker 2 01:10:20 
OK，那其实大概了解了，就相当于，哦，他就是帮你客观地看待一个事情嘛。对，那你觉得你还有什么比较 interesting 的任务中，或者说你觉得还有什么场景中你用到了ChatGPT？

Speaker 1 01:10:39 
我其实大部分来讲的话，一个是当这个工具使用，很多情况下查一些信息，然后再就是我会跟他去 battle 一些言论，这个是真的。

Speaker 2 01:10:57 
battle 言论指的是什么呀？是什么场景下你要跟他battle？

Speaker 1 01:11:02 
就比方说我之前有一天我在外面吃饭的时候，我就是看到我旁边桌有一桌男生，一桌男性就是看起来有点土豪的样子，然后他们在 share 这个自己什么打球，什么什么钓鱼，然后也说到自己最近遇到的一些姑娘之类的事情，然后他们在讲这些事情的时候，我就感觉到他们，我不知道他们对待那个对象到底是喜欢还是不喜欢，但我起码是感受到不是尊重的，所以我就对于这个问题我就会问 g GPT，我就说就是在就是男性的心理底层。他们到底是不是尊重女性的？比方说问他这种问题。对。

Speaker 2 01:11:50 
但是这个的目的是为了什么呢？就是你希你是希望去了解这个男性，还是说。

Speaker 1 01:11:58 
我想要了解就是女权在这个社会当中到底进化到什么程度了。

Speaker 2 01:12:07 
所以就说现在你只是想觉得这个事情好玩、好奇，然后让 ChatGPT 帮你判断，可因为可能你判断不出来，也。

Speaker 1 01:12:16 
不是说好玩、好奇，而是说我认为是遇到了一些我认为我觉得挺挺。嗯，怎么说呢？挺不公的一些事情，比方说就这个事情，比方说这个这样的一个事件，我可能还会问几个直男的朋友。嗯，然后问他们说，诶，你，我就是遇到了这样的事，我在想你们到底是内心当中尊不尊重女性？有一些可能就是会很直接地告诉你，他说男生跟男生在一起就不存在完全尊重女性，或者说他们就会告诉你说，嗯，男人他可能会只尊重部分女性，不会尊重所有女性。就每个人的说法可能都不太一样，然后有一些可能就是说你不会存在这个问题，我都是很尊重女性的这一种，但是我就想看 GPT 它站在一个比较大的一个数据量上，它可能怎么回复这个问题？

Speaker 2 01:13:14 
对，那他给你的结果你觉得满意吗？还是怎么说？

Speaker 1 01:13:19 
我觉得光说满不满意，我只能说是了解了一某种现象。

Speaker 2 01:13:27 
就是说他回复之后，你觉得他的描述就是能代表一类的群体吗？还是说普遍的一个现象。

Speaker 1 01:13:38 
呃？他的描述基本上会涵盖我去问那些单样本的那些结果。他的也，他基本上都会涵盖，然后告诉我大概是比方说有存在几种心理背景这样子的。

Speaker 2 01:13:53 
所以你不会有下一步的行为，就大概了解一下这个现象而已。

Speaker 1 01:13:58 
我会就比方说就是从这个，我比方说就这个问题我会让他从心理层面来拆开看，就是比方说在生活当中这些男性的行为跟他的态度对应到他本身对于女性的尊重，这个心理怎么去表述出来？这样子我可能会问得比较细一点，或者说是会问他一些这个某种影响的可能性。比方说这个男性家里面有兄姐妹之类的，我在想问他这样子会不会去帮助他们去建立女性尊重这一种的哦？就会问他这一种问题。对。

Speaker 2 01:14:43 
但是你了解之后，后续就是这个事情你已经知道了有什么东西可以，比如说能提高女权，或者说能缓解这种现象。那你下一步会去做什么？就是已经知道这个事情。

Speaker 1 01:14:58 
我认为这个东西它完完全全他没有办法改变，我只是知道了这样一个现象，我只是自己心里知道了，OK，大概这样我明白了，没有任何。

Speaker 2 01:15:10 
是，我以为你说可能会有一些什么啊？把这个言论可能会发布，或者说会增值什么，就是说其实不会有后续的行为的。

Speaker 1 01:15:20 
不会就是更大程度上帮我了解。那。

Speaker 2 01:15:24 
对，那可能就相当于他是处在了一个信息检索以及概括的一个工具，可以这么理解，信息检索加概括这个设备可以对一个现象的一个分析。OK，我问了三个的任务，确实跟整个题，那我还有一些就是带你整个过完，然后后面，对，就是如果说你觉得就是你从跟 AI 的使用过程中对你目前的一个处理生处理工作或者生活方式、学习方式等，你觉得有什么一些显著的变化，肯定前后的一个变化有。

Speaker 1 01:16:13 
我觉得肯定是更高效了吧。然后再就是捋清思路，我觉得有的时候你的思路不清晰，就是你做什么事情之前你要先想明白再去做，我觉得这是一个很重要的一个事情，就不论你是做工作，还是说你就是做别的，我是觉得他可以帮助你先把思路理清，这个是一个很重要的事，一个事。然后这个是我，我是那种一旦思路比较清晰的话，我就会比较好执行的人，所以我的效率提升针对于这个 AI 来讲的话，它主要是帮助我去做这个。

Speaker 2 01:16:51 
明白了，所以说其实相当于它有一种像可能叫做防止你犯错，也不能说犯错就减少你的一个损失，对吧？可以减少你一些后续可能会要承担的后果。

Speaker 1 01:17:06 
呃。倒也不能这么说，我觉得他更大程度上像一个tutor，像一个带教的人，就是有的时候我们可能在一个新的一个一个学科里面，我们像变成了一个学徒，然后有一个老师告诉你，但是那个老师他也不一定完全是对的。

Speaker 2 01:17:25 
对对对，对吧？所以。

Speaker 1 01:17:27 
说，但是只不过你会形成一种怎么说呢？就是不是那么孤立的感觉，就是你现在虽然每个人都是一个individual，是一个个体，然后你去面对不一样发散的事情，但是因为 AI 它的存在，然后你会追这个事情，它是有经验的，它可以告诉你大概的思路。我觉得这样是这个很大的帮助。

Speaker 2 01:17:52 
那有点像就是提供一些别人的经验嘛？看一看。对，然后让自己有一定的思考，我不会一股脑地往前冲。对，OK，OK，OK。你会存在那种过度依赖 AI 的情况吗。

Speaker 1 01:18:11 
呃？会，哈哈哈。

Speaker 2 01:18:14 
这一般是什么时候你会过呃？叫什么叫啊？就是在什么情况下会过度地依赖它？

Speaker 1 01:18:22 
我不太好确定这个度到底在哪，怎么叫做过渡，但是我觉得现在的基本上所有的场景好像都在用AI，我觉得这可能就是过渡了吧。

Speaker 2 01:18:35 
呃。没有，我觉得过度的情况应该是你没有思自己的思考了，就是完全地去使用它，帮你处理一些事情。我觉得这可能会更加像过度依赖吧。

Speaker 1 01:18:49 
嗯，我更大程度上是让他帮我判断，然后帮我觉得可那可能是没到过渡的这个程度。

Speaker 2 01:18:57 
对，可能只是说我觉得应该，嗯，可能就是让他帮你思考，我觉得应该。对，我。

Speaker 1 01:19:03 
觉得他 like assistant，像一个助理之类的那个。

Speaker 2 01:19:08 
那你觉得在就是在 AI 的这种一个发展过程中会，以后会改变你的一个合作方式吗？或者说你的使用方式会再进一步的变化吗？毕竟 a i 一直在发展嘛。

Speaker 1 01:19:21 
你是指跟 AI 的协作方式还是说还是？

Speaker 2 01:19:26 
对对对，跟 AI 的协作方式？

Speaker 1 01:19:32 
我觉得我不知道诶。

Speaker 2 01:19:38 
OK，好吧。

Speaker 1 01:19:42 
我觉得可能它的功能迭代的程度会影响我跟它的协作的这个形式，但是它如果一直以来是就是比较平稳地停留在这个状态，因为很多限制 AI 发展的可能很多法律法规要是存在的话，它可能就不会那么快迭代的话，那就是可能维持目前的一种写作模式，我认为。

Speaker 2 01:20:09 
诶，我突然想到一个问题，你有没有存在过 AI 的？就是它那些回答中存在一个自相矛盾的问题会存在，那你怎么去解决掉？就是说你只能自己来改，还是说我让另一个 AI 来解决？就是你会怎么去处理这种问题？

Speaker 1 01:20:31 
嗯，我可能会纠错，他。

Speaker 2 01:20:36 
就说你跟他讲你这里有点问题。对，再重新核对。

Speaker 1 01:20:40 
一下，可能会，或者说是我直接就是question，他就是跟他评审，对，不是你这一块为什么？怎么样的？对。

Speaker 2 01:20:50 
那有没有可能，比如说有没有出现过一个情况？就是 AI 来询问你，他觉得你提供的信息不够多，或者说就是可能希望你能提供更多的描述，有没有遇到这种情况？

Speaker 1 01:21:04 
有，这个要看模型，如果说用一些比较思考比较长的模型，他就会提出问题。

Speaker 2 01:21:14 
就是可能会说你这个是不是这样的？然后让你回答一下，对吧？

Speaker 1 01:21:19 
对，大概提出个 3 ~ 4 个比较框架型的问题，然后我去。

Speaker 2 01:21:25 
这深度思考型的模型，那就是说你如果遇到一些普通模型可能就不会，嗯，我认为。

Speaker 1 01:21:31 
复杂，对，我认为不会。

Speaker 2 01:21:33 
明白。那好像我是这样，目前应该好像是这样的。那你觉得比如说，对于，嗯，可能，比如说 critical thinking 比较一般的人，那你会提供一些什么样的建议来让他们更好地协作呢？

Speaker 1 01:21:52 
我是，我讲实话，我认为 critical thinking 一般的人其实也不会依赖AI。

Speaker 2 01:21:58 
为什么 critical thinking 一般的人反而不会依赖AI？有可能比如说我在写一个什么东西的时候，我直接让它完全生成，我也不改了，我就直接交了。

Speaker 1 01:22:09 
但是他的这个输出东西的可用程度到底有多大程度上可用的其实并没有很大程度上可用，我认为如果让他直接输出的话。

Speaker 2 01:22:23 
但你不是也干过把输出的答案直接给老板，不是被他骂了。

Speaker 1 01:22:29 
但我那个也是调教了很多次了，我告诉他怎么这那的那只不过 AI 很进人很明显而已。

Speaker 2 01:22:37 
那意思就是说，嗯，你那难道没有什么一些建议吗？比如说你可能觉得有些事情，比如说不是不应该，不能说，应该说在合作协作的方式中，你觉得有什么建议给到这种实验对象什么的？或者说一些用户。

Speaker 1 01:23:01 
我感觉可能就是告诉他为什么吧？就是 AI 输出的时候要告诉用户他为什么这样输出。

Speaker 2 01:23:08 
你的意思说是把他的思考过程给出也一起输出来，是吗。

Speaker 1 01:23:14 
一个是思考过程，另外一个就是他是如何这样思考？他为什么要这样思考？

Speaker 2 01:23:21 
他为什么要这样思考？难道不是你给他的指示吗？

Speaker 1 01:23:24 
那你很，你现在说的问题就是那些人不会 critical thinking，他就是只是下达一个指令，他没有那个 thinking 的那个method，所以就告诉他怎么思考的吧。

Speaker 2 01:23:36 
你的意思是说我这里有点没有 get 到，就是你希望他去给出他的思考，但他的。思考不就是思考流程吗？还是你的你，你指的这个输出指。

Speaker 1 01:23:50 
的是你，你想啊？你比方说你现在就是很简单的一个指令，嗯，给 NTU 写一个描述型的报告，很简单的一个指令，嗯，你带有思考吗？你没有带有思考的他，但是他会给你输出一个完整的一个report，不论是这个成果怎么样，你为什么没有办法纠他的错？因为你没有的思路，对吧？然后你就着他的这个结果就直接应用了，但是如果你可以看到他的思路，你或许就可以知道他思路里面的bug。我是这样想。

Speaker 2 01:24:24 
哦，你的意思说相当于是希望他把他自己的思考流程或逻辑也一起输出给你，这样的话就能帮你进一步判断。对，或者提高你的 critical thinking。

Speaker 1 01:24:37 
对，一个是思考的流程，另外一个它引用的数据的确切来源，这样。

Speaker 2 01:24:46 
没去来源它也会去造假，就是也不一定是真实的，就目前还是会出现这个问题吧。

Speaker 1 01:24:53 
那你看它跳转的话，你比方说你 click 它跳转的话，你就可以发现是假的。

Speaker 2 01:25:00 
我懂你意思就是说多一个链接的话，反而就是虽然说是假的，但是我也能判断这个信息也是假的。

Speaker 1 01:25:06 
对，你就可以看出它，比方说就刚刚那个输出那个report，你就知道它大概可能只有 40% 可用或者 60% 可用。嗯，它是个及格分数的一个一个report，然后我再经过40%，我就可以 creative thinking 一下我给他的意见了，对吧？

Speaker 2 01:25:28 
OK。那我们的访谈也差不多了，你看一个小时了。

Speaker 1 01:25:37 
没有？应该五十几分钟，因为我在这边看着时间。

Speaker 2 01:25:41 
你没发现，就是其，因为我现在还可以继续问，比如说我下一就是你肯定要问，就是对于那个 experiment study 我后续会有相关研究，你还会对，你愿意参加吗？如果愿意参加，到时候我会把 sign up link 发给你，你可以问这么一句。

Speaker 1 01:25:58 
那还会有 50 新币吗？

Speaker 2 01:26:00 
哈哈哈，这个价格我目前定的是一小时 30 新币。然后如果你的 performance 因为访谈是没有效果评价，但是我的任务是需有是会有效果评价，如果你的效果，比如说你这一次完成任务的叫什么呃？表现比较好的话，如果是在前 5% 奖励 20 新币，如果在 6% 到 15% 奖励 10 新币，就是我会有个奖励机制。

Speaker 1 01:26:32 
这样，但你又怎么有这个评判标准呢？因为是这个东西你输出的可用程度是吗？不是。

Speaker 2 01:26:40 
我这个任务是 product design，就是产品设计。那你产品设计肯定会有你自己的一个判断优劣好坏，然后对吧？这里的评分标准我也放在了那个任务书上，那你根据任务书的评分标准，那我们也会根据评分标准跟然后找几个专业的人士来评判，那好不好？大家心知肚明。

Speaker 1 01:27:02 
比方说像我这种算是好还是不好？

Speaker 2 01:27:04 
你现在只是访谈大哥。

Speaker 1 01:27:06 
对，就访谈，访谈。

Speaker 2 01:27:08 
没有效果，没有这种。

Speaker 1 01:27:11 
就你得输出来这个 coding 之后，对吗？对。

Speaker 2 01:27:15 
对对，也不是访谈，我没有奖励机制，我只有在后续的任务中设计了奖，因为你知道为什么吗？因为那个人很多， 150 ~ 200 人，那个必须设置奖励机制，我怕摸鱼啊。嗯，因为 35 个人的访谈，我一直在问你不可能摸鱼，对不对？你肯定要回答我呀。

Speaker 1 01:27:35 
好，就后面还有一个大样本量的访谈，是吗？

Speaker 2 01:27:39 
不是 in experiment，是实验研究，就比如说我可能会让你们三个、四个人来到这间房间，然后大家一起使用一个 ChatGPT 或者是一个 platform 来完成我这一次的任务。诶，不对对对，这个我还没全部写出来，流程还没全部写完，反正就是跟他们讲会有一个 experiment study，他们感不感兴趣就好了，感兴趣到时候会给他们发 sign up 链接。

Speaker 1 01:28:10 
可以，OK。

Speaker 2 01:28:12 
你直接确认，因为其实在问卷里面也有这么个问题，其实相当于你就做进一步确认。好的，然后你其实如果你觉得他们的问卷中你觉得有一些比较有趣的，比如说我就是很不信任AI，我很信任AI，你觉得有意思的，你也可以深度地问一问，对吧？就是利用问卷，是。

Speaker 1 01:28:33 
不是一般像我这样对 AI 的信任程度到这样的还是比较少的。

Speaker 2 01:28:40 
其实大家都有自己的性能程度，我觉得看情况，比如说这些。这些博士 research fellow 的话就很不信任 AI 的writing，就他们说不会用它来writing，然后我就比较喜欢用它来writing，就每个人信任程度是不一样。

Speaker 1 01:28:55 
他们肯定不会给不我writing，我觉得这个东西它值得商榷，但是我愿意相信她对男人的判断。

Speaker 2 01:29:06 
OK，所以你能 get 怎么反弹了吗？其实就是反弹完之后，你其实你要在反弹过程中能判断这个点有没有意思、有没有趣？就比如说你刚才聊的这几个过程中，我觉得比较有趣的点，刚才忘记写了，就有趣的点，比如说第一个。

Speaker 1 01:29:27 
没事，我有录那个转录的，一会可以发给你。对。

Speaker 2 01:29:32 
我其实有想到几个有趣的点，就是可能多个模型的验证中发现这个有一小部分信息不一致的时候，你可能就会去判断一下，这可能就是比较一个有趣的点。然后还有就是其实前面也还有一个有趣的点，我其实本来也想到，但一下忘记了，就分阶段让他产出一些那个 output 程度，对吧？就分阶段这个是一个insights，然后还有一个点是相关利益者的，相关利益者的输入就是告诉他你所处的一个角色位置，所以我觉得这些可能都算一些比较有趣的insight。就是我的，就是我，我们在聊的时候会有一个大致判断，就是有没有一些好玩的地方，就跟我们不一样，跟我们使用不一样，或者说跟你访谈这么多人里面你使用的有点不一样，我觉得就是一些interesting，但是。

Speaker 1 01:30:34 
我觉得也跟你们大部分就是你的同僚们相比，应该会比较少人会用它去解决感性问题，对吧？

Speaker 2 01:30:47 
哦，这你看你访谈对象，因为我之前有访谈过工作的，有些人把他当心理咨询师，有些人把他拿来算命，其实都会遇到这么一个问题，就是情感支持。但情感支持的话，我觉得就是一些insights，看看有没有什么有意思的喽？因为我们后续任务肯定是放在那种具有高度 critical thinking 的任务中，肯定不是这种心理咨询师，这你肯定完全信任你，要不然就是不相信，就没有，就是没有做的价值，就是你可以聊，对，但是这些聊的过程中你可能会发现一些有趣的点，可能在我后续的实验设计中我可以加入这些点来提示他啊。比如说你在一个任务设计过程中，你可能可以分阶段地让 ChatGPT 给你输出一个 output 程度。然后也可以说让，嗯，在你写提示词的时候，你应该注意一下你所处的相关利益者的一个环境中，所以就相当于这些点，我可以用到后续的实验来看一看能不能帮助那些 critical thinking 一般的人去提高 critical thinking，这个就是我这个实验的一个目的，或者说最终的一个呈现。



受访人20:
2025-08-25 23:37:44 CST|1h 12min 39s

Keywords:
论文、理论、文献、迭代、情感、教育、认知、段落、问卷、人机交互、语言模型、数据分析、头脑风暴、研究方向、研究话题、语言思考、语言工具、语言习惯

Transcript:
Speaker 1 00:00 
OK，好好，我开始录音了哈啊。哦，OK，对，我是商学院的一个项目，关于那个基于交互记忆系统优化人机团队表现，主要是想了解一下，就是甚至是 AI 的高频使用者，就是我们在那个就是 sign up 时候，我们就是选了一些高频的使用者，然后观测一下，就是你们在工作或者学习流程中是如何和 AI 进行协作的，主要是关注你们的一个互动的一个模式，和你的思考的一个行为，以及就是怎么去使用 AI 的一个协作方式啊。然后你对我上面的有什么问题吗。

Speaker 2 00:45 
我想问一下这个项目的 PI 是你，对吧。

Speaker 1 00:48 
不是， pi 是我的导师。

Speaker 2 00:51 
嗯，所以它是一个你的 sessions 的一个part，还是说你老板的一个project？

Speaker 1 00:58 
你是说这个研究是吗？是我的pro。对对，是我的意思。对对对。

Speaker 2 01:02 
就是你的 PhD something 的一个。

Speaker 1 01:07 
对，是我 PhD 里面的一个研究子研究。OK，行，好，那我们就正式开始哈。好，那您能简述一下您目前的职业或者是学习的一个领域吗？

Speaker 2 01:22 
我现在是在 Nie 教育学院做 research fellow。

Speaker 1 01:29 
OK，那您主要的优势就是你会处理一些什么样类型的任务啊？在这个领域。

Speaker 2 01:35 
我主要就是负责，嗯，研究相关的，比如说从数据收集到数据分析以及论文的撰写，就是主要负责 research 部分。

Speaker 1 01:47 
教育领域没问题，那您是大概从什么时候开始使用？甚至是 AI 或就是某一个类型的，还是说其他多个的 AI 工具的？

Speaker 2 01:58 
我是用 ChatGPT 的， ChatGPT 应该是在 13 年二 23 年初发布的，对，然后它大概是发布了三四个月左右，我大概是在 23 年的五六月份开始使用的。

Speaker 1 02:14 
就说已经就很挺早的了，对吧？就是，对对对对，那您在就跟他的协作的一个频率怎么样呀？是就从之前到现在。

Speaker 2 02:25 
基本上是每天都在。

Speaker 1 02:26 
使用，每天OK。对啊，那你有开会员吗？check，对于 check GPT。

Speaker 2 02:34 
我不需要，因为无论是之前或者现在，我们学校是有那个 plus 版本的，所以我不需要个人去开。但是其实我使用的是会员版本。

Speaker 1 02:45 
OK OK OK。那就是有用过别的一些生成式 AI 吗？就还是说只用ChatGPT？

Speaker 2 02:52 
95 PERCENT 都是 check GPT。

Speaker 1 02:55 
哦，OK，好的呃。那，那为什么会选择 check GPT 呢？

Speaker 2 03:02 
因为首先它是最早出来的，其次我的工作语言是英语，那它是更适合处理英语相关的任务。

Speaker 1 03:10 
就是说没有考虑过谷歌的，或者是cloud，或者是一些别的我。

Speaker 2 03:15 
也不是很了解，因为好像 ChatGPT 是最早出来的，然后我在使用，然后我觉得也OK。

Speaker 1 03:21 
没问题。那您能描述一下，就是一些任务，典型的任务在你的工作中。

Speaker 2 03:31 
嗯，两方面，一方面就是在日常的邮件沟通中让他帮我 polish 一下，帮我把这个邮件就是，嗯，更 native speaker 一些，就是日常的使用。另外一方面就是在论文撰写中让他就是 refresh 一些，或者说是嗯。对，大概是这种类型的，就我主要还是把它作为一种语言润色工具，我相对来说较少地使用它作为一种回答的工具，或者说是百科全书式的工具。

Speaker 1 04:09 
意思就是说主要还是用于语言上的润色。就是诶，那他比如说你有没有可能就是你会有 coding 的任务？或者是。

Speaker 2 04:19 
没有？因为我们不涉及编程，就是有非常非常小非，就是我只会在 3/ 300 ~ 五的情况下会让他帮我 check 一下我的一些语法上的东西，主要是这部分相对来说我使用得非常少，因为我所谓的语法不是他们，就是计算机他们那些的那种 Python 之类的。然后我们是在做数据分析，所以我一方面我不太信任他， o 不OK，另外一方面大部分情况我都可以自己处理，我只有在极少的我非常不熟的情况下，可能会去让他帮我 check 一下这个中间有没有。问题。

Speaker 1 05:01 
OK，那我们要不然就先聊一下润色这个任务，就是那对于润色任务的话，你怎么去使用它的？是，比如说是整篇文章还是怎么一个你使用。

Speaker 2 05:14 
就是它分为两种。嗯，网中日常生活中，比如说我需要回我同事或者anything，我要需要回个邮件，那我会大概的 general 的，有时候我会说我需要回的点是哪些？那你帮我用一种更礼貌的、更职场的，或者说更像 native speaker 的一种方式，帮我把这篇语、这篇邮件写出来，这是在日常生活中的，或者就是我会希望我的语言更 native 一点，然后更重要是我需要礼貌一点，不要太offensive，然后展示一些 warmth 之类的。

Speaker 2 05:49 
这是日常交往中的一趴，然后另外一趴就是在我的专业领域，就比如说在我的论文撰写阶段，在论文撰写阶段我主要是根据我撰写的不同阶段，我会有不同的使用方式。那最开那它可能分成几类，比如说我想想，如果概念化的，如果结构化的说来说，它可能就是第一种类型，是说我大概知道我这一段需要写什么，但是可能我的大部分的思想资源我会用于思考说我写什么，所以我的语句可能说是非常的错乱颠倒，只是 piece by piece 的这种部分，那我就会说我这一段想要表达这个核心思想是什么？然后这些是一些我的想法供你参考，你帮他，你帮我把他 recognize 成一段话，就是等于他帮我把我比较破碎的想法 organize 在一起，这是一种阶段，这是一种啊。

Speaker 2 06:48 
然后另外一种的话就是可能会说，因为你在论文的写作过程中你可能需要一个，比如说一开始的那种 leading sentence，或者说 leading paragraph，或者说你最后要有一个 conclusion 的paragraph，或者 p conclusion 的sentence。那会说我中间已经写了这个部分，你帮我想一想，写一个比较合适的开头或者结尾之类的。嗯，就是相对来说它的自主性更多一点。

Speaker 2 07:11 
还有一种就是说我可能会有一个比较长的，因为我自，比如说我自己在 re 做 review 的时候，我已经找了一些东西，然后我把每篇文章 summarize 了一下。嗯，那我就需要他，我说我，比如说我找了这些东西，那你帮我更有逻辑性的，然后比如说把它简化了，或者说各种方式，你帮我把它重写出来，大概是这样几种类型。

Speaker 1 07:34 
呃。就是我其实有个疑问，就是你用它来写这些的话，你不担心学术上的问题吗？

Speaker 2 07:40 
是我不是很担心，因为这个 ideal 本身是我自己的，我让它更多承担的是一种组织的部分，而且我不会说它出来我就直接使用，其实他只是帮我 organize 完了之后我是需要自己从头到尾再重新去写，只是说他只是承担了组织一下的部分，他承担的不是结尾的工作，而是初期或者中途的工作。我不是说他出来我就直接使用，而是说，对。

Speaker 1 08:09 
那你觉得在这三个任务中它的表现都挺优势的，就是相对于你来说，对吧呃？就是我。

Speaker 2 08:20 
觉得他相对于我来说，他是他比我要快很多，比如说我有一些 piece by piece 的东西，我自己把 organize 出来，我是需要一些我的认知资源去做这件事情，可能他需要 take a long time，但是他可能会比较快地把他完成，那基于他，但是一般我不认为他做得有多好，但是他只是帮我颠倒的语序错乱的句子，没有语法，因为我可能给出来的是一些，就是因为我们本来就不是英语母语者，我们可能就是只是脑子里有一些东西把它写出来，然后他可以帮我理顺这个东西。

Speaker 2 08:56 
那理顺完了之后其实我是需要再去看，因为我觉得它本质上是一种语言模型，所以它其实并没有，那就是我并不认为他有足够的批判性思维和这些东西，他只是帮我进行这个语言的加工，那我拿过来之后我还要再去看他的理论部分，可不可以他前后的顺序再怎么调整之类的。所以我认为在这个过程中他承担的只是比如说如果这段话从最开始的撰写到我，最后他用在我的终稿中，比如说一个 timeline 的话，它只是发生在前 1/ 3 甚至说 1/ 4 的阶段。

Speaker 1 09:31 
所以，所以其实它是只是一个初期工作，那它还会跟你存在一个迭代行为吗？

Speaker 2 09:36 
什么叫迭？对，我觉得他是起初，那我是要在他的基础上进行一个迭代，但是就是比如说他帮我 organize 完了之后，我自己会要继续调整，就调整一些语序，使用一些我觉得更合适的表达等等等等等等。但是我一般这个完成之后我会让他再去 check 一下我的语言是不是 native speaker 的，就是有没有一些语法上的错误之类的，但是这个部分就是更不需。需要那种就更把它当为当成一种语言润色工具，而不是把它当为一个 kind of 有一点点思考能力的工具。

Speaker 1 10:09 
OK，相当于在第二个任务的话，它更多会是一个思考能力，对吧？因为前一个是属于你，有一些你自己的idea。

Speaker 2 10:18 
对，我说的第二个任务是啥来着？

Speaker 1 10:22 
你第二个任务说的是你把你的中间的 body 写出来之后，然后让他去，对对对对，去构思前面和后面的。

Speaker 2 10:31 
他。我觉得他很擅长去归纳总结。

Speaker 1 10:35 
但我有个疑问就是他的归纳总结指的是你让他写前面的一两句，还是说一两句？

Speaker 2 10:41 
我从来不让他写整个段落，他写得很差，我不满意。

Speaker 1 10:45 
你说的是用那个之前 O3 吗？还是说用那个？

Speaker 2 10:48 
就是说，比如说我的problem，可能就是说我再写一段关于什么的内容。嗯，它将是for，比如说 for 一个。

Speaker 2 10:57 
Manuscript for academic journal.

Speaker 2 11:01 
然后我已经写完了这个 body 的部分，然后我可能需要一个 leading sentence 或者 leading paragraph 来 cover 到这些东西。那请你试着写一个。

Speaker 1 11:12 
那你会不会存在？就是说因为你段落和段落之间是存在一个叫过渡。对，那如果存在一个过渡的情况下，你会让他去帮你整合这个过渡的逻辑吗？

Speaker 2 11:24 
不会，我觉得他不行。

Speaker 1 11:26 
所以说你只是让他 leading 和其实。

Speaker 2 11:28 
我只是我 kind of。我不是让他承担，我只让他try。大部分时候我只说你做成这样。他只是给我一个想法，而不是说我依赖于他去使用我，更多的是说因为我自己，可能因为我们的思考是有一个过程，那你如果基于一个东西你再去思考可能会更简单。

Speaker 1 11:53 
能理解，就相当于他给了你一点idea。

Speaker 2 11:56 
都去说。行，我大概知道了，那我在这个基础上我再去进行一个迭代，这样子。

Speaker 1 12:03 
我网是不是有点不太好喂？

Speaker 2 12:06 
嗯，可能是我网不太好，我换个位置。

Speaker 1 12:10 
没有，可能也是我网不太好，因为。

Speaker 2 12:13 
好。嗯，再试。

Speaker 1 12:14 
一下，刚才说什么来着？收到收到。他给你一个初步的一个想法，然后你会跟他，然后你会自己再把前前和后给改一改，对吧？会迭代一下，对，然后第三个是什么的？

Speaker 2 12:28 
第三个，第三个就是说，嗯，比如说他让他去summarize，比如说这个东西很长，就是这个是我最近才遇到的，因为就是不同的人写作风格不一样，那我现在的老板他的写作风格就是需要我把每一篇的文章先 summarize 他的findings，然后再把这些文章放在一起写成一个paragraph。那对于我来说这其实不是我的写作习惯，我会觉得这很麻烦。

Speaker 2 12:52 
那可能我对于我来说，我觉得我可以把每一个 paper 它 summarize 出来。那可能每一篇，比如说有三篇、五篇之类的，那这五篇我们是用来想论述一个观点，在一个 paragraph 里面。嗯嗯嗯，那我可能已经把这三个 5 个文章我已经 summarize 出来了。那我就会让 check PT 先把这 5 篇，比如说我告诉他我要写一段关于什么的东西，我已经找到了一些文献，他们是这些，请你基于这些文献你去帮我写一段话出来，然后让他承担这 first step，然后他写出来之后我会在这个基础上再进行迭代修改之类的。对，嗯，就是其实在我自己的个人任务中我不会这么去做，我不会去做每一篇论文的summarize，然后再把它放在一起，但是因为我老板需要这个步骤，那我就。

Speaker 1 13:43 
诶，我其实好奇的是 summarize 是你来做的是吗？而不是 GPT 来做的？

Speaker 2 13:49 
播每一篇 paper 是我自己做的，因为我觉得他 summarize 的不准确、不正确，甚至有错误，我不信任。

Speaker 1 13:57 
你觉得他因为我目前访谈的一些他们 summarize 其实基本都是用 ChatGPT 来做，你觉得他。

Speaker 2 14:03 
我不信任。

Speaker 1 14:04 
你是觉得有是发现了不准确的地方吗？还是。

Speaker 2 14:08 
我就是不信任？因为而且我觉得我要对我的东西负责，我必须要看到第一手资料。如果说我连这篇文章的第一手资料我都没有看到，我直接让他summarize，我不知道他 summarize 准不准确，而且我其实有一些我觉得重要的内容他未必知道，比如说很简单，比如说我们要研究 a 和 b 的关系，那我找到了 a 和 b 关系一些论文，那其实他们俩的关系可能是比较复杂的，他们可能有一些中介调节，甚至说各种各样的关系。但是3，但是他可能会在某些群体中，或者是之类他有非常 specific 的细节。

Speaker 2 14:41 
如果我不去看这篇原始的文章，我是非常没有心里没底的，所以这一趴我一定要自己做，就是 kind of 我自己需要知道这篇文章到底讲什么的，它的侧重点是什么之类的，因为就算让 GPT 它去summarize，它也未必。首先因为你让他 GP summarize，他可能基于他觉得重点，他给你 summarize 东西，但他可能遗漏到我其实真正想关注的东西，而且我也没有办法提前给他一个 propose 说我想关注这些，因为可能在我阅读的过程中我会发现这个点有趣，但是我可能在我看这个文章之前，我不知道这个文章有这个有趣的点，所以我一旦让 ChatGPT 去 summarize 的话，它很有可能就遗漏到了这个点，而且我也没有提前办法预知，所以对于我来说，我觉得我需要掌握每一篇文章的内容。

Speaker 1 15:32 
嗯，就是我知道你的使用流程，就是说你会来先summary，诶？那有没有可能就是 check PPT summarize 之后，然后你再精读呢？这样会影响你的认知吗？

Speaker 2 15:42 
我觉得这个浪费我时间没有必要啊。

Speaker 1 15:45 
好像也有道理，就是说所有的文献其实你已经知道是必须要读的，而不存在这篇文章可能需要 check PPT 先帮你过一遍，我不。

Speaker 2 15:53 
需要，我全部就是我在我的论文写作中需要用到的所有的文献是我要自己去读第一手的，我只对我自己放心。对。

Speaker 1 16:04 
那就首先你选择这个第一手的时候，是哦，你就是已经在大量地阅读就大量地，对。

Speaker 2 16:10 
是我自己去检索，然后自己去找到它和我相关。因为我觉得你作为一个研究者，你要对这个领域有这个 domain 有一个非常 general 的认知，其实在你检索过程中你也会知道大家普遍在研究什么，关键的年份是哪些，然后关键的作者是哪些？重要的研究话题是哪些？我觉得检索本身它其实对于我对这个 domain 的了解是很重要的这个过程。然后包括文献的筛选以及阅读，对于我来说也是我在丰富我自己的想法，我觉得这个部分是没有办法让 check BD 去替代的，如果他替代完了之后，那我怎么写论文呢？我不知道，我不知道这个领域是什么样的，而且我也不信任他 summarize 出来的东西。

Speaker 1 16:48 
明白，那所以就是说你把大概你会输入多少篇？因为你就一个段落肯定只能输入那么多篇嘛，对吧？就是你去写的时候，就是你会让就输出给 ChatGPT 多少篇，大概。

Speaker 2 17:01 
不一定就是这个取决于。

Speaker 1 17:04 
这一块。

Speaker 2 17:05 
对，这就取决于这一块我们看了几多少个文献，但一般来说我不会让它处理过多，因为我觉得。

Speaker 1 17:11 
处理不准，就是它。

Speaker 2 17:13 
处理过多的话我也要去看很多，我为什么不把它 break down， piece by piece 地去做呢？

Speaker 1 17:20 
对吧？对对对，我知道你意思，就相当于可能，比如说你看了几篇就可以让它先整理，是，这是大概会就是。

Speaker 2 17:26 
嗯，我觉得可能是我们对于这个文献的理解是不一样的，就是说你在写论文的过程中有一些你大概知道这个文章的发现是这个样子的，但是其实你在你的论文中是不需要提及的，它只是作为一个，就比如说有个括号证明了你这个东西。如果我有个观点，我说比如说运动越多的人他越快乐，那我写了这句话，我要有个reference，对吧？有一些文献我只需要找到我把它 inside 进去就行了。但是其实，但是除了我们写这个之后，我们有时候比如说在写一个论文的 intro 或者 review 部分，我们还需要说 for instance，就哪些文章它发现了什么？这个里边我们应该会找一些比较重要的核心的这些文献，那这些文献我就会简单地去讲一下它的研究发现。那这个部分是我需要去从一个更长的我自己的 summary 部分进行一个简化的一个版本。那从这个长的到短的简化的版本，我会让在 GDP 去做，所以其实它其实在最后我的 manuscript 里，它其实也就是一句话。

Speaker 1 18:26 
明白了，所以其实他是在帮你精炼你的。对。

Speaker 2 18:31 
那是why？我说我觉得在 GB 主要是我的 language 的这种工具而已。

Speaker 1 18:37 
明白诶，其实我就是除了因为我觉得这里面有个点，就是因为然后它精简，我觉得应该是 OK 的啊。然后。诶，我觉得你刚才提到中介调节，那他会帮你去处理，比如说帮你探索一下有什么合brainstorm，就是帮你想一想，比如说什么调节合适，什么中介合适，什么理论合适。

Speaker 2 18:56 
我偶尔会让他去跟我去思考一下，但是这些部分的话，嗯，它更多的是发生在就是我的论文，比如说 Reviewer 的意见回来之后，它有些问题不太好处理，然后我可能会去说，诶，你觉得有什么想法？就是这个是会有一个 Brainstorm 的部分，那但是我觉得他只能回答一些相对来说比较基础的部分，就是再深入的，因为它本质上是一个大语言模型嘛。嗯，就这一趴一定要是有足够多的以往的研究了之后，那它能够输出，那其实有一些比较刁钻的，比较 critical 的问题，它其实也很难去回答。但是有一些部分我是会和他去，我会让他简单地去说一下，大概有一些怎么样的可能之类的。

Speaker 1 19:44 
那那，那你觉得他提供这些可能，比如说可能给了几个点，那你觉得是有些确实能用，还是说基本上也。

Speaker 2 19:53 
嗯，50%。

Speaker 1 19:55 
那还算可以吧？我觉得在，但是。

Speaker 2 19:57 
我觉得是这样子，就是看你怎么去定。你比如说你这个可能跟我的就是非常我的 domain 相关了，就是我之前有一篇paper，然后就是他要我区分两个概念的关系，嗯嗯。就是 social acceptance 和popularity，就是他要我区分这两个概念的关系，那我 general 地来说我大概能够感受到这两个概念是有区别，也有 overlap 的部分的。嗯嗯嗯，但是我其实我自己就又觉得我的语言可能也表达不好，而且我的脑子其实没有想得特别清楚。

Speaker 2 20:29 
那我就会去跟詹吉贝说，那我写了一篇关于什么样文章，涉及了这两个很关键的概念？然后 Reviewer 来问我说这两个概念是有什么同或者不同？他是这么问的，那你觉得我会让他说，你觉得这个问题怎么回答会比较好？请，尤其非常重要的是请你给我提供一些 sales ready。

Speaker 2 20:47 
Co foundation transition, necessary references.

Speaker 2 20:50 
然后他会给我一些，那他可能他上面就是其实对，从他的工作的角度来说，他会根据他的库去做一些总结，然后给出一些东西，其实他这个东西本身有很多东西是不准确的或者不正确的，但是他至少给了我一个线索，比如说他给我说有一些 potential 的 theoretical foundation，一些理论之类的，那我可以去再去看这些理论能不能够解答这个问题，就是anyway，它也是 first step。

Speaker 1 21:21 
诶，对，你刚才提到说就是他提供这些理论以及文献，你是觉得这些，因为不是一直说 ChatGPT 给的文献不太行，你发现他给的怎么样？就这些。

Speaker 2 21:32 
就是看你什么类型，如果比较经典的理论它是可以，它是没问题的，就是它会说你这个东西可以用一些什么什么样的理论去解释怎么样，但其实因为我也不是说我在每一个 domain 都非常非常的深入，那它可能就说给了我一个线索，这个理论可能可以用来去解释，所以我说的 reference 更多的是指的就是这样一个，它就是理论的名字，而不是说具体的某一篇文章，这个是不可信的。

Speaker 2 22:02 
我懂你只是说对，他只是会说你就好像你做人，就是好像你做人机交互一样，你肯定你也有些理论去可以解释各种各样的问题，那可能因为你的阅读的比如说有限或者怎么样，你可能只是知道部分，那这个问题之后，你目前的理论资源你解释不了，或者说你没有想到这个方向。

Speaker 2 22:21 
那你可能跟 GPT 聊一下，他说，哎，什么其他的什么什么理论也可以用来解释，然后我就会去看这个理论他说的是什么内容。那有时候 GPT 他会乱用，他就会这个理论可以去解释，但其实这个理论跟他说的没有半毛钱关系，但是有的时候他会说这个理论我会觉得可以，我可能基于这个理论我可以大概怎么去想之类的，所以更多的是因为他，更多的是他拥有更多的知识资源。所以让他从那么多的浩如烟海的这些东西里面去帮我找一些点这样子。

Speaker 1 22:55 
对，所以我大概能理解，就是说你会根据他提供的这个理论，你会去大量地阅读文献。

Speaker 2 23:01 
对，我就去看一下他说的这个点有没有可能去支撑，我去回答，那我去再去 check 他这个点的一些基础，我再去基于他这个点，因为有时候你搜文审，你只需要一些关键词，只是说我最开始看这个问题的时候，我不，我想不到用什么样的关键词之类的去检索之类的，那他可能提到了一些，那我基于他提到这些关键词，我觉得有 make sense 或者之类的，我会再去检索，再去阅读，去看看怎么去处理这个问题，这样子。

Speaker 1 23:29 
明白。所以说这个是在回复 in review 的一个情况下，对，所以还是能给一定的帮助，对吧？应该可以这么说，对，可以。

Speaker 2 23:42 
那就这个时候是把它作为一种 kind of 百科全书式的帮助，这样子。

Speaker 1 23:46 
那，那你会不会，比如说可能有些，比如说 review 的回复，你可能就什么那种套话，什么你会让他帮忙写一写？

Speaker 2 23:54 
这也不需要写套话，因为我们啊很反感写那种套话，大概就是 thanks for your comment，然后下面就是很正常的我的内容了。

Speaker 1 24:03 
OK，OK。

Speaker 2 24:04 
对啊，大家都不喜欢读套话，对吧？没有必要，没有必要那么长，就是就我现在发现确实就是有些人就是，对，因为我也会收到一些别人给我的邮件，就很明显就是 GDP 给他写了很长一段，但是我也可以理解，就是心是好的，对吧？就是他是想要更礼貌地去回复你，然后更，对，所以然后我也可以理解，因为我们大家都不是 native speaker，所以就我也可以理解了。对，比如说我自己个人的话，我不太喜欢，就是大家都没有必要，就是那么冗长、那么冗杂，对吧？

Speaker 1 24:37 
对对，提高效率。是，我懂你呃。那除了这方面你还会有什么？我其实好奇，因为你说数据分析，就我感觉教育专业应该可能跟三科也挺像吧？就。

Speaker 2 24:50 
比如说，对，我们都属于社科。

Speaker 1 24:52 
对，可能是 data 或者是survey，或者是什么的，有没有可能比如说你在做，你会去做访谈或者是问卷调查吗？我不是很懂你的研究方向。

Speaker 2 25:02 
我们是做量化的，我们是纯做量化，所以我们就全是问卷，然后收回来全是数据的处理，我们不做执行的。比如说我不做，对。

Speaker 1 25:12 
什么你不做。

Speaker 2 25:13 
那就我自己是一个量化研究者，我不做置信这一部分哦。

Speaker 1 25:18 
明白明白，你说你是做问卷的。对哦，那你会不会哦？就是比如说这个 idea 就可能需要他帮你去列个大纲什么的，比如说或者是问卷的问题，有没有什么好的idea？会不会去寻求 chatbt 的版本？不会，完全不会。

Speaker 2 25:37 
因为我自己最知道我的研究内容，然后我自己最知道我这个领域它下一步最需要去解决的问题之类的，就是它没有，我找不到任何它可以帮助的地方。

Speaker 1 25:49 
就相当于。

Speaker 2 25:50 
就是其实因为我做我这个领域也做了好几年了，我大概知道下一步需要研究什么。就是如果我再做，再准备一个project，或者说再准备一个study，我知道我的研究问题是什么，就是我知道我要做什么，就我没有这个就是头脑风暴的这一部分。

Speaker 1 26:08 
明白就相当于对熟悉这个领域。

Speaker 2 26:11 
了。对对对对对。嗯，然后我觉得 check b 它也，它只是会给你非常 average 的一些方向，对吧？嗯，我觉得 ID 对，但是对它只是一个非常 average 的水平，但是其实我们作为 researcher 的话，我们是需要去探索更一更深的一步，就是大家你觉就是有趣的，更有意思的，然后更新颖的部分，我觉得这个 GPT 是做不到的。对哦，明白，所以我没有跟他这有这方面的这样子一种。对。

Speaker 1 26:45 
啊，可我其实是想说，就是因为比如说我去准备一个访谈提纲，我可能就会让他帮忙构思一个框架什么的，就好像你好像没有会帮你处理这种现象，对吧？就是比如说可能要给你一个整体的逻辑，或者说整体的一个大概样子，好像你没有遇到这种情况。

Speaker 2 27:03 
你这样不对，我所知的咨询研究不是这么做的。

Speaker 1 27:09 
对，没有，因为访谈提纲我会让他帮我列个大概，然后我再看有什么问题，我是需要的，哪些问题我不要，就是我会判断。

Speaker 2 27:15 
就是我所，我有做置信研究的朋友，就是他们还是需要有一个 theoretical framework 的，对吧？我，对吧？是基于你要基于此去做我觉得是比较合适的。

Speaker 1 27:26 
对，我懂你意思，就基于理论来框架。

Speaker 2 27:30 
对，而不是说我东一榔头，我想出一个问题，西一棒槌又想出一个问题。哇。

Speaker 1 27:36 
其实我也没跟着梵兰提纲来问，因为梵兰提纲这种问题太但我但。

Speaker 2 27:40 
anyway，我没有办法去评价你们，因为我知道质检研究非常难做。 that' s why 我只做量化。

Speaker 1 27:47 
明白，因为其实我也是第一次做，我也有跟你说，我邮件里面说我也是第一次做。

Speaker 2 27:54 
对，我非常佩服每一个做自信研究的人，因为他的数据量是海量的，因为对，他从数据收集到数据分析都非常的麻烦。之麻烦对我非常理解就很困难。

Speaker 1 28:09 
我之前学计算机的，所以我真的很困难。

Speaker 2 28:13 
对啊，我觉得很困。你都不是说说算，我不？哥们真有勇气，甚至不做量化，做访谈真有勇气。

Speaker 1 28:23 
有。我还有一个方向是做，就你说这个量化这一块，我是做二手数据，你应该懂，二手数据就是。

Speaker 2 28:30 
我明白，就是大的 data set 去做。

Speaker 1 28:33 
对，我会用那些数据，还有可能会加点 machine learning、 deep learning 什么的。对对。

Speaker 2 28:39 
做这个多好呀，量化那个事情真的很难做诶。干嘛呢？一年了，一年还不一定能做出一篇文章来，真的。

Speaker 1 28:46 
很麻烦，为了博士第一。

Speaker 2 28:48 
你们没有要求非得做置信吧？

Speaker 1 28:51 
没有，因为导师要求他觉得这个话题比较热点，就因为他觉得现在深圳的 AI 是个热点话题，然后我们，我其实也是在往教育方向做的。

Speaker 2 29:01 
可能也是就是同样的研究问题可以有使用不同的研究方法，但是anyway，自信研究是好，是我佩服每一个做自信研究的人，没有真的对，非常大的勇气。

Speaker 1 29:11 
对， ChatGPT 目前不适合做二手，我也想过二手该怎么做，但。

Speaker 2 29:15 
他没有办法做到二手。你要就收一手嘛？

Speaker 1 29:17 
对，我现在想到也是这种情况。

Speaker 2 29:19 
唉，说一手我觉得挺无聊的，因为我觉得现在在教育领域做的生成式 AI 都挺没意思的。对，我就这是为什么我会去报名这个研究？是因为我自己也会，我在做我自己的研究话题是有 AI 这一部分的，但是我不是在教育领域去做，我做得更偏心理学领域。所以我也会很好奇，因为我本来以为你是教育领域的，所以我对。

Speaker 1 29:46 
你在哪里看到我贴的。

Speaker 2 29:50 
校巴站啊？

Speaker 1 29:51 
哦哦哦哦，就是那个校车那个所，那个绿线。那个什么线的那个校车站。是吗？我。

Speaker 2 29:58 
忘记了，反正是某一个校车站了。

Speaker 1 30:00 
挺好的。没有，对。

Speaker 2 30:02 
我很好奇你们会关注一些什么样的问题？因为我觉得目前教育领域做都挺没意思的。

Speaker 1 30:08 
因为我属于商学院的 information system，属于人机交互方向嘛。那人机交互的对。

Speaker 2 30:14 
你做这种就是你做的，你可以再做啊。当然了，我不好对你们指指点点。

Speaker 1 30:20 
没有，其实我现在跟你聊完之后，其实我都是在对系统进行变化，还是不完全只对人。对，因为我还是在做系统方面的。对。

Speaker 2 30:28 
你做人机交互部分，可以做更 social 的部分吗？因为我是做比较 social interaction 的部分的哦。就是，我也是刚接触这个话题，其实我一开始是很排斥 AI 这个话题的，因为我觉得 AI 终归根到底它只是一个工具，它再归根到底它只是一个大语言模型，哈哈，是这样，对吧？行，它只是大语言模型，你只。指望他有什么脑子呢。

Speaker 1 30:52 
对啊，所以现在就在看。其实你我的访谈的目的其实是为了找一些有趣的insights，就是看在写作过程中有什么有意思的一些使用方式。

Speaker 2 31:03 
是因为你关注的是比较 learning 的部分，对吧？嗯，就是它其实更多的是learning，尤其是在学习工作的这样的领域。对，其实，对，就其实。但是我因为你知道现在还有一种就是把 AI 作为一个人，作为一个陪伴的伙伴跟他去聊情感。对，我做的是这个部分。

Speaker 1 31:27 
我觉得这。

Speaker 2 31:28 
我做的是这个部分。对。

Speaker 1 31:29 
我访谈的时候其实有那么几个女生有跟我提到说当心理咨询师，或者是说。

Speaker 2 31:36 
对吧？对，所以我觉得这个是有趣的。

Speaker 1 31:39 
对，但不是我研究的方向。哈哈，对。

Speaker 2 31:42 
就是就想起来聊两句啊。对对对，我的合格被试。

Speaker 1 31:47 
OK，然后还有说用到那个 dating APP，对，用到 dating APP 上也是一个女生跟我提到的，然后还有一个，对，对，还有那算命，我觉得这些都是情感支持方向的一些探索的点，这挺有意思的。对。

Speaker 2 32:04 
哈哈，是挺有意思，这是我的研究方向。

Speaker 1 32:07 
OK，所以你也是在做跟 AI 相关，然后他做一个情感支持的。

Speaker 2 32:12 
对，我是做得非常非常的情感支持，这一部分就是对我比较对。

Speaker 1 32:18 
我。

Speaker 2 32:19 
因为我本身是做的更偏心理的方向，我在 education 的 context 相对来说比较少。

Speaker 1 32:25 
明白。嗯，所以说你还没有可能我更 education 目前是。

Speaker 2 32:30 
对，所以我也会是想去看，就是我为什么会参加，也是因为我想去看一下，比如说教育领域他们会关注一些什么有意思的话题之类的。对。

Speaker 1 32:41 
结果发现是商学、商课。

Speaker 2 32:44 
没事，我觉得商，因为我看到，因为我又有去看一些关于人际交互的paper，因为他们有一些会把机器人做得比较更偏社会的方向，明白会有一些，就韩国有一帮人就一直在做这个东西。

Speaker 1 32:58 
那我觉得我之后的实验，我觉得你感兴趣可以来参加呀。我后面会有 experience study 和 design study 的话可能就是。

Speaker 2 33:07 
哇哈哈。你这 PSD 读得真累呀。

Speaker 1 33:11 
我真的很累，我又要学计算机，又要学商科，要学心理学，又要学。

Speaker 2 33:17 
人机交互，是吧？

Speaker 1 33:18 
对，人，这只是我一个方向，我还有一个方向是企业管理，属于战略管理。

Speaker 2 33:25 
很有意思的。

Speaker 1 33:27 
反正都做了，什么都做了，我也是也麻木了。

Speaker 2 33:31 
可以的，就是会有一些 SaaS 的人，就我之前用的一个量表，就是那个 AI empathy，就是 NI 有没有AI？有没有同理心？这个量表？我一看 Daas 的人做出来的，OK，fine。这是一个非常心理学的概念，但是他的开发者，他的全部都是 CS 专业的，然后他 publish 也是在一个 CS 的会议上。

Speaker 1 33:58 
明白，那他可能就没有那么没对，是客，但是人家。

Speaker 2 34:01 
做得也很好啦。对，也很好，就是，唉，你知道吗？心理学会有一些。天呐那种自命清高啦。

Speaker 1 34:12 
对啊，不太懂啊。我觉你应该也不能算心理学专业吧，对吧？就是也属于我。

Speaker 2 34:18 
属于教育心理学这一块。

Speaker 1 34:20 
教育心理学。

Speaker 2 34:21 
但是我不是很教育，其实我更偏心理，我是发展心理学，就是做儿童和青少年的心理健康这一块。

Speaker 1 34:28 
那你的情感支持可以用到这方面，还挺有意思的。嗯，对啊。

Speaker 2 34:35 
那我为什么会做情感支持呢？

Speaker 1 34:37 
对哈，OK，我应该是属于比较一个很有趣的领域，应该关注也比较少目前。

Speaker 2 34:43 
对，那是why？我要做，我，对，哈哈哈。

Speaker 1 34:48 
OK，不行，我要先继续我的访谈，我就要有。

Speaker 2 34:51 
停，对，你继续，没关系。

Speaker 1 34:53 
OK，OK。诶，那你是怎么去探索出它就对于 ChatGPT 的一个的优势和劣势啊？因为肯定也要对它进行有一个大概的认知嘛。

Speaker 2 35:02 
我最开始都对，就是对他持一个非常谨慎的态度。

Speaker 1 35:06 
就说。

Speaker 2 35:07 
就是我，包括到现在我对他持有的都是一个非常谨慎的态度。

Speaker 1 35:12 
这个谨慎的态度体现在所有东西你都要进行判断以及审核。对。

Speaker 2 35:17 
那对，我不会相信他给我的任何资料。

Speaker 1 35:21 
呃。那在什么情况下？除了邮件诶？有没有一些比如说很日常你也会使用到它呀？

Speaker 2 35:27 
不会，我知道很多人就像刚才说的情感支持这一类的，我知道很多人在做这样的事情，但是我只会把它使用在我的工作场域。

Speaker 1 35:36 
呃。是，就是说可以说是很理性、很有深度思考的。对于使用ChatGPT。

Speaker 2 35:43 
就是就像我说的，我归根到底我认为它是一个大语言模型，我不信任它，但是我又客观承。但是他至少他是一个非常好的语言润色者和语言思考者，就他你本质上理解，因为他是大语言，所以他对语言的把玩是非常可以的。其就是我不是我不相信他的任何的回答，我认为他的任何的回答都是对于语言的重新组织。

Speaker 1 36:09 
可以这么理解，其实我，因为我其实当时在选受访者就报名人特别多。那我就选的时候我看见有教育者，就因为我看到有一个教育的，然后我觉得，哎呀，挺好奇你会怎么去看待嘛？看待ChatGPT。嗯，对。那你在跟他合作关合作的方式中有什么比较有趣的？ insight 就是有趣的点什么的。

Speaker 2 36:32 
怎么叫有趣？

Speaker 1 36:33 
嗯，可能比如说有些人在使用 ChatGPT 的时候会，我就昨就前两天访谈的时候有一个提到说会把他所处的相关利益者，因为他三科也比较偏三科，然后他会提到就说把相关利益者都说清楚之后再让 ChatGPT 去完成这个任务。

Speaker 2 36:54 
就是你要给他一个context，我也觉得就是你在使用 ChatGPT 的时候，你要告诉他一个context，就比如说你要告诉他这件事情是怎么发生的，然后对方是一个什么样的人，然后这样他会给你一个更合适的语言。比如说因为我现在，比如说我在带学生，所以我就会说你要把帮我把这个，我是在回一个学生的邮件，然后你尽量帮我把语言措辞温暖一些、礼貌一些。然后或者之类的，我就是我会，我比如说让他措辞邮件的时候，我会告诉他前因后果，这样的话他的语言会更加的 make sense 一点。

Speaker 1 37:29 
其实我能理解，就是相当于你刚才在说回复 review 的 respond 的时候，你其实也就是context。

Speaker 2 37:37 
给你要告诉他这个情境是什么样的，就是我会发现你告诉他情境之后，他是非他是比较能够去结合这个情境去处理，他做这方面是非常靠谱的。明白。

Speaker 1 37:51 
那其实会不会有趣的insight？可能会在，比如说你做情感支持，那你做情感支持肯定要去用 ChatGPT 来做，那你有没有发现就可能比较有意思的？你在使用它的过程中，比如说可能是帮你去构建什么。

Speaker 2 38:04 
我不会使用它作为我的情感支持，我知道很多人在用，这是我的研究问题，但是我自己个人不把它作为情感支持使用。

Speaker 1 38:13 
明白，所以说相当于你只是研究，但自己不会去尝。

Speaker 2 38:17 
我其实非常不理解这件事情，但我又知道很多人在做，然后我就觉得这个东西非常的有意思，非常的有趣，我想知道这些人到底是怎么想的，哈哈哈。

Speaker 1 38:27 
那其实这个你不应该试一试做访谈嘛？因为访谈的话其实可以，我不要。

Speaker 2 38:31 
访谈，数据太难处理了，我可以用问卷解决，能用问卷解决的我绝对不会上访谈的。

Speaker 1 38:37 
但如果你用问卷去处理这个情感支持的话，其实很难去。

Speaker 2 38:41 
挖到他，所以就是我，所以就是不同的研究范式有不同的差异，就是有利弊嘛。诶，那我可以在我的 paper 里，我就在 limitation 说需要更多的 interview 去知道他们更深入的观点之类，但我自己不会去做。

Speaker 1 39:00 
那如果用问卷来做的话，就是说这一部分其实你也不会去考虑什么 ChatGPT 跟这些的关系，只是他们，你去研究他们跟 ChatGPT 的关系。

Speaker 2 39:10 
对的，就我自己，不是因为我，就我没有自己involve，其中在这个过程中拆 GB 只是我的研究课题而已。

Speaker 1 39:17 
嗯，明白。

Speaker 2 39:20 
那可能有趣的点就是我在使用过程中，我觉得切换壁纸就是蛮蠢的，这种蠢的时候你就需要给它新开一个窗口，不然它就会将错就错，一错再错。

Speaker 1 39:30 
我大概能理解，就是说他在可能会受到历史记录的影响，然后对。

Speaker 2 39:34 
就是你让他改的都就是不，你，你告诉他这你不对，你需要怎么样？然后给你改了，他给你改了，顾头不顾尾，这个时候你重新开一个，然后重新把这些summarize，然后把这些 context 重新跟他讲一遍，然后让他从头再来一遍，他就会做得还不错。

Speaker 1 39:52 
那你在给他 context 时候，你会不会把前面，比如说他回答得还可以的一些东西也会，OK，就是。

Speaker 2 40:01 
就他已经迭代出了一个部分还可以的了，那这个中间还有什么一些欠缺的部分？我发现他基于历史记录，如果我告诉他一些东西之后，他没有办法再继续去修改了，那么我就会重新开一个窗口，然后把一些我觉得已经不错的东西拿出来，然后告诉他这里面欠缺一些东西。我为什么觉得他欠缺？需要怎么去做？然后就像一个老师一样，我来教你怎么去改，然后你去做，就说你，我时常觉得我跟 GDP 的交流特别像，来，我来教你怎么做事。

Speaker 1 40:33 
因为就是有点，就是我在你这就能看到，就是你把你教育他的样子，对吧？就你来教育他，然后我在别的一些访谈者就觉得他是一个tutor，就是他来指导哦。对，那如果你对于一些不熟悉的任务会存在跟他交互的行为吗？因为肯定不是。所有任务你都很熟悉嘛。就哦可能某个名。

Speaker 2 40:56 
我偶尔会跟他做一些头脑风暴的事情，比如说我想想我最近一次跟他做头脑风暴的事情是干嘛？

Speaker 1 41:05 
你可以放。

Speaker 2 41:05 
一，就是我要写一篇paper，然后我不是很熟，就这个 topic 从头到尾我都不是很熟。

Speaker 1 41:13 
那你怎么。

Speaker 2 41:14 
那？所以比如说我就跟他讲我需要写这样一篇paper，然后我现在在写 introduction 部分，那我觉得 introduction 部分我分为了几个section，每个 section 的标题大概是什么？我希望在这个标，在这个 section 里面阐明什么什么什么样的关系。然后你试着写给我看看。

Speaker 1 41:36 
哦，就是说你只是知道个大概，可以这么说吗？只是知道个。对，我。

Speaker 2 41:41 
知道个大概。

Speaker 1 41:42 
那这里面你有没有把，比如说两者之间的关系，你有写吗？还是说只是说会写。

Speaker 2 41:49 
就是说就是其实本质上来说就是我已经跑完所有的数据了，我知道这个故事应该怎么讲了。嗯嗯，那其实但是你写一篇 paper 的时候，你最开始其实你需要有很多 background 东西，你需要有个非常基础的解释的东西。然后你需要从理论上去建构，比如说其实我在我的研究中已经发现了 a 能预测b，OK，那我大概知道 a 也是能预测 b 的，但是我需要有更多的理论去支撑。为什么？ a 是什么？ b 是什么？ a 为什么能够预测b？ a 怎么预去预测 b 的？就我需要论述这个部分，对吧？那我可能就是会再会跟他说，我现在就是我把所有的 context 告诉他，然后告诉他你要写这个 paper 了，然后怎么样？这一段是什么什么样呢？请你试着写出来看看。然后那其对他，可，然后他写出来了之后，我就，我大概知道，嗯，他关注的点，那我大概知道可以这个样子，那我会去自己去重新去写，这样子，就是他只是给我一个非常初期的基础的一个草稿这样。

Speaker 1 42:50 
子。诶，那我有个疑问，你，你让他来给的时候，对吧？那他相当于理论，你还没定，那他来提供这个理论的话，你会不会觉得不合适什么的？

Speaker 2 42:59 
我会去check。

Speaker 1 43:01 
然后就说你可能会把它理论给改掉，也就是说反正对，只是看个大概。

Speaker 2 43:06 
它，我就是特别类似于假如说你现在你读PIPD，对吧？你有一个Ra，现在刚读本科，然后你要写个东西，你说哎呀，你先给我写写看看你也未必会用他的东西，但是你想去看看。嗯，他怎么想的，万一有什么有意思的东西。anyway，你有一个draft，你从 draft 开始比你从 0 开始写要好写一点。

Speaker 1 43:27 
是那但是有个问题，它会不会影响到你的下一步的思路，就可能你被它局限住了。

Speaker 2 43:33 
不会，我又不是傻子。

Speaker 1 43:35 
不是，我的意思是说因为你本来可能有，就是因为就他给了你这个思路，可能你就会去考虑他这个思路了，就可能你比如说你要是自己去看文献，你可能会看到一些别的思路。

Speaker 2 43:47 
我也会去再看文献，就是 XDBD 没那么聪明，没有你想那么聪明，它给你的是非常简单的、非常基础的、非常线性的关系，它没有论，它没有办法去完成非常深入的批判性的思考。所以我只是用他大概地去知道，他只是大概、非常大概地给你讲 a 为什么能够 use b。然后有一些非常 normal 的、非常 common sense 的这种东西。

Speaker 1 44:12 
OK。

Speaker 2 44:12 
然后那我们是需要往里面提充提填入更加深入的思考，就说只是先让他写一个东西看看，然后我自己再去看文献往里面填了，只是说我就是，就我本身对这个话题也没有那么大感，没那么大的感兴趣，然后也不想投入特别特别的多的精力。那我但是我anyway，我要把它写出来，所以就先让它写写看喽。然后我再往里面我再看看，填一填总比我 start from Zero 要好一点。这样子。

Speaker 1 44:42 
这这这不对，这个，所以这个任务属于有点应付式的，是吗？我可以这么。

Speaker 2 44:46 
理，对，就是可以，就是我不是很喜欢这个topic，但是我必须要完成。然后他也不是我非常擅长且精通的领域，然后，对，然后我对他的投入是不是可持续性的？我只是为完成这篇paper，而这个话题我不会在我接下来的研究生涯中继续深入地去研究。

Speaker 1 45:08 
就这个明白了应付式任务的话，你可以让他来帮你。如果是自己我真的很感兴趣，你绝对不会让他来帮你去。对。

Speaker 2 45:17 
可认可就是我用来给自己安身立命的东西，是我自己要完成的。

Speaker 1 45:23 
嗯，我其实好奇的是你担心这个，比如说让他来帮忙会出现什么结果？你是觉得其实他这个东西也根本没法用，还是说可能我看不上啊？那你会不会担心你的东西泄露呢？就比如说你的输入的东西被大数有啥。

Speaker 2 45:38 
可泄露的呢？我觉得。

Speaker 1 45:42 
那我就不太懂了，有什么可以泄露的？这是你的研究吗？

Speaker 2 45:46 
对啊，就是我觉得每天他都叫。处理海量的数据，对吧？对对对，然后我们又不是搞那种高精尖技术，说白了我们心理学研究的都是太阳底下不新鲜的东西，哈哈哈，我们只是在一个非常小的点可能发现一个有意思的现象而已，就是我们，我就是我们没有非常说这个idea，一定要保密，一定不能让人知道，知不知道？我觉得没有，我就是这个观点，怎么样？是没有啦。

Speaker 1 46:17 
其实我觉得可能跟真的跟计算机差别最大就是人文社科，它是发现现象，然后这个现象其实对。

Speaker 2 46:23 
你做，你用一个有趣的意思去用一个有趣的方式去解释它。

Speaker 1 46:28 
对，因，对，我，因为。

Speaker 2 46:29 
但是这个东西它不太容易被泄露了。

Speaker 1 46:33 
是。

Speaker 2 46:33 
它更重要的是在于你用你自己的方式把它组织起来，组织出来、表达出来、发表出来。他没有那么大的说所有就是靠近天的，就说这个东西一直要怎么样就怎么样了，不存在了。

Speaker 1 46:48 
可能真的人文社科可能都这么想的，我感觉然后计算机那边就会不太会把这些。对啊。

Speaker 2 46:53 
你们，对，因为你们可能非常的重要，就是你们就是这个想法，或者就是一旦说出来，那别人可以复刻，然后快速地取代你。但其实在我们这一个 ideal 没那么重要。说真心话，至少我是这么觉得的。嗯嗯，更重要的是你把它做出来。对，然后更重要就是我说白了就是我们有一个idea。首先你要去收集数据，然后把数据收回来，跑出来看看结果能不能验证，这是其一个非常长的过程。然后你收回来了不同的群体，不同的sample，不同的国家、不同的东西，它可能出来的也不一样，哪怕是一样的东西在不同国家做它也不一样，你解释的东西也不一样，你一点小小的变化，那就是total。另外一个 study 它没有那么的唯一性，不可取代性，这样子。

Speaker 1 47:35 
能get，就是我太能理解了，就是我现在做法一直在变，就是后续的 idea 真的一直是在动的，唉，真的很累，对。

Speaker 2 47:45 
吧？就是你觉得我说真心话，你做的这个这一个部分，所这一趴，你关于这个的所有的 research design 也好，你收来的 data 之后，包括你的分析、你的理解、你的想法之类的。嗯，你会觉得它有多么的保密性吗？和你去做计算机的相关的话。

Speaker 1 48:02 
确实差别很大，对吧？对，计算机 idea 确实比较独特一些吧。他们的idea。

Speaker 2 48:07 
对他们可能我不了解，但是我的猜测他们可能是一个优化的方法，他，诶，他想到了他就能这么优化，他就做出来，那别人如果万一也想到，那别人就做出来了，对吧？对对对对对，你们有很大的，他们有很大的独特性，然后那种保密性我们没有啦，我们不存在啦，哈哈哈。我们更多的是讲故事，把这个故事讲得非常有趣啦。

Speaker 1 48:27 
是这样的，读了三科我也发现了，都是在讲故事。对。

Speaker 2 48:31 
啊，就是我们更重要的是解释现象。

Speaker 1 48:34 
是这样诶，我其实好奇就是你有没有接触过提示工程，就 prompt engineering 相关的？

Speaker 2 48:42 
我不太确定你是指。

Speaker 1 48:45 
就是比如说你会去了解一下这个提示词怎么写更有效，或者说就是。

Speaker 2 48:52 
我知道有很多这种，就是 guideline 这种，对， to box 之类的懒得去弄了。

Speaker 1 48:58 
就是我就是。

Speaker 2 48:59 
对，就是我，我知道有这些，然后包括有很多那种开源的资料的去分享。

Speaker 1 49:06 
那就我可以理解为这种纸质版的或者说电子档的，你其实是不愿意去看的，可以这么理解吗？

Speaker 2 49:13 
我就觉得唉。哎喂，哈喽喂。就是老实话，就是说首先我虽然理解说提示词的不同会带来不同的结果，如果你用一个更合适的提示词，或者你有更有想法，你会可以得到你更想要的结果。我理解这件事情，但是基于我自己的经验来说，我认为我现在的使用没有造成什么，我没有遇到什么困难，所以我没有这个动力去学习。

Speaker 1 49:46 
哦，我懂你意思，就是相当于就是说你觉得你现在提示词已经能解决你所有的问题了，目前的就是。

Speaker 2 49:52 
就我，也许我学了之后可能就让我能够写得更好，anyway，但是因为我没有遇到什么困难，就我没有去学的这个，就是我自己没有这个动力去学，没有这个动机。对哦。

Speaker 1 50:05 
懂你意思，假如，比如说，因为我目前在想就是说把这种 guideline 集成到系统里面，就是会提示你你可以怎么去使用或怎么去询问，就是这就是一系列的在系统里面集成，这样会不会对可能帮助大一些，就不用。

Speaker 2 50:20 
累？我还需要在一个 pool 里去找到我想要的提示词哦。不是不是，在这种情况下我为什么不直接问他呢？

Speaker 1 50:26 
不是，我的意思是说就是可能你提示完之后，他可能会提示你，诶，你可以这么去问，会更加的合适一些，或者说你还可以继续这么问。就是就是我可能会集成到 output 里面。

Speaker 2 50:39 
哦不，就是说我已经问完 AI 了， AI 回答完了，然后再告诉我说我还可以怎么问？

Speaker 1 50:44 
对对对对，就可能进一步地透传你的思维，可以这么说。

Speaker 2 50:50 
我不太确定，我理解了你这样的一种构思，但是我觉得也许。

Speaker 1 50:54 
等我后续的实验完，你来参与一下，我觉得你很适合来参与我的实验。

Speaker 2 51:00 
就是，但是我因为现在不是有 5.0 了，然后我发现 5.0 最大的特征就是他在回答我的完了我的问题之后，他会再缀一句，他说你需要我怎么样吗？我觉得我猜我喜欢。

Speaker 1 51:13 
你，喜欢。

Speaker 2 51:14 
就是我让他完成一个工作或者之类。之后他有时候会问我说，诶？你需要我怎么样吗？就说你需要我进一步用什么样的方式，或者进一步怎么样？你还别说，他有时候问我的需要，需不需要做的这个进一步我还真需要。

Speaker 1 51:29 
明白。我懂你意思，但我发现最近 5 的能力下降很多。我之前是一直在用 Chrome GPT 开的会员，然后发现它能力下降之后开始转谷歌的 GMV 了。好用吗？我觉得它的学术能力高于ChatGPT，然后信息检索能力低于ChatGPT。就我使用的感受是这样的。

Speaker 2 51:51 
我发现我已经用惯了我的 GPT 了，用惯了我的账号了，我就是我发现我哪怕开一个新的GPT，因为就是如果我就是，比如说我没有登录我的账号，我用别人的，然后开一个新的GPT，我觉得他的回答的问题跟我想象的就是差得好远。

Speaker 1 52:09 
哦，就可能。

Speaker 2 52:10 
我不确定这到底是不是我的主观感受，还是说就是这样，但是就我已经习惯了我的账号下的这一套，然后他回答的我的也是我比较想要的，因为就比如说包括润色这一部分。它已经能够，就是我会觉得有一，就是哪怕同样都是GPT。嗯，我开一个新的totally，新的之后我发现不行，就是太擅作主张了。

Speaker 1 52:36 
我懂我懂，你意思。

Speaker 2 52:37 
就是我的已经用习惯了，可能是因为我又，我不断地会有一些提示文档之类，他会比较是我想要的那种修改程度，因为我有时候只是想让他帮我 check 一下，或者说只是做 20% 或者 10% 的修改，就大概看一下的那种，不需要那么自作主张。嗯，就是。对，所以我已经 totally 习惯了。然后至于 5.0 和 4.0 的差异的话，我目前没有收到，但是那个啥 4.0 跟 3.5 的差异是很大的， 3.5 是真的蠢。

Speaker 1 53:08 
我有个问题，你刚才说你对它的这就是你，你不是说会有差异性，那这个差异性指的是比如说你这一个对话，就这一，就只有就这个对话，你是都让他润色吗？还是说，哦，对。

Speaker 2 53:24 
就是比如说我一篇文章，其实我已经写得差不多了，这一段这段我其实我自己相对来说满意了，但是我还是需要确认一下他是不是 native speaker，有些词替换会不会更好之类的啊。所以其实我心里预期的就是他只是做 10% 的修改就行了，就最后一部分了。

Speaker 2 53:42 
嗯，然后我同样的提示词，我放到我用习惯的这个里面，他确实他会改，而且他改的一般都是我比较喜欢的使用的一些词表达之类的，我会觉得是符合我的语言习惯的。但是如果放在一个新的里面，首先他有时候会自作主张把一个句子虽然表达是同样的意思，他的表达方式 totally 改变了。然后他改变了这种方式，我就是我不喜欢的一种表达方式。

Speaker 1 54:08 
所以说你会有专门一个对话来论色你的一些段落。对，不会。

Speaker 2 54:14 
它只发生在我的 account 下面，就是我可以开，就我其实我是每一个新的任务我都会开一个新的conversation，但是它都发生在我的 change PD 的这个账号下面啊。但是因为我们学校还有一个平台资源，它是可以用学校的内网连接的一个，另外也是一个拆 GDP totally，就是但是因为我没有长期使用，因为它每次登录都认为你是新用户哦。那你可以这么理解，所以我同样的东西我放到这个里面也是开一个新的conversation，但是我就不太喜欢它的输出了。

Speaker 1 54:49 
我明白，就是说你可能比如说这个任务现在需要写一篇文章，对吧？然后写到后面之后发现这一段话还需要 native speaker 一点，对吧？然后对，继续放回这个对话。

Speaker 2 55:02 
不一定也可以开新的，无所谓。

Speaker 1 55:06 
就是说只是放在你自己这个 GPT 下面，可以这么说吗？

Speaker 2 55:09 
对，只是放在我自己的 GPT 下面。

Speaker 1 55:12 
就说就算你新开对话你也不会出席。

Speaker 2 55:15 
无所谓。对，他跟你开不开新对话不影响，我不知道别人的使用，我不确定一直使用一个对话合不合适，但我大部分时候改一段话，就是比如说这段话再改这个内容，然后我要改下一段话了，我会直接就开一个新的对话。我不知道这种使用方式对不对？但是我目前我自己是这么使用的习惯。

Speaker 1 55:33 
你再说一遍，就是比如说。

Speaker 2 55:35 
就比如说我润色这一段话，已经润色完了，我就会离开这个对话，然后开一个新的对话去为了我的下一段话。

Speaker 1 55:45 
对，我其实有个疑问，为什么要这么去润色？因为。

Speaker 2 55:48 
我不知道，我只是有这个习。挂而已，就是。

Speaker 1 55:51 
说你整篇文章其实都是一篇，对不对？但你还是会拆成几个对话。

Speaker 2 55:56 
拆成无数个对话啊。你可以这么理解，就是我一个小任务只开一个对话。

Speaker 1 56:03 
很新奇的使用方式。

Speaker 2 56:06 
因为我不想让他记忆这么多，然后勾连那么多。

Speaker 1 56:12 
你就很担心这么多这一个对话把你很多东西都连在一块了，对。

Speaker 2 56:17 
不对？因为我不需要他直接有关联性。

Speaker 1 56:23 
你担心因为你想你后面的修改吗？可以这么理解。

Speaker 2 56:27 
不是，就是我认为你需要在一个对话里的，是因为你前后的东西是有关联的，他需要去不断地追问或者怎么样的，他是在一个 context 下的一件事情，那他只是我个人使用习惯了，那我这一段话改完了，对吧？嗯，我要改下一段话了，对吧？这段话它要表达的思想是另外一个思想了，对吧？就是它是一个，那我要修改这段话了，那么我就会把新开一个对话框，然后去处理这一段话。

Speaker 1 56:56 
嗯，其实我很好奇的是，因为你这段话其实都是这一篇文章里面的，对吧？可以这么理解。

Speaker 2 57:03 
但是就是，但是我只是做语言润色。

Speaker 1 57:07 
就是你不会有后续需要过。

Speaker 2 57:09 
链。对。

Speaker 1 57:10 
后续没有后续。

Speaker 2 57:12 
那对，就是我每个任务其实只是你帮我修改一下这个段话，而且只是要上一个 native speaker 就行了，你不需要做太多的。

Speaker 1 57:20 
那其实你刚才提到的这三，就比如说 little child review 的 summary summarize，然后让它精简finding，你可能也是一段，可能就换一个。

Speaker 2 57:29 
不是这是一个任务。

Speaker 1 57:33 
这个就属于。

Speaker 2 57:34 
就你，比如说我告诉他这 5 篇我已经是 summarize 好的这个 literal review 了，我要写一个paragraph，对吧？嗯，那你就，那我接下来可能就是你已经写出来了，那我不断地跟你迭代，我告诉你这样写的可能不合适再修改之类的。那我这段话现在我写出来了，我再修改一下，那他完成的是一个任务在 for 这 one paragraph，所以他在一个对话框里发生。

Speaker 1 57:56 
如果写第二个段落，你就会换一个。

Speaker 2 57:58 
换一个新的呀。

Speaker 1 58:00 
诶，那你如果想把几两个段落连在一起怎么办？

Speaker 2 58:03 
我为什么需要连？

Speaker 1 58:05 
不是有一个上下文逻辑关系，比如说可能。

Speaker 2 58:08 
我自己解决这部分了。

Speaker 1 58:10 
你自己解决我大概 get 了，就是说不管什么任务，反正这段话就归这段，就归一个对话框，然后就知道就是。

Speaker 2 58:17 
它是取决于我想让 GPT 干什么，比如说我的核心诉求只是让你帮我润色语言，那这件事情是不需要所有的东西发生在一个对话框的，因为它不需要。

Speaker 1 58:31 
嗯嗯嗯，明白了，明白。

Speaker 2 58:33 
那如果我想说我要把这三段话变得前后连贯，那它就需要放在一个对话框里，对吧？它取决于我的使用需求，我的使用需求是它不需要发生在一起。

Speaker 1 58:47 
那我那能不能理解为比如说你这三段话要关联在一起的话，那你会不会出现一种使用情况？就是一段话一个对话框，然后最后再使用一个对话框把三段连在一起，我不。

Speaker 2 58:58 
需要，就我没有这个需求，哈哈哈，你理解。

Speaker 1 59:03 
吗？我理解，其实大概能懂，就说像我们这就是有相关联的一些任务，就是会放在，就是。

Speaker 2 59:10 
你需不需要他们发生在一个对话框，取决于你现在想要让他完成什么任务。

Speaker 1 59:19 
能get，对吧？

Speaker 2 59:21 
我大部分时候只是需要让他帮我润色一下语言，每一段分别润色一下就行了，那它没有发生在一段话里的需求，反而你可能会干扰他，让他做出一些不必要的修改。

Speaker 1 59:38 
那我觉得你的 check GPT 的 memory 应该是很散的、很碎的那一种，就你有看过你的 memory 没有？你可以看一下你的 ChatGPT 的memory，它会满掉，你可以清，也可以删掉一些你觉得没用的。

Speaker 2 59:53 
就怎么说，他也没有影响到我啥，所以我也就没。

Speaker 1 59:58 
管，因为他是会记住，比如说这个用户他可能倾向于喜欢论色文章，然后他就会一直记住，就他会记住这些一些奇怪的点。

Speaker 2 01:00:07 
对，特别好，就是他就是我现在要用我这个账号，就是因为他记住了，他知道我的偏好，记得非常好，我非常满意。

Speaker 1 01:00:17 
OK，OK，OK，我，我大概能懂你意思，能。

Speaker 2 01:00:19 
懂了，然后我再用一个新的账号，我就觉得好难受，就它润色的方向跟我想要的方向不一样，我真的不想再去调教另一个新的了，就这种感觉。

Speaker 1 01:00:29 
我懂，就是不想再带一个本科生了，太蠢了，哈哈哈。唉，懂得都懂，那就是你用了将近有两年了，对吧？那你觉得对于你目前你的认知，或者是说思维深度，或者是说效率质量，你觉得有什么变化吗？毕竟也用了挺久。或者说跟你读博的期间对比的话。

Speaker 2 01:00:57 
喂，我想想，我觉得还好，我也，我不觉得他对于我的思维方式产生了一个很大的影响。

Speaker 1 01:01:14 
就说你就说它没有影响到你的writing，也没有影响到你的各种方面，对吧？

Speaker 2 01:01:25 
就你很难去界定影响，对吧？因为就我没有办法想象如果我没有使用它会是怎么样？

Speaker 1 01:01:36 
就是说你以前呗，比如说你以前写论文肯定那时候还没有 GPT 的时候。

Speaker 2 01:01:43 
那会可能就，但那会有 grammerly 嘛。

Speaker 1 01:01:47 
哦，懂你意思就是说反正就是现在效率可能比以前高，但。

Speaker 2 01:01:52 
凑合过呗。对。

Speaker 1 01:01:55 
OK，我大概的了解。那你觉得你之后的协作方式会出现什么改变吗？毕竟 AI 一直在发展。

Speaker 2 01:02:08 
我对于 AI 去从事比较 critical thinking 的这个部分一直是持一个比较观望的态度。

Speaker 1 01:02:17 
就对。

Speaker 2 01:02:18 
所以然后它对于我来说，它在我的使用场景中，虽然它在迭代，但是我也没有说，虽然说我知道 AI 一直在更新了，怎么样？嗯嗯，但是其实我体感上的它的改变，我只是会觉得说它在润色的方向上跟我自己的语言表达方式更合、更配合。

Speaker 1 01:02:44 
懂你意思就是说他而已，他。

Speaker 2 01:02:47 
的对他只是说对，所以我没有会觉得就是我其实从我的使用体感上来说，我没有觉得他变得聪明或者怎么样，我只是觉得他更理解我的写作风格了。

Speaker 1 01:02:59 
我的我能懂，就是说他慢慢地，慢慢地，慢慢慢慢地能理解你的意图，意图能理解得更清晰了。

Speaker 2 01:03:06 
我很难说这是因为 AI 本身的嗯发展使它的嗯性能提高了，还是因为我使用得多了，我输入得多了，它学习了我的方式，明白我的意思吗？

Speaker 1 01:03:20 
嗯嗯，明白。

Speaker 2 01:03:22 
所以我很难说以后 AI 的发展又能够对我的协同方式有怎样的变化，因为我难以说我之前的使用的体验的改进是因为我使用频率多了，还是因为技术的发展？这样。

Speaker 1 01:03:35 
子，嗯嗯，都会有影响吧。对，诶，对，那比如说，嗯，因为你是属于很有很就是理性且有思考的人。那如果，假如说你对于本科生，或者说对，就对于本科生来说，他们去使用ChatGPT，你会给到一个什么建议吗？就是说可能指导或者说就有什么好的一些。

Speaker 2 01:03:59 
那对于本科生就说你把它当成个小学生在用啊。就是你要混，就我觉得是这样子，我觉得就是哦使用AI，你应该是你去教 AI 怎么去做事，而不是用 AI 来教你。我觉得。

Speaker 1 01:04:13 
但如果其实因为对于大学生来说，我觉得 AI 其实能力应该说还是高于了大一大二的这样的一个学生能力了。

Speaker 2 01:04:23 
我觉得就是说你应该知道你要什么，就你在使用 AI 的时候，你应该知道你去要什么，就是怎么说？

Speaker 1 01:04:33 
就是你知道你需要它的输出结果怎么去符合你的预期，是吗？还是说？对。

Speaker 2 01:04:38 
对对，是的。

Speaker 1 01:04:39 
还说你不是我，我意思还是说你清晰地知道你这个任务是什么？是哪？

Speaker 2 01:04:44 
我我觉得你要清晰地知道你自己的任务是什么，然后你自己心里要有个map，你要怎么去达到这件事情？然后你只是分配任务，让他去做了这个任务，那你需要跟他一个一个地去做任务，执行的就是就我觉得在使用的过程，就像说就是你首先你自己要知道你这段要写什么。明白这些点是什么，然后你再让他去写这样子，而不是说你就直接帮我写吧。

Speaker 1 01:05:15 
啊啊，所以相当于就是说你就是至少能有个大概的目标，然后同时这个目标要完成什么样的程度自己是需要有判断的。

Speaker 2 01:05:26 
对，而且就是它不仅是任务本身，就是因为我主要是做的是写作任务，所以我的建议可能是更针对于写作任务，我认为就是说你自己永远要知道你想要写什么。

Speaker 1 01:05:43 
你就我，我就大概能懂，就说你希望知道自己能。但如果我其实很因为你你也懂，就本科生其。可能在写论文都不知道自己要写什么。

Speaker 2 01:05:52 
对，所以这是我觉得非常就是一个issue，就是其实就如果他直接让 AI 生成的话，那对于他来说他就是缺少了这一部分的训练。

Speaker 1 01:06:02 
嘛。对对对，所以这是。

Speaker 2 01:06:04 
其实就是那15，哎，我说你要把它就是如果说你本科生使用的话，你可能你把它当成一个高中生，anyway，就是大概这个意思，就是说你要告诉他你需要写什么东西，你自己要知道你要写什么。你要把这个 break down，或者说你至少要跟 AI 一起把它 break down，然后你自己要有这个脉络，然后你自己都要清晰地知道你要写什么、怎么写之类的。

Speaker 1 01:06:26 
对对对，但我知道你的意思就是如果出现了这么一个问题，所以就属于一个，因为比如说大学生写本科论文，可能自己都不知道本科论文是什么东西，那这时候可能就会出现完全被 AI 带得走，有可能。对，那这时候可能就没办法很好地就应用是你说那个方式，他很清晰地知道任务大概完成什么样的程度，可能 AI 可能才能知道这个任务要完成什么样的程度。

Speaker 2 01:06:52 
对，所以你要从 AI start 的，就，你不能直接让 AI 说你把这段写出来吗？你要跟他协作去思考吗？你就是说比如你要写个论文，那你刚才讲我现在准备写个论文，这个论文是关于什么什么的？我现在在准备什么？什么样的部分？那你认为我可以把它分成几个任务？然后你自己就是，虽然我知道 AI 是个黑箱，但是你尽量把它清晰一点，你自己要知道这个过程的procedure，对吧啊？而不是说直接把这个东西写。

Speaker 1 01:07:19 
出来，我其实能理解，就是说你可以拉 AI 来帮你 break down 那个任务的，就是。

Speaker 2 01:07:24 
对，就如果你自己 break 不会 break down，那你让 AI break down。对，然后你让 AI 帮你去思考下一步是什么，那你跟 AI 一起协作，那总比让 AI 直接给你生成一篇好很多，对吧？

Speaker 1 01:07:35 
对，就相当于这个过程，相当于就是说他帮你输出了一个框架，你可以去看一下这个框架哪些点合适，哪些不合适，你再换掉他，然后再让他对点，一个点一个点地去完成。对。

Speaker 2 01:07:48 
嗯，然后我觉得很多时候就是我还是那句话， AI 是一个语言工具。嗯，大量的东西，一手的资料还是要去自己去看。嗯，对，不要信任，真的不要信任他。

Speaker 1 01:08:00 
这我知道他会犯错的。对，这对于博士或者是 research fellow，那肯定是OK。对，我其实就是在关注这个思考的一个问题，就对于人的一个思考。嗯，对诶，刚完蛋，刚突然想到一个点，我给忘了。

Speaker 2 01:08:18 
没事，你再想一下。

Speaker 1 01:08:20 
没有，因为时间有点久，我怕耽误你时间。

Speaker 2 01:08:23 
没关系。

Speaker 1 01:08:26 
我刚才想到想就是讲 break down。哦，我刚，哦想到那个点了，就是你说就是说也，其实也应该让大学生去把他当成一个，就让他意识到他是个高中生或者是个小学生，首先他要有这个意识，对吧？

Speaker 2 01:08:40 
就是你手把手地去教他怎么去做事。

Speaker 1 01:08:43 
嗯，对，就相当于要有认知上的一个改变。

Speaker 2 01:08:48 
我是觉得这样会。

Speaker 1 01:08:49 
好一些。对。

Speaker 2 01:08:50 
可能是因为我是一个这样的人了。

Speaker 1 01:08:53 
没有，这肯定跟学科有关，因为从教育心理学或者是说什么就教育性来看的话，那肯定在这种，就我觉得应该会比我理了解得更清晰一些吧。

Speaker 2 01:09:05 
就是反正因为我从最开始我就不信任它，所以我从始至终把它当成一个工具，所以在我的使用方式上就是我觉得就是你的观念影响你的行为。嗯，我的观念是这样的，所以那我的行为就必然是因为我不信任他，所以必然我就会，我会觉得我要去 supervise 这个过程，我要去 control 这个过程。

Speaker 2 01:09:28 
但是你其实你对于本科生来说，他们的观念，可能他们就是觉得 GPT 比他了解得多，比他聪明、比他better，但他们那他可能就会更倾向于他来做那个被支配的部分，因为他的观念就是这样的想法，但你也很难说他这个观念对或者不对，那确实 AI 会知道的比他多很多。

Speaker 2 01:09:49 
但是anyway，我觉得他至少现在不是提 AI literacy，他至少他要知道怎么去使用，对吧？对，然后你至少你不能让 AI 去非常 general 的，就是给你一个 output 之类的。嗯，你还是要学会 break down， step by step，因为很多事情就是你需要去了解这些过程，我觉得对于人的本身是一个训练。这样。

Speaker 1 01:10:13 
其实我觉得你刚就很之前提到的说，对于可能，我觉得可能也取决于这个任务的本身，可能比如说可能只是为了满足一个课程作业，那这时候可能大家都希望水一水嘛，对吧？或者说不喜欢的投屏就是相当于水一水这篇论文可能也会取决于这个任务本身的一个，就对吧？任务本身的一个要求，应该可以这么说。也对，是的，你会决定 AI 怎么去用。嗯，明白，OK，OK，我明白，OK。好，我想一下还有什么应该差不多了。好呃。那我后续肯定会 set up，对吧？哈哈哈，就好，哈哈哈，对，其他时间我也不知道你有没有时间，到时候再问你。

Speaker 2 01:10:58 
到时候你再给我发schedule。

Speaker 1 01:11:01 
对对对，发邮件可能大概，我目前预计应该，我猜应该是 10 月，我应该会再做一个实验，然后我希望尽快做完，我想毕业。

Speaker 2 01:11:11 
哈哈哈，你几年级了？

Speaker 1 01:11:13 
我延迟了，在第五年了。

Speaker 2 01:11:16 
嗯，我的天呐，加油吧哥们。

Speaker 1 01:11:18 
好的，加油。

Speaker 2 01:11:20 
妈耶，你这又是 interview 又是实验。对，我是真 workload 太大了。对。

Speaker 1 01:11:25 
有interview，然后还有 design study，还有那个实验室实验，我真的有点痛苦。

Speaker 2 01:11:34 
你给自己整的太多了。唉，可能你老板要求高吧。

Speaker 1 01:11:39 
要求很高，我导副校长。要求好高好高。

Speaker 2 01:11:44 
那你老板要求高，那你只能干不了哇。不是，你这访谈你分析就要很久啊。

Speaker 1 01:11:50 
对，还要 code 你 NV 我们，对，还要code，对，然后他给我安排了Ra。

Speaker 2 01:11:57 
用起来嘛。

Speaker 1 01:11:58 
对，他在帮我做访谈，他去帮我做那种，我现在每就我们每个人都分了一点。对，每个人都分了一些。嗯，OK，OK，OK。好的，感谢。

Speaker 2 01:12:11 
你。没事，你后面可以再给我邮件，这样子。

Speaker 1 01:12:14 
好，没问题没问题。好，谢谢谢谢，好好好，那。

Speaker 2 01:12:18 
今天那就结束。

Speaker 1 01:12:19 
好好好。哦，对，谢谢你。要那个钱的话，我因为他我们这边是扣，就是公司的 pay now 的话，我觉得可能就财务部门我不确定，可能，反正会尽快，对吧？我尽快尽。

Speaker 2 01:12:31 
没事，没关系。

Speaker 1 01:12:34 
告诉一下说一下。对。

Speaker 2 01:12:37 
可以，没问题。好。

Speaker 1 01:12:38 
谢谢，谢谢啊。


受访人21:
2025-08-25 23:38:16 CST|1h 6min 27s

Keywords:
文献、新加坡、business use、科研、答案、传播学、谷歌、学术、企业、老师、搜索引擎、研究方向、人机交互、学习模式、工作效率、思考方向、方向发展、工作软件、写作需求

Transcript:
Speaker 1 00:02 
刚说到，就是说想了解一下高频的使用 ChatGPT 的用户，对于就是怎么去使用 AI 的？然后就是他的一个，就是你们的一个协作的一个模式，然后还有你的一个思考的一个方式，以及就是主要就这两个方面嘛。然后你有什么问题吗？对于我这个项目。

Speaker 2 00:28 
嗯，没啥问题，你就问就可以了。我，我就是，对，我要讲我为什么参加这个吗？就是因为我们也要，差不多也是做这个人机交互相关的那个。

Speaker 1 00:42 
没事没事，我会之后问的话你应该会聊到就是，OK，嗯，那你简述一下你目前的职业或学习的领域。

Speaker 2 00:50 
我目前是也是 into 的学生，然后我 research student，然后我的主要的这个研究方向是也是 human AI interaction，但是我是在传播学院，所以是在就是传播学的这个，嗯，学科的视角下，然后可能是传播学，然后社会心理学研究这个比如说人使用AI，它可能我的那个课题是跟就是 conversational chatbot 有关的，然后在这个交互的过程当中，它交互之后或者说只之中可能有一些变，有哪些变量会比如说这种会引起什么影响吧？就差不多是这个意思啊。

Speaker 1 01:40 
也想说就是在人人机交互过程中， AI 的一些什么变量会影响到人的什么什么。

Speaker 2 01:49 
对，主要是技术的影响。

Speaker 1 01:54 
传播学也在做这一块吗？

Speaker 2 01:57 
嗯，有啊。你是什么？你是什么商学院？

Speaker 1 02:02 
对，商学院的 information system。

Speaker 2 02:05 
信息系统。那我们还是蛮相关的，我不知道你去不去 ICA SA 有一个大的那个就是。 International Communication Association. 它是国际传播学会，然后它有一个大的session，就是 INFO system，就是在传播的视角下研究 INFO system 对人的一个影响，就它的 INFO system 可能是比如说这个chatbot，这就是一个非常微观的，然后突然宏观的那种大的 info system 的这个技术也还是有的。嗯，我们系有老师做那个 organizational behavior 跟你们 b school 的那个更贴近了，就比如说这个 AI 里面不是在协你这个课题不是跟协作有关。嗯，比如说我同步的一个波姐就是做这个 organizational behavior，但是她做的是置信的，就是。

Speaker 1 02:57 
就访谈、问卷。

Speaker 2 02:58 
访谈，就是在嗯企业里面，然后比如说他们运用那种协同式的工作软件，就是跟 AI 相关的，这这这种怎么优化他们的体验之类的这种。

Speaker 1 03:12 
这这我知道，这这我们也有老师在做，就是什么 AI 客服，对于什么什么什么的公司绩效的影响啥的，我也搞不懂。

Speaker 2 03:20 
哈哈哈，对，差不多吧，就这种心理学的方法都是这样。

Speaker 1 03:27 
那你就是在这个领域的话，你会用，你会处理一些哪些类型的任务？就你这个专业或者是这个研究。

Speaker 2 03:36 
就是我用比如说 ChatGPT 的工具就是怎么辅助我科研，是吧？

Speaker 1 03:42 
也行，科研或者生活，什么。

Speaker 2 03:44 
就是行科研的话就是可能最大的对于我来说的用处还是读文献，然后。嗯，可能最大的用处就是读文献，然后汇报文献，还有就是搞一些想法的，这个创意有的时候会和 ChatGPT 讨论一下，它更像，如果说非要做 HCI 的，可能都知道metaphor，这个 metaphor 非要给它一个 metaphor 的话，它可能更像是我的一个加强版的这个搜索引擎，或者说加强版那个翻译器就是我，比如说我通常会用到 ChatGPT 去帮我快速翻译一下，然后 grasp 这个文章的要点，嗯，这样的话我能够节省很多的时间用来。比如说做我的研究设计，或者说是，嗯，更多时间用来找变量表，这些就是能大大节省时间嘛。因为我还是一个非母语的，非英语母语的这个学习人阅读文献这一块确实是可能会花时间，会花多一些啊。

Speaker 2 04:52 
然后是 idea pool，这个就是加成版，所以就是有的时候我们自己想的只是很小的一个方面，然后它可能你把你这个 idea 升输入到这个 chatbot 里面，然后它，嗯，虽然他可能总在是用一种 p policy 的方式回应你，但他可能会带有一些detail，是你没有想到的。嗯，那我可能就大概看一下，就是他可能这个方面可能还有一些东西是我需要照顾到的，然后我再去自己再去搜啊。然后这可能是对于我来说最主要的这个两方面的一个用途，生活层面的话，那我其实我觉得我还算是比较重度的使用患者，因为我同屋的其他的这个几个同学都是来自其他国家的，嗯，然后他们也岁数比我大，有的来自印尼，然后那个我刚刚说的新加坡，这个坡姐，还有这个嗯。

Speaker 2 05:42 
反正其他都是新加坡人，包括他比我们岁数也大一点，他用 AI 可能这只是GPT，但是我可能会比较是不同 AI 的这个长处，然后，嗯，就用得多一点，比如说短的这个生活类的问答，可能会用国内的这种APP，会多一些元宝啊。然后 DeepSeek 它可能就是跟中文文献的训练有关，它的那个中文的比如说生活上的信息接触可能触达会更方便一点。然后写作的话就是润色可能会用一些文笔更好一点的AI，就这种会就是比较，然后在也是在学习的过程当中，虽然我觉得我比他们强一点，但我觉得还有比我更强的，就是人家真的是就是玩 AI 的，就这种，所以还是要继续学习。

Speaker 1 06:37 
嗯嗯，行，那我等下可能会跟你具体聊一下这些任务哈，那我还是先把基础的一些问题先聊一聊啊。那你先说啊。对，那你大概是从什么时候开始使用这些生成式 AI 的呀？

Speaker 2 06:51 
嗯，我想想。

Speaker 1 06:53 
22 年， 23 年，估计 23 从。

Speaker 2 06:57 
差不多刚开始出来的时候， 23 年的时候当那当时 23 年年初的时候。我当时还在国内，但是因为我当时的那个在国内的时候，有个同学他是计算机专业的，他就在国内不能用GPT，然后他自己搭了个墙，然后那个我们自己弄的墙。其实也都上不了，但他自己搭了一个，然后我们那阵就可以开始玩这个东西，但他那个不太稳定了，就是有的时候能用，有的时候不能用，后来国内这他这 AI 发展速度也很快，后来新加坡又是一个，当时也是没有 ban 很多，那个就没有加很多限制，所以而且那个时候刚开始上课作业也很多，必须要用AI。你就是差不多从那个时候开始。

Speaker 1 07:43 
对，OK，那其实说，所以一开始用的时候，你会用到什么领域啊？应该一开始不是科研，对吧？

Speaker 2 07:51 
嗯，最开始的领域可能还是跟科研，因为我之前的工作是跟科研相关，但是不会说是那么特别，就是说像写文献那种，之前的更多是个科研管理层面的这个，而且最开始大家用的时候肯定也就探索性质就是那种啊。对对对，对吧？你就是玩一玩，而且你不可能就是非常非常的那个啥呀。嗯，当时我记得我还加了一个那个 QQ 群，后来那个同学他就毕业了，那个学长就毕业了，然后我就，但我还想玩这个东西，然后我加了一个QQ，那个 QQ 群等于他是当时就是把那个课镜像过来， GPT 镜像过来，然后他自己搭了一个那种套了一个壳，然后他在群里分享他那种内测链接，然后就可以玩一玩它，当然那个东西就是准确率或者说是反应速度都不如真的 GPT 好，但就是玩一玩。

Speaker 1 08:52 
那其实说就是后面慢慢地才说他的能力提升了，所以你才用得他更多了。

Speaker 2 09:00 
可以这么说，而且客观条件来讲，因为来到新加坡你用过大许多吗？

Speaker 1 09:13 
刚刚说什么？到新加坡什么？听得见吗哦？刚刚才有点断了，喂喂。哦，喂喂，可以哈。OK，就刚才说到新加坡什么，然后那边断了一下。

Speaker 2 09:28 
OK，那我继续说跟整理一下思路，就是客观条件是因为来新加坡比国内就是有更多条件接触到这些嗯。嗯，不一样的软件，因为国内其实还挺多限制的，就你不能什么软件都用，然后用什么，嗯，不是很方便啊。嗯，再有一个就是客观条件，就是这些软，这些模型的这个能力确实是提升很多。嗯，也确实更方便了。是现在就是国内你要想用，但我知道我国内做科研的也基本都在用，就不过你要花点钱，就是额外花一些费用嗯。

Speaker 1 10:06 
那你目前所用的一些，你最习惯用哪些版本啊？就是因为肯定AI，它和工具很多。

Speaker 2 10:16 
其实最重度使用的还是GPT，因为它稳定。我之前重度使用过的还重度使用过cloud，但 cloud 它很容易被封号嘛。然后有一次我写的东西还挺重要的东西啊。我好像就是因为回了一次国，我再回到新加坡，他那个号隔了大概一个礼拜突然就 ban 掉了，然后我再怎么申诉了好几遍，可能申诉得不下 10 遍，他那个号现在还没有给我找回来。

Speaker 2 10:44 
以后我就cloud，就是轻，非常轻度地在使用像这种它管得比较严的这个APP，它当然它那阵 cloud 那个输出的那个结果非常好，就是还是比较灵敏的嗯。他可能为了保证一些质量，然后保证别他那个模型那个就是清洁度，他，嗯，用这种方法就导致我有很多数据都就没来及存，有对话没来及存就不那个什么了。嗯，所以因为 GPT 还是比较稳定，虽然它可能算不上最聪明的，但是还是常用它。那有，嗯，还有嗯隔，还有其他的，我想想。

Speaker 2 11:25 
对，谷歌，你先，你说啊，谷歌的，对谷歌的，我是在搞了一个那个 Pro 以后才重度使用的，也谷歌的那个使用的那个频率也挺高的，就是它因为回答没有长度的限制，所以可能翻译或者说是特别是用一些 Google cloud 它系列的那个文件的时候，比如它能快速地存在谷歌那个硬盘上的东西，能快速给你 grasp 一些重点，这个还用还挺多的。嗯，还有什么。

Speaker 1 12:02 
我现在开了好几个会员吗。

Speaker 2 12:06 
那个会员其实是你想办法就能免费开的，它有一年免费。

Speaker 1 12:11 
就说用那个美国 edu 或者是印度的什么。

Speaker 2 12:16 
对对对。

Speaker 1 12:18 
OK，所以你会员只开了谷歌，不开了 GPT 的。

Speaker 2 12:22 
对， GPT 的。

Speaker 1 12:25 
OK，但是，但 GPT 不是最近出了5，你也没感觉它下降了呀。

Speaker 2 12:31 
我觉得它是有一点下降，所以我有的时候用那个 o for mini， o 我最喜欢的是那个 o for mini，因为它会记住你之前说的话，他的记忆会更好。然后他的那个回答就是 task response 也比较精准。5，然后我用 5 的话，它现在 default 经常给你5，我也会用5，是用 thinking 比较多，就是不是那个 general 的。

Speaker 1 13:01 
我，我懂我懂。嗯，那 offer MINI 是哪个企业来着？我都没听过这个。

Speaker 2 13:07 
那就是拆 GPT 的 o for mini，它不是有很多种类型可以。

Speaker 1 13:11 
选吗哦？我想起来了，上一个版本的，对吧？就那个。

Speaker 2 13:17 
对的。嗯，我对，我还是会用上一个版本的。对。

Speaker 1 13:20 
我一直用 o three，所以我一直没有用过 O4 的那个版本。

Speaker 2 13:25 
我可能，嗯，我觉得这可能跟他擅长的领域也不一样，比如说你是做这个 business 还是什么？他们理科的人好像用 o three 也多一些，就一些数理的这个推导什么对 o 付他可能就是回答得更像，就是更知道你想在讲些什么，所以他回答的我觉得还比较倾向于人类的那个人味比较重一点。

Speaker 1 13:49 
嗯，明白，那现在也没办法体验了，对吧？可以，只能调他API。

Speaker 2 13:55 
可以，他有的，你看我打开GPT。

Speaker 1 13:59 
现在这边。这个 PPT 好像已经没有这几个 model 了，我看的话就有的，我。

Speaker 2 14:05 
前两天还在用啊。嗯，传统模型这里，因为最开始有的 open mini 他最开始没有给出，最开始不让大家用，然后 Twitter 上大家都在骂，说那个奥特曼不干人事，然后来他又把这个 access 给打开了。

Speaker 1 14:22 
是吗？我还刚退订了GPT，哈哈哈。

Speaker 2 14:28 
你这是在国内吗？还是并没有。

Speaker 1 14:31 
在新加坡？哦对，我退订了。

Speaker 2 14:34 
还是可以的。很，还是可以，那个退订也不失为一种策略。嗯，你退订了之后，嗯，再现在不是有那种 dark design， dark design 那个就是你，它现在也跟那个 WPS 一样，你点要退不退的时候它给你打折。对。

Speaker 1 14:51 
然后我还是退了，哈哈哈，好吧，没事，问题不大啊。然后，诶，那你其实使用频率是不是应该很高啊？就是这些AI，对吧？这么多个。

Speaker 2 15:04 
对啊。

Speaker 1 15:05 
就基本是每天都在用了。

Speaker 2 15:09 
基本上每天都在用，我们干活的时候都在用。因为每天都在干活，所以每天都在用。

Speaker 1 15:14 
没有 user 福利，没有周末，是吧？

Speaker 2 15:20 
嗯，差不多了。

Speaker 1 15:22 
OK，那我们就继续聊一下你刚才提到那些任务，因为我其实想知道就是你有没有使用的一些，比如说你觉得一些 interesting insights，或者是说你的协作方式可能会有你特殊的点嘛。对，我就想了解一下这个。

Speaker 2 15:41 
什么意思？是我因为和 GPT 互动而形成的一种我特殊的写作方式吗？

Speaker 1 15:47 
对，可能比如说你的 prompt engineering，或者说你的 prompt 怎么用的？或者说你的跟他合作的一个方式，可能你觉得哪些他不擅长，你就不会去考虑用到，就是，可就是你的一些思考，我其实就想聊一聊这种东西。

Speaker 2 16:06 
可是你们这个不是跟在 organization 里面的吗？还是不是还说你要研究。

Speaker 1 16:13 
individual？我是 individual 方向的就是organization，它其实更偏向企业管理，然后我们在 information system 下面更偏向于 individual 微观层面的啊。对，所以我更加偏向于教育学、心理学这种发。

Speaker 2 16:32 
那我真的蛮交叉了，真的。对，那我们还是可以，可以，以后可以潜在的 Po potential collaborator 可以。行，那我就直言不讳了就是嗯。嗯，我觉得他不太擅长给出反对意见，所以。

Speaker 1 16:55 
有点讨好型人格，对吧？ way hello Wei。

Speaker 2 19:10 
喂，你们可以听到吗？

Speaker 1 19:12 
可以，该，OK。

Speaker 2 19:14 
我电脑死机了刚才，哈哈。

Speaker 1 19:17 
不好意思，我还以为我的网络又不行了。我还以为我。

Speaker 2 19:21 
也刚才想给你发个消息，发现没有办法找到你。就是看赶紧把它重新重启，然后再进来。不好意思，真的，我这个电脑不要买Thinkbook，这破电脑真的是让我。

Speaker 1 19:37 
drive me。我懂你， Thinkbook 好像确实一直遇到各种问题。那我想到我朋友他也是 Singapore 号，就买了Mac，就跟我一样，我也用了Mac，就大家都用Mac。

Speaker 2 19:46 
真的是国补，真的害死人。我再也不买这个了，等回国的时候再换吧。气死我了他已经换两次了今年。

Speaker 1 19:55 
那确实要换，要不然很影响效率和工作。我觉得。

Speaker 2 19:59 
他每天必死一次，哈哈哈，他一般在 9 点钟的时候死，没想到今天提早这么早，不知道礼拜一可能给他太多 mood 了。接着说你开始录了吗啊？你开始录了我就开始说，OK。

Speaker 1 20:13 
那说到的是讨好型。对，讨好友好就是不会。

Speaker 2 20:16 
反对，他不太会给反对意见。所以比如说有的时候我觉得我这个 idea 可能需要一些 feedback 的时候，我就不太会找他搞这种任务。但是比如说就像刚才我说的他，我如果需要一些，比如说发散的，或者说是，嗯，需要我开始一个东西，我不知道怎么有哪些思考方向的时候，我会问他，虽然他给的方向都可能会比较浅，但是嗯，他会给你一些就是一些提示，然后让你继续往下想，到底怎么想？然后你就会想，嗯，根据他的这个反馈，你会比如说他这个 ChatGPT 这回给的反馈可能比较general，但是我可以从哪个方面 improve 他的这个方面的idea？然后这样的话我大概又有一个想法再去搜，然后我再去就是整理我的想法，然后再发给他，然后再进行讨论，就是差不多是这种模式，我觉得对于我来说是比较第一，这是第一个比较有用的一个点。

Speaker 1 21:24 
跟，那对于这个协作的话我其实有点好奇，就是你一开始是输入什么给他，是输入你的 idea 还是。

Speaker 2 21:33 
这个还算，比如说研究设计阶段？嗯，我大概有一个想法，我说，比如说，嗯，我想研究这个，嗯。 human 和 AI 的这个团队合作行为，嗯，我比如说identify，我随便乱说的，我这并不是我的研究方向。嗯嗯，对，我就大概讲一下我这个模式，但是我并不知道这个领域是哪些人在关注，有哪些学者在关注，然后这个领域比如说更细化的是在什么场景下，人和 AI 的这个协作，嗯？会产生什么样的问题？有哪些被研究？然后我可能会大概写一个 prompt 给他，然后他就很快地给我feedback，这样的话我就能知道，哦，可能是，嗯，比如说是在艺术领域，然后艺术家和 AI 进行合这个合作，然后能帮助他们解决什么问题？然后有哪篇文献，然后大概就是这样吧？就是这样的一个。他是有那个方式，他。

Speaker 1 22:39 
给的文献不是一般都说会有一点问题，就你还是挺相信他提供的一些信息，是吗？

Speaker 2 22:46 
不不，我还是要去 check 的。嗯，还是要。嗯，但我常用的一个它是不是直接的GPT？它是那个consensus，我不知道你用没用过呃。听过，就是consensus，它是 based on 那个，它等于是一个插件插在那个 GPT 里面，插在 GPT 里面，然后它有一个链接到它 consensus 这个平台，那平台上会返回它的那个，比如说一些期刊的基本的一些论文什么的哦。

Speaker 1 23:22 
你意思。

Speaker 2 23:23 
说对，但我说这意思其实不是文献搜索，就是大概的，比如说这个领域我不太知道，我不知道怎么去 touch on，然后呢？我想大概地了解一下，然后我就还是会看一眼 GPT 的这些东西。嗯，它会帮你整理很多信息，咱们可以给你形成一个结构化的一个东西。我就能再去搜。

Speaker 1 23:46 
嗯，明白，其实相当于就是说他是帮你去，帮你提供一些idea，然后这些想法你会去验证，对吧？会一一验证。对对对对。那你觉得他能帮助到你多少？大概确实能有能发展下去的 idea 吗？

Speaker 2 24:05 
这比喻没有办法，因为我没有算过，就，但是一般来讲都是我有这个需求，我就还是会大概去看一下，我就拿它当一个整理信息的一个工具。

Speaker 1 24:20 
明白，就是反正就是多一个渠道来了解一下这一个领域，对。

Speaker 2 24:25 
吧？对对。但是我也会去用很传统的搜索方法。

Speaker 1 24:29 
了，您说然后有个学术就是。

Speaker 2 24:32 
要，对对对，然后 Web science，然后这种有的时候 Web size 就我觉得还是要就多搜一搜，真的是有的时候能产生不一样的这个想法，或者说，嗯，就像拼图你这一块信息在这里，然后它是这样呈现的，然后但是它在另外一个渠道，它可能通过另外一种搜索的一个逻辑，它给你呈现出来另外一个品种。嗯，它可能都有所对你的这个研究，这个领域都有所这个贡献或者说价值，在时间允许的情况下都看看呗。

Speaker 1 25:11 
能懂其实就相当于从就一，就比如说ChatGPT。那你会多考虑多个 AI 来帮你去想这个问题，还是说就用ChatGPT？

Speaker 2 25:26 
我觉得是在我知道。嗯，就光说这个，这这一个领域，比如说我还是要看我的这个大概的这个方向，他可能会他唱什么，那我可能，嗯，最主要的还是GPT，但如果是有中文的这个发表，或者说中文的这个写作需求的话，那我可能还是会用国内的这个 Kimi 什么的多一些，他搜知网的文献会更准一些，或者说对中文的他更擅长组织中文的语言啊。是，但外文的基本就 GPT 了，这个方面搜索的方面有时间的话会多对比一下，如果没有时间可能就只用GPT。

Speaker 1 26:14 
了。明白，所以就是偶尔也是会用多个GB，不，多个 AI 来帮你看一个问题，对吧？就是可能你会输入一样的point。

Speaker 2 26:24 
对，这也不用很久嘛。就是。

Speaker 1 26:28 
但是要。

Speaker 2 26:28 
反正你就给他几秒钟。

Speaker 1 26:30 
对，我的意思是说但是要看他们的答案还是挺耗时的，就每个 AI 肯定输出的答案是不一样的嘛。

Speaker 2 26:37 
还行，看久了你就不会太那个。

Speaker 1 26:42 
但最终还是会通过传统的 Web of science 或者是谷科学术来。

Speaker 2 26:47 
对，它肯定不能是主力了。

Speaker 1 26:50 
然后。

Speaker 2 26:51 
对，是有的时候你主力觉得会有一点那个。

Speaker 1 26:55 
不足了。然后那如果，对，如果你这些验证完，你还会再进一步地跟 AI 协作吗？或者是用它。

Speaker 2 27:05 
嗯，我其实写作上我可能只会用它来润色，就是比如说我的英文不太好，或者说我写的是一个中英夹杂的东西，那我可能会让它就是串一下我的思。对对对，因为我是就是中文，肯定就中文逻辑在思考，但其实英文写作的话，它其实是英文的逻辑在思考。不同的语言是不同的思考的逻辑，那我可能写的到给他这一步的时候，已经是比较成熟的一个东西，就是我只能会让他帮我 improve clarity 或者说是 editing 之类的，看看有没有什么，嗯，用词或者说是结构上能够在 clear 的这个程度。对，我不会说让他帮我写，因为他写的东西我觉得还是不能用。

Speaker 1 27:55 
那你输入的东西就是一段一段地给吗？还是说。是，只是给一个，因为大家会担心学术不端的问题，你是怎么去给这个 AI 的一些你要修改的东西啊？

Speaker 2 28:12 
我觉得这个方面学术不端，是，比如说要看你这个要投的这个期刊，还有你所在的这个学校，比如说，嗯，南洋理工大学，它是怎么界定学术不端？我觉得我用这个范围我远远不到那个，因为我首先这东西是我完全是我自己写的，然后我也没有让它，嗯，进行就润色以外的工作，润色就是编辑文字，对，然后还有就是给你suggestion。

Speaker 2 28:45 
How the wording and learning a better organization, the words.

Speaker 2 28:54 
可能只是对我自己的这个版权问题，可能会有一些issue，因为我 feed 给他了这个，其实像 GPT 这个后面这个公司，他虽然是我可以 declare 说我不把我的材料分给其他的模用于改善模型，但是我其实还是把我这个一部分作品的权利让步给了他。

Speaker 2 29:15 
但是你的这个我们作为一个 individual 的一个用户，虽然我们 pay subscription 给他，但是我们这钱里面其实买的只是他们的这个服务，并没有真的保护我们自己的权益，对不对？我当时是在，我还在新加坡的公司做过实习了啊。嗯，我当时那个公司它是一个制药公司，它等于就是什么让那个它买了这个 ChatGPT 的企业服务？他为了又想要保证工作效率，又想要能够让员工加快效率，就是因为企业都讲效率，他就 build 了一个专门的那个企业的那个GPT，等于企，而且装在了每一个员工的电脑上。就你如果要用GPT，你只能用这个软件，而且你要发的东西必须是合规的，因为它是一个就比较讲合规的一个行业，然后就是包括所有的这个东西。

Speaker 2 30:19 
For personal use shouldn't for business use.

Speaker 2 30:22 
然后它的这个 data 等于其实是不会留，就是怎么说不会那个 share 给那个GPT？嗯嗯，对。然后它是数据是留存在新加坡的，当然这是因为这个公司还比较有钱，他能够做到这一点。那我们作为individual，我们没有这个办法，就只能这样喽，对吧。

Speaker 1 30:45 
那你在实习的时候会做一些什么工作来跟要用到ChatGPT。

Speaker 2 30:51 
很多就是因为他那个等于其实是给他们那个公司 design 了一个专属的呃。比如说最基础的办公功能，那时候其实 GPT 还不能做现在这么多，比如说 agent delegation 这种功能，但是它等于可能你是内测阶段的功能，或者说应他们公司的要求，那些功能就给他们上，比如说是用他做那个嗯 BI 表格的insight，比如说我这个销售数据，然后我通过就是内嵌在这个我的网页端的这个 Excel 里面，我不用很久，不用输公式，不用输那个任何的这个手动的功能，我能够获得一个大概的 Infographic 和今年的这个 year to day 的销量是如何啊。然后这个 rundown 的这个就是转化率 turn over。

Speaker 2 31:46 
Before marketing, can they click through rate to?

Speaker 2 31:51 
节省很多时间在制表和会 PPT 上面，它 PPT 有一个模板，然后比如说那个招聘的那个，比如说招一个Intern，写 JD 就几乎是你 Intern 要干的所有的杂活，然后他都能，就比如说你写一个想法需求，然后他有那种模板，你模板的那个回复给你，而且因为可能是他内部 training 的那个模型，它的其实回复其实是比你 send 给general，我做过测试，就是那种比较纯粹或者对比靠自己做的测试，也那个就是拿同样一条prompt。然后非得给我自己的 GPT 公司的 GPT 就写一个GD，这也没有，那个就是涉及任何隐私招聘 Intern 那种GD，他的那个基于的那个行业的数据库给我返回这条结果比 general 那个 GPT 的结果就是要准确。

Speaker 1 32:47 
所以他如果有提供大量的材料的话，因为他那个公司肯定是有大量材料提供进去了，对吧？就会限定行业了。对对对，那他的总结。

Speaker 2 32:58 
估计，嗯，不止那个公司，你要之后做这个方向，可能新加坡其他的公司他可能都会有这种需求，然后包括国内其实也是你像他，可他除了那种 publish 版本的那个GPT，或者说是insight，还呸GPT，或者他们肯定有一个内测版本的，或者说内部使用的那种，或者是买这种就是搭建 GPT 模型的，需要这种 AI 来辅助他们工作的肯定是有的。其实我当时还想继续做这方面，但是后来没有时间了，我的研究方向主要也不是这一块了，所以就哎这个 idea 就暂时先被存起来了。嗯，对。

Speaker 1 33:44 
诶，就说实习的目的只是为了增加个精力是吗？也还是说，嗯，你了解一下这个。

Speaker 2 33:50 
行，因为当时我没有想做学术，哈哈哈。

Speaker 1 33:56 
OK，OK。哎呦，那这怎么一路学术深似海啊。

Speaker 2 34:01 
你是博几？

Speaker 1 34:02 
我博下学期博 5 延迟了。

Speaker 2 34:07 
OK，对，一切顺利，你马上就要熬出来了。

Speaker 1 34:12 
可能会打算做驳后。唉，随缘吧。

Speaker 2 34:16 
那你都在新加坡了，这不是近水楼台嘛， NBS 又这么好。

Speaker 1 34:20 
嗯，准备问一下导师。还没想问，主要看先不扯这些。刚聊到谁？对，刚聊到说你说的话，那就是说实习这一块，其实它处理任务是主要集中在提高效率上，就是图表和 PPT 的制作，对。

Speaker 2 34:37 
不对？我觉得因为我之前在国内的企业，大大小小的企业也实习过，可能因为我那个timing，他们还没有引入 AI 这个东西，所以我们当时其实我不知道你在没在企业里面工作过，尤其是外企。嗯，最大的工作就是做PPT，无论你在哪个岗位上都要做PPT，都要做presentation，还有基于就什么能够 support 你的PPT，那就是报表最核心的两项工作了，然后就开会。我可能说比较直接，但是，嗯，这是事实了。嗯，你如果在这个阶段提高了很多的工作效率的话，其实有很多就是。嗯，label，就是 manual label 的 work 都可以被大大地简化了。

Speaker 1 35:30 
懂了懂了。所以现在就是说它真的节省了，那其实那但如果在科研上反而就没有那么大的效率的提升的话，除了读文献，对不对？除了读文献这一块。

Speaker 2 35:43 
对于我来说，其实。

Speaker 1 35:45 
诶，我其实很好奇，你说读文献的话，你是把文章这些丢进去吗？然后生成什么呀？是总结还是什么？

Speaker 2 35:55 
没有呀，我可能还是我读到这一部分我会有问题，然后我把这个其实跟他就是 discuss 相当于是这种读法。嗯，因为我觉得我个人是那种，嗯，就是我需要读什么东西，然后来学什么东西是这种学习模式，但有的人不是这种学习模式，所以它可能，嗯， chat BG 对于它来说是一个assistant，那可能对于我来说它更像是一个partner。

Speaker 2 36:28 
To actually discussion leader today.

Speaker 2 36:31 
这种很难很难说了。

Speaker 1 36:33 
那比如说你现在有一篇文件，然后可能这个概念不懂吗？还是说这个什么？因为我觉得文科类的好像都是一些概念理论，这些不太清楚，可以这么去理解，嗯，差不多，嗯，对。然后因为。

Speaker 2 36:50 
是其他的那个，比如说 method 什么，这个就比较清楚吧。嗯， concept 部分可能会抽象一点，所以说我会问问他。嗯，就是这样的话，就你帮你理清一些思路。

Speaker 1 37:05 
你丢进去之后你怎么去跟他讨论？是说你对于这一个理论你有什么看法？还是说你对于这个理论应用于这篇文章有什么看法？你一般会怎么去point？

Speaker 2 37:17 
我会，比如说分情况了，就是，嗯，这篇东西我就会，大概我读完之后我读懂了。嗯嗯，那我可能就不会问一些基础的问题，我就会问一些就是，嗯，这个作者他就是比如说这篇文章写 1971 年的这个作者是一个非常有名的一个作者，然后他领域是什么？他同时期也没有人写文章反驳他，或者说他是属于哪个流派的？然后他为什么这样写？有没有就驳斥他柳派的观点？然后再有一个就是，嗯，就 following 他这个 tradition 会不会有其他的人来补充他的观点？或者说他自己之后有没有什么观点进行了一个补充？有的时候你去问他这些问题，他会给你比较惊喜的回答，当然这个是比较，嗯。

Speaker 2 38:11 
Specific. 就你要看你读什么文献，这个就是理论类文献，或者说是它已经是你非常知道它属于哪个tradition，但有的时候你做实验的时候，或者说更实际一点的文献你不会这种，你就会提一些更像我这就会提一些更广一些的问题，比如说针对这个 specific variable，那其他人是怎么测量的？你可能在他回答当中再去，嗯，返回了一些这种。嗯嗯，你像这个我觉得比较看你文件的类型，因为你文献不可能说文献是一个非常抽象的词，它可能还有很多种类型，你要根据每种文章的一个不同的类型，然后再去，反正我是这样做的啊。嗯，不会说是每一篇文献都是同一个问题。

Speaker 1 39:02 
我能理解。没有，我觉得这种方式挺有意思的，因为我是第一次听到这种协作方式，因为我都访谈了快 20 个了， 20 多个了。对，然后我是第一次听到莱特秋对文献是这么这么去用的。对。

Speaker 2 39:19 
因为这个就是自己的方式了。嗯，密薪属于密薪。

Speaker 1 39:29 
能理解，其实就相当于就是说我这边有点吵你，你会，你能听到吗？

Speaker 2 39:38 
没有，你这个收音效果还蛮好的。那。

Speaker 1 39:42 
是，那说明麦克你可以考虑一下，哈哈哈。OK，刚说到，就是说对于文献的话，你会更加像一个就是讨论，就跟他讨论或者说他也可以相当于是帮你收信息，有这种感觉帮你去收集一些跟这个相关的一些信息。

Speaker 2 40:03 
嗯，差不多就里面就像我刚才说的就是增强版的搜索引擎。

Speaker 1 40:09 
增强版的搜索引擎，但那你用到文献上还会用到，比如说 idea 上，对吧？也研究设计上。

Speaker 2 40:18 
嗯，也要看他具体返回给你的答案怎么样，可能他返回你给你答案 80% 都是不能用的。嗯，因为比较general，或者说是比较就是废话吧。但你要我觉得跟大家对话你就是要有耐心，你就要有耐心，对吧？你最后可能最后反就是你问 100 次，总是有一次是你会发现一些什么。对，但前提是你要问。

Speaker 1 40:52 
对，那你这个耐心指的是你是一会重复问这些问题，还是说引怎么去引导地去问出你想要的结果？

Speaker 2 41:01 
我觉得这个我也还在探索，我是觉得是没有办法一次，我的耐心是说你没有办法给出一个完全精确的prompt，然后你就能想到。嗯，你能得到，你想要你的答案是完全你要建立的预设是这种，就 AI 它肯定是，就是会有一些 repetitive 的，或者说会有一些就是误差的。对，你要接受这个事实，你不能说这东西比我聪明，然后我问他什么，他就返回给我答案，我就觉得他好傻。这不是用他的方式，我觉得，嗯，包括我，其实我为什么这样想，是因为我们之前有一个professor，他就是这样教我的，教我们就他是一个，其实他是一个老年人了，他是一个六七十岁的， 60 多岁，一个教法律的，他就是也刚开始用 AI 拥抱 AI 新加坡人。他就说你不能总是给他一个预设，说他是人工智能，所以他什么都能回答。但是你可以把他想象成一个就是对话者 conversational partner，就是我问他一个东西，嗯，他可能给你一些答案，给你一些想法，你觉得没有用，你觉得有用你就添有用的部分，你看就好了，对吧？所以我觉得包括他说的耐心，或者说是，嗯，就我说的耐心，或者说他说的这种 conversation partner 其实是从这个角度来考虑的。

Speaker 1 42:35 
明白，就是说对于有用的话你就汲取一下它，如果没用的话其实也可以再慢慢地去尝试问聊就相当于聊天，对吧？就聊着聊着可能就能符合你的预期了。

Speaker 2 42:48 
嗯，也可以这么说吧，你不符合预期也没有关系，就是对，我因为肯定不可能是按照他给的答案去想，你自己肯定还是有一个判断的，就是你这个东西你要怎么做，然后，嗯，你懂我意思就是。

Speaker 1 43:04 
懂懂懂。嗯，那是他的建议。诶，是为什么法律会？你们是说法，你是说法律这门课还是什么？

Speaker 2 43:13 
我就说那个老师是法律专业的，就是他之前是学法律，没有说他任何，就是跟这个，他也是我们传播学专业的老师。

Speaker 1 43:23 
那他就是给你们上课的时候就跟你们讲 AI 怎么去使用吗？还是什么？这里。

Speaker 2 43:29 
他有讲到，就是他是，就不是主要来讲 AI 怎么使用嘛？他主要那个课是讲他自己的研究的，但是他就是因为大家都在课上会谈论就 NTU 的什么，当时好像我们上那个课的时候， NTU 刚出那个什么 AI policy，所以他就提了一嘴，我就觉得他说挺对的。

Speaker 1 43:49 
有道理有道理。是的，是还有什么任务吗？就除你刚才提到的这些文献，然后 Brainstorm 还有什么？还有什么？还有什么来着？

Speaker 2 44:05 
还有可能跟工作就不是很相关了。

Speaker 1 44:09 
你不是说你是重度使用者嘛？那你。

Speaker 2 44:11 
嗯，对，就是不是工作相关的，虽然那可能跟我各自的兴趣有关吧。就这是能播的吗？这是你就展填能播的那个什么嘛？就是我比较喜欢研究。嗯，星座命理，然后有的时候这 Deep Seek 的，是吧？OK，然后那个 Deep Seek 其实最开始出来的时候大家不都拿它算命嘛啊？对，然后有的时候会，有的时候会玩一下这个，就拿这个做一个例子，就是有的时候会有一些比较新奇的idea，或者说是。

Speaker 2 44:52 
这种比较冷门、偏门的东西，然后最后突然想到了，然后就会问他一下，我觉得 AI 很重要的一个功能是解，就是把提问然后获得回答，然后就变得非常简单，即使他给那回答不是非常 quality 的，不是非常，嗯，达到你预期的，但是有的时候能就是这怎么说呢？ test knowledge 就让你获得一种test，一种 knowledge 就是你 how to s how to say test it 就是就他不会怎么形容呢？天呐。

Speaker 2 45:34 
哈哈哈，对呀，就你脑子里有一个idea，对吧？我们都会有这个灵光乍现的时候，嗯，然后你就想知道这个问题的答案是什么？然后你要搁平时，比如说你错过这个时机去问，那你这 idea 就会没有了。但是对于我来说就是你要问一下AI，可能他也不会给你非常 OK 的回答，但是你问了这个动作就很重要。

Speaker 1 46:06 
是我知道你的意思，所以相当于说，其实也相当于留了个记录在里面，然后你也可以了解一下你的想法什么的，但我yes，但是那个算命问不对，这跟算命有什么关系啊？这个。

Speaker 2 46:20 
有关系。

Speaker 1 46:21 
不是你的所有的商品，难道不是把你的什么生成什么生辰八字，或者什么出生的什么这些信息输给他，对吧？还是？

Speaker 2 46:30 
嗯，我觉得因为为什么对算命感兴趣？首先不仅是因为对于自己财富和这个什么，什么这个命运的这个啥，把这个运势感兴趣，我觉得还是因为对我来说，我还是想更 know more about life，所以我会问这样的问题。

Speaker 1 46:52 
就是比如说问什么问题？我主要是没有 get 到，因为星座我算。

Speaker 2 46:57 
你知道，就是八字它其实是会有时神的，这听起来有点偏离题目，大概我就跟你讲一下，就是我其实是用它学，你知道吗？就是这个时辰关系，然后在这个古文献当中会是怎么样？其实还是一个增强搜索，就是如果它是帮我学这八字应该怎么学？就比如说你这个，嗯，金木水火土哪个元素？就八字，就是八个字它代表的是不同的金木水火土的元素，然后它之间的关系怎么流动嘛哦？我懂。嗯，就是说。对，但是中间这个我们自己学就会遇到一些困难，比如说这个不知道这个是怎么过去的，然后我就会问他，诶？你现在是一个expert，然后呢？嗯，我现在遇到了一个这个问题，然后遇到了一个这样的例子，然后呢？这个食神之间的关系，比如说底下这个人水和这个鬼水，哪个是他的用神？然后呢？我现在没有办法判断了，你能从网上找到什么资源，然后帮我去，嗯，就是 support me。嗯， justify my 判断或者说是能够给我讲一块这一方面的知识啊。我可能是这样，不是说让他 tell me fortune，不，并不是因为 DeepSeek 并不是一个神婆，对不对？

Speaker 1 48:21 
那所以说你是你这个看的自己的新盘，还是说自己的命理什么的？是看的自己的然后学吗？还是帮别人去算的时候？没不太懂怎么算。

Speaker 2 48:34 
我觉得我反正没有给他过，就是自己的那种信息了，但是因为你学是一个循序渐进的过程，包括紫薇，包括新盘，它可能都会有一些比如说，嗯，那种基础的知识，比如说这个结构的框架，比如紫薇就是公信四化，它代表什么意思？然后有一些这个四画之间的流动，八字就是元素之间的流动，你不可能一下子 get 到所有的信息，那其实你就包括你学语言，你肯定是先知道这个语法是怎么走的，然后你又背更多的单词，你才能，嗯，或者说你更练习更多次，然后你才能不断地能够把你的语这个英语学好，那你学其任何知识都是一样的。诶，你肯定是先知道有一块piece，然后可能对，你它这个在 piece 是在这个大的拼图是在哪个位置？然后你才能再一点把这个 case get 逃，那我用这个 AI 其实就是更快地让我知道我怎么把其他拼图捡起来。这个过程。

Speaker 1 49:43 
其实我感觉好像并不是把它当算命工具，只是当一个学习的帮助你去学习的一个工具。

Speaker 2 49:52 
可以这么说，嗯，对吧？但是确实我用它最多是因为我要学算命。

Speaker 1 49:56 
这个东西。对啊，我发现你确实。

Speaker 2 49:58 
挺好用的。

Speaker 1 50:00 
嗯，就反而不是，就其实相当于，比如说我现在要学一门课程，比如说我可能学一个什么三科的课程，然后我发现不懂怎么学，然后去问他，就相当于请教他的意思，帮你收信息。

Speaker 2 50:11 
嗯，yeah。对。

Speaker 1 50:13 
我以为因为我之前访谈有人说会把生辰八字放进去，然后他给他算，然后我就问他你对他的信任程度。

Speaker 2 50:22 
怎么样？

Speaker 1 50:23 
他觉得就是参考，就说反正也不会全信，就是当一个娱乐看一看他的，对吧？看怎么去讲你的意思呢。对。

Speaker 2 50:33 
因为对你测几次，或者说我们有同学这样干，你就发现他自己跟自己的回答会是矛盾冲突的啊。对，嗯。

Speaker 1 50:43 
那我，那你现在学得怎么样？我其实挺好奇的，那你现在能帮别人上吗？

Speaker 2 50:50 
我能帮你大概看一下，就是大概是你是，就其实大概看大家都可以看，就是你多看几个你就会了。嗯，但是具体的你说大十几说你让你知道你哪年有灾，哪年有这个不行，没那功力。嗯，我觉得学更多是为自己学，就是你知道这个学八字，其实我觉得是一个包括命理，包括星座还是怎样，你是知道这世界其实还有不能解释的部分，然后它不能解释的部分也有它的规律，你就遵循这个规律就好了，并不是说知道这个东西，是知道为知道这个，为什么我哪年发财，哪年暴富，你也走上人生巅峰？并不是的，你也走上人生巅峰，你可能离下来也不远了啊。

Speaker 1 51:41 
没有，因为我是福建的。你知道福建是很信这些。

Speaker 2 51:46 
我懂的，我有福建的朋友。嗯，就是家，老家是福建的啊。

Speaker 1 51:50 
对，然后我们基本都是会，就是专门有这种算命的，所以就是比如说我回国就会去问一问，聊一聊这种东西。

Speaker 2 51:57 
嗯，我觉得还是敬畏吧。对，就是了解算，其实是不是算就是学，是为了解，然后了解是为了尊敬，对吧？你有的时候不了解就会口出狂言。

Speaker 1 52:09 
哈哈哈，所以你是山东的吗？

Speaker 2 52:12 
我不是山东的。

Speaker 1 52:14 
那你是哪的？我觉得像北方的应该是。

Speaker 2 52:16 
对，我是天津的。

Speaker 1 52:19 
OK，因为我觉得就整个的聊天方式跟我的一个山东朋友特别像北方，可能都差不多。

Speaker 2 52:25 
可能我之前对，可能我这个口音到了新加坡之后又进行了一些变异。

Speaker 1 52:33 
对，OK，所以相当于你除了学算命这一块还是还会学什么吗？就相当于其实我可以归类于就是一种学习方面的一个任务，对吧？

Speaker 2 52:46 
嗯，这么一说我的生活好无趣啊，感觉都是学习，连娱乐都是在学习。

Speaker 1 52:52 
也不算，比如说你的学习是为了你的进一步娱乐。

Speaker 2 52:57 
可以，这个回答我喜欢。

Speaker 1 52:59 
对啊，那。

Speaker 2 53:00 
还有别的好像也没有啥了。

Speaker 1 53:03 
我有个问题就是你刚才提到prompt，那你有学过 prompt engineering 相关的知识吗？或者是课程，或者是你自己学的什么的？

Speaker 2 53:12 
大概的。就参加一些workshop，就是有的，而且次数也不是很多，我会看一些，比如说，嗯，论文，有的人为什么会？但非常细碎的脑力有人会在微博上转，比如说为什么？比如说他的那个写 prompt 经验，然后还有一些，嗯，就是图书馆的讲座，当然不是 NTU 图书馆，是别的别同朋友推给我的，或者说我自己找到的，我会在 YouTube 上看一看别人怎么写的。

Speaker 1 53:49 
写什么？我刚才没太听清，写。

Speaker 2 53:51 
就写prompt。

Speaker 1 53:52 
哦哦哦，你刚才说写 prompt 会哦，就朋友推荐。不是，或者是 YouTube 学一学。那你觉得对，那有对你的 prompt 有什么变化吗？就是你比如说看了这些。

Speaker 2 54:03 
嗯，有变化，但是也不会有太大的变化，因为我不是那种很会写 prompt 的人。

Speaker 1 54:12 
那。

Speaker 2 54:12 
现在有一门生意是，就是他写好了，然后他卖给你。

Speaker 1 54:19 
他写好的 prompt 卖给你。

Speaker 2 54:22 
对，这更常见于一些数据分析的一些需求。明白就是因为你更需要，比如说你像我们跑数据，你就像代码，别人是你可以抄过来自己那个，嗯，再进行改变， prompt 也是一样的，这种的结构化的东西都是一样的，但是有人就是帮助你把这件事情做得更快嗯。嗯，但我没有买过，我是看有人干这样的生意，我听那些讲座完全是因为我对这个东西，我对于怎么把 AI 使用得更好，来帮助我提高效率。我是比较持开放态度，所以我会听一听、看一看，如果有时间的话，对我的改变可能是还是有一些改变，因为你自己尝试过了以后，嗯，你就会发现非常细微的回答的差别。那其实你知道这样的话，就相当于你知道这个路这样走会更近啊。嗯嗯，这个就会内化成你的经验。对，但这个很难描述说它多大程度上给你有增益，这个很难描述的。

Speaker 1 55:30 
嗯嗯，那比如说有什么？比如说有什么点你会经常用到吗？就是在写 prompt 的时候，比如说你刚才提到的说会学算命的时候，是会让他写一句什么啊？你是一个专家。

Speaker 2 55:45 
我觉得能让他 get 到你比较快速的方式就是聊，其实你要了解这个东西它是怎么 create 出来的。你像 HCCI 他们这里面给 prompt 大家你可能也听过，就是你要给它指定一个角色，嗯，是因为它设定的时候，嗯，他就是这样的理解这个文本、这个逻辑，或者说理解人类语言的逻辑，你要尽可能地让他知道你现在是什么角色，就指定给他，他是给Persona。所以说他能快速地定位到这部分的信息，或者说如何组织。嗯，那再有一个就是，嗯嗯，你不要一次性把你所有的需求都提给他，你要就是，嗯，分阶段的分，然后去不断地和他进行对话，就我刚才说的有耐心，嗯，这是可能这两点是比较重要的。嗯，这个我可能觉得大家都知道吧？这。

Speaker 1 56:45 
那基本都知道。那其实有个问题就是说对于这个任务，其实你自己会先划分阶段，还是说让 ChatGPT 帮你来划分阶段？对于任务来说。

Speaker 2 56:58 
什么叫。

Speaker 1 56:59 
就你刚才提的划分阶段，然后。

Speaker 2 57:02 
嗯，那我可能还是自己有一个判断。

Speaker 1 57:06 
就不会说让 ChatGPT 来帮你看一下这个任务应该完成什么样的程度，或者是，对吧？就是就确实 GPT 没有在这里面起到一些作用，帮助什么的。

Speaker 2 57:21 
不太有。

Speaker 1 57:24 
所以还是说自己去分工，然后对处理这个任务分为哪些阶段，然后看哪些需要他来帮忙，对吧？大概是这样吗？

Speaker 2 57:32 
对，我只是我有需求的时候会找他哦。

Speaker 1 57:35 
嗯，不就不会说，我懂，我懂。因为有些人他们是会，比如说这个任务他其实不是很了解，然后就会让 ChatGPT 给他一个框架，给他一个阶段，然后他再看，嗯，去做。

Speaker 2 57:47 
对，我觉得对于我来说，因为我主要的使用是我自己的工作方面，我工作方面肯定是我自己更了解我自己，但比如说有一些日常生活方面，我懂你说那个意思了。嗯，比如说我要想开始健身，那我可能会问他，比如说我就是一个启动困难的一个患者，嗯，那我可能会问他我这怎么安排？然后大概心里有个嗯，但我也不会完全 follow 他给。我的规划，但我大概懂你是怎么说这个的意思啊。嗯嗯，那反正工作层面不太会，我还是会，我需要了会找他，是我比较常用的一个姿态。

Speaker 1 58:28 
刚提到你刚才说不会完全 follow 他，是因为他给的建议超纲了，还是说他的给的建议是不太可行？是哪一？他。

Speaker 2 58:38 
给的肯定是一个均值，他肯定给的是一个均值，就是。

Speaker 1 58:44 
我想起。

Speaker 2 58:45 
就是综合，对对对，他你，但是你完全就比如说减肥这件事情，对吧？你肯定更了解你自己更喜欢吃什么，什么时间吃什么，然后你大概能需要多长时间？他可能就给你更多的信息来讲你这个易参，比如说你就问他这个这几天就要怎么organize，怎么点？嗯或他肯定给你是不可能有那样的计划，因为学校啊。对。

Speaker 1 59:21 
都断了，该前面一句，前面那两句话都断掉了。

Speaker 2 59:26 
我就说，嗯，说到哪了？嗯，收到就说，比如说你不说那个完全 follow 是不太可能的。就比如说举个例子，就是我问他我怎么安排我的健康餐，他肯定会给你非常细致地告诉你早上吃什么ABC，然后中午吃什么ABC，然后晚上最好吃什么。但其实你知道学校不会有这么多给你健康餐的选择，然后你知道你自己也控制不住，对吗？那就没有办法 follow 他的计划，对吧？明白，但是你大概会知道他是给你按照什么样的方向规划。

Speaker 1 01:00:07 
诶，我刚才突然想到你刚才提到就是他不是一个反对者诶？你是有跟他进行让他反驳你吗？是有这种 point 有。

Speaker 2 01:00:17 
嗯，我不知道你看没看过诶，你等一下，我回来再回答你这个问题啊。有个事我回来了，可以听见吗？

Speaker 1 01:02:30 
可以。

Speaker 2 01:02:32 
OK，我是有了。我不知道你看没看过？有一个。嗯，就是网上之前很火的一个，就是让 ChatGPT 吐槽你是 roast you with ChatGPT。嗯，你可以不仅 roast with 你自己，就是他会给你返回一些关于你人格的吐槽。嗯，他你也可以 roast with you anything 就是你写的任何 piece of work 或者说你的idea。他有的时候说着说着就会朝着 please you 的你那个方向发展，就会，我就你会诶， end up with 感觉他是在 please 你，就即使他在 roast 你，但是他还是在 please 你。

Speaker 1 01:03:11 
是是是。这样吗？我。当时看到说什么什么用犀利的语言，还是用什么语言来吐槽哪个什么学校什么什么什么的，我看他写得确实挺像骂人的话。

Speaker 2 01:03:27 
但我没有试过国内的那个吐槽。我用过 GPT 吐槽，但是其他的我没有试过哦。

Speaker 1 01:03:34 
嗯，好像好像是，好像 GPT 确实没有感觉出来那种反对的感觉。好像是。

Speaker 2 01:03:41 
就他会开始是吐槽，感觉像是在吐槽，但是最后还是会。你感觉这东西也不太像吐槽，就说了跟没说一样。

Speaker 1 01:03:49 
哦，你说的吐槽指的是比如说对某个某些文章进行一个debate，还是说吐槽某个生生吐槽什么生活的事情吗？还吐槽哪一种？

Speaker 2 01:04:03 
我都试着问过。嗯，但其实结果我感觉也都没差。就他，比如说他让他 critical 一篇文章 critical 这个idea，他也没有真的 critical 出来什么，就感觉他站在了一个用了一些 critical 的词，但其实他并没有任何观点，或者说就是没有在 critical 的那对我个人的那种 personal 的这种。嗯，反正你就感觉说了一堆，好像没有说那种感觉。

Speaker 1 01:04:35 
明白，所以就是说假设，就是假设，他是个反对者，他也不能把这个做得很好。

Speaker 2 01:04:43 
对，就因为，嗯，你说。

Speaker 1 01:04:46 
我其实好奇的是他能对他自己的答案进行批，就是 critical 怎么说呢？就他不能对你的说的东西进行 critical 的话，那他就是。

Speaker 2 01:05:01 
听不到了。

Speaker 1 01:05:37 
Wei，喂，能听到吗？

Speaker 1 01:05:50 
we。

Speaker 1 01:06:06 
hello，hello。

Speaker 1 01:06:17 
哈喽。

Speaker 1 00:00 
没有问完，后面我就是没有听见了，哈哈哈。

Speaker 2 00:03 
我想起来就是你刚才说反对者的话，是对你自己意见的反对，还是对他自己的回答的反对？我其实是好奇这个来着。

Speaker 1 00:13 
我问他其实就是我 feed 给他的东西，肯定我想让他对这 something 做出反对意见。

Speaker 2 00:21 
但是你不会说，嗯，你自己的答案进行一个反对，或者说 critical of thinking 什么的七七八八的。

Speaker 1 00:29 
我会问的这个就，嗯，不是反对，是对你说内容进行那个 source check，这个我会做这个我也是从一个博主那里学来的，就是这是他是一个KOL，但是他介绍了怎么他使用 AI 的一些就是技巧了，他会比如说在让 AI 给出一轮回答之后再问，再进行一个追问，就是你要检查一下你自己的回答是不是都基于真实的 credible source，然后它会进行再一次思考，就是 critical thinking 一步，但它是 critical thinking，它并不是对自己的意见的这个反驳，或者说是怎么样明白，这个我还蛮常用的。

Speaker 2 01:12 
嗯，就觉得效果还挺好的，是吧？

Speaker 1 01:16 
还行吧，就有的时候他也不会真正的 critical thinking，但是会比平时就你直接 input 得到的答案会好一点。

Speaker 2 01:24 
嗯，明白，所以我想一想还有什么要问的。好像聊得也很多了。主要是这断断续续的太影响思路了。太无语诶，你有什么问题问我吗？其实，其实我现在一下想不到可以聊啥。

Speaker 1 01:49 
我有问题就是你什么时候发这个论文？

Speaker 2 01:53 
我什么时候发？我现在现阶段才做那个，这叫什么？这叫 interview study。 interview study 做完我还要再做 experiment study 你我不是有一个问卷里面有个问题是说 OK 对，是否还对后续的 study 感兴趣嘛？对吧？那我好像你也选了yes，对，然后我这个做完之后，这两个合在一起是一篇论文，然后这个我现在又在做另一个 design study，就是我设计 AI 系统。对，然后这个又是另一个study，我相当于都在同步进行。

Speaker 1 02:27 
你要设计一个AI，你要coding，我。

Speaker 2 02:31 
没有牛的，我没有对 AI 完全coding，就是想把它的这个输出，因为我们做人机交互，那肯定要看它的界面输出有没有一些能改进的、改变的。没有。没事，等你等等我发 step up 邀请的时候，你就知道我要在做什么，只要来参与实验，OK。

Speaker 1 02:49 
可以，OK。我也了解一下这商学院这边是怎么做这个东西的，因为我们其实，嗯，怎么说呢？感觉每个学科的去切入它的那个重点也会不太一样。

Speaker 2 03:02 
差别很大，差别大，比如说，对。

Speaker 1 03:04 
对对对对。那我导你们一般都用什么专注？什么变量？用什么理论？

Speaker 2 03:10 
用的，比如说有认知卸载理论或是原认知理论，还有什么？还有团队协作理论， 7 的 8 的一套就蛮多的，就跟有相关的。

Speaker 1 03:22 
明白。

Speaker 2 03:23 
还有心理学相关的，懂了。其实我好奇的是，你们比如说用的方法会倾向于问卷吗？还是更倾向于哪一个类型啊？

Speaker 1 03:33 
我觉得跟你用什么方法其实取决于你的问题。

Speaker 2 03:38 
你就是。

Speaker 1 03:39 
你们，以及你，是你，你们院能给你开什么样的方法？

Speaker 2 03:46 
没有没有，没有，我是说你，你常用，比如说你的研究，因为你不是也在做人机交互相关，我。

Speaker 1 03:51 
这边我导师怎么做实验比较多，所以我可能也会做实验，然后访谈。

Speaker 2 03:57 
就跟我一样知道。

Speaker 1 03:58 
哈哈哈，大概我大家都是这样。但你国内做这个你是出了，你是从读博士开始就做人际交互吗？还是说。

Speaker 2 04:10 
没有？我是这样的，我是在国内读博，然后我现在是属于交换，然后交换呢。是啊，我这我的情况很复杂，我的硕士是学计算机的，然后在国内读博，我又做的战略管理，做的企业管理，然后我的博士学位又是 information system，导致我的我没有这一方面的积累，然后我又在国外找了 information system 的 supervisor 来帮我指导我去做 information system，现在我做了很多的专业。

Speaker 1 04:41 
那你这个确实挺交叉的。交叉不是清华的，清华不是有一个 future lab。什么什么？嗯，future。

Speaker 2 04:49 
lab。你说的金华是那个 HCI lab 吗？我记得有，我有关注那个。

Speaker 1 04:54 
对，我有关，对未来实验室什么什么没有你这个图片去那做驳后，嗯。

Speaker 2 04:59 
我不。你说我其实想留在新加坡或者香港做个博后，然后就再找教职了，该。

Speaker 1 05:08 
你这学计算机，对你来说洒水，再做一个什么界面之类的。

Speaker 2 05:13 
但重点都难，就是难在访谈，因为我这第一次做，这真的是我第一次去接触定性。嗯和对，因为你们可能也不用二手数据吧？我之前是做二手数据的，我没做一手，有点难做。

Speaker 1 05:28 
我们用二手数据不多。对啊，对对，可能经济学用得多一些，因为我们这种问题很难用二手数据。说实话有谁会跟你关系一样的问题？就是跟一样问题，可能你这文章也发不出来。嗯，对。

Speaker 2 05:43 
就我之前用的都计量经济学，相当于我是从 deep learning 模型 learning 到计量经济学，然后再到现在的定性的访谈问卷lab，然后还有design，就是我跳了好几个这种研究范式。

Speaker 1 06:02 
确实挺跳的。

Speaker 2 06:03 
对，然后individual。

Speaker 1 06:05 
确实是交叉型人才。

Speaker 2 06:07 
自我交叉，缺。

Speaker 1 06:10 
紧缺的交叉型人才。

Speaker 2 06:11 
对，然后我现在做的可能就跟你很相关，因为你也在做individual，对吧？你怎么？你还没开始访谈是吗？还是说还在构思idea？

Speaker 1 06:20 
我还没有过 QE 呢。

Speaker 2 06:22 
哈哈哈，要过了 QE 才能开始研究吗？也不一定嘛， research 不是想什么时候我。

Speaker 1 06:28 
的导师比较希望我设计的就是你要找到一个真的问题。对，所以才开始。

Speaker 2 06:35 
会随意让你的挥霍他的钱来做访谈，对吧？

Speaker 1 06:41 
嗯，你看来你的这个外导是一个比较 generous 的这种。

Speaker 2 06:45 
嗯，因为我也很赶，我想马上毕业嘛，然后他可能也觉得 AI 这种话题不早点做的话也没什么可做的，就大家都在抢这个这一块饼嘛，对吧？

Speaker 1 06:58 
那你这个广定性发不了吗？你广定性就可以发一个，还是说你想憋个大的。

Speaker 2 07:04 
呃？我们商科一般都在投顶刊，因为如果你只做个定性，投不了好期刊，然后我就想定性加实验两个 study 去做一篇，这不很正常嘛。那。

Speaker 1 07:22 
对对对，就普通的。确实。哎，你们商课期刊真的太卷了。我那天我们在搞另外一个project，然后搜文献的时候看到一个 journal of 什么 consumer behavior consumer b 一篇得有 4 个实验。我天就。

Speaker 2 07:38 
CB 播他们消费就是试营市场营销这一块，他们的实验基本是在 6 个左右，就是 study 123456，对，是他们的基本客户。

Speaker 1 07:48 
我，OK，你们是有钱人。

Speaker 2 07:51 
对，然后他们是 consumer behavior，然后我们是 information system，现在的实验好像是两到三个，还没有他们那么卷，他们那么卷其实我觉得很花钱，就是很花钱。

Speaker 1 08:08 
真是，我们就是你要 plan 好每一个，就做实验之前要想很多东西一样。 com 比较没钱。

Speaker 2 08:18 
哈哈哈真的吗？应该还好，不是新加坡应该都还好吧，项目上的花费。

Speaker 1 08:25 
我觉得你们算是比较有钱的，你像你一个访谈能给到50，我们给不了。

Speaker 2 08:29 
我给多了。我知道我给多了。我怎么会给这么多，当时都导师还跟我聊这件事情，就是一个小时该给多少钱，然后我就去问了同门，同门说他们是半小时给 40 金币，我说，怎么这么高？

Speaker 1 08:44 
那他们半小时给 40 坡人吗？还是中国人？

Speaker 2 08:48 
中就是国外，就是新加坡。我导的学生之一，然后他在，小导师在指导，然后肖导师指导的话说半小时给 40 新币，我说怎么这么高？他说是 AR 相关， VR 相关的，然后说实验吧，然后说给到了 40 新币，我说太高了，然后我就跟老师聊嘛，说三个 30 分钟给 40 新币，太高了，然后我就说那能不能啊？一小时，比如说 50 啊？是这种这样给，然后没想到还是给高了。

Speaker 1 09:17 
你们真的是挺有钱的，你导还收学生吗？PDD，我现在换方向还来得及吗？好有钱的感觉。我导好像开玩笑。

Speaker 2 09:28 
没有，我导这几年就他一个博四的学生，加上我来 CIC 交换的一个学生没了。他没学生了，就两个。

Speaker 1 09:37 
就是比较大了。

Speaker 2 09:39 
比较什么？

Speaker 1 09:40 
就比较德高望重了。是吗？

Speaker 2 09:42 
他才50，然后是副校长，我觉得他应该是行政太忙了，太忙。

Speaker 1 09:49 
明白。嗯，然后。

Speaker 2 09:50 
对，他没空管我有钱。对，然后都是让 Ra 来帮我。比如说我现在interview，我现在是做中文这一块，因为我觉得中文我能更好地去理解，然后如果用英文去聊的话。可能会忽略一些东西，然后英文他就帮我安排了 Ra 和博，后来帮我做。

Speaker 1 10:04 
我天，你这太凡尔赛了。我天，你这。

Speaker 2 10:12 
啊，不是你们的研究难道不会有 Ra 什么的吗？应该都会有。

Speaker 1 10:19 
我的 ID ChatGPT。这不是梗啊，这真的，我知道，怎么可能？我让你。

Speaker 2 10:32 
没有，你。

Speaker 1 10:33 
要现在，我现我为什？你说我们要是真像有像你一样的团队，谁天天跟这 DBT 对话，对不对？

Speaker 2 10:45 
没有因为他，我因为那个 Ra 是我导的全职Ra，然后就是哪里有需要帮忙就会让他来帮一下。

Speaker 1 10:55 
嗯，天呐，我感觉我现在就像冷宫里发疯的妃子。

Speaker 2 11:01 
没有，你要考虑到我的访谈的人数大概是60，我一个人做不过来，太辛苦了。真的太辛苦了。

Speaker 1 11:10 
你越说你别说哈。你越说我越觉得。

Speaker 2 11:16 
那你转商学院吧。

Speaker 1 11:22 
而且一般我们这边 CSC 就是。对，我觉得还真的，你也很幸运了。

Speaker 2 11:30 
你们那边怎么就是只是过来交换是吗？

Speaker 1 11:33 
对，只是过来交换，然后换一个地方自己写论文什么的好像就真的很少外导，外导可能会给你一些指导，但是就是外导也因为你就一年。

Speaker 2 11:43 
对吗？我不止，我是两年的，然后。

Speaker 1 11:46 
你现在是两年的。

Speaker 2 11:47 
对，我交换很长，然后我觉得很烦待的，然后自己缩短了。也不是吧？反正就是我自己缩短了一半的时间，不，缩短了半年，我缩短了半年。

Speaker 1 11:57 
一年半等于是。

Speaker 2 11:59 
对，我本来是两年制的，然后我想早点结束。什么。

Speaker 1 12:02 
学校能交换两年啊？我天。

Speaker 2 12:05 
这跟学校没关系，它是在国家申请，你可以选 12 ~ 24 个月。我只是选了 24 个月，然后又申请中了。一般来说 24 个月比较难拿，只是说试一试结果就升到了。

Speaker 1 12:20 
我明白了。

Speaker 2 12:21 
对，然后时间久一些，但我觉得可能也是因为外导缺人，然后又因为这个选题他很感兴趣，因为我放弃了我国内的所有研究，重新开始，他应该也要支全力支持一下我，对吧对吧？

Speaker 1 12:40 
这不一定的，只能说你运气比较好。

Speaker 2 12:45 
那希望吧。他，但我觉得博厚的话，如果能在他这边继续做的话，可能确实也挺有帮助的，就是能争取把这两篇发出来，对。

Speaker 1 12:57 
牛的。

Speaker 2 12:59 
其实我比较好奇你去做 Indiv 的话，你怎么去做相关，你说你们肯定不去做界面设计，因为不是 information system 这一个方向。

Speaker 1 13:13 
可能比如说我们这个专业它会 design online experiment，然后在我导的也是也做lab，我没有 lab 的实验，就是请那种花费就会高一些， online 的话你就会快一些。然后那种就是 design 一个interface，或者说是跟他交互，交互完了以后让他回答一些问题，填问卷什么的。

Speaker 2 13:37 
诶，所以你们也是去做界面诶？ interface 不就界面。

Speaker 1 13:41 
有啊？这个肯定会有的。

Speaker 2 13:44 
诶，那不是很像吗？跟我们，跟我现在做的对，所以相当于说可能真的之后可能真有机会合作，假如我继续做这一个。

Speaker 1 13:58 
方向有的，那肯定有的。

Speaker 2 14:02 
OK。假，对，有些有个疑问，因为我其实现在访谈的都属于 critical thinking 能力比较高的，那假如你如果对于比如说这种大学生就是可能刚入学或者说大一大二的，那你觉得你会有什么一些比较好的？一些比如说可能思考方式或协作模式上有什么建议吗？就是对于这种干，就是可能还没有很有能力去深度思考的一些人。

Speaker 1 14:33 
我觉得，嗯，不能以这个年龄来划分就他有没有 critical thinking 的能力，是在他有介入 AI 作为一个 intervention 之前他应该考虑的事情，然后 AI 只是他辅助的一个帮助他思考的一个工具，可能会 enhance 他本身的这个personality。他如果本身就是一个，但 critical thinking 这种能力并不是。就你要靠很多技术以外的东西来去支撑你。嗯，获得的，比如说你是一个有好奇心的一个人，这很重要，但这个其实也很难定义喽，你是靠什么追问你的好奇心是你的这个，比如说。

Speaker 2 15:23 
哦，我懂你意思。

Speaker 1 15:25 
这种，对吧？怎么。

Speaker 2 15:26 
去提高他的一个好奇心？可能也是一个关键的方式。

Speaker 1 15:32 
yes，然后但我觉得其实也不一定非得吧。当然你这话题是我知道你要 make 什么point，所以是顺你这个回答就是，嗯。还是要多看一些，就还是有一些，就是和技术detachment，就是你要用的话你要想不能说是用就是用。嗯，你就像什么是用就是用，比如说我跟 AI 对话完了之后我 copy paste，这就是用。嗯，但用完了想，比如说你任何一个加工，你觉得 AI 学得不好，这不就是用完了之后想那个 reflection 那过程。嗯嗯嗯，就把它这个 reflection 尽量地扩大，这个可能是，嗯，你更好地使用工具的一个方法。嗯，明白，但是我觉得可能大概大一大二的学生，现在他们比我们更聪明，哈哈哈，对不对？我觉得不需要任何的忠告，我刚才说的这个意思就是他只要提高他的好奇心就可以了，他有任何方式可以支撑他获得。嗯，技能比我们学的东西快多了。

Speaker 2 16:52 
没有，其实可能存在一个问题，就是可能就是就就 NTO 不是也发生过，就是说直接用 GPT 来写作业，然后就导致了学术不端、诚信不端什么的问题嘛。对对，怎么去把它干预掉？或者说就是怎么去避免这种情况的产生，可能也是我研究的话题之一嘛。

Speaker 1 17:15 
避免？那你要和人性的你人性劣根性做对抗吗？这个没有办法避免，我觉得。嗯，所以，但你要研究这种阴暗面还是挺有意思的。

Speaker 2 17:30 
对，可能就是类似的吧。就是其实，诶，其实我这么去聊，是你能去揣测或者说能揣测到我的地图，是吗？就是说大概我想去研究什么？就我是说访谈过程，就访谈过程没说后面这些。

Speaker 1 17:50 
这还用揣测吗？这不挺直接的吗？

Speaker 2 17:52 
就能知道我是想去研究什么，是吗？

Speaker 1 17:58 
你可能还需要多做一些访谈，你才能把他的，把你的意图，然后比较好的 head 起来。嗯，有经验的访谈者或者说被访谈的人都会多少 get 一 get 到一下有可能是因为我们方向太交叉了。

Speaker 2 18:19 
所以。对。

Speaker 1 18:21 
但其所以我会非常容易知道你要做些什么。

Speaker 2 18:25 
对，但其实应该其实还是只能了解。那。

Speaker 1 18:28 
你也挺灵敏的呀。我不也并没有直接说。那你 get 到这个意思。

Speaker 2 18:34 
没有？我只是好奇，因为我第一次做访谈嘛，就其实也没什么经验，然后我就很好奇，就是因为他们经常说能揣测得到，就是那个科研者他们到底想做什么研究吗。

Speaker 1 18:47 
很容易。

Speaker 2 18:49 
但其实还好，因为我后续的干预其实还是在体现在一些啊。你也懂， information system 肯定是体现在技术上，肯定不会体现在心理学上。

Speaker 1 18:59 
嗯，对对对。

Speaker 2 19:02 
呃。好像啊，我们聊了也好久好久了。我我我好像也没啥了。嗯，你也应该没有什么问题要问我的。

Speaker 1 19:13 
我没有什么问题了，就是对，期待健康，期待成功发表。

Speaker 2 19:19 
哈哈，好，谢谢。嗯嗯，你不应该说期待合作吗？

Speaker 1 19:24 
哈哈哈，也期待合作，加微信。那就。但是这个好像不违反学术伦理，应该。

Speaker 2 19:30 
应该还好，我觉得还好，可以，到时微信直接发聊天框也可以。

Speaker 1 19:36 
好的好的，我搜一下。

Speaker 2 19:39 
慢慢查。唉，没有，其实就是这么反弹的，因为我之前反弹，因为有一些是我朋友，所以其实无所谓吧。我觉得明白。

Speaker 1 19:53 
这串数字吗嗯？

Speaker 2 19:54 
对对对对对，我，我用的是QQ，对， QQ 号，然后嗯，到我的微信。诶，所以你现在是博一吗？可以这么理解吗？还是博二？

Speaker 1 20:05 
我是硕一第二学期硕士。

Speaker 2 20:09 
但是他的直接可以转博吗？可以，比如说 1 + 3 可以这样吗？

Speaker 1 20:14 
不太行，你要重新apply。

Speaker 2 20:17 
那不很麻烦吗？听说 NTO 的博士不承认 NTO 的硕士的英文好像是还要再考雅思。yes，好努力好努力。

Speaker 1 20:32 
我恨自己没有早升几年。

Speaker 2 20:35 
就是说这个是新加的是吗？对，OK。

Speaker 1 20:39 
二三年之后，二三年之前还没有。

Speaker 2 20:42 
对，因为我学妹她也是 NTO 的硕嘛，然后她说只要升 NTO 的博就很麻烦，然后她就不想升了，然后现在去香港。

Speaker 1 20:52 
香港又是另外一个坑啊。

Speaker 2 20:54 
对，唉，都是命嘛，如果现在都驳回，那就是很卷。

Speaker 1 20:59 
你要庆幸自己生得早。

Speaker 2 21:02 
不也一样承认自己的。

Speaker 1 21:03 
幸运。

Speaker 2 21:06 
那就可能跟你说的算命有关了。你。

Speaker 1 21:08 
竟然还有Ra，我今天真的是。

Speaker 2 21:16 
我真的有要比如说我去贴小广告，我就把阿姨抓着跟我一起去贴小广告。

Speaker 1 21:21 
而且你还不用给阿姨付钱。

Speaker 2 21:23 
对啊，不用我付，好像。

Speaker 1 21:25 
越说越嫉妒了。

Speaker 2 21:27 
对，我听说好像可能一个月给了五六千新币吧。我也不知道，我认识导师。那也不多，不懂。全职 ia 五 6 千还是六七千？我记得挺还可以，就是相当于全职工作。

Speaker 1 21:39 
五六千。那得看他 workload 怎么样，他如果没啥工作的话五六千还可以。

Speaker 2 21:45 
因为听他说他租房都租 2, 000 新币的，那我觉得他工资肯定不低。

Speaker 1 21:50 
嗯，那可能还有些项目收入之类的基本工资这些。对诶，你们上个月真的太有钱了。我天，我真的是听完了，真的是。

Speaker 2 22:01 
我也不懂，反正商学院可能比较喜欢捞钱重利益的一个学院。

Speaker 1 22:07 
停，好的。嗯，好，我那个好友请求发过去了，嗯，OK。

Speaker 2 22:11 
OK OK，OK。那我通过一下，然后那其之后有什么再聊呗。其实我现在真的想不到要问你啥了。

Speaker 1 22:20 
嗯嗯，行，如果有需要的话我们再看时间。 o 不OK。

Speaker 2 22:27 
但如果我，但我可能觉得这样子可能不太合适，因为有点，会不会违反伦理道德？会吗？因为对吧？可能是。

Speaker 1 22:35 
有一点，哈哈哈，是有一点，可能不太对，你就。嗯，对，反正你要不用再约一个整的时间也可以，你要有什么补充的问题，我可以语音发给你。行，然后你要转文字再转录就行，因为可能我以后也抽不出这么整的时间了，这一个一个半小时比较rare。哈哈哈，因为我这个学期很挺忙的还就是啊，都明天有课，明天后天都有课，然后还有学校的project。

Speaker 2 23:04 
嗯嗯，很感谢你，很感谢你。然后那个关于费用的话，我其实不太确定到底能不能在两周内转给你，因为他用的是 corporate pay now。对，就是要经过商学院的财务部门，对就对，尽快安排。这个对。

Speaker 1 23:20 
行，好。嗯，反正我能看到嘛，对吗？就是来自你们商学院的，来自 NBS 的这个 corporate 配套的这个打款。

Speaker 2 23:29 
嗯，肯定能，对，就后续了，然后之后的话我会再给你发 sign up 的那个注册，就如果我后续开启其他。

Speaker 1 23:39 
好的，没问题。

Speaker 2 23:40 
嗯，好，谢谢，谢谢。

Speaker 1 23:42 
好。

Speaker 2 23:43 
拜拜。好，拜拜。拜拜。

受访人22：
2025-08-30 12:13:53 CST|1h 4min 2s

Keywords:
模块、数学、关键词、算法、交互、公式、论文、验证、答案、文本、Account performance、文献、课程、强化学习、深度学习、高斯分布、深度思考、研究方向、代码交互

Transcript:
Speaker 1 00:02 
好，那我就先简单介绍一下哈。哦，就这边是商学院的一个项目，是研究的课题是基于交互记忆系统来优化人机的一个团队表现。具体来说就是我在招募的时候也是提到了要高频的使用者使用 chatgpt 或者其他的甚至是AI，然后主要观测观察一下，就是在就是这些使用者在工作或学习流程中怎么和 AI 协作，就特别就主要是关注于这些的互动模式，就还有那个协作的一个方式，还有一些思考的方式，就看有没有什么一些有趣的见解，或者是有趣的一些协作方式。你对我这个项目有什么问题吗？

Speaker 2 00:46 
嗯，暂时没有，我这边感觉讲得挺清晰的。

Speaker 1 00:51 
OK，OK。然后我需要录音跟你确认一下。ok，好的，好，然后那我们就正式开始吧，您能简单描述一下目前的工作或学习的一个领域吗？

Speaker 2 01:05 
我现在主要是在强化学习这边进行研究，我是巨智慧学院博三的一名博士生，对，然后我主要工作是在强化学习、深度学习这方面，然后有的时候我也会涉及到一些大语言模型的编程，就是应用大语言模型去解决一些实际的问题。

Speaker 1 01:26 
就是那主要研究领域是什么呀？是，就是强化学习应用于什么方向是吗？

Speaker 2 01:34 
主要应用于水下无人潜航器的自主调度。水下无人潜航器就是无人潜艇的自动调度。对。

Speaker 1 01:45 
OK，有点高级。

Speaker 2 01:47 
没有？听起来高级，但其实做起来也是还。

Speaker 1 01:52 
ok。那在这些领域的话，那你会用 ChatGPT 或者是其他真是 AI 来处理一些什么类型的任务？

Speaker 2 02:02 
我其实主要大的是分为两个部分，第一个部分是有时候我会请他帮我写代码，比如说有一个函数或者有一个类，我已经很明确他的需求了，然后我会把这些需求整理成一份我觉得比较详细的描述，然后直接给GPT，或者给Claude，或者给Jermaine，然后让他们帮我生成出我对应所需要的东西出来，这是第一种让他帮我写代码。第二种主要是有的时候遇到一些数学问题，我可能没有很好的这个数学功底，然后我看不懂那篇论文到底在讲什么，然后我会请 GPT 帮我解释一下。对。

Speaker 1 02:42 
哦，OK，就主要是这两个类型，是吗？

Speaker 2 02:45 
对，没错，这主要两个大类。是这样。

Speaker 1 02:47 
哦，没事，等下可以慢慢聊其他的一些。

Speaker 2 02:49 
OK，好的。

Speaker 1 02:51 
那大概从什么时候开始用的呀？就是这些AIGPT。

Speaker 2 02:55 
一出来马上就注册了，哈哈，因为当时确实非常的火，而且效果也非常震撼。

Speaker 1 03:03 
是 22 年吗？还是 23 年？ 22 年年底。

Speaker 2 03:06 
22 年。对，我记得 22 年年底的时候它出来的，然后当时是3，我记得一开始是3，然后到3.5。

Speaker 1 03:14 
好像是那时候效果好像不太好啊。

Speaker 2 03:18 
对，那个时候一些数学问题是没办法帮忙解决的，但是一些很简单的代码，包括一些什么邮件的润色、文章的润色，这种还是没问题。

Speaker 1 03:29 
OK，那其实相当于，那现在的话应该就是能力提升，那应该就是每天都在用，还是。

Speaker 2 03:36 
的每天都在用？

Speaker 1 03:39 
那你一般用什么的模型啊？就是还是说都用？

Speaker 2 03:44 
我如果遇到如果只是一些简单的问题的话，我一般都是用 GPT 它那个 auto 的模式自动帮我选。然后如果遇到一些比较复杂的问题的话，我就会在几个不同的模型上边都用他们最好的那种深度思考的模式，就 recently 的模式，然后同时发几个，让他们同时去做同一个问题，然后看谁的效果最好。

Speaker 1 04:08 
你一般会用到哪几个？比如说ChatGPT、Claude，然后谷歌的，还有。

Speaker 2 04:14 
对Gemini，然后我最近看 Grok 好像也不错，但是我没有充他的会员了。

Speaker 1 04:21 
你充了几个会员？

Speaker 1 04:22 
chat g p TGPT。

Speaker 2 04:24 
有一个，然后 Gemini 那个是之前白嫖的，就是他之前送。

Speaker 1 04:29 
的OK，然后就开了两个。对，是的，那你觉得不会存在某个版本更好用啊？就是还是说都要用到？

Speaker 2 04:39 
其实他们有的时候真的是我，我很难总结出某一个可能在每一个领域都好，因为不同的问题发给他们，他们经常会有不同的表现，所以有的时候可能是 GPT 的就好，有的时候可能是 Jennie 答的好，这个都不好说。

Speaker 1 04:57 
就是说两个都会参考一下。

Speaker 2 05:00 
是的。

Speaker 1 05:01 
那如果每个任务都这么去处理，不是很耗时吗？不会有一些特定任务是使用某个版本吗？

Speaker 2 05:08 
如果是主要是数学问题的话，我还是会问 GPT 多一点，其实更多的还是主要使用GPT，可能有的时候 GPT 的答案我觉得不合适，包括它的数学解释是不通畅的。嗯，那我就会去看，我问一下Gemini，然后看看它的效果怎么样？有时候 Gemini 也不太行，但有时候它会给出一个比较让人惊喜的答案。

Speaker 1 05:31 
ok 诶，现在 5 出来你感觉怎么样？因为我觉得 5 好像也没那么好用。

Speaker 2 05:38 
GPT 5 它的 auto 模式下就一些简单的任务，比如说是用润色邮件这种很简单的东西，它就很快给出回复，这个还是 ok 的啊。然后它的 thinking 我感觉其实和之前 GPT O3 差不多，但是它的 O4 好像会更好一点。对，而且它现在 O3 也回来了，所以如果有时候确实thinking，我觉得它的答案有问题的话，我会跳到 O3 去继续用。

Speaker 1 06:11 
哈，OK，所以说就是说反而之前的版本会优于现在？

Speaker 2 06:17 
是的，我觉得是这样。

Speaker 1 06:19 
OK，那其实可以具体聊一下那些刚才你谈提到那些任务的具体的协作方式哦。刚才提到coding，对， coding 一般是什么样的任务啊？该是写代码吗？还是说 debug 还是什么？

Speaker 2 06:36 
我一般会让他帮我写代码，就直接从头开始写。因为如果 debug 的话，因为如果 debug 需要我项目中所有的文件，我一起给他，我不太认为他可能有能力处理这么多的文件，所以我一般是某一个子类或者某一个模块，我让他帮我从头开始写这个小的模块，然后写完以后我一般不会直接复制链接，直接开始跑，我一般会看他到底在写什么，然后再去微调，再去改一下。有的时候他的代码是没办法直接运行。

Speaker 1 07:11 
可以理解为比如说现在有个任务，就比如说你现在项目很大，对吧？就是比如说自动加自动巡航的一个项目很大，然后其中的一个模块是可能是算法优化，还是说是只是数据的导入输出这种模块让他来写。

Speaker 2 07:28 
对，比如说最简单的一个例子，就是说我现在训练完了，然后我有一系列的数据，我希望他帮我画一张图出来，这张图我希望比如说是折线图，然后它会反映不同的方差，那这种东西一般它就是一个比较独立的模块，就是说我只要在程序的最后加一行这个模块的调用。然后把历史数据喂给它，它就会给我出一张图出来。就这个是非常独立的模块，这种情况下我就会让 GPT 直接帮我生成一个这种画图的模块。

Speaker 1 07:59 
出来，你就是说是要比较独立，那如果中间的部分，比如说比较核心的。

Speaker 2 08:06 
这个，我一般就会自己写，然后我可能会用那个vscode。 Co pilot.

Speaker 1 08:12 
A competit.

Speaker 2 08:13 
对 copilot 编程的话，它会看到我项目的其他文件，所以这样它给出的建议会比较好一点，但是大部分时候其实还是自己写，就这种可能跨很多个模块交互的话，还是得自己解决。

Speaker 1 08:31 
是不是因为项目太大了？就因为可能商学院这边的项目都比较小，所以他们都会直接全部扔进去。

Speaker 2 08:41 
可以这么说，因为我可能，比如说不同的模块要分不同的文件去放，然后可能可能有可能 50 个、 100 个这样的文件，我不可能全部都飞给他，这样的话我觉得他可能读不过来，可能抓不到我想表述的重点。

Speaker 1 08:55 
明白，所以就是说因为像，就比如说那你也不会提供项目背景，让他帮你去写一个完整的代码，因为你说的都是特定小模块。

Speaker 2 09:05 
是的，因为如果完整代码的话，我暂时不觉得他有能力写出这么长代码出来。

Speaker 1 09:13 
OK，所以用到的其实还是边缘上的一些模块撰写吗？可以这么理解吗？

Speaker 2 09:20 
对，可以这么理解。

Speaker 1 09:22 
然后那其实就是说你是会把任务拆解成很多很多的步骤和模块，你自己先拆。

Speaker 2 09:31 
对，没错，我一般比如说我要开一个新项目的话，我一般会想好的它中间有哪一些模块要写？然后。

Speaker 1 09:42 
明白，对，就是不会让 ChatGPT 来生成大纲，或者是帮你发散什么的。

Speaker 2 09:49 
写论文的时候可能会它帮我大概整理一下这个思绪，或者是写做 PPT 的时候，对，但是代码一般还是我自己写。对。

Speaker 1 09:58 
就说代码能力比较强，所以就。

Speaker 2 10:02 
对，也没有，只是代码这个比较具体，就是他可能写错一点，就整一个就崩，这样就不太好，所以我还是习惯自己写论文或者 PPT 这种，他可能有一点描述的偏差，这个无所谓，我看出来我就给他改就完事，ok。

Speaker 1 10:20 
但是他的确实有点不一样，因为他们就是代码，代码会基本交给chatgpt。嗯，ok，确实，那除了代码，除了这种边缘模块的撰写，还有什么方式会使用到？你刚才说 debug 应该也用得很少。

Speaker 2 10:38 
对，因为 debug 的话它需要运行每一步程序，然后把程序现在在当前环境下这些变量要给到GPT。那这个其实是一个很复杂的过程，我不想手动一个一个拷贝。对，所以我一般会自己去做debug。

Speaker 1 10:55 
那代码上怎么我感觉用的不是特别多诶？就是在只是一些特定的模块上的话。

Speaker 2 11:03 
其实这些小的模块我把它拆分好以后，很多时候我还是会问他，就让他帮我写，然后我来改，这确实就是模块之间交互的时候，可能确实要我自己来，但是具体某一个模块内部还是可以大量的依赖于 GPT 的，它这个能力还是挺好的。

Speaker 1 11:24 
比如说还有什么一些特定模块会用到chatgpt？

Speaker 2 11:33 
我可以这么说，比如说我要控制这个水下的这个潜艇，那它有一个动力学的模块。对，这个动力学模块我可能提前已经定义好了所有的数学公式，但是我想把它变成一个代码。对，不仅是变成代码，我希望它可以有更好的封装，这样保证我在用不同的动力学模块的时候，我可以比较方便地切换。

Speaker 1 12:00 
明白。

Speaker 2 12:01 
那么在这个时候我就会希望 GPT 能帮我生成一个比较好的封装的一个模块。

Speaker 1 12:08 
那这个的问题是你本身是不太想写呢？还是说是确实也不太懂用什么封装的语句？

Speaker 2 12:17 
其实主要是不太想写这个封装不太不是件太难的事情，但我主要是不想去思考每一个封装层面它包含哪些变量，所以我一般直接给它GPT，就是来，你帮我搞定，哈哈哈。

Speaker 1 12:34 
对，明白。对，那比如说如果具体到，比如说算法模块的话，是就不会依赖它，是吧？还是说会让它先写一个大概？

Speaker 2 12:44 
因为我这边用算法，我背后用了一个一个一个库、一个包，这个包 GPT 我发现它并没有很好地掌握，因为这个包它本身是在高速迭代，所以说 GPT 它可能有一定的这个滞后，所以导致它根据它的理解写出来的代码是没办法直接运行的，但是大概的逻辑是 ok 的。但如果我们更具体一点，比如说我抛开这个强化学习，我只说深度学习的包。比如说我用Pytorch，那这个就是很明显这个 GPT 是非常了解的。嗯，比如说我要，我，我需要有一个具体形式的一个网络，我需要一个CNN，我需要接一个啥？接一个Transformer，这个让它帮我写都没问题，这种也是高度模块化的东西，所以它也是非常擅长，我觉得。

Speaker 1 13:33 
明白，所以相当于就是说太前沿的东西它没掌握，所以还是要自己来完成。对，是的，OK，那 coding 就相当于coding，也就这些了吧？那还有我刚才那就提到还有什么来着？下一个什么 writing 吗？还是什么？你刚才第二个，你说。

Speaker 2 13:55 
我想一想，哦，数学方面的，就是说，比如说有一篇您说的是 coding 方面吗？还是说整整一个大的方向。

Speaker 1 14:05 
都行嘛？就是你刚才不提到数学这一个大的领域，因为我很少见到会用到数学上，因为 ChatGPT 大家都不觉得数学不太好。

Speaker 2 14:14 
对，是它，如果让它去推导具体的公式，比如说让它从零开始推的话，确实它效果不好，但是比如说我想了解一个全新的一个领域，比如说我发现了一个新的某一种概率分布的一种表述方式，或者是在相关的一个矩阵。这个东西它可能对于数学系的同学来说它只是非常基础的一个内容，但是对于我来说我从来就没听过它。所以我如果要从 0 开始学，我要去网页上搜课程去看的话，这个其实是非常费时间的，包括它可能课程也讲得不是非常系统，那这个时候因为它对于数学系同学来说只是一个很简单的内容，所以对于 GPT 来说它也并不是很复杂。那么在这种情况下，我就会希望它帮我生成一个比较 comprehensive 的一个，一个对，一个introduction。

Speaker 1 15:09 
就是说你只是让它生成一个introduction，而不是让它生成代码，或者是帮你去给出一些往下推的什么公式之类的，对吧？对，是的，这里相当于像一个学习的过程。

Speaker 2 15:24 
是的，对，可以，可以这么理解，可以这么理解。

Speaker 1 15:28 
那就比如说你是直接把这一小部分丢进去，还是说会把我？我也不太懂，你是说 paper 还是说 book 里面的？

Speaker 2 15:37 
我一般读 paper 读不懂的时候，我会找到它这个关键词，就是比如说我想知道这个所谓的。

Speaker 2 15:46 
If a feature information metrics.

Speaker 2 15:49 
它就是一个关键词了，然后我给它一些我要应用的背景，然后放进去，然后我希望它可以在这个背景下帮我解释这个概念到底是什么意思，然后在什么情况下它可以使用？它有哪些优点和缺点？

Speaker 1 16:03 
哦，OK。那，那如果你不会直接把 paper 丢进去吗？还是说没必要？

Speaker 2 16:10 
我觉得 paper 直接丢进去它可能抓不到太多的重点，它可能会偏到一些其他的方向上面去，所以我更习惯于自己提取出一些关键词以后给他一定的context，然后让他帮我解释。

Speaker 1 16:25 
这个 context 不一定是 paper 下面的。

Speaker 2 16:27 
可能是对你项目，这也是个问题。

Speaker 1 16:30 
是你项目上是的，那这里其实是概念解释。那比如说公式呢？公式，比如说你直接截图揪进去的话，他能帮你很好地理解吗？

Speaker 2 16:40 
其实也可以，因为我毕竟不是数学系的同学，我很多时候他只是我找到一个很好的一个概念，我觉得他跟我这个项目比较契合，那么我也只是希望简单地了解一下，然后我直接拿来就用，我也没有想去往下继续推导或者是继续去就这个公式本身给出一些新的结论，我更多的只是希望把这个公式拿来用，所以在这个层面上 GPT 还是挺好可以解决。

Speaker 1 17:11 
那你下一步的话会不会就是把公式让 GPT 帮你写成代码，或者是写成什么？

Speaker 2 17:18 
嗯，这也会，就是如果这个公式比较复杂的话，比如它涉及到一些坐标转换、矩阵转换这种东西我就懒得去想，直接就飞给他，哈哈。

Speaker 1 17:31 
ok，对，你的背景是都是 EE 吗？就是一直都是EE。是的。那其实现在算 CS 吗？可以，我有点分 EE 和CS。

Speaker 2 17:42 
其实更多的时候，因为 CS 他主要是要做算法本身，但是 EE 可能更多时候是用把这个算法进行应用，这就是我刚刚说的，我可能对于数学公式本身并不需要太多的了解，我需要的是应用怎么把它拿来用。对。

Speaker 1 17:59 
但应用的过程不也要提升准确性嘛？那提升准确性不是又落到了算法的改进上了？

Speaker 2 18:07 
是，但是这在这种情况下，我们对算法的改进可能只是比较小的改进，不会像 CS 或者是数学系的同学直接就给你整个全新的出来。我们，我反正我个人没有这个能力去做这件事情。

Speaker 1 18:22 
OK，可能是我还没反弹到 CS 的，就目前还没有反弹到 CS 的，我还挺好奇的。对，ok，那其实算学习 learning 的过程。那还有writing，就是 writing 的话，你刚才说到会把它生成大纲，然后再，然后往下就是你具体的整个任务是什么样的？

Speaker 2 18:44 
是的，比如说就拿我前段时间过 Q1 的这个例子来说，ok，比如说我要做这一系列的 PPT slides，做出来，那么我可能脑袋中大概有一个概念，就这个 Q1 我要怎么讲？我要先讲问题，然后再讲 literature review，再讲我的算法，讲实验、哔哩这些确实大的方向没问题，我们我自己有了解，但是每一个方法下面我应该怎么就每一个模块下面我应该具体怎么讲这个，嗯，有的时候可能概念不是那么的清楚，那么这个时候我就会把我做的东西以及我想讲的东西形成一段我自己的描述，但是他可能不是那么具有结构性，这个时候我把这一段不那么有结构性的文的描述放给GPT，然后让他帮我整理出我这，比如说我就要做 10 页这个模块，我就 10 页。那么每一页我大概应该做什么？应该讲什么？

Speaker 1 19:49 
那有个问题就是因为那你是相当于把你的 QE 的整个的丢进去，就是整个的文本丢进去，还是说把之前的一些 paper 给丢进去？丢进去的是什么东西？

Speaker 2 20:01 
更多时候其实我是，这只是我自己的描述而已，就我会做一个初步的处理，我如果我把整一个 Q1 报告丢进去，我感觉他可能不太行，因为比较长。

Speaker 1 20:11 
嗯，是你的意思说你自己先描述一下我大概什么什么东西？是的，然后让他生成一个。

Speaker 2 20:20 
对，是这样，比如说我现在就想做 introduction 这个模块，那么这个模块里面这一个部分，那么这个部分里面我想讲哪些东西？我把它大概列一下，然后我他们之间的逻辑关系大概是什么样子的？然后我就写完以后放给GPT，然后请他帮我生成，就是更细化的一些，每一页 PPT 上面应该展现哪些东西这样的内容，然后让它更有逻辑顺序一点。

Speaker 1 20:49 
那比如说 introduction 的话，你之前不已经写好报告吗？ introduction 不能直接丢进去吗？

Speaker 2 20:55 
introduction 在报告里面可能太长了，就它覆盖了很多很多的方面，但是我邱毅只有introduction，我只给他 8 分钟，那么 8 分钟之内我能覆盖的东西其实没有那么多，所以我要做一定的取舍。

Speaker 1 21:09 
那就是没有考虑过，就是比如说 introduction 直接丢进去，然后让 ChatGPT 先总结几个点出来，然后你再把这几个点再让它做成PPT。

Speaker 2 21:18 
对，这确实应该是更方便的一个一个办法，但是我可能有时候对于它，对于长文本的处理能力不是那么有信心。我一般都会自己先处理一下，但下次确实可以试一试这个办。这个写挺好的。

Speaker 1 21:35 
可能是计算机类和商科，因为我们商科文本的东西特别多，所以基本就文本上会用的比较多一些。还行。对，你刚才说到就是，那你把你自己就是，大概就是比如说你要做哪些事情，只是很零散地丢给他，然后他帮你生成，那不是会遗漏一些地方吗？会不会？

Speaker 2 21:58 
确实是会，但是我一般在提前做这个文本预处理的时候，我会大概想好，就即使漏了些东西，那可能就真的没办法了，哈哈哈。

Speaker 1 22:10 
哦，就是说其实你是自己想好大纲了，然后让他帮你去整理。

Speaker 2 22:16 
对，我可能每一个大纲内部我要讲哪些东西我大概是有数的，但是这些东西它之间的逻辑顺序如何把它排列起来，然后讲得让观众听得更加，就是更加可以说服观众，这个是我需要他去帮我总结这个前后顺序。

Speaker 1 22:35 
就其实相当于帮你梳理，给你一个是的，是的，逻辑线，是的，那这个其实不算，他就是不太算那种，是，就是正式的那种writing，更像是把你的一个成果进行一个梳理之后像 presentation 的感觉。对，就是帮你去表达。对，那你正式的 writing 会用到它吗？比如说你的 Q1 的 report 里面会去。

Speaker 2 23:00 
也会的。对。

Speaker 1 23:03 
嗯，那这种是一般你是怎么让他去写的？

Speaker 2 23:08 
这种情况下其实大概逻辑是差不多的，但是有两种，两个步骤吧。第一个步骤就是说我，比如说我还是写introduction，那么 introduction 里边要包含哪些内容？这个东西我也有个大概的想法，然后请 GPT 帮我生成每一个章节，我应该说哪些东西，然后它就这个要点生成完以后我不会让它继续往下写，因为如果让它继续往下写，它会写的东西会比较空泛，我会自己去把每一个里边东西填好，不用我自己的语言填好以后我让它进行润色，所以润色就是第二个步骤。所以总结来说，第一个步骤是让它帮我生成大致的框架，第二个步骤是让它帮我润色，我自己具体写出来的内容。

Speaker 1 23:53 
诶，那我可以诶，等等，等下，就是因为你是先写 introduction 还是说先写后面的？那就是你先写哪个？因为它很长，那就是那个 Q1 的report。那你先去让他撰写哪一个模块呢？

Speaker 2 24:06 
其实我从 introduction 开始写，因为我后边的那个 experiment 和 methodology 那个层面，其实我之前写过论文，我直接把论文粘过来就完事。

Speaker 1 24:17 
对对对，我其实有个问题，就是你会把这些已经写好东西再丢给他丢进去 chat GPT，然后你再去写 introduction 吗？

Speaker 2 24:25 
不会，我暂时没有这么干，我即使要这么干，我也只是把之前论文的，比如说 abstract 把它放出来，就是我简要的告诉他我写了哪些东西，然后让他。

Speaker 1 24:36 
为什么呀？

Speaker 2 24:37 
就，就我我，我还是不相信他的这个长文本处理的能力，我觉得他会偏到其他的地方去，这可能是我我对于他的一个比较刻板印象的问题。ok，ok，对。

Speaker 1 24:51 
没有，因为我觉得假如你把你之前写的东西全部丢进去，现在他已经学习了你的大概内容，那可能写出来东西可能会精准一些，更。

Speaker 2 25:02 
理解。确实，对，如果那行，如果我对，确实这样应该理论上来说确实应该是这样。

Speaker 1 25:10 
那比如说你把你想让他写的东西就是零零散散地丢进去之后，然后他给你生成的是，嗯基础文本，还是说只是一些简短内容生成是什么？

Speaker 2 25:23 
在第一个步骤就是我让他帮我列提纲的时候，嗯，我希望他只是一些简短的内容，就他每一个部分只是简短的描述一下这里应该写什么。

Speaker 1 25:35 
哦，就是不会，相当于不会说先完整的给你，然后你再拿他的改。

Speaker 2 25:39 
不会因为我觉得他写的东西有时候实在是太空了。对，就是一句话前后反复的说，我也有点顶不住哦。

Speaker 1 25:49 
懂你意思，但是你有没有考虑过？就是虽然说你给他大纲了，然后再让他对每一段进行写，就是不要整个一起拉群，直接写给你。

Speaker 2 25:58 
嗯，这个其实是会的，比较常见的一个场景就是说我前一段已经写完了，然后我后一段也写差不多了，但是前后之间这个衔接的这个段落就我希望他稍微有一点逻辑，过渡的比较平顺一点，但是我又没有找到一个很好的办法，那么我就会把前后两段一起放给他，然后告诉他你帮我中间生成出一段出来，就起到一个过渡的作用，我觉得这也是让它比较大段的生成的文字。

Speaker 1 26:30 
中间生成一段吗？我以为你只是前后两句，让它帮忙帮你改写一下。

Speaker 2 26:37 
看情况，有的时候比如说前后两大段写完以后，可能前面那一段的最后边，还有后边那一段的最前面给它稍微改一改，如果这样能连起来也ok，没问题。但是如果可能比较需要比较多的描述的话，我会让它重新开一段出来，我也会这么干。

Speaker 1 26:56 
嗯，那你觉得 writing 的话是 GPT 好用一点还是 gemino 好用一点？还是。

Speaker 2 27:02 
writing 的话，我觉得 GPT 和 Gemini 差不多，但我个人更偏向 GPT 一点，因为我用它用得比较顺手。

Speaker 1 27:12 
但我是的，我最近觉得还是谷歌的好用一点，我还挺上瘾。

Speaker 2 27:16 
谷歌的。

Speaker 1 27:17 
就Gemini。对。

Speaker 2 27:19 
谷歌 Gemini 它是不是对于长文本处理能力会稍微好一点？但这个我没有具体地了解过。

Speaker 1 27:25 
我觉得它可能没那么造假，会比较学术一些。但是那它找文件的话， GPT 会找得更精准。就是我觉得两个功能不太一样。

Speaker 2 27:35 
确实。

Speaker 1 27:36 
对，比如说我这么干，就是比如说假如我要写一个横向那种项目，那种项目书的一个总结的时候，我就会让 Gemini 去写个框，然后这个框架再让 check GPT 帮我去找文献，帮我补充进来。应付的话我就这么做。

Speaker 2 27:52 
就两个工具，这样确实可以。对，确实我也干过这样的事。是的，我觉得这样挺方便的。其实。

Speaker 1 27:57 
你也干过这样的事。

Speaker 2 27:59 
对，因为它确实很方便，因为比如说GPT，它的 deep research 功能代表它其实已经有能力去阅读一些比较大量的文件，对吧？所以没有其实是可以。

Speaker 1 28:11 
没有就是假如不用 deep research 的话，好像也可以，就是 thinking 那个功能就行了。

Speaker 2 28:17 
GPT，是的，确实是。

Speaker 1 28:19 
然后我发现 research 好像反而没有。其实我觉得 research 目前用我觉得不是很好用。

Speaker 2 28:25 
它 research 我看它，其实我觉得它大致的逻辑是说，比如说你输入一个关键词，就是你想要让他帮你解释这一部分的内容，嗯，我发现他会去找，就是综述他会去找这一部分的综述，然后从综述里边把东西抠出来给你，就他可能很多时候并不是原创性的给你的这一些框架他可能更多从综述里面抠出来以后就是，然后再给用户。

Speaker 1 28:54 
意思就是说 deeply search 反而是从一些文献就是不会造假。然后如果是正常生成的话，可能会有他自己发散的一些东西在里面。

Speaker 2 29:05 
我觉得应该是这样，因为 deeply search 的话我可以很明显地看到，比如说我现在已经，我之前看过这个领域内的一些综述了，然后我知道它的框架是怎么样，如果我再问GPT，让它在我帮，让它帮我在这个领域内做一个 deeply search 的话，我会发现它给出来的内容和我之前看的综述是很像哦。

Speaker 1 29:27 
对，原来如此。

Speaker 2 29:29 
这是我个人的感受啊。

Speaker 1 29:31 
没有没有，我看 deeply search 的时候就发现它偏文献的东西太多，然后就是没有一些创造性的东西。那如果是，对，就如果他自己生成的话，就创造性的东西会多一些。

Speaker 2 29:42 
嗯嗯，确实。

Speaker 1 29:44 
对诶，那我就好奇了，比如说没有 Brainstorm 的，就是头脑风暴的一些跟他的一些交互。

Speaker 2 29:54 
这个我确实说的比较少，因为我之前其实尝试过几次，效果都不好，就是说我希望解决这一个问题，然后我其实脑子里已经有几个潜在的方案了，然后我就问，我就把这几个潜在的方案以及我想解决的问题一起给他，我说你能不能我们再讨论一下有没有什么其他更好的方案？但其实我发现他还是就很难跳出这个框架，他主要复述的还是之前我讲的东西，所以我感觉他这个头脑风暴可能我使用起来没那么顺手，或者说可能这个领域内也就确实只有那几种解决方案，所以他怎么想也想不出去。

Speaker 1 30:35 
我不是，我有个问题是你已经输入背景了吗？还是说就已经给了东西是吗？就是想让他头脑风暴的时候。

Speaker 2 30:45 
对，没错，我会把一些比如说 context 给他，然后我一些基。技术的想法也会告诉他，就是我，我这么告诉他目的是说我已经想到这个了，你就别再说了。

Speaker 1 30:54 
但是你说你就是因为我的理解，就是你给他，你想到这些context，他反而会从这里面继续去挖我，我最近发现是这样的，对，就所以我反而就是不会给太多的那些信息，就是让他自己去想。然后我就想说，比如说给我一些 interesting idea，或者是嗯哼，对，就是可能用的方法会不太一样一些吧。

Speaker 2 31:20 
确实这也是个办法，下次可以试一试，就是不告诉他太多我现在想的东西，直接让他从就从开，从头开始做。

Speaker 1 31:27 
没有你你也可以这么问，比如说我现在想法是这些，请你找一些别的来对比。我的想法就是，对，这样子的话可能。

Speaker 2 31:36 
确实下次可以试一试。

Speaker 1 31:39 
那我就是那个 Prompt engineering 的话，你有学过吗？还是相关的？

Speaker 2 31:45 
这个确实没有，我没有去学过 Pro- prompt engineering，这个。

Speaker 1 31:51 
就是完全没了解过。

Speaker 2 31:56 
如果他有一套系统的理论的话，我这个确实没有了解过。嗯，但是我只能说我发现比如说你把你的问题分成不同的小点，这种比较基础、比较直觉性的东西还是会一点。

Speaker 1 32:11 
就是说没有查阅过相关资料，也没有去学习过相关课程。可以这么理解。对，是的。然后就是可能平时用着发现那些 prompt 比较好用，就是经常用。是的，那除了分成小点，你还觉得有什么比较好用的？point。

Speaker 2 32:34 
分小点，然后还有关键词，就是我会先把关键词给他，告诉他你主要是在这个领域下边进行工作，这些你这些是主要使用到的。

Speaker 1 32:46 
关键词，就比如说。

Speaker 2 32:56 
怎么说呢？比如 GPT 它有个功能是说我创建一个新的project，对吧？那这个 project 里面它也可以放一些 project description，然后我会把这个工程里面涉及到，比如说我现在想研究这个高斯分布，那么高斯分布就是一个关键词。然后我希望具体了解哪一部分的高斯分布，比如说是离散的或者是比较稀疏的高斯分布，那么这个时候我会把这些关键词一起放给他，但其实总的来说还是比较原始的一种方式。

Speaker 1 33:30 
哈哈哈，我也不知道什么原始的方式，因为我很少用到 coding 和数学上，很少用到数学上还有概念上。

Speaker 2 33:45 
Prompt engineering. So you're a professional, like academic writer, avoid to use some sort of two flowery language and use formal term. Alright, okay. You're encourage to diversify your vocabulary. That's it. Just just like just started.

Speaker 2 34:05 
就把这些要求也是列成小点分给他。那。

Speaker 1 34:08 
懂了懂，其实就是把 prompt 写具体一点嘛。然后是的诶，你觉得就是假如你刚才也说把它定义成一个角色的话，会确实明显提高吗？还是说只是一个心理暗示？

Speaker 2 34:22 
我现在可能只是心理暗示，因为这个我其实用的不多，我更多的时候可能我只是开一个新的 project 的时候，比如说 GPT 的 project 的时候，我会把它放在 project description 里面，ok，它那个 add instruction 的地方我会给它写一些这些东西。但是如果你让我每一条问的时候都给它写，我就嫌烦，我就，我很不乐意干这个事。

Speaker 1 34:45 
那其实我比较好奇是你，你大概什么情况下会新开一个project？就是比如说这个对话框是完全都是跟这个项目相关，那什么时候会再新开一个？

Speaker 2 34:57 
嗯，这是个好问题，我一般开 project 的时候是我要学一些东西的时候，比如说我现在要学这个数据库的这个操作，那么这是我要开始全新学一个东西的时候，我就会在这里边开一个project，然后去问他。但是或者说我要我知道这一个代码的工程，我可能有很多子的模块需要他去生成的时候，我也会把它开一个新的工程，但是很多时候这个工程于我而言它只是一个文件夹的作用，就是我希望把这一系列的东西给它放在一起去。

Speaker 1 35:34 
诶，那比如说，比如就假设以 writing 来说的话，那比如说你现在这个是撰写，那比如说到润色你会再新开一个吗？

Speaker 2 35:44 
对话框我会新开一个，但写完以后我一般不会让他直接继续润色，因为我觉得这样可能对话太长了。

Speaker 1 35:51 
那 project 短一点，没 project 的话是那个新的一个功能吗？我记得好像有一个 new project，是不是在 Chat GPT？

Speaker 2 35:59 
对，就是那个new。

Speaker 1 36:01 
project，我还没用过，那。

Speaker 2 36:03 
它其实更多就像是一个带着一点 context 的文件夹，就是说你可以把你一系列的对话放进来，然后给他们加一个统一的instruction。

Speaker 1 36:14 
新的一个o，OK，我没用过，我觉得这，唉，好吧，那，那我可能可以尝试一下。

Speaker 2 36:22 
对，那我为什么在学东西的时候希望把它放在一个文件夹里面？就是因为我学东西的时候可能会问一些比较零散的问题，然后如果这样，我在总的那个 chat 下面一起开这么多对话框的话，我就嫌它整得很乱。对，然后可能我学了以后要回看的时候，我就直接找这个文件夹，会方便。

Speaker 1 36:43 
哦，明白，那其实就是相当于说你在这个文件夹下，比如说都是一些学习的东西，就零零散散的，就是也不用管对话的情况，对吧？就是比如说，对吧？就比如说这个对话可能是跟高斯什么什么相关，然后另外一个对话可能跟什么什么相关？还是说你会把比如说这个对话无所谓，什么东西都可以丢。

Speaker 2 37:03 
我一般不会这么干，我一般一个对话就干一件事。

Speaker 1 37:06 
就可能交互也没有太多轮，对吧？

Speaker 2 37:09 
对，是的，我一般避免这种比较长的交互。

Speaker 1 37:13 
那这种学习是避免长交互。那如果对于正式的任务，比如说就是你刚才说 coding 啊什么的，那这种会不会就是长对话了？

Speaker 2 37:23 
这个那就没办法了，就是因为我一定需要他之前的一些 context 嘛？我一定需要这个的话，那我也只能进行长对话。那如果有的时候我发现他写着写偏了，那我就会重新开一个。

Speaker 1 37:36 
哦，我懂你意思，就是写着写着，唉，就是反正也给不出好的东西了。那你重开。对，相当于就是又要把所有的 context 和那些东西又要输入进去。

Speaker 2 37:48 
对，我一般是说，比如说我发现要重开的时候，就代表它结果不好。对，那么我就会把它之前改的一个我觉得还 ok 的一个中间的结果复制出来，然后新开一个给它，然后让它在这个上面继续改。

Speaker 1 38:03 
明白，那你有没有评估过大概多少轮之后会出现这种情况？还是说遇到一些问题的时候才会出现这种情况？

Speaker 2 38:14 
我觉得长代码交互的话，可能 10 轮以后他可能就会忘记一些内容。

Speaker 1 38:25 
ok，那如果最后那 writing 也会这样吗？就是因为你刚才说是coding。

Speaker 2 38:31 
writing 的话，如果单纯润色就无所谓。ok，因为润色它就是基于当前的输入，然后你给一些简单的 instruction 它就可以做。那如果是，比如说有逻辑性的一些写作的话，我觉得可能在写作方面可能要短一点，我觉得可能六轮、 7 轮它就会出一些问题，但是可能我让它生成的东西比较长。

Speaker 1 38:55 
明白明白。没没没，我只是在评估一下如果我后续实验大概要多少轮来做这个实验。OK，那刚才说到 writing 润色还有什么吗？还有你会用到的场景。

Speaker 2 39:15 
简单的就是邮件润色，有时候写邮件、发邮件给老板，或者发给一些学生的话，我会让他润色一下，但这个都是比较非常基础的。其他的。

Speaker 1 39:27 
比如说有没有什么比较有趣的协作方式？就是比如就无所谓什么场景，就比较有趣的协作方式。这个。

Speaker 1 39:48 
诶，我还我这个那。嗯，没有，可以先聊别的吧。就如果某个任务你不熟悉的话，你会怎么处理啊？因为不是所有任务你都是熟悉的，比如说coding，或者是哪一个。

Speaker 2 39:58 
不熟悉的话，我会把我要做的东西写用自然语言描述一下，然后给 GPT 让它帮我生成一个初稿，然后根据这个初稿它给出一些信息点，我再去学习每每一个信息点代表的是什么，比如说它用了不同的方法，它用了这一系列的方法，但是这一系列比可能有 10 个不同的方法，可能中间我只有可能 5 个， 6 个是懂的。那么剩下 4 个我就会开单独新的对话框去问他，然后等我把这 10 个都搞清楚以后，我会再回来继续这个，就是在一开始写这 10 个任务继续改进之类。

Speaker 1 40:36 
诶，但我有个疑问，就是你不会去选择，比如说他给了 10 个方法，你不会去选择你熟悉的方法吗？就把不熟悉的全部都去掉。

Speaker 2 40:44 
我说这十个可能是就是一系列，比如说他用完第一个以后，第一个的输出是第二个的输入，这样一系列的往下走。哦，是这样的，对，是的。

Speaker 1 40:54 
我以为就是会更加倾向于那种 brainstorm 的那种感觉。就是这些，对，这些是你熟悉的，那我就保留，那些不熟悉的我就去掉。

Speaker 2 41:04 
如果这种情况下，他一般给出那种熟悉的，我熟悉的一般是比较简单的，就我不乐意用，因为太简单了。我确实熟悉，但是我觉得可能效果不好，所以我就更希望他能给出我一些我之前没听过的，然后我去查一下。

Speaker 1 41:19 
OK，OK。那有没有存在过？比如说在构思论文 idea 的时候让他帮忙？

Speaker 2 41:30 
有，比如说我现在要评价我这一个系统的值的性能如何，那么这个时候，嗯，我希望他能帮我找到一些已经存在的数学指标。这个其实是一个我觉得如果没有 GPT 的话是一个比较难的过程，因为我需要阅读大量的文件，对，我才能看出来大家是怎么用。嗯，但是这个对于 GPT 来说可能我觉得是比较简单，因为这些基础的知识其实它是掌握的。比如说最简单的我要评价三个潜艇之间它们的通信效果如何，这个其实我们人类描述它是一个非常抽象的概念，就如何表示这个通信效果。嗯，那我要描述这个东西的话，确实学界中有人用大量不同的方法去做，但如果我要找到他们，我要一篇一篇读，或者说找好几篇 review 出来一起读，那这个我就纯懒了，我不乐意干这个。然后我就问他，就是当前领域中大家一般用哪一些方法给我几个备选？然后在这几个备选中我会去验证一下，比如说 123 没问题，确实大家用过这个，OK，那我就会把它拿来用作我的一个指标，这样就极大的加速了这个项目的推进。

Speaker 1 42:48 
有点像信息检索。

Speaker 2 42:51 
那对，确实可以这么理解。

Speaker 1 42:53 
那不会存在，比如说老板只给你一个大概的方向，idea，你自己要去构思。有存在这种情况。

Speaker 2 43:01 
我在 Phd 刚开始读的时候确实存在这种情况，就是这个强化学习，它是一个非常宽泛的概念，那么它中间具体有哪一些指向是，就哪些小的方向是值得做？嗯，我其实一开始问过他这个问题，他给出的答案我觉得还是蛮好，然后我验证过以后，其实也是我现在研究的一个方向。

Speaker 1 43:23 
你的意思是说 ChatGPT 给你生成什么？就是比如说跟潜艇结合的方向，对吧？然后就是给了几个，可以这么理解吗？

Speaker 2 43:33 
它如果具体跟任务合并的话，其实对于他来说有点难度，我更多的是问他单纯在算法层面的，因为这样的话整一个 context 就会很小，就他能检索的信息会变少很多，他单纯只看算法的话，比如说强化学习他有多智能体的，或者是分层的，就是强化学习他自己的一些子类，那么在这个方向上 GPT 确实可以给出一个比较好的一个总结，那比较依赖这个。

Speaker 1 44:02 
那比如说下一步的话会哦。会把这些子类，比如说结合我现在研究方向，你再帮我再构思，会这么去用它吗？

Speaker 2 44:12 
会，我会说结合这些子类在我现在研究方向上它会有哪一些优点？ok，这个就是我比如说做 Q1 的时候，我说明我为什么要用这个方法？这就很重要，因为如果它有一些优点的话，那我就可以拿来用。

Speaker 1 44:28 
嗯，那就相当于说你现在的研究方向是指那很值钱这么去弄出来的吗？就是生成出来的吗？

Speaker 2 44:37 
可以这么说，因为一开始的时候我对强化学习了解也不多，因为那时候刚开始读，所以我需要他给我一个大致的脉络出来。

Speaker 1 44:46 
现在也算是一种 Brainstorm 给你 idea 的过程。对。

Speaker 2 44:51 
确实，但这个 Brainstorm 出来的结果是一定要去验证的验证，要不然出事。

Speaker 1 44:57 
嗯，那你验证的方式一般就是 Google scholar？还是说怎么去验证？还是点他的文献？

Speaker 2 45:05 
他给了我这几个方向以后，我就有关键词了，我就用这几个关键词去搜相关的这个综述，然后大致瞥一眼他的综述，你不会。

Speaker 1 45:16 
表述错误丢进去让 ChatGPT 读吗？

Speaker 2 45:21 
确实，我为什么不这么干？哈哈哈，但我当时还是因为当时 22 年，刚 2 年底的时候刚出嘛，所以，ok，你也不太信任他，我还是更多的自己读，但确实这应该让他自己再帮我读一下啊。这快很多。

Speaker 1 45:39 
就说现阶段也不会让他帮你读文献了。

Speaker 2 45:47 
我一般不这么干，因为我觉得他读出来的文献和我直接去看 abstract 其实差不多，除非我是带着问题去，就我想知道这份文件，就他这个处理方式为什么可以这样做？那这个时候我会让他帮我读，但是如果只是简单的速读的话，我更倾向于直接去读 abstract 和conclusion。

Speaker 1 46:09 
就是说如果精读的话也是自己去就好好地读它，那可能是因为就之前的访谈的时候有人提到说 copilot 吧，好像是 copilot 说读先会导出思维，导图什么的，还挺有用的。我还没尝试。我我也想尝试一下这个功能。

Speaker 2 46:27 
因为可能就是我这个学科，他一篇论文不会太长，所以说他可能只是集中于某一个方法，这个方法很多时候是数学的一些问题。如果我让他帮我做一个粗略速读的话，他其实没办法给出太多有效的内容，他只是用他自己的语言把这个数学方法描述了一下。那我不如去看abstract，因为 abstract 可能也会写。嗯，然后明白。对，但是精读的话，比如说这个数学我确实不懂了，他为什么这一步可以这么干？他涉及到了哪些基础的东西？我确实数学不好，那我也只能问他，带着问题去学其实挺好的。

Speaker 1 47:07 
对，如果有问题的话相当于就是帮你解答问题。是的，学科差异吧。学科差异，因为上因为授课都四五十页，烦死了。

Speaker 2 47:17 
嗯，对，我之前也看过一些这个上课论文，看的我是。

Speaker 1 47:22 
头都大。你看上课论文是看什么类型啊？是 information system 吗？还是 operation man- management？

Speaker 2 47:31 
其实之前做 RA 的时候做过一个，是那个，就是总的来说就是我有一个公司的数据，比如说他每一年他要披露相关的数据，但是他披露的数据中有一些数据是他不披露的，就他不是法定需要披露，他只是自愿披露，有自愿，有时候不披露。嗯，那么这个时候我可不可以根据他以往的披露信息去预测他这个值到底是多少？就抽象出来，就他其实相当于是一个regression，是一个回归的一个过程，就是用 deep learning 就可以把它做完了。

Speaker 1 48:12 
有点像公司金融。

Speaker 2 48:15 
对，可以这么。

Speaker 1 48:16 
对，就是年年报的年报他前几年的值，然后来预测他下一。

Speaker 2 48:21 
年的。对对对对对，是这样。

Speaker 1 48:24 
但这个我一直对这种方法一直存疑，就是可能对于商科，因为我觉得就是受到各种大事件的影响，比如说中美贸易或者是 Covid- 19，就是就它的波动性其实很大，就是所以我们一直都很质疑深度学习能不能预测股票什么的。

Speaker 2 48:42 
对，所以其实我当时做的时候我也不太 care 这个问题，我做 IA 就是纯着干活就拿钱，他具体整一个项目如何走我不太关心，他给了我具体任务，我就把具体任务完成了，就仅此而已。至于这个效果到底好不好，那不是我来考虑的问题了。哈哈哈，就是说。

Speaker 1 49:03 
paper 上是不会挂你名字。可以这么理解。行。

Speaker 2 49:05 
对，没错，所以我也无所谓，哈哈哈。

Speaker 1 49:08 
哪里的 r 呀？你是说国内还是国外？

Speaker 2 49:12 
SMU 的。

Speaker 1 49:13 
哦，你在 SMU 做 r 诶，那你不是之前？对，那你不是已经碰到三科了吗？那你怎么又回到了一一？

Speaker 2 49:21 
哦，这是我在读博的时候做的。

Speaker 1 49:23 
嗯，你读博还做 r 啊？

Speaker 2 49:26 
对啊，没问题。牛牛的，其实纯纯牛马。这个。

Speaker 1 49:33 
我懂，因为你如果去帮三科的做数据处理，基本就是给你数据，你去跑预测，他也不会告诉你什么叫你做什么。

Speaker 2 49:42 
对，所以我至于你刚刚提的那个问题具体有效与否，这不是我要关心的，我要关心只是把数据回给他就完事了。是的，哈哈哈。

Speaker 1 49:53 
能理解，因为这种像的东西是哎，商科要考虑的问题。

Speaker 2 49:58 
因为他很有很强的这个专业背景，这个让我去学就不现实。我也学不明白，所以对，我懂，对，我只是关心数据而已。ok。

Speaker 1 50:10 
那还有什？我想想。

Speaker 1 50:17 
还有什么吗？好像也聊到很多的任务了。

Speaker 2 50:22 
对，这其实是我平时主要让他帮我干的事情，就是这些。

Speaker 1 50:27 
你存可能我问的有点就是会存在情感支持的对话吗？因为我发现女性会比较多，我其实。

Speaker 2 50:37 
我可以理解，但是我个人我目前没有什么需要这方面的需要，因为我觉得独播已经让我累得不行。

Speaker 1 50:46 
不不不，这个情感支持，我指的是比如说生病，或者是就是有些人会。

Speaker 2 50:53 
这个，确实，我有听到一些朋友确实会这么干，但是我觉得这个有点过于赛博朋克。对，我一般不干这种事情，而且我个人对这个算命这些东西我可能不是那么感兴趣吧。

Speaker 1 51:06 
OK，OK。你哪里人啊？北方吗？广东人，不感兴趣吗？

Speaker 2 51:11 
哈哈哈，可能深圳不算广东，哈哈。

Speaker 1 51:17 
OK，因为我福建的其实会对这些比较了解一些。

Speaker 2 51:22 
嗯，那我觉得可能如果真的要去算的话，还是得找大师这个GPT，毕竟，对吧？这个是一个西方的产物，这个没有做本土化改造，它可能没有这个功能。那。

Speaker 1 51:33 
你意思说 DeepSeek 是吗？ DeepSeek 属于本土。

Speaker 2 51:36 
哈哈哈，或许 DeepSeek 会有更好的效果。确实，但是我一般比较少用DeepSeekok。

Speaker 1 51:42 
OK，那其因为我聊到就觉得很奇怪，因为有些就主要是还是女性的访谈过程中，就是有些会提到心理咨询师，因为他觉得就是这种过程比较私密，也不会存在，你会有心理负担，你爱怎么问啊。对，然后还有就是说把用于 dating APP 中怎么去用户画像什么的，我觉得，嗯，是我没有考虑过的一些那个场景。

Speaker 2 52:06 
这个确实很，我觉得很有意思。

Speaker 1 52:10 
对，也是他们，也是，对，也是，他们目前也是一个研究领域，好像是 media 还是education，他们会研究一些这种情感支持。确实，那你还有什么别的场景？可能也没有了。

Speaker 2 52:27 
我一般除了工作和学习以外，我一般不太碰GPT。对，其他的。

Speaker 1 52:35 
比如说旅游场景什么规划？

Speaker 2 52:39 
旅游规划可能都，我可能相信小红书一点，哈哈，因为 GPT 的更多，我之前尝试过，之前去台湾玩的时候，我其实尝试过让 GPT 帮我生成这个旅游规划，但是我发现它更多的只是非常笼统地把一些概念、一些有知名的景点把它给笼络起来，它不太考虑这个时间和空间上面的这个联系，比如说我，比如说去台北，你不能前一个项目是在北边，后一个项目在南边，这个就很不合适。但对更多的时候可能还是得像看小红书，或者说找到这些景点，然后自己排，这个是我比较常用的办法。

Speaker 1 53:23 
但是不存在一个问题，就是可能是你给的 prompt 不够具体了，你可能是没有先指定说，比如说这一天你要帮我安排好合理规划这个。

Speaker 2 53:33 
路程。确实对，我当时就很敷衍，就是来，我要去台北玩三天，来，你给我来一份，然后就确实，嗯，ok，好像没有这个习惯，确实可以考虑。

Speaker 1 53:49 
一下，可能你把它当工具。可以这么说嘛，就是相当于说我对它也不抱有太大期待，也不带有不太有耐心，反正就是对，因为可能，对，可能每个学科真的用的方式差异很大了。就没耐心的话，就是就可能也会存在不信任，就是各种的心理上的一些问题了。

Speaker 2 54:12 
对，我更多确实是把它当工具在用。

Speaker 1 54:15 
ok，OK，OK。想一想，那你觉得会存在就是 GPT 用这么久以来，某些可能技能或者是某些思维方式上有下降吗？或者是有没有担心过这种问题啊？

Speaker 2 54:32 
嗯，展示来说下降倒是我没有观察到，但是它的 5 确实和 4 我觉得是齐平的，所以也算是只是持平而已。它没有下降，不是。然后至于担心对你自己，对我自己，嗯，怎么说呢？应该确实是有这一方面的顾虑的，比如说这个英文这个润色的能力，可能我之前会用一些比较简单的工具，比如说 Grammarly 这种工具，它只是单纯的查语法，然后润色的话我确实需要自己绞尽脑汁去怎么把这一段写得更加比较好一点。然后现在长时间用 GPT 以后，这个我的这个功能确实可能是有一定下降。

Speaker 1 55:18 
但我感觉好像也不叫下降了，可能更多是节省了很多时间嘛。

Speaker 2 55:23 
对，就是很久很久没有这样绞尽脑汁地去润色过一段东西。

Speaker 1 55:29 
那很没必要，因为 GPT 的发展，这个东西就是稳定的发展，它又不可能。对，是，我觉得还好。对，我觉得只要不影响自己的深度思考，因为 critical thinking，对吧？就是。

Speaker 2 55:41 
对，这确实是，这方面可能还好我觉得，但它毕竟没有个量化的指标。哈哈，只能说自己安慰一下，感觉还好，没什么问题。

Speaker 1 55:53 
那比如说因为我现在目前反正都是 critical thinking，能力很强，那比如说你对于有没有就可能大意，或者是就是可能能力弱一些的，就可能直接用他的答案，这种你有什么？比如说有什么写作方式上的建议，什么的。

Speaker 2 56:14 
协作方式上的建议，可能不要完全相信他给你的数学内容，他给的数学内容有时候确实是会是假数学。退。

Speaker 1 56:22 
你指的是你去问他概念的数学内容还是什么让。

Speaker 2 56:26 
他推导，让他推公式的时候，他确实会胡编乱造一坨东西出来，就是不要过于相信他，他有时候会出问题。

Speaker 1 56:35 
就你验证完就是结果确实对不上，还是说。

Speaker 2 56:40 
就是我看到他我就知道他出问题了哦？他这个公式前后驴唇不对马嘴，就很明显的出问题了。

Speaker 1 56:47 
因为我尝试过，就是之前，唉，就是我们社科他要过一个什么什么什么伦理审查的那个证书，一定要拿，然后我就截图所有的那种，因为他每每一个上完那种线上课程都要做题目，然后那个他是都有很多个选项，然后我就全部截图进去，我发现准确率挺高的，基本都在百分之。

Speaker 2 57:09 
到100%，我可以证明他这个功能还是很强。对，就。

Speaker 1 57:13 
我发现好像就是可能我线上课程也没看嘛，反正我也不想看，然后就是这么去做的话，我发现准确率很高。然后你说数学上我还没验证过数学，我只验证过一些逻辑上的。

Speaker 2 57:25 
嗯嗯，这个数学上我之前也有朋友跟我说，就是不要相信他，他是专门做数学系的朋友，然后说有时候他就给一坨不知道什么东西，哈哈，那一坨。

Speaker 1 57:37 
那数学系怎么去用？你有数学系的朋友对吗？

Speaker 2 57:41 
他其实之前读数学系，但现在已经转到去做一做应用了，因为数学实在是太难。

Speaker 1 57:47 
因为你刚才说数学系，我就很好奇那他跟 ChatGPT 怎么协作？因为他数学又不太行这一个方面 Chat GPT。

Speaker 2 57:55 
所以他们用的就比较少，他们用的更多，只是润色而已。有时候他确实会希望他帮他推导公式，但是推不据，我得到的反馈似乎效果非常的不好。

Speaker 1 58:07 
OK，那可能的只，那也对，那就数学公式可能只针对某一些专业，那比如说 writing 呢？你觉得 writing 会不会有什么写作方式的建议？

Speaker 2 58:20 
writing 层面我一般我个人习惯的方式是我会先把大字的内容都写好，就我写的时候我可能不太需要注意一些比较用一些比较好的语言，我可能只需要把信息点全部给出来以后，我让他帮我润色，但是我不建议，就是让他从头开始完全描述一个内容，这样的话会比较空。嗯，他会说套话，一个话来回反复的说。

Speaker 1 58:48 
就是你想说 context 具体一些就是。对，没错。

Speaker 2 58:52 
我觉得把信息点给足了以后，单纯让他对于信息点描述之间的连接进行润色会比较好一点。诶，比如说最简单我们写这个文献综述的时候，我写一二三四五。 5 篇文章，嗯，这 5 篇文章我一开始自己写的时候，我可以只是简单地把它信息，就是它描述，就这篇文章干了什么？它有哪些优点？它和文章联系是什么？但是这个不需要写得非常的好，就我只需要用比较直接的语言把它写出来，然后把这五段内容把它放给GPT，说你可以做合适的省略，然后把它们连成一段有逻辑性的学术文章。

Speaker 1 59:35 
嗯，明白，对不对？我其实想问的其实是假如那个就是比如说本科生，或者说就直接把答案拿来教了，这ok，对，这种反而才是目前存在一个比较多的问题，那你会有什么样的建议？对，这种。

Speaker 2 59:56 
在 writing 层面上。

Speaker 1 59:58 
不，也不一定， writing 我们就是说比如说应付作业，那我是不是可能要考虑什么什么样的一些写作？比如说 GPT 应该怎么去设计啥的？乘以。

Speaker 2 01:00:12 
你可以分两个方面来讲，比如说这代码层面的问题，比如他有一个大写代码，一个大的作业，那么这个很明显就是他给了答案以后肯定要跑一看能不能跑通，然后测一下能不能测通，这才是重要的。嗯，然后对，因为 GPT 有时候他的代码是没法运行，他觉得理直气壮一点问题没有，但其实是跑不起来的。对，然后写作的话还是之前那个观念，就如果让他从头开始写的话，其实大家是可以看得出来，就特别是如果，对，就是如果老师对这个领域非常熟悉，那肯定也很熟悉。他其实是能看得出来的这个东西就反复地说，就明显就不像是正常写出来。

Speaker 1 01:01:00 
明白。嗯，其实就是说太完整的就从头写的话，可能很明显的痕迹很严重。 chat GPT。是的是的，ok，OK，OK。那我想一下，还有应该也没什么了。对，后续可能还会有 experiment study 和 design study，你有兴趣吗？因为我后面可能会有两个实验。

Speaker 2 01:01:24 
没问题，随时发邮件给我，我都 ok 的。你都ok。

Speaker 1 01:01:27 
但，但，对，但是我考虑到就是因为我后续可能招募的人会比较多，这一次反弹还好，招的也就三四十，他如果后续可能就是150，一个时间可能就150，200，这样对我这么多人，对我钱肯定就会降下来了。

Speaker 2 01:01:42 
就没问题，这都可以理解的。

Speaker 1 01:01:46 
对，可能一个小时，可能我是这么，就是我这么打算，就比如说可能 45 分钟一个小时，然后 30 新币，然后，对，然后我还。

Speaker 1 01:01:55 
Account performance just be.

Speaker 1 01:01:57 
说那个输出的东西，因为我也怕付款就只是为了钱，然后我就想 top5% 的话就可能再多给 20 薪，然后对 6% 到 15% 给10，多给 10 薪就是有奖励机制吧。我就觉得可能。

Speaker 2 01:02:12 
我觉得这是非常好的一个办法。对。

Speaker 1 01:02:15 
因为我觉得反弹不需要奖励机制，所以就我也发现给高了。

Speaker 2 01:02:21 
ok，ok，对，没问题，对，从后续有所有这些东西您都可以发邮件，就是没问题的。ok。

Speaker 1 01:02:30 
然后，对，然后这个反弹的钱我估计尽快，因为它要经过商学院的财务部门转账。

Speaker 2 01:02:39 
然后理解，完全理解学校这个确实效率很低。

Speaker 1 01:02:42 
对，然后我准备下周一，下周一跟导师说一下能不能先转一部分人的钱，就不要等全部人弄完。对。

Speaker 2 01:02:50 
好的，麻烦你了。

Speaker 1 01:02:52 
麻，没有，其实应该是麻烦你了。

Speaker 2 01:02:55 
我不没有这个学院层面这个经费审批确实是非常的慢，这都可以理解。

Speaker 1 01:03:01 
对，那你有什么补充或者是什么问题吗？就整个下来。

Speaker 2 01:03:08 
暂时没有，我觉得聊得很开心，信息点。我觉得我平时用GPT，用这种 generative AI 的，一般使用的场景一般都已经 cover 到了，我现在实在是想不起来还有什么其他可以用到，因为我确实只是把它当工具，除了学习和工作以外我一般不会碰它。

Speaker 1 01:03:29 
哈哈，没有，其实我更多地想了解，就是比较有趣协作方式，具体场景其实没太大关系，因为每个人场景真的很不一样嗯。哼，对，我就看，其实对，就是在看协作方式上的不同，然后来进一步地去往下做我的 experiment study。对，就是从访谈中来，OK，行，那基本就这样吧。好，谢谢，谢谢。

Speaker 2 01:03:54 
ok，好，麻烦你，谢谢，谢谢。

Speaker 1 01:03:56 
嗯，好，那我就结束访谈了哈。

Speaker 2 01:03:59 
好的，好，谢谢，好，拜。



受访人23:
2025-09-03 17:39:09 CST|47min 13s

Keywords:
文案、活动、规则、思路、格式、准确性、答案、灵感、疑问、迭代、文本、验证、模板、数据分析、工作经验、时间效率

Transcript:
Speaker 1 00:00 
没问题，好，好，谢谢。就是我们这边的项目，其实刚才韵姐也介绍了，就是说我们其实想了解一下，对于甚至是 AI 这些高频的使用者在工作中或者是就是学习过程中是如何跟 AI 进行协作的，也就是说主要关注于你们是怎么去互动，或者是对于你们的思考是怎么去完成，主要是这么一个研究的一个项目。

Speaker 2 00:25 
嗯嗯嗯，OK，ok。

Speaker 1 00:27 
对，好，那您能简单的描述一下你目前的职业吗？其实就是具体一些的。

Speaker 2 00:36 
其实我就是做 WAP 3 的，然后在交易所里面从事平台的活动运营，还有用户运营的岗位。对。

Speaker 1 00:46 
哦，大概这样，嗯，那这就是甚至 AI 会怎么去使用到这些这些这种这些工作中。

Speaker 2 00:56 
首先第一个就是我找资料的时候，找一些资料的时候可能会去用到AI，比如说我要做一个活动，比如说举个例子，比如说我要做一个针对新用户的活动，嗯，我会去问 AI 说有什么，有什么类型的，有什就是有什么好，有什么比较好的案例？别的交易所是怎么做的？请他给我分享一些别交易所的案例，这是一个一个使用场景，还有一个就是我会把整个活动的文案都出完之后，我会让他帮我去做一个润色，因为可能我写的这个活动的文案它可能比较偏冗长一些，或者说规则比较复杂，那我会让他去帮我做优化、做精简。

Speaker 2 01:43 
这是第二个场景，然后第三个场景可能就是在活动结束之后，我们可能需要他需要去做一些数据的分析，那我会把我的数据喂给他，然后让他帮我去做数据分析。那其实就是在这个部分上，就是每个 AI 的他的这个给我感受是不一样的，有一些 AI 他会需要你给出比较明确的分析的指令，比如说你要从，比如说从用户注册时间、交易量等等，或者说人均交易量等等，就是你要给一个很具体的指标，他才会去帮你分析。那但是有一些像，比如说我昨天，就昨天用国内的某一个大陆，国内某一个AI，它会帮我去从各个维度去分析，不需要我给出指令，而且都是分析得比较的详细。但是因为有些时候给它的这些数据可能是以图片，或者说以一种就是可能以图片的形式喂给它，可能数据上不是很准确，但是它的它会给我提供一些思路，然后我会按照它的思路再去填这些数据，然后再去做分析。对，大概是这几个应用的场景。

Speaker 1 02:55 
对，OK，那刚才提到这些场景其实用的比较多的 AI 是哪一个呀？就是。

Speaker 2 03:03 
其实第二个可能会是最多的，就是那个要润色文案的这个部分，以及说翻译的部分，其实是我觉得是占了百分之六七十这个场景。对对对。

Speaker 1 03:15 
对，那那那你常用的 AI 的那个模型，或者是说是哪一家会用的比较多？是 ChatGPT 还是说Gemini？还是说是 Claude 这一些。

Speaker 2 03:26 
就是它就是那个推特的那个。

Speaker 1 03:29 
推特是Grok。

Speaker 2 03:31 
对，Grok。然后但是我因为其实是这样，就是我其实会，就是我，我会有迭代，因为其实早就比如说去年的时候我可能会用GPT，用得比较多，包括那个谷歌的那个我也会用，就是我会根据我的一些，就是我用下来之后，比如说同一个问题，我会喂给两个平台，但是它喂给我它的答案可能是不一样的，那我会根据我觉得哪一个比较准确，我才会，我就会选择使用哪一个，然后长期的去用。

Speaker 2 04:02 
那其实像g，我但这个就是比如说像GPT，我其实并不是特别喜欢用GPT，因为我就确GPT，就是比如说因为我很多文案可能是中文文案，那可能它帮我润色的话，帮我润色的时候它并不是很准确，或者说并不能，不，并不是很符合我的要求。对，那后面我就用谷歌的那一个，那谷歌那个呢？就是也挺好用的。然后后来就今年就开始用微信那个推特的那一个，对，然后最近有在用这个腾讯的那个元宝，对。

Speaker 1 04:38 
嗯，这个切换的原因是什么呀？就是发现谷歌也是不能满足你的需求吗？还是说。

Speaker 2 04:44 
就是还是一个工具？因为毕竟它是工具，对不对？那我要打开它的网站，对吧？从这个，从那某一个某个地方点进去，从某个地方进入其实便捷性上会差一些，对，然后因为，然后。推特，用推特的那个 work 是用的比较多，是因为我们这个行业就是要天天要看推特，所以说进就是在看推特的时候就会用上，那我觉得是比较方便的。那现在为什么会用腾讯元宝呢？就是因为它有个客户端，我直接可以在我的电脑里去打开这个客户端，直接就输入了，而不用去打开一个网页。

Speaker 2 05:22 
对，所以就是其实我是觉得就是 AI 的它的这个就它给我的答案其实大差不差，就是各家都其实我觉得不会差太特别多。对，但是它的便捷性其实是我觉得我会考虑去替换掉的一个原因，对，包括其实在手机上也是一样的，手机上可能以前会用，就是可能会用一些，就是什么什，什么豆豆宝，什么乱七八糟的，就是用些其他的一些国内的一些厂商的它的这个AI，但是后来就用也还是用元宝，是因为它有小程序，它有APP，然后包括我换，包括我现在换了这个手机，手机上也会自带一些 AI 的软件，对吧？那我不用去下载了。诶，既然有，既然已经装在手机里了，那我不如就去用一下。对，所以就是便捷性上也，我觉得也是一个更换的最大的一个原因吧。对。

Speaker 1 06:17 
这个确实是不常见的点，因为我之前没有遇到过这个，就是这种反弹的这种问题。对，那其实就刚才是提到比如说 ChatGPT 和是跟谷歌进行比较嘛？就比如说你要去润色一个文案的时候。

Speaker 2 06:31 
会有，对对对，我们就比较。

Speaker 1 06:33 
对，那你比较完之后，你会发现就是一开始就发现 ChatGPT 更优于谷歌，是吗？

Speaker 2 06:40 
因为可能还是语，就是可能还是语言模型的问题，我觉得因为我不是一个研究 AI 的人，所以我不太理解，但是我的体感上，就是我感受上我会觉得 GPT 的它给我的文案太，太死板了，然后可能谷歌的文案它会更加的人性化一点，就是可能会更加的优美一点，就更加的人性化一些。对。

Speaker 1 07:03 
对对，ok，所以我会用。嗯，那比如说就是说你就是它就是一直会让两个模型都去跑呢？还是说哦？比如说谷歌生成一次之后觉得它不错，那就持续去用谷歌。就是比如说你这一次的工作。

Speaker 2 07:19 
其实我可能会，就是可能在某一个时间段，嗯，就是我要比如说举个例子，比如说从 9 月份开始举个例子，OK，我会在这两三天里面，这把这两把我所有的工作都在这两个平台上去跑一下，但是跑完之后我发现谷歌的可能更好，那我就只会用谷歌，后面就不会用 chatgpt 了。

Speaker 1 07:42 
对哦，明白了，所以说也是看任务的会不会取决于任务的时间，比如说如果任务没那么紧，可能两个都会再量用一用。

Speaker 2 07:52 
嗯，不会不会，我觉得是这样，就是我选择是主要还是看一方面，是看你这个任务的类型，比如说是翻译，比如说是润色文案，对吧？那你用如果说是翻译的话，那我可能会选择一些海外的平台，比如说 GPT 等等的，因为他们老外做的，对吧？那如果说是一些中文的润色，OK，我可能会选择一些国内的一些AI，因为他们毕竟国人做的，对吧？那可能与中文上可能处理会更好。

Speaker 2 08:21 
对对对，其实还有这里我也想补充一点，就是其实我举个例，比如说我刚才在提到第一点的时候，我会，我需要用 AI 去帮我收集一些资料的时候，因为我们这个 WAP 3 这个行业，其实大部分的平台它都是海外平台，其实国内的这些 AI 它不一定能够，就是说它的这个怎么说？资料或者说这个素材库可能比较少，其实它给我的这个就是这些内容其实并不是很鲜，而且很新，但是一些海外的，比如说谷歌的，或者说这个推特的，它可能都是海外的这些 AI 它能够抓取到一些海外的这些资料，对吧？那我可能就会根据任务去换不同的AI。对，嗯。

Speaker 1 09:08 
诶，我其实有个疑问，就是说你说用它来收集资料是为了给你头脑风暴，还是说只是给你查些资料？

Speaker 2 09:16 
就是其实就是为了给我一些灵感。对。

Speaker 1 09:21 
对对，那这个任务具体来说是你输入，比如说希望他帮你去生成一些idea，还是说帮我收集一些资料，就是这个的任务是怎么去工作的呀？协作。

Speaker 2 09:33 
就是我会问，比如说举个例子，比如说我要做一个法币的任务，比如说 c to c 的，我这个场景比较具体了，比如说我会，我直接问他，我说你帮我找几个别的交易所平台的法币、信用卡买币的任务活动，我会很具体地告诉他，我说我要什么、什么什么功能的一个活动。对，这是第一个，如这是第一个。问题，可能第二个问题我就会问他，我说那我的目的是什么？我会让他再帮我再找。对对对。

Speaker 1 10:07 
哦，就是说其实你已经对你自己的这个任务进行了一个划分，就比如说分工，或者说把它拆解，可以这么对对对，可以这么理解，对对，然后让他去帮你撰写，或者说给你一些资料，反正就是帮你写东西，对吧？有这种意思吧？

Speaker 2 10:23 
对对，是的，没错。

Speaker 1 10:25 
那他写完东西之后，那你是比如说下一步是直接对他进行修改，还是说直接用？还是说会下一步会怎么处理这个文本？

Speaker 2 10:34 
我会，我肯定会把它先复制到我的电脑里，然后再去，我再去润色，对，不可能直接用的。

Speaker 1 10:41 
就是说你不会说，就是说跟 AI 说，就是你这一块写得不太行，然后根据什么什么什么修改，然后最后生成一个你比较想哦，比较符合你预期的一个答案。

Speaker 2 10:51 
我，那我觉得会更麻烦，就是从效率上来说我就会很慢。对对对。

Speaker 1 10:56 
明白，所以说就是在追求时间效率的情况下，其实还是没必要去让 AI 一步一步去改到符合你要求的一个东西。

Speaker 2 11:04 
是的，但是就是我这里想，就我个人是这样的，就是但是我有遇到一些同事，就是我的一些同事。嗯，他会让 AI 一定要改到他的，帮他改到他想要的为止，就是这个，但这个场景可能不太一样，他可能是一个做数据分析的，他就会一直让 AI 去帮他改到他完全满意为止，他直接复制粘贴。但是我个人是不会这么，不会这么做。对。

Speaker 1 11:30 
那他比如说给这些，就比如说你是给他，给你一个初始答案，他能符合你预期吗？大概能满足你多少的一个要求？

Speaker 2 11:43 
其实这个说实话，这个如果说就是深究来说，其实还是要分任务。嗯，但是如果说是你说准确度或者说参考性，我觉得六七十肯定是有的。对，七八六七十我觉得是有的。对。

Speaker 1 11:56 
对对，ok，那其实相当于就是说在后续就是你直接自己修改的时候会去查阅资料，还是说通过工作经验来修改？

Speaker 2 12:08 
我肯定后面就是通过工作经验去改了。

Speaker 1 12:12 
OK，所以那会去验证 ChatGPT 的信息的准确性吗？就是也没必要验证了，不能都在自己工作领域熟悉的东西。

Speaker 2 12:22 
是的是的，其实就是他举个例子，比如说我让他帮我收集资料，对吧？他收集完之后我可能会去看一下他的一些引用，但是实际上这个次数很少，因为我觉得他们应该是不太会犯错的。

Speaker 1 12:38 
对，就是说你觉得他们提供的网址一般是对的。

Speaker 2 12:43 
对对对对，一般都是对的，一般都是准确的，就信息大部分是准确的，但是他肯定会有一些信息是我不想要的，那我不想要那些信息，我就会把它从，就是把它就是从我这把它剔除，就直接就是不录、不引用了。不，不使用它的这些内容。对，但是我不会去改它，不会去验证它到底有没有，它到底是正确的还是错误的。

Speaker 1 13:06 
对哦，那假如它真的出错了，会影响到你后续的任务吗？就假如某些信息是给错的。

Speaker 2 13:16 
其实说实话它给错的信息我是能看出来的。我跟你举个例子，就是我跟你举个例子，就是我刚才有提到嘛？就是我会用 AI 去做一些数据分析，对吧？那其实我刚才也说我会给它一些，我会给它的这些数据，可能是以图片的形式，我直接从表格里面、 Excel 里面直接贴给他，可能是图片的形式，其实他抓数据的时候是肯定是会抓错的，就是他不是很精准，对，他可能会，可能可有大部分时间他会算错，所以他算错了，我会在我这边手动的去帮他修改，会帮他去修改，但是他最更多的在这个要在这个任务上，他给我提供的是一个思路。

Speaker 1 13:58 
就是说在数据分析上，就是数据分析的任务中他给你思路。那这个我其实好奇的是，你是让他给你思路去写代码呢？还是说给你就这个任务具体是什么？就是给你写代码，还是说帮你处理什么？

Speaker 2 14:13 
就是比如说我这个场景非常的就是有画面感，就是我每个月要写这个月报，我要分析整个平台的活动参与率、交易量等等的这些数据。嗯，就是怎么说呢？就是你刚才你的问题是什么来着？我突然忘记了。

Speaker 1 14:38 
我刚刚问题是说就是你，你把数据给他，那你的目的是去写日报吗？你刚才你也提到或者是周报。对对对，那这个过程中其实相当于是说你希望他帮你去画图呢？还是说就直接生成图呢？还是说给你coding，就是你希望他给你的是，哦。

Speaker 2 14:53 
对，他给我的是一个文，一段文案，一段报告。

Speaker 1 14:57 
就说其实生成是文本，而不是说。

Speaker 2 15:00 
对对对，那他。

Speaker 1 15:01 
文本，那他这个文本的话其实相当于说数据是你提供的，也不用去帮你的。那数据分析的在哪个？就是比如说数理上的分析有吗？不存在，好像有。

Speaker 2 15:12 
存在的，存在。是，其实我觉得是分，是两个部分，一个就是他数字的一个分析，比如说百分，比如说前，举个例子，比如说前 10% 的用户他交易量占了多少？前 50% 的用户占多少？他会帮我去，就是做数据上的这个洞察。

Speaker 1 15:30 
哦，我明白了，那其实相当于说你截图，对，截。诶，那你刚才说到截图的时候会导致他识别不准，那为什么直接不直接把 Excel 数据直接丢进去了？

Speaker 2 15:41 
其实说实话就是这是一个便捷性的问题，还是一个便捷性的问题？一个效率问题。我需要把文档从电脑里把它保存下来，然后再扔到它的 AI 里面，其实整个过程会比较麻烦，对吧？而且因为你知道我们，可能我们这个行业用上班用的是Lark，我不知道别的公司他们用什么，对吧？那我很多的文档都是在 lark 里去编辑的，我的这些数据都是在 lark 里， lark 又不能直接保存成一个Excel。你理解我意思就是我要从 lark 上复制到 Excel 里，然后再从 Excel 里面保存下来传给他，其实整个过程会很慢。对对，就所以我还不如直接贴个图给他。对。

Speaker 1 16:24 
就我能理解，就是就是说你自己主动地去核对会比你去下载那一套流程数据会更快。是的，OK，这没有，这个是我发现比较有趣的一个地方，就是便捷性高于了准确性。

Speaker 2 16:39 
其实我觉得是这样的，就是我因为我们肯定身边有很多用 AI 的同事，对吧？我们以前我有碰到的同事，就是他会真的是把整个文档下载下来给，然后他会在，他会对这个 Excel 这个表格去做一个很详细的整理，然后再喂给他。但是我不知道他的准确性怎么样，因为我没有这么喂过，但是他是这么做的，我看他是这么做的，所以其实我能理解，但是我不接受，哈哈哈，对对对。

Speaker 1 17:13 
明白明白。那其实相当于截图，那你觉得截图的准确性就是大概会有多少？百分之七八十，也是这种几。

Speaker 2 17:20 
5%，六七十、七八十的样子，就是六七十这样子，我觉得对。

Speaker 1 17:25 
明白。那比如说这些东西写完之后你还会进行修改吗？他比如说给你提供了一段文字，那文字部分也没必要改了，还是说自己在要改，就觉你觉得问题出现在什么地方？就比如说。

Speaker 2 17:39 
就是因为AI，它毕竟是个人机，对吧？它是个机器，它的语言描述上会很生硬。

Speaker 1 17:46 
对，生硬，那就是说你不会说，比如说你能不能帮我写得更加的口语化一些？不。

Speaker 2 17:53 
会不会不会不会。我不会这么，我不会这么，它就是我我我的我的我的，我觉得我不会这么喂它。对，就是如果说你这么喂它的话，那我觉得就挺它。怎么说呢？就是挺挺奇怪的。哈哈，你让一个机器装成一个人去帮你写一个很人性化的文案，我觉得挺奇怪的，我觉得是这样的。

Speaker 1 18:17 
对，明白，那其实现在这是这另一个任务数据分析刚才还提到的是润色，是吗？你说的润色那指的是对语言上的什么？因为你刚才说也不会对它进行生动化的一些指令，那你这个语言润色指的是什么呀？

Speaker 2 18:34 
首先就是我写文案的时候，可能就是说写得比较的冗长，比较长或者说不够，不够就是精简，然后不够能不是能够很直接地传达我的这个规则的这个意思，他可能我希望他帮我去把这个规则写更简单，因为有一些活动的规则很复杂，就相对说比较复杂。对对对，所以说我会有希望说他帮我去润色，或者说而且有一些为AI，他会给我一些格式，就是一些活动的格式，就文案的格式，应该就是说他会把，比如说第一段是写什么，第二段是写什么？第三段是什么？他会给我一个这样的一个提示，然后我会根据他的提示再去优化我的这个文案。对对对。

Speaker 1 19:18 
诶，那，那其实这个的输入是你写好的文案，还是说你给他描述这个任务的背景，然后帮你输出每一段写什么？这这这好像。

Speaker 2 19:28 
不会，我会直接把文案给他，我会先写好一段，然后我告诉他，我会告诉他帮我润色文案。

Speaker 1 19:35 
哦，就是说你写好之后帮你润色文案，那你也不会跟他。那这个第一段、第二段、第三段你会跟他写 c 这个框架，你会给他吗？

Speaker 2 19:44 
不会。

Speaker 1 19:45 
就完全让他给你生成。对。

Speaker 2 19:47 
对对，因为其实你想嘛？就是说我用它是为了方便，我其实是不想动脑子去想第一段、第二段，那我现在告诉它第一段、第二段了，那，那我要它干嘛，对吧？对，我是这么理解，我是这么理解的。对。

Speaker 1 20:02 
那比如说它搜出来这么多段，那肯定有那么多不符合你要求的，那你就直接也就自己改了，还是说会再去调教它？

Speaker 2 20:11 
我大部分时间可能八九十的时间会直接改，就不会用，就是把它复制下来，然后在它的基础上去改，在它的格式基础上去改 10% 或20%，我可能会让它帮我再去改，比如说我希望它帮我写得更人性化，或者说写得更加的就是怎么样优美或者怎么样的，可能会会有这样的情况，但是很少会有这样的情况，很少，但是很少。对。

Speaker 1 20:37 
那我是不是可以理解为就是你的输入，它的输出就是在你的输入基础上，就是基本都符合你的预期，就是就它的那个纲要就每一段写上。

Speaker 2 20:46 
对对对对，基本上都是符合我的预期。对。

Speaker 1 20:49 
那挺神奇啊，因为就真的可能跟学术这一方面确实不太一样，就是基在工作上好像大多都能符合你的预期。

Speaker 2 20:58 
嗯，就是我觉得我用它的这个，用 AI 的这个感觉更像是一个更希望说它是一个帮我找灵感的这么一个角色。对对对对。

Speaker 1 21:11 
那这个找灵感就是他给你的这个想法会就是还挺符合你预期嘛？就比如说你之前，比如说那这些文案的刚初始，就是比如说这些文案的怎么说呢？就是说构思这些文案的构思也会让他来帮忙吗？就是因为你刚才提到找灵感。

Speaker 2 21:31 
构思，对，肯定会有这样的一个情况，但是大部分是，大部分其实还是他辅助我输出完之后，他帮我去修改，帮我去美化。对。

Speaker 1 21:45 
这个文案是，比如说是商品的文案还是说是什么的一个文案？其实。

Speaker 2 21:49 
规则就活动，规则。

Speaker 1 21:51 
就活动的文案。

Speaker 2 21:52 
对，活动的文案、活动的规则或者说是活动的描述。

Speaker 1 21:56 
明白，那就是说这场活动其实是已经有了，就是说也不需要他来帮你构思这个活动策划。

Speaker 2 22:02 
什么的，是其实他不需要他帮我去策划，对，但是这只是一个场景，就比如说我还是回到我其实很想补充一点，就是在数据分析那个部分，其实我因为我觉得机器它可能分析数据可能会更加的准确，所以其实它能够查看到或者说敏锐洞察出这些数据背后的一些原因。对，所以说用数据，用 AI 去做数据分析的时候，其实我更希望他能够帮我找出这个数据背后的一些问题，或者说一些原因。对。

Speaker 1 22:38 
那比如说，就是比如说你截图了之后，你会跟他讲清楚这场活动是什么什么什么，就会具体的描述清楚背景和任务，就是背景不会就直接截图给他，然后让他对，这样也能分析出你想要的就是那个原因什么的。

Speaker 2 22:57 
其实跟这个，其实跟你丢给他的数。数据是有关系的。

Speaker 1 23:02 
对吧哦？对对对对，但可能是我没有，就可能我不太能理解，就是这个数据包括哪些？可能就是可能数据也是比较详细的，可以这么理解吗？

Speaker 2 23:13 
肯定是比较详细的，我跟你举个例子，就比如说我会扔给他一张图，这个图上面有一个交易量，然后交易成交金额，然后以及说这个报名人数等等的，可能就是四四五行或者五六行的一个数据，然后他去帮我做数据分析。

Speaker 1 23:31 
明白，就是说你不用跟他讲清楚这场活动是什么，是什么，就是说要干嘛干嘛，这些都不用说清楚，但他就会跟你去描述这场活动他的一个原因。

Speaker 2 23:41 
对，他的一个数据，对，他的一个一个数据分析。

Speaker 1 23:44 
对，OK，可就确实就可能，就确实没有想到过的这么一个用法吧。对，嗯，那就是说其实是不会有，其实我就会，就是因为想到就是头脑风暴这个过程，那会不会有给你提供比如说什么头脑风暴的一些写作方式？

Speaker 2 24:04 
在头脑风暴这个部分，其实我肯定是希望说他去结合别人的别家平台的一些活动，然后给我提供一些思路哦。对，其实主要目的是这其实主要的目的是这一个，但是具体的文案肯定是我自己去写。

Speaker 1 24:23 
OK，所以相当于有点像信息检索，因为通过别，对。

Speaker 2 24:28 
对对，你是这么说是没错的。对，但是我知道，但是我觉得是大部分人可能还是就像您说的，他会让一 A AI 去帮他输出整个活动的文案，对，输出整个活动规则，但其实这样做我觉得也没什么问题，只是说我个人是不习惯这么去用。

Speaker 1 24:49 
就是你不喜欢这么用的原因，是你说的是便捷性的，还是说会影响你的思考呢？比如说可能会打断你之前的一些想法。

Speaker 2 24:56 
我觉得可能还是便捷性的问题，就所以对，我觉得还是便捷性。因为坦白说就是我觉得我是这么想的，因为我没这么操作过，但是我是这么理解的，如果说我现在告诉他你帮我输出一段，就结合什么什么平台，对吧？你帮我输出一个活动，然后规则是什么样的？怎么样的？写一串给他，可能一两百字的东西给他，然后他帮我输出一篇文章，他输出，他帮我输出一个活动的这个方案，但是他输出完之后我还是要去改他的。

Speaker 1 25:29 
明白，所以相当于说还不如直接的对对对对，明明白，对对对。

Speaker 2 25:35 
对，而且这里面还有一点就是什么呢？就是说因为平台的公告它是有一个固定的模板的。

Speaker 1 25:44 
就是说你直接把模板输进去也是 ok 的，对吧？就是。

Speaker 2 25:48 
它不，它输出的这个活动文，说输出的这个活动报告活动方案是不匹配我的，或者说不符合我的这个平台的公告的规则。

Speaker 1 26:01 
那如果你把活平台的规则输入进去，它是不是也能给你生成符合你规则的一个文案？

Speaker 2 26:08 
不是规则，不是规则，就是这格式，就我说错了，就是格式，这个公告是有个格式的，对吧？它输出给我的这个格式可能不是我想要的格式。

Speaker 1 26:18 
对，那如果你输入正确的格式给它，那它可能也会按照你的格式来输出。

Speaker 2 26:22 
那那，那您不觉得这整个过程太繁琐了吗？太长了吗？对吧？我大概。

Speaker 1 26:29 
理解了，就是你不希望迭代超过那么多轮。

Speaker 2 26:32 
对对对对对对，可其实坦白说我，我就是说我可能问它一次两次我就能把整个活动的 idea 想好，然后我就有方向了，然后剩下的我可能花 15 分钟或二十分钟我就出文案就可以了。那我但是如果说我要一直跟他喂喂，给他告诉他要帮我怎么要帮我怎么改，那我觉得这个过程那给就反而会很长，反而会很累。

Speaker 1 26:59 
哦，对对对，明白明白。就是不想花那么多时间去教他，还不如自己。对对对，明白明白。哦，那还会有什么样的任务呢？因为好像也我我也不太懂。你工作可能还会遇到什么样的任务？就这些都还会有别的一些任务吗？

Speaker 2 27:14 
比如说翻译，其实就是文案了。对。

Speaker 1 27:18 
那这个翻译其实就是说中译英，那这个估计这些 AI 应该都能完成得比较好。

Speaker 2 27:24 
但是其实这个也不能说就是中译英，中文翻译英文是可能占90%、 95 这样子，但是有些场景它会翻译小文、小语种。

Speaker 1 27:35 
翻译小语种。

Speaker 2 27:36 
对，比如日语、韩语，然后我们以前也做越南地区，还有泰国地区，所以会让它去帮我翻译不同地区的小语种的文案，这样子。

Speaker 1 27:49 
对，那你怎么去校正它的翻译的，对不对？就这个，因为。

Speaker 2 27:52 
没办法，哈哈哈，就觉得他说什么就是什么了，对。

Speaker 1 27:58 
吧？那么有没有可能比如说你。 chat GPT 输出之后，然后你能让谷歌的帮你去校对它有没有什么输错，这种可能会不会让你增加你的准确度？

Speaker 2 28:07 
其实是这样的，就是我用，其实用翻译是用了很多的，就是每一家翻译的同一句话，或者说同一段活动文案。嗯，你去问三家，三家都不长得不一样，所以你很难去说谷歌翻的就一定比这个 ChatGPT 要准， chat GPT 一定翻得比谷歌要准，我觉得这很难说，很难去，就是说完全有一家是完全准的，那确实。对。

Speaker 1 28:34 
对对，就算输出给另一家，他另一家也不一定会说这个语法有什么问题，估计也是，对，明白。那你有比如说有学过，比如说那个提示词怎么去撰写吗？就是这一块。

Speaker 2 28:54 
就是有我们，我以我就怎么说，因为我们这个行业就是还是 AI 项目还是比较多的，那有些项目他是做什么 AI 图片什么的，那你肯定就要喂一些关键词给他。对，但这个场景在我的生活里，或者是在我工作里其实用的是非常少的。

Speaker 1 29:11 
你是说让 AI 生成图片吗？还是。

Speaker 2 29:14 
图片？对，或者说文案，其实这个都是在我生活，在我的工作和生活里是很少的。对，我是我都会比较具体，就不会是一个关键词，可能会反而会是一段句子，或者说是一个很明确的任务指令。

Speaker 1 29:31 
OK，其实我能理解，就是说比如说你对于这个提示词你会写得很具体一些，我可以这么理解吧？

Speaker 2 29:36 
对吧？可以这么理解，对。

Speaker 1 29:37 
对。我其实刚才想问，就是有没有比如说自己看过一些，因为现在很多那种怎么去写更好的提示词？这种，这种什么公众号啊？什么什么链接啊？什么？哦，那我没有o，ok，没有。OK。那你觉得用 AI 会降低你思考或者说影响你的思维这些问题。

Speaker 2 30:00 
不会，我觉得不会。

Speaker 1 30:02 
对，因为就是好像没有影响到，就是比如说 idea 这些的产生，对吧？

Speaker 2 30:08 
就它会打开我的一些视野，我只能这么说，就打开我的一些想象，因为每就是我的，我相信我的视角可能肯定是相对说比较狭窄的，嗯，对吧？比如说这对活动的这些这个内容上，对吧？肯定是比较狭隘的，狭窄的，但是 AI 它能帮我找到别人在做什么，或者说我有什么新的好的idea，对吧？它能给我提供一些这个方面的一些思考，反而它会引发我的思考，而不会说我就完全不思考了，我觉得我不是这样的。

Speaker 1 30:37 
对，嗯，明白。OK，那我其实是一直有个有，因为我觉得你 critical thinking 能力应该是很高。那如果对于，比如说，因为我是针对于，比如说，可能是针对于学生这种群体，他们 critical thinking 能力是比较低，那你觉得你会有什么建议？对于这种人群，对使用 AI 的一些建议。

Speaker 2 31:05 
我思考一下，因为这个问题我从来没有想过，对，就是我也不会去要求，或我也不会去跟我朋友或跟我的一些什么人说你要去用 AI 什么的，你就给他什么建议，就是我觉得，我觉得是这样，就是要把它当成工具，而不是要把它当成一个，就是说刚，因为您其实刚才有问我，你，我会不会去校准它的这个正准确性？其实这个问题我觉得是非常好的一个问题，的确我没有思考过它会给我的这个东西到底准不准确，所以很多人可能会忽略了这一点，所以我结合这，结合您的这个问题，我觉得是这样的，就是要把它当成一工具，要去对它有一个这个词叫什么？就是有这种也要有这种纠错的这么一个心态去使用它。对对对。

Speaker 1 32:02 
哦，就是就我知道你意思就是说带着好奇，或者说带着那种批判性的一些啊。

Speaker 2 32:08 
对对对对对，没错，没错，对，就带着这种视角去使用它，因为其实的确是这样的，就是我会让，就比如说因为我的文案工作还是比较多的，其实我会让它帮我去做一些文案工作，大部分情况下其实它给我输出的这个文案，我觉得我能使用的范围可能就只有百分之四五十这样子。是，但是大部分就是剩下百分之四五十，可能还是要靠我自己去写。对，所以我觉得做用使用 AI 的话一定要还是要多去，还是要想，还是要去学，试着去改改改，修正它，而不是完全地引用它，完全地使用它，完全地 copy 它。

Speaker 1 32:53 
对，明白，这挺好的建议。那其实我反，就是我其实聊了一下，因为我是对真的，对工作这一个怎么去用 AI 的其实很完全没有了解过。对，所以我才说让玉洁帮忙去问问她的朋友，然后看看工作有什么不一样的地方。就我确实没有考虑到，就说便捷性确实是一个很大的问题。

Speaker 2 33:17 
反正就是我，我是觉得就是说 AI 的怎么说呢？就是说它毕竟是个工具，如果我用起来很复杂，我觉得是这样的，有些人他会为了用 AI 而去使用AI，其实这个我觉得也是一个很大的一个问题，就是有些东西其实完全不需要 AI 去帮你去解决，或者说帮你去做，但是他就一定要用 AI 去做，其实我会觉得这样有一点本末倒置了，虽然说它是个工具吧。对对对。

Speaker 1 33:47 
是是，你是觉得就是它依赖性过强，是吗？就是。

Speaker 2 33:51 
对对对对，没错没错，就是什么都要去找AI，什么样都要去使用它，去帮它，帮用AI、去帮它搞，我觉得这样是就不太好。对对对，还是要自己去做。

Speaker 1 34:04 
嗯，我其实就这么一个问题的话，那你觉得它的一个心理状态会是什么样的？为什么什么都要依赖于AI？是因为。

Speaker 2 34:12 
我觉得就是这样，就是如果有一个全知全能的神在你面前，你肯定会希望说他给你所有的答案。

Speaker 1 34:21 
就是我懂你意思，就是有点把它神化了，就是说就是把，对，明白，这确实是有这么种问题，可能对于能本科生或者是那种高中，就是确实没办法去很好地批判地看待这个问题的时候，可能会觉得 AI 确实能力比他强。

Speaker 2 34:39 
很多。是的，尤其是一些年轻小，就是比较年轻的人，就是说小朋友他对世界的认识是比较有限的，当然我们，我对这世界认识也是有限的，对吧？他会觉得AI，哇，真，什么都能帮他找到，什么都能帮他解决，对吧？他就说，哦， AI 给我什么我就用什么，那我觉得这样是肯定是不对的。对对对。

Speaker 1 35:00 
对对，其实这个也就是我研究问题的一个核心点了，对，您还有什么要补充吗？其实我聊的也差不多，因为就是。

Speaker 2 35:11 
我，我再给补充一点，就是比如说在一些其实我用AI，在生活里也会使用AI。那举个例子，比如说我对一些我不熟悉的领域，比如说健身，比如说就是说，比如说用一些药等等的，就在我不熟悉的这个领域里，我会也会是使用AI，而且就是，但是，而且我在这些领域里其实反而会，就像我刚才说的就会有一点反而会依赖它，或者说是盲目的去相信他。

Speaker 1 35:40 
对，那比如说就真的，比如说你健身的这个问题，你去盲目的依赖他，就有按照他的去练吗？就是。

Speaker 2 35:50 
我其实更多的是问他有什么东西是有什么东西是不能吃的？有什么东西是能吃的？哈哈哈，对，我肯定肯定会，我肯定会参考他的意建议，但是不会完全按照他的建议去做。

Speaker 1 36:03 
你觉得他的建议是不符合你的一个需求，还是说他给的你觉得有一些小问题。

Speaker 2 36:10 
举个例子，比如说就是因为他太理想化了，就是我只是只带健身这一点，他太理想化。

Speaker 1 36:17 
了。我，我懂了，没考虑你工作的时间，或者说没考虑到你现实情况，可以这么理解。对对对。

Speaker 2 36:23 
对。那比如说我很爱吃甜的，你说你让我一天都不吃，就是一个一个月都不吃甜的，半辈子都不吃甜的，那怎么可能呢？对吧？但是我也不可能，就是说一直是修正他，你也知道我，我不会是很我，你也知道我可能不会跟 AI 去做过多的交互，对吧？我不可能一直告诉他我很爱吃甜的，我怎么我不会这么去喂他？我只会说，ok，你跟我这个建议我可以听，但是我不会照做，我只，哈哈哈。

Speaker 1 36:51 
那比如说用药呢？那你用药是怎么去问他？是你吃多少药吗？还是什么？

Speaker 2 36:56 
就是比如说我不知道，举个例子，比如说我现在长了一个什么东西？比如说长了痘，发了痘，对吧？我会问他，我说这个药一天要用几次，以及使用的规则是什么？比如说能不能晒太阳？其实他会不，他会告诉我这些比较详细的使用规则以及注意事项。嗯，对对对，我不用为他，就是我不需要问他太多的问题，他基本上一次性就能够告诉我所有我想知道的。

Speaker 1 37:24 
那这个应该就应该是比较信任，因为也没有什么超过常识的一些问题吧。对，就是没有什么特别药理学的东西。

Speaker 2 37:33 
因为我不懂，我不理解。就是在药这个方面的话，主要是比如说在药这个方面我不懂我才会去问他，那如果我懂的话，我就不会去问他了，对吧？所以他给我的这个结果，我可能百分之八九十我是完全是相信他的。对。

Speaker 1 37:49 
明白就相当于就是说不熟悉领域你会更加信任一些，毕竟你也不太了解。那如果是对对对话就你也不会太信任他。

Speaker 2 37:57 
对对，是的，没错没错。

Speaker 1 37:59 
ok，OK，OK。那应该这些就是常见的任务场景了，我应该也没有什么遗漏吧？

Speaker 3 38:11 
我觉得吴淇，我觉得这就是我们两个一直在说的一点，我就跟他说，我说就是做学术的人跟可能上班的偏实操的人的思维跟思路，还有处理任务的这个目的是很大不同的。包括刚刚你有问 Peter 很大程度之上为什么会就是他的一些思维你觉得是头一次见到，首先就是结果导向不同，一个是对待于一个输出，比方说就输出一个文案，或者说输出一段文字，我们说是文案，可能你们来说就 report 一些，就是比较正式的一些 paper 之类的东西。

Speaker 3 38:52 
那对于我们来说的话，这个东西它只是整个一个任务里面的一个一个辅助性的，这个任务包含很多一开始的策划，一开始的策略包括它前期的去做分析跟竞品去比较，包括本身这个活动，它的这个活动机制，以及它最终是要 make benefits，它最终是要赚钱的。

Speaker 3 39:17 
所以说这一个文案也好或者怎么样，它在这里面起到的作用它会有，但是并没有说像您这就是比方说做学术类的输出一个paper，输出一个report，它是一个很大比重的一个一个 KPI 的存在，所以说这就是变成了结果效率导向就是 Peter 会更大程度上依赖，因为本身 Peter 在做很多的活动，也好去做很多的这个相关的这个策划也好，他已经很有自己的一些经验了，或者说是对于这一方面理解已经是在一开始已经有一个 insights 在脑袋里面了。所以他一开始出来的时候就。

Speaker 3 40:00 
不会说我这个东西，我要先去找一找第三方的研究，我去看看二手的信息，这个就变成了 AI 帮他来做这件这些事情，他更大程度上依赖自己的这个经验，快速地把这个工作做完就好了。这个就像是我之前跟 Peter 合作，也是有的时候可能我们出一个活动，他上午告诉我大概的一个方向怎么样的，可能一上午就可以输出两三个活动了，这样子，所以说结果导向就是伴随了可能大家使用的这个怎么说呢？场景或者说是使用的方法追求的效率我觉得都不同。我是这样认为的。

Speaker 1 40:42 
OK，我能理解，就所以我才说要增加一些工作的样本来了解一下大家是怎么去用。

Speaker 3 40:48 
的。对对对，但是我觉得还是蛮好的在于，哈哈哈，就是听了一下皮特老师的思工作的。

Speaker 2 40:59 
思路，就是我觉得是这样，就是很，就是因为我从事互联网还是比较久的，就是我以前做游戏的就很早就开始做这个互联网这个行业。嗯，就是也是看着整个互联网它在发展，就是有这样好的工具出来，我觉得是很棒的一件事情，但是就是不能够过度，因为过度了肯定会带来很多不好的结果。对，以及人也不能过于去依赖它。

Speaker 1 41:30 
对，但这其实应该是比较对，像工作经验比较久，或者说比如说是 Phd 或者 master 这种。那其实对于那种，我其实我们研究就主要关注于那种这种能力还不够很强的那种学生上，该怎么去引导他们正确的使用 AI 嘛？对，嗯，对，所以想多了解一下大家的想法。韵姐你要OK，对，韵姐你有什么补充吗？就我反馋有漏掉什么点吗？

Speaker 3 41:57 
应该是没有。我觉得 Peter 要不然就是在学生维度上可能没有，但是你觉得对于下属的维度，比方说你现在新来了一个小朋友过来跟你去辅助，你去做一些工作，然后他你觉得他应该怎么去跟 AI 协作？如果说你站在一个过来人，或者说站在一个领导的一个角度。

Speaker 2 42:19 
其实就是我带下属的时候，我会经常跟他们说，我说你可以去抄别人的，不是，比如说我们做以前做游戏，就腾讯游戏都是一大抄，对吧？就是别人家出一个什么游戏，他就出一个什么游戏，其实抄这个事情是一个很好的一个在初期的时候，初步入职场的时候，你去做，你去抄别人的，去学习别人的，是很好的，就是一定要这么做的。

Speaker 2 42:42 
所以如果说我要给他建议的话，我会让他去抄，就是抄别人家的，用 AI 去抄。对，就是怎么说让 AI 帮你收集资料，然后你去抄别人家的，用 AI 去帮你快速地收集这些资料，然后你可以快速地去抄袭到别人的那些活动，抄袭到别人的那些的idea。对，所以就是你说要真的要给什么建议，就是要多问多抄，哈哈哈哈。

Speaker 3 43:12 
但是你不会害怕说，比方你这样子，你的下属他慢慢的他就没有了自己的那些就是创意的那个能力了，或者说是他就是依赖于曹特，反而去觉得这个工作就变成了一个我，我去让 AI 去学，我去把它搬出来。

Speaker 2 43:36 
我觉得是这样的，就是很多时候做活动或者做很多事情还是要考虑，要想到就是要知道背后的逻辑，对吧？你去抄这个东西，他去做这个活动也需要，你也需要去思考他为什么这么做，他的目的是什么？肯定不能说你是单纯去抄，而是说你要明白他的其中的道理，然后你才去抄，这样的话，你去抄的话才能抄到抄的味道不对，然后而且才能抄到你的这个点子上，然后这个东西才能最后变成你的。

Speaker 2 44:07 
其实我也会经常跟我的一些下属说，我说你有什么问题可以问我，对吧？但是其实很多时候他们并不敢，因为可能刚入职或怎么样，他其实并不敢，有些可能性格比较内向，他可能都并不敢，那有了 AI 之后他可以去问这个，可以去问AI，对吧？他可以也，其实也可以帮很好地去解决一些，就是说这个工作上的一些疑问。

Speaker 1 44:31 
对，嗯。

Speaker 3 44:34 
最后一个问题就是你觉得如何平衡一下属把自己 like 95% 的工作全丢给AI，然后自己其实工作了一年还没有积累的这个问题？

Speaker 2 44:49 
这个其实没有办法，因为这是跟人人人性是有关系的，也是跟每个人的这个使用习惯是有关系的。其实如果说你是着例子，比如说你是个比较上进的，或者比较爱学习的，我相信他不，他哪怕他用百分之有他，哪怕他有 90% 的这个工作都是靠 AI 去做的，他也一样能够从 AI 身上学到东西。如果说这个人他没有这样的这个思维，你，你怎么教他都是没有用的，你理解我，我想表达的其实这个东西还是看个人。对哦，那。

Speaker 1 45:28 
对他表达为是不是就是这个人一直，就算一直使用AI，但他确实具有具备 critical thinking 能力的人，他其实。对对对对，ok。

Speaker 2 45:36 
对，没错。那就说就拿我举个例子，对吧？我虽然也用，但是我不会完全地用，我觉得我这样的人是应该相对来说是少数的，我个人认为是比较少数的。对。

Speaker 1 45:51 
少数嘛？可能是吧？

Speaker 3 45:55 
我是那个多数。我知道刚刚 Peter 说那个把文档直接喂给 AI 的人，就是我。

Speaker 2 46:03 
就是问，其实问也没有问题了，就是说但是你还是要去理解嘛，就是他为什么要，要这么要这么做，对吧？或者说这么做为逻背后逻辑是什么？对，要去思考这个问题。

Speaker 3 46:14 
对，然后但是我是有优点，我是很爱问，我一天问他 500 个问题呢。

Speaker 2 46:22 
这是好事，哈哈哈。

Speaker 3 46:24 
OK，我觉得anyway，今天应该是差不多了，吴老师。

Speaker 1 46:29 
可以啊可以啊。可以可以。

Speaker 3 46:30 
可以。我觉得有什么问题大家就是Peter， Peter 是很好很好的，我的伙伴、我的朋友，然后也是我的前辈。所以说有什么问题我觉得随时私下沟通都可以的。对，然后我们进一步如果有什么相关的研究还是需要这边辅助的话，然后也是会，我会去寻求 Peter 的。

Speaker 1 46:54 
帮助。对。

Speaker 2 46:55 
没问题，没问题，这个都是小事情，就是为人类的进步做贡献一点，做一点贡献吧。

Speaker 1 47:03 
好，好，非常非常感谢。对，没有。

Speaker 2 47:06 
客气。好，那先这样。

Speaker 1 47:08 
好嘞好嘞，好。

Speaker 2 47:09 
拜拜，感谢感谢，好。

Speaker 1 47:11 
拜拜。

受访人24:
2025-09-03 17:39:03 CST|1h 2min 15s

Keywords:
论文、计算机、学生、语料、语义、邮件、mobile prom、学长、博士、老师、思路、文案、数据分析、代码生成、机器翻译、机器学习、逻辑漏洞、生活场景、逻辑思维

Transcript:
Speaker 1 00:00 
要确认正规流程哦。ok，那我们就正式开始哈。就是这是商学院的一个项目，然后主要是想了解一下，甚至是 AI 的高频使用者在工作或学习过程中是如何和 AI 进行协作的，也就是说关注一下就是怎么一个互动的方式，以及怎么思考的，然后怎么去写这些提示词，一些相关的一些行为，您对这些有什么，有什么建或有什么问题吗？还是没有的话，我就继续往下继续。ok，您能简单地描述一下你目前的职业或学习的一个领域吗。

Speaker 2 00:46 
我的职业是 NTU 的博士后，然后我从事的领域是。

Speaker 2 00:53 
As software engineering for AI.

Speaker 2 00:57 
这属于计算机每一个领域，就是这种软件方工程的方法来更好地保障智能化软件的开发和测试修复等等。

Speaker 1 01:08 
OK，那在这个领域的话，您通常处理哪一些类型的任务呀？

Speaker 2 01:15 
你是说研究领域，还是说我用GPT，用那个什么 GPT 这些东西来处理啊？

Speaker 1 01:21 
其实都可以，反正就是先了解一下您的背景。

Speaker 2 01:26 
我们做的研究的话主要就是什么？就比如说训练一些机器学习的模型，然后用一些优化算法保障它的一些属性，就比如让机器学习的一些功能性或非功能性的属性变得更好等等，主要是做这些。但是我在整个过程中我几乎是不太用，我很少用 GPT 之类的去帮我写我研究上的代码，因为我之前有遇到过情况，就是我刚开始的时候会用，因为它出刚出来的时候我用了，就比如说我让它写一些数据分析的代码的时候，它给我生成的好像很有道理，但其实有一些代码又是什么包，又是什么包的依赖什么的，就是有些函反正就是里面有一些小错，然后我就 debug 这些小错的时候非常非常费劲，就整个花的时间非常长。

Speaker 2 02:21 
我觉得我后来觉得因为我们做这种机器学习的，经常他有很多开源的资源可以供我们参考，比如说一些我用的一些现成的仓库，一些仓库他的 library 等等，他一般都是有 guideline 的，怎么用这个东西？他会给一些example，我自己还不如就对着那个 example 自己写呢。

Speaker 2 02:36 
哦，我是这样，所以我一般不太用它来做代码，就是我的这个研究的代码相关的东西。但是它有一个好的，就是它会给我提示，就比如说它会告诉我哪一些包，或者怎么样擅长做这个事，可以做这个事情我可以再去调研，就在 high level 上可以给建议，但实作上我不太用它来做。这。

Speaker 1 02:57 
明白就是说它能给你一些，比如说思路可以这么理解吗？就是怎么去用哪些包？

Speaker 2 03:04 
对哦，他甚至会告诉我这些包的优劣性，我告诉他我的一些我现在的需求等等，他会告诉我哪一些会更适合等等，就这些他是能给的哦。

Speaker 1 03:14 
明白，就是说他不能去给你写一个完整的，就写完整方案，还有更多的小错误需要你去debug。

Speaker 2 03:22 
对，因为这个东西我觉得我写那些代码其实不算复杂，但我感觉他也写不到太好。然后因为我们其实现在还会做一些代码生成的工作，就比如说用 LRM 或者用 LM 搭成一些 agent 去自动做代码生成，然后其实效果的话，也就是他们一般都是刷点看指标，但是本质上指标你看着那么高，但其实这有的时候也不能反映在真实生活中使用的这个情况。

Speaker 2 03:48 
就比如说你现在看到你说看个热闹，说你用 LM 或者 LM 生成基于 LM 的 agents 去做代码生成，它生成的代码有百分之九十几是正确的，但只是在你这个 Benchmark 上，你真实去使用的时候，比如说它会不会说擅长某个领域的代码呢？然后比如说我们做数据分析，它会不会这种领域的代码就不太擅长生成呢？就记领域特定的代码就怎么生成？包括说在一种大的那种面向真实场景的这种项目级的代码怎么生成？我觉得这些都是不光是我们真实世界中遇到挑战，也是软件工程，就是研究领域大家也在面临这些挑战，就是以前的那些数据集都比较简单，那些任务都比较简单，但现在真实它可能跟真我真实生活中是有 gap 的。

Speaker 1 04:29 
OK，OK，我明白。那我继续问，就是大概什么时候开始用生成式 AI 的。

Speaker 2 04:37 
24 PPT？出来之后就开始用，我不记得是哪一年了，它是哪一年出来的？应该是。

Speaker 1 04:42 
2422 年年底好像， 23 年初好像是。

Speaker 2 04:46 
23 年，反正也就这两年，它出来之后我基本上就开始用了，就是你，你从网页上能用的时候，我就因为我一般是从网页去接入用的。

Speaker 1 04:54 
ok，就。

Speaker 2 04:55 
那我没有用 API 去做。

Speaker 1 04:57 
嗯哦，那用的是就从之前到现在版本是不是有什么变化？还是说一直都。

Speaker 2 05:03 
有的？因为他一开始我是发现，因为我发现我好像用他来做的时候，比如说像你说的，我做的就是我刚跟你描述那些，我让他做的一些任务，其实也并不是太复杂，就是我总觉得我让他做很多很多任务的背后，其实主动权在我，就比如说我，包括我让他帮我写一些文字，我觉得主要也是我提供主思路等等，所以我觉得我对这个东西的性能的要求不是太高，所以刚开始的时候就是他免费版本，他那个网页里面 ChatGPT 点那个什么。

Speaker 2 05:33 
那个网站输进去他是什么版本，我就用什么版本，然后中间有一段时间我是用过付费版本的，但是我整体体验下来感觉好像付费和不付费，对，我这种用户使用情况好像差别不大，所以后面我又开始用免费版本，一直用到现在，我觉得挺好的，就没有什么对我来说没有本质区别。

Speaker 1 05:51 
所以就是说一直都在用ChatGPT，而没有用什么。

Speaker 2 05:55 
DeepSeek，我用过。我，但 DeepSeek 我不喜欢。我觉得它的幻觉情况很严重，尤其是它更新版本出来之后，就现在的DeepSeek，现在最新版本出来我觉得反而比之前的幻觉更严重，它喜欢说很多很冗余很废话的话，就有点时候那种像假大空的那种，我不知道是不是因为它用了很多中文的一些奇怪的语料去训练，有点像有的时候中文的一些，我们读一些新闻，或者读一些时文，就它有点，你看它所有写的话好像很厉害，但其实它本质是很脆弱的，就是经不起深深推敲的那些。

Speaker 2 06:26 
所以我现在是不会用 DeepSeek 来做这个，就我原来以为是 DeepSeek 是中国产，所以它应该更处理中文任务会更好， ChatGPT 用英语更好，这是我原来就是 by default，我会这样用，但是后来我发现其实 GPT 更能满足我对中文任务的需求，就是它，它不会过多的给。

Speaker 2 06:43 
就比如说我有一个东西，我让 GPT 去帮我润色这段话，它可能给基于我，它是忠于我的原意的我，它知道我的inside，我的想法是怎么样的，写得很好，但 DeepSeek 会给我做非常多的扩展，会写出一些好像看似很深奥，就给我加了很多技术色彩，很多背景，但这些东西根本就不是我想要的，就是我觉得它就是假大空的东西，所以我现在基本上就是用 GPT 的默认版本。嗯，已经能满足我的需求了。

Speaker 1 07:10 
ok，OK，可能中文的。好像我之前访谈有他们提到那个腾讯的，他们说好像用腾讯的比较多。现在元宝吗？还是什么东西。

Speaker 2 07:18 
来着？元宝最后接的是什么？元宝接的是哪一个模型来着？就元宝它只是包了一下，它的本质的就是那个叫什么 backbone 吗？是另一个模型。

Speaker 1 07:29 
就是说它模型可能跟 DeepSeek 不一样，是吗？我其实也没有用过。

Speaker 2 07:33 
对这个你得这个地方你做研究的时候你得注意，就是元宝它只是一个有点像那种，我了解，你可以再调研一下，据我所知元宝应该它是一个一个平台，就是你元宝它不是一个大模型的名字，它元宝是一个平台，它做的是什么东西呢？就比如把一些大模型接在后面，把服务接过来，你可以通过元宝来调这个模型，调那个模型是这样一个东西，就有比如说很多云服务商它也是这么做的。

Speaker 2 07:57 
那举一个具体的例子，你比如说 GPT 在国内你去用的时候，你是不是要付费版本，对吧？你要花钱，但这个时候你没有办法报销，因为它这个，它没有一个能产生能报销的账单的这样一个一个东西，所以说好像就没有办法报销。然后合法的报销方式是你使用一些这样的云平台，这样云平台把 GPT 可能接在里面，也就是说你把钱付给这个平台，它像个中介一样，它把这个模型接过去，你通过这个平台来调用这些 GPT 或者怎么样的服务，然后他觉得能给你开发票，能报销。所以我觉得我理解的元宝可能也是像这样云平台一样，所以你本质上你如果说你把元宝当成一个模型，可能研究就会出问，你应该是看它背后它到底用的是什么模型。

Speaker 1 08:36 
嗯，OK，明白，其实我也不是很关心他们用什么具体的AI，其实我还是要看他们之间的一个协作关系，协作方式，ok。

Speaker 2 08:44 
ok。

Speaker 1 08:45 
对对对，那学长您能描述一下，就是在工作或学习或个人身份中有一些什么典型的任务嘛？就是你用到除了刚才说到的叫 coding 嘛？对数据分析这一块还有什么任务吗？

Speaker 2 09:02 
我最常用的任务的话，第一个是就是写邮件。对，就是我觉得 GPT 它真的能够，就是它现在比机器翻译，就是比传统机器翻译软件更好。就是我一般只要告诉我，只要告诉他我要跟一个人，比如说我跟一个老师、一个教授去发邮件的时候，我的需求是什么？那能给我写出一份很得体，又不是很啰嗦，就是反正非常适合国外沟通的这种话，但你得把控，就有的时候他们好像也会反映出他会写一些很啰嗦客套的话，然后一眼就是 GPT 写的，反正我一般会控制，或者他别这样。然后邮件是一方面，就是反正就是叫什么 Multi lin- lingual 的这种communication，我觉得用它比较好。

Speaker 2 09:46 
第二个是写论文，对，写论文也是，对，因为这个地方的话，就以前大家经常开玩笑，一个论文一眼看上去就是中国人写的，因为觉得中国人的英文写作不好，但现在有这样的功，有了 GPT 之后，你明显感到你审稿的时候，你不太容易看出一个文章是中国人还是英文人写的，就是感觉好像大家写都挺好的，所以我觉得现在 GPT 它在这个 writing 里面使用也是很广泛，然后我的 writing 的话我很少让它去生成一个东西，就是 creative 的内容我是不会去让它生成的，我一定是说我有自己的思路。

Speaker 2 10:20 
就比如说我刚刚在写一段话，比如说我想要总结一个方法，流派可能从静态分析流派，再到这个数据驱动的流派，然后最后再到知识驱动的流派，然后再到怎么样？就这种流派我一定是会告诉他，我想要从这三个流派来着眼，然后每个流派我还给一些具体的examples，然后让他把帮我串成一个逻辑，比如说前他们每一个有什么关，就是我一定会给他非常详细的guideline，然后让他把这个任务做好，然后好了之后，但我一般他给出了一个东西我不是很满意的时候，我可能我不管满不满意，反正我经常会习惯性地加一句，把我的一个要求再说一遍，你就说对照我的。

Speaker 2 10:56 
要求你去反思一下你给我的这个答案需不需要进一步优化？然后 GPT 很好，他一般就会说，哦，你的要求我总结起来有 1234 点，然后第一点怎么样？然后他会说这个已打勾、已达到，就说需要提升是什么？像就是会这样的一个方式， writing 上是这样。然后还有一些的话是还有一类就是 ground proposal，就是写，哈哈哈。

Speaker 1 11:22 
ok。

Speaker 2 11:23 
对，写 ground proposal 这些的时候也是，但是主要也是说我们把 creative 的内容把它放进去，就是我自己已经告诉他是怎么写，只是让他帮我润色或者给我提很多的建议。对，因为你有的时候，那反正就这里跟 writing 有点差不多了，都是属于。

Speaker 1 11:39 
writingok，那我们就继续聊 writing 嘛，因为我其实是想深入了解怎么去，对吧？去写作。那刚才提到 writing 的话，比如说先是邮件，那邮件的话你说会提示是会告诉他哪些会控制吗？那控制的话你是会控制他的，就是那个冗余部分，对吗？就比如说他可能写的话很啰嗦啥的。

Speaker 2 12:00 
不会，我一般写的时候我是直接，我喜欢写。

Speaker 2 12:03 
Fine. Please help me refine the.

Speaker 2 12:05 
the email 然后我就说，比如说有一些人我就会特地加一个 to be 什么 polite 或者怎么样，有些时候我就会说什么什么 it is urgent，什么我想表达就类似这种，我一般会把邮件自己先写一下，就是我先，我先，就写的时候我没有任何语法，我只是用英语单纯地表达这个事情，没有语法做语义。比如说我给了它一个有完整语义的邮件，我让它帮我转换成一个更得体、更 formal 的语义等价体。

Speaker 1 12:33 
所以学长您是，比如说你是在跟 AI 对话，其实都是用英文输入吗？还是全部？我。

Speaker 2 12:40 
基本上是用英语输入，但有的时候就是图方便，我会用中。但是大部分情况下我喜欢用英文去输入，因为我总有一种刻板印象，觉得 chatgpt 应该对英语的输入会更好。我甚至之前看过说什么如果你对它更礼貌，它会更好。所以有的时候我甚至会跟它说， please help me 或者怎么样，我是说什么 thanks please 什么？什么 rewrite this part 有什么？就是会加这种东西。

Speaker 1 13:02 
那你比较之后确实有还是心理作用，比如说中文、英文这样输入之后，你确实有发现。

Speaker 2 13:09 
我在 GPT 上没有太大的感觉，英语或中文会对我的就是沟通的这个流畅度有什么影响诶，但是现在不是很多报道说什么 GPT 会让会在英语上表现最好，什么导致那些小语种将来都要退出什么历史舞台了？怎么但我自己的用法用的上面没有太大感觉，我觉得本质原因有可能是因为中文本身也是一个比较大的语种，所以说可能我们在英语和中文上使用的话，这个 gap 不是太大。

Speaker 1 13:39 
其实我就在想是不是他们训练的语料的问题。对。

Speaker 2 13:42 
因为他训练语料的话，你肯定是用的语料越多，那你这个语言处理更好嘛？所以我刚刚说了，就是中文它语种是相对比较大的一个语种，所以说它的语料也比较多，所以我们可能在中英的交互上会感觉区别不太大，但有可能那种很小众的语言的人，他就会发现可能有差别，就跟以前机器翻译一样哦。

Speaker 1 14:01 
明白，但我发现比如说用Gemini，比如说我输入中文，它其实是用英文去思考的，我在想它们会不会出现一个就是翻译的过程，然后再把它翻译成中文输出给我？

Speaker 2 14:13 
对，这个之前也有人跟我提过，确实有可能是这样，你要看这个模型内部机制，它有可能是真的是它那些逻就是让你怎么圈 of thought，怎么思考过程，它可能是用英文在那做的，所以它可能是中译，英译中就这样的，像你这个说的这个过程还挺有可能是这样的。

Speaker 1 14:30 
OK，刚刚才提到 writing 好像那。哦，我觉得你 writing 这一块好像比较有一个好的insight，就是说会它输出之后再跟它确认一下你的需求是否都满足，是这意思，需它。

Speaker 2 14:44 
的。对，这是我使用习惯，我很喜欢这样。

Speaker 1 14:48 
就比如说这个任务是你想让他写什么呢？是帮你生成一个introduction，还是说其实就是这个任务的一般是什么样的？是整篇还是说一段一段的？

Speaker 2 14:59 
这个是这样，就是比如说是比较短小的一段文本生成，然后的话我一般可能就不会这样，就是小短的。但比如说像大的，比如说像你刚刚说的 introduction 这种的话，我一般就会这样，就是我给他整个我的思路都给他了之后，我让他帮我去 refine 的时候，我后面就会说你觉得他满足了哪些要求了吗？我会把我自己的要求再提上，让他一个个去对照，对，包括有的时候有一些填一些东西的时候，他是有明显的，比如说一些申请表，他会有明显说你去总结这些工作，然后这部分。

Speaker 2 15:29 
Your description, describe this from a describe.

Speaker 2 15:31 
什么？然后你 generate 的时候是把这些 requirements 和你的草稿，就是你这个已经表达出你的思维的这个东西一起给他input，但是因为这个文本整体写下来偏长，我是会怀疑他可能会没有满足所有的requirements，然后我会就让他自己去反思一下是不是都满足。对，一般反正就是长文本的生成，我一般会做这一步。

Speaker 1 15:52 
ok，那比如说你让他写 introduction 的话，是输入什么？是输入你的思路？比如说第一段写什么？第二段写什么？还是说我现在就是一个类似于摘要的东西，然后让他帮忙生成一个。

Speaker 2 16:07 
introduction？我一般会很少，我让他整篇输入，诶？我会先给，就是我会拆成component，这个这部分是背景，然后这部分是 knowledge gap，然后这部分是我们的insight，然后我们的具体实现，然后我们的evaluation，然后最后 sum contribution，就是一般是这样，但是我这种整体的拆成 component 一部分地去让他帮我润色，之后可能整体我也会再输入一次，就说你帮我看看这个 introduction 是不是达到了怎么样，然后我有的时候还会加一些形容词，它是不是什么 very strong，什么reasonable，什么什么 compiling 什么的？就类似于这种。

Speaker 1 16:44 
OK，那比如说就是你输入了这一部分，那你输入的是你写的大概嘛？就是比如说这一部分的。

Speaker 2 16:51 
对，我很少让它凭空去生成，除非是一些我觉得就是相对来说比较空洞的东西。

Speaker 1 16:59 
OK，OK，就是说你写完这部分之后，然后它输出了，然后你会问它满足，一般会满足你什么要求？你会输入什么样的这个提示词？

Speaker 2 17:08 
这个就是你自己的对它定义了，就比如说有一些是本来这个任务，就是我做的这个任务，比如说我要填一个表，对吧？嗯，你说你，它让你这部分描述一些介，概述你的工作什么研究方案，它本来就有很多要求，比如说你要突出自己的 knowledge 在哪，你是不是介绍了 state of the art？你跟它的什么什么，就是会有这种一般这种要求就显示的影视的话，就是我对这个部分有什么，比如说introduction，我就会想说我有没有把 knowledge gap 介绍清楚，对吧？然后我有没有把自己的 insight 介绍清楚，或者说作为 reviewer 读完之后他能清楚地明白我的 concept 我解决了什么 technical challenges 吗？就是这些东西。

Speaker 1 17:46 
明白，就是说其实这个要求会根据你的任务不同，然后也会满足不同的需求，然后你让他检查。

Speaker 2 17:54 
对，那。

Speaker 1 17:54 
检查完之后你觉得就还是让他继续改吗？比如说检查，比如说不符合这些点，你让他继续改，还是说你自己改？

Speaker 2 18:03 
我一般就是他给我一个结果，之后的话我会再看，如果现在就已经相对比较完美了，之后的话我就可以把它弄到开始自己去改这段文字了。如果说我觉得还是有很多东西可以让他改，我就会再提一些要求。就是我是让 LM 去不断地refine，但最后一定是我自己会再把关和修改一些东西的，因为包括他有一些语言习惯也不是我很喜欢的。嗯，就跟我自己的语言习惯不是很一致，比如说他很喜欢用很多破折号什么之类的。对，然后还有一些，对，一些单词，就是那些都不是我很喜欢，所以我自己会去修改。

Speaker 1 18:35 
ok，OK，就是说你不会让他去把这些改掉，你自己把改一改就好了。

Speaker 2 18:39 
对，这些我不会让他改。

Speaker 1 18:41 
ok，那哦，就是说，比如说你说一部分输入之后，然后你又把整个输入进去，那这时候会有些什么区别吗？还是说其实也是一样的处理这些。

Speaker 2 18:51 
文会有区别，因为你整个去输入进去之后，他能把整个 introduction 的脉络都看清楚了，所以他就可以给从宏观上看，就比如说什么跟什么之间感觉连接有问题，或者觉得什么 tag 了解没有写清楚或者怎么样，这个就是逻辑层面的东西，对吧？

Speaker 1 19:09 
明白。那如那这个 writing 的话，在 grant proposal 应该没什么区别，还是说会有一些不一样？

Speaker 2 19:17 
grant proposal 的话，写作跟这上面我觉得很像，只是 grant proposal 的这一些部分，其实你我反而觉得你用 GPT 去生成有的时候会更好，你懂吗？就是我，就是你用 GPT 做的，你用这种 LM 来辅助你的时候，他需要你花的精力会更少。

Speaker 2 19:37 
为什么呢？因为你想我们如果去写一篇论文的话，其实你的论文是 grounded in，你就是你自己做了什么，对吧？你必须非常客观、如实地去刻画你自己做了什么东西，所以你后面的人工去检查，包括你在表达这些东西让他改得都非常的仔细，因为你不能说让他写出来修改完的东西跟你做东西已经违背了或者怎么样，所以这个部分的话就是这个 human efforts 反而会更多。但 grant 的好处是因为我是在畅想我将来要做一个什么东西。

Speaker 2 20:06 
我觉得 grant 有的时候就是你把这个 insight 讲清楚，你的这个创新点讲清楚，你让他去写的时候，反而他有的时候会给我一做一些很好，就是在实现层面具体把这个 grant 给，就是这个 proposal 给具体化的时候会给我一些很好的想法，因为本身我也不知道我将来可能会做什么嘛？他这个时候反而会提供我的想法，然后我们在做这个人工去检查的时候，就是相对来说要做的修改也会少一些。OK，除非说他很不靠谱。嗯，就是像 DeepSeek 有时候写的东西我就完全觉得不行，就不太那啥。

Speaker 1 20:37 
嗯嗯，那比如说他提供你想法，你会觉得这个想法不一定能实现也没关系，对吗？就是反正你也不用去验证具体可行性。

Speaker 2 20:47 
grant 的话我觉得相对来说可以大胆一点，因为你本身就是畅想将来要做一个什么东西，你就算是你不是用 LM 写，你自己去写，你也不知道这东西将来能不能实现。我觉得大概率就别太夸张就行。但我的感觉是 GPT 也很少写很夸张的东西。

Speaker 1 21:04 
对的，就那还会用文献，比如说去查一些资料来一来辅。

Speaker 2 21:10 
这个也是我自己会自己做的事情，你比如说你里面，你要具体说你跟前面一些工作的不同，我是会给我会去自己找一些代表性的工作的。嗯，然后再去让他放进去作为input，让他知道这些工作流派是怎么样。就是literature，关于 literature 那一部分我是不会放心让他去写的，因为我觉得他经常会有一些假的ref。 Differences actually.

Speaker 1 21:33 
Mean. But. 但我好像发现 GPT 的那个 thinking 的那一个能力，好像他给的文献比较真实，就是这我感觉的。

Speaker 2 21:42 
对，anyway，就是不管他真不真实，我就觉得你真实我也得去 double checkok。就是我觉得这部分自己做会比较那啥一点，除非是我完全不懂的东西，但是anyway，完全不懂东西也几乎不会需要我去写。

Speaker 1 21:57 
对诶，那刚才提到有一个提到什么流派这些，所以相当于说这一部分其实都已经是你看完文献整理好了，然后再让他帮你去。

Speaker 2 22:08 
对，所以我觉得我整个在跟 GPT 的 LM 交互的过程中，我觉得我属于一个指导者，就是从认知上就是各种方面我都是一个值，它只是起到一个辅助的作用，就是没有它我也能做这个任务，只是我要花的时间会更长而已。我是这么。

Speaker 1 22:23 
理解，可以理解为比如说你是educator，然后它是student，可以这么理解吗？就它会像更像 student 的这个角色。

Speaker 2 22:33 
对对对对对，是这样。

Speaker 1 22:36 
对，可能是因为我之前访谈中是有他希望他把 chatgpt 当做educator，就是他自己会当一个学生的角色，我觉得这种角色好像也挺有意思，可能我之后会研究也会考虑这个问题。

Speaker 2 22:49 
这个感觉就是取决于你人的expertise，就是比如说他们有的时候他要做的那个任务对他来说是他不知道的，或者他觉得自己本就是离开LM，假如现在没有进入 LM 时代，他自己不能做的，他就会以这种角色。然后我们做的这些工作相当于说我们原来 expertise 都已经很够了，没有 LM 时我们也能把这些事做到很好，所以可能就是角色就互换了。

Speaker 1 23:12 
明白，那学长你会有遇到这种不熟悉的领域，然后让 ChatGPT 来做。

Speaker 2 23:21 
会，但做的话一般也是提供一些想法，我自己会很辩证地去看这些东西，我很少说完全依赖他给我的一些。

Speaker 1 23:30 
东西，那一般会是怎么去？比如说是让他brainstorming，还是说是帮你处理一些什么样的任务？

Speaker 2 23:40 
我一般是一些问答，就比如说我听说了一些东西，或者我好奇一个东西的时候，我会让他给我去，给我一些解释。就比如说我今天中午想到什么，什么什么多重统计检验，一起做好几个统计检验的时候应该有什么注意点？我们需不需要做什么 p value 的？什么什么校正什么的？就这种问题，就是很适合问他。

Speaker 1 24:07 
ok。计算机也要用 p value 吗？

Speaker 2 24:10 
对啊，我们需要做那个，我们要做 empirical study。

Speaker 1 24:13 
的。OK，我也刚知道，因为我以一直以为计算机只要做算法的改进什么的。

Speaker 2 24:20 
怎么没有？我们还挺重视 empirical 的，我的 tag 我也喜欢写empirical。

Speaker 1 24:26 
明白，所以就相当于说有点像一个学习的时候遇到不会的让他帮忙去信息检索或者是给一些学习。

Speaker 2 24:37 
而现在他不是有那个联网什么的，所以有可能会让他去给你总结一些东西，还挺好的。

Speaker 1 24:43 
明白，然后就直接参考了，还是说还要再看看他给的链接什么的？

Speaker 2 24:49 
他像这种，像我刚刚说的那种问题，我感觉一般，我好像潜意识觉得他给我了，我就觉得是对的，就这种问题好像我感觉好像是不是因为跟他用多了？你好像似乎有一种sense，就是有一些问题，他应该答案给的就是靠谱的。他刚刚那个问题我感觉也不复杂，就很客观的一个 general knowledge，就好像就会觉得没什么好 double check 的，他说的东西话也都有理由为什么要做什么头 p value 自己校验，或者怎么就是这种，好像看着就不会有啥问题。

Speaker 1 25:18 
对，可能属于 common sense 或者说属于，反正也不是自己熟悉的领域，感觉他说的也大错不错。我觉得熟悉领域的话反而会更加批判的去看待这个问题。

Speaker 2 25:30 
嗯，有可能。

Speaker 1 25:32 
也有可能，反正我觉得应该是比较简单这种知识的话大家属于常识的问题，应该属于。对，然后除了 writing 还会有比如说coding，刚才 coding 说到说是基本是不会用到它来写核心的代码哦。

Speaker 2 25:50 
对，我以前会用，刚开始用了，然后后来就不怎么用。因为后来也有可能我 coding 的 task 比较少了，我不怎么要 coding 了，但后之前那些 coding 我几乎不怎么用，它。

Speaker 1 26:02 
OK，就是说之前之前是。

Speaker 2 26:04 
有一些不好的体验。

Speaker 1 26:07 
明白就是说它的调包这个问题，明白，那还会有什么样的场景？会用到 Chat GPT？

Speaker 2 26:15 
还会有什么场景？我来翻翻我的聊天记录，主要就是 writing 一些方面，还有一种很好的场景 rebuttal 或者response。给审稿人这种场景也很常用。

Speaker 1 26:34 
哦，就是写 response letter 是吗？

Speaker 2 26:37 
对，因为它好像GPT，有的时候我觉得特别是我们不是 native speaker，我们有的时候写的一些话可能会给审稿人的时候，就你可能达不到那个意思，或者说你的语气上或者什么东西不太对，然后 GPT 在这方面还挺擅长的，就是写 response 等等，我觉得还挺，但有一个问题就是它的 response 一般偏冗长，过于礼貌，然后有的时候也我反正要都做简化，但是anyway，你看它写的一些东西就逻辑上还挺好的，有时候就你告诉它我想按什么思路，它是能辩证地告诉你你这个思路可能带来的一些隐患啊。什么什么东西的，这个也是我挺爱用。

Speaker 1 27:10 
的。意思是就是说就是把审稿一，那要把论文给扔进去吗？就是你再把。

Speaker 2 27:15 
审稿，不用，我会，我一般的常见做法是 reviewer 什么什么指出什么什么把这段话写出来，我就说我的就什么response，你觉得已经 address 了他所有的问题吗？然后他说东西之后我可以再改，然后一般我有的时候会特别说，我就说是不是perfect？哼，解决了他的问题，然后他会给一些想法，就是一般会这样。

Speaker 1 27:41 
哦，懂了，那就是说你只给了意见，然后你会把你的思路，那你一开始就已经写得很完整了吗？还是说你也只是写个大概，然后让他。

Speaker 2 27:49 
完整？我倾向于我一般就是我跟你说，就是我整个使用我经常这些内容的话，因为你想 rebuttal 和response，和我刚刚说的写论文一样，它是基于一个你具体做了什么去写的，就是必须要实事求是，所以这个时候我给他的应该就是一个语义的等价题，他只需要帮我做别的，就是比如说他指出这个语义可能帮我把做了个语义变换，变成一个更好的形式，或者说指出我逻辑有什么漏洞，他跟 grant 这个 proposal 这些类型是不一样的。

Speaker 1 28:20 
明白，所以其实相当于就是帮你改一改表达，或者说改一改得体的地方。

Speaker 2 28:25 
还有逻辑的漏洞，什么它也是能查得出来的。

Speaker 1 28:28 
那逻辑漏洞比如说它查出来了会帮你直接改了，还是说你自己再去改一改？

Speaker 2 28:33 
这是看你怎么 prompt 它，哈哈，它一般会告诉你这地方可能有些问题，就比如说什么啊？觉得这个地方什么审稿人的疑问，其实在这个地方说你只是什么 partial 类的解决它的问题，有的时候会这样。

Speaker 1 28:46 
嗯，那就是说会根据它的意见，比如说确实这个地方有问题，论文也会跟着改，对吗？就是假如有些小问题。

Speaker 2 28:56 
论文吗哦？论文自己去改。

Speaker 1 28:58 
不是，我的意思是说就是他不提出了，这里有一些小问题。那可能不一定，仅仅是审稿意见的回复问题，会不会有这种论文这些点没有改到的问题。

Speaker 2 29:10 
我不会把论文内容给他，因为感觉没有人在意你论文怎么改，他们只看response，因为 response 里都说了怎么改了，那还要看论文吗。

Speaker 1 29:19 
是这样吗？那我不知道，因为我们上课会说页码是哪一页，然后跟他讲清楚怎么改的。

Speaker 2 29:26 
对，都是这样的，我审期刊的时候，我从来不会去看你的文章最后怎么改，因为我期待你的 response 应该写得很清楚，你在第几页，第几段、第几章已经写了，加了如下内容，就只需要 re- response letter。看完这个文章我就知道要就是这个修改满不满意。

Speaker 1 29:41 
原来如此，哈哈。

Speaker 2 29:43 
没有。对啊，所以说 response later 是最重要的。

Speaker 1 29:46 
明白了，那是要注意一下这个，哈哈。嗯，ok。然后还有什么样的一些场景呢？好像其实我一直有个问题，就是那对于计算机来说，就是除了写作 writing coding，那比如说调 API 的时候会有一些什么其他的写作方式出现吗？调。

Speaker 2 30:12 
API，对，就他给的代码有bug，他经常很自信给你一段代码，但其实有bug。

Speaker 1 30:20 
你是不是我的意思说，比如说调 GPT 的 API 来用，会调，对，会调 API 来用，我其实不是很懂，因为计算机这一边我。

Speaker 2 30:28 
没调 API 来用，但他们做实验的时候，学生做实验的时候会调 API 来，因为你要做大规模实验，你不可能一个个地去人机交互地在那做，他们其实在 GPT 是开放了 API 的，你可以直接通过写代码去调用这些API。

Speaker 1 30:45 
Edo Prom prompting. 什么什么？那一篇。

Speaker 2 30:48 
他绝对就是调 API 做的。

Speaker 1 30:50 
OK，就是说学长，其实你比较少写代码了。其实应该说这么说。

Speaker 2 30:55 
少，就现在这些代码我都不怎么写了，现在这些都是他们学生他们去写的。嗯，但他们会调代，会需要调这个 API 去做，然后再付费。

Speaker 1 31:06 
OK，那。 Inside. Okay.

Speaker 2 31:25 
还有一些东西，因为我觉得我之前我的研究，我很多要做那个东西，做那个什么。 Fairness to discrimination. 这就是歧视人类的歧视公平那些研究，所以我觉得他这个还挺有用的，就是我之前投一些文章的时候，你比如说你做的研究是去什么什么 Anti discrimination，做什么fairness、improvement、 BIAS mitigation，在你的写作上会有很多很多的问题，然后我就发现 GPT 它其实现在，因为以前他们不是指责说什么什么LM，又可能有、性别歧视等等等等，但通过不断的这个加强之后，现在 LM 它其实已经有一种防范意识，它是比较伦，符合伦理规范的。所以有的时候我会用它来做伦理规范的一个一个评测。

Speaker 2 32:12 
就比如说我写了一段话，我那个像之前上次我投了一个文章，是特别有点，反正就很危险，就是你这个结论可以讲，但是有可能讲得不好，就有可能会让有一些人看着不舒服或者怎么样，那个文章我几乎是全文都让 GPT 帮我把关过的，就哪一些话你觉得有可能会有一些伦理风险，有可能会引起有些人不适或者怎么样？就这个方面我有的时候还挺相信他，因为我觉得他在这方面比我们有sense，有的时候。

Speaker 1 32:41 
懂了，所以说其实就是说他的伦理判断会比我们做得好。就你就可能有些词不是。

Speaker 2 32:48 
不可能比我做得好，因为可能我自己这个方面意识比较，你比如说有一些社会学背景的，比如说社会学是不是有什么性别学研究，还是什么那些人的背景里，他可能对这些很敏感。但是我们来说的话，我们离伦理相对于比较远，就这种情况下，但伦理又是现在你做 human 这种 AI 这种东西上必不可少的一个一个部分，所以说有的时候他是可以帮你把关这些东西的。嗯，就你写的话会不会有 stereotype 啊？或者说你写的一些东西结论 deliver 是不是有问题，对吧？

Speaker 1 33:20 
就是说其实不会说所有论文都会让他去过伦理，只是说这篇的结论出现的可能会有点，其实。

Speaker 2 33:26 
有一些我觉得比较高伦理，就 topic 比较风险比较大的时候，我会让他去看这些话用的包括他懂很多很多讲究，比如说什么什么 black 跟 white 怎么用什么有的时候建议你不要用black，然后有的时候又说什么不能 white 的 w 小写，不能 black 的 b 小写， white 的 w 大写又是不要 white and black。

Speaker 2 33:47 
最好说 black and white，就是他有懂很多这种门门道道，因为我们如果是这种 topic 的文章，经常会漏到落到这种对伦理非常在意的审稿人手里，所以说他有的时候帮你把关这些还是挺有好处。然后反正审稿人最后也没有人指出我的文章有伦理的问题。

Speaker 1 34:03 
明白，那确确实大家会很难考虑到有伦理的这个问题，只有做到 human 这个话题上才会去考虑这种。对，明白，还有什么的？我。

Speaker 2 34:19 
还会让他帮我做PPT。

Speaker 1 34:22 
GPT 可以做 PPT 吗？

Speaker 2 34:24 
好像我没有买啊。他们花钱的人加插件之后他可以帮你把好像 PPT 做出来。但我是这样的，就是一般我会告诉他，我会prompt，他就说我现在要做一个这个PPT，我想要展示一些什么东西，你可以帮我规划一下这个 PPT 怎么做嘛？然后他就会告诉你这个 PPT 分几个部分，什么左边、右边、左边列哪些点？右边列哪些点，还会告诉你可以加一些icon，然后还会还，有的时候还，反正就是有的时候他会用那种像写代码那个框那种感觉，像那个中断的那种感觉，会列出那种很简单的图，就比如说什么层级式的，就是它以那种横线竖线写字那种感觉给你截出来，反正我还挺喜欢用这个东西给我做这个，然后我还会让它帮我润色 PPT 的这个讲的就是脚本等等，然后它还会告诉你说作为一个什么 PPT 演讲的脚本可以不用太formal。还要告诉你怎么之间串联，应该怎么弄。嗯，就反正这个我也挺爱用的。

Speaker 1 35:18 
这种情况一般是比如说是汇报自己的paper，还是说跟导师汇报，还是说给。

Speaker 2 35:24 
各种求职的 PPT 什么都爱用这个东西，因为我觉得它这特别是英文的中文我倒还好，不怎么爱那啥英文的，我还挺爱让它帮着润色的。对，因为有的时候我们中国，特别是中国人讲英语的时候，就好像我们觉得英国人他可能学中文的时候也没学到来，他可能说的一段话从我们日常当中觉得有点别扭，就过于太过 formal 了那种感觉，所以我们在做 Pre 的时候也是，所以我会让这方面我还挺爱，让他帮我把关，就怎么讲会写得比较又是可以达意，但又不是显得好像很让外 native 听得很别扭那种感觉，然后包括怎么去凝练啊。嗯，反正之类的我会让我还挺爱让他做的。

Speaker 1 36:04 
那这就是相当于说会丢一个完整的文档进去吗？然后让他来。

Speaker 2 36:08 
不是也是一页一页的，比如说我就会说我现在我会告诉他我在准备一个 job talk，然后下面我会给你每一页我的一个，就我也是一般会写好这一页，我要干，哦，这个会有一个draft，然后我就说现在 please 帮我 refine 这个什么scripts，什么 for 每一页的，然后我就说记住保持每一页中间的什么流畅性或者怎么样，然后有一些页会有一些特殊的要求，我可能会进一步加强一下，就比如说这一。点，你觉得我讲的会过了吗？就是会不会显得让读者听着不舒服你或者对你的 contribution claim 太大什么的，就这些我会 specifically 会问他。

Speaker 1 36:46 
哦，明白明白。那他输出，其实你刚才提到他是生成一个终端的界面，那这个界面的话。为什么？为什么不直接搞个插件让他直接生成一个出来？

Speaker 2 36:57 
没有界面。是，刚刚不是界面，是我说的他那个有的时候画图，你让他画一个PPT，他有的时候会给你这啥，我刚刚说的是写脚PPT，这可以让他生成一个，但要插件好像给钱，我记得他是有做 PPT 的插件，那好像要给钱的，我没花钱买这些。

Speaker 1 37:13 
懂了懂了，所以相当于说，就是说写脚本的话，其实就相当于是你要去讲了，然后那个文本你可能觉得需要润色一下，然后 PPT 的话只是给你一些大概怎么布局，对吧？

Speaker 2 37:25 
对，他会告诉你怎么布局，里面要列哪些比较重要的point，因为有的时候 PPT 如果说有些人不追求图文并茂的话，他告诉你一些那个什么 bullet point 列在里面已经够了。

Speaker 1 37:35 
OK，所以说他给的其实还是挺符合你的需求的，就是你想要的那个东西的。

Speaker 2 37:43 
因为我的 input 也比较specific。

Speaker 1 37:46 
哦，OK，好，懂了，那其实相当于说这个场景好，还应该也没有，还会有什么样别的一些协作场景吗？

Speaker 2 37:59 
协作场景？

Speaker 1 38:02 
嗯，对对对，因为我刚才想到 PPT 其实用于求职，就是把那些，就是没有就那个脚本，那你之后会把它背下来吗？还是说只是大概。

Speaker 2 38:14 
要么它我就把它 copy 下来了，就贴过去，我会自己再修改一下，然后就把它贴到 PPT 里去，你后面就可以去练习了。你。

Speaker 1 38:22 
是说那个 note 里面，是吗？然后就对着那个 note 练。

Speaker 2 38:26 
对。

Speaker 1 38:27 
明白，所以还有。

Speaker 2 38:28 
什么，而且反正 anyway 好像大基本上就是这些。

Speaker 1 38:37 
好像有会有一些什么生活场景吗？因为。

Speaker 2 38:42 
还真有抓到了朋友圈配文，请你帮我优化。对，这个我也会有，经常会用，我也不知道为什么就我有时候会说，我现在朋友圈发的这个配文，你觉得幽默吗？得体吗？会让大家看了有什么反应，我经常会问他。

Speaker 1 38:57 
ok？哈哈哈，没有，这是我没想到就是这种朋友圈文案，可能是我不怎么发，那如果你觉得他润色完会不会有那种 GPT 的风格？很明显。

Speaker 2 39:08 
有，这个地方就不太那啥，所以你得最好有一些好的idea，他会给你建议批判，就他适合做判断题，但他做简答题这种方面就不太符合我们中国人的那啥。因为有的时候我让他生成一个东西，我说想要幽默一点，或者他给我的句子一听就像那种很 8 股，就是一看就是 GPT 生成的，但除非说我恶意的想要让，就是想让大家看出我就是 GPT 生成的，然后就我就会觉得挺好的，我就贴上去，就大家一眼就能看出是 GPT 写的。

Speaker 2 39:34 
就比如说我之前说我就说我在吃巴斯克蛋糕，我觉得这真的好好吃，你能帮我写一段评价吗？然后他就跟我说巴斯克就像甜点界的皇冠，它的每一口都是对味蕾的极致宠爱，仿佛整个宇宙的甜美都浓缩在这一块小小的什么黑焦、黑外皮之下，什么是被太阳亲吻过的黄金？然后下面的人就开始说，你这个文案写的跟我老板一样，用 GPT 写的什么的，然后还会说你是人工智能朋友，就是这种，他们就一眼能看出来。哦，就他写的这种文案不太行。

Speaker 1 40:06 
有点搞笑啊。哈哈哈，对，懂了，所以就是说他写文案的时候，其实相当于就是说他没有一个就还是不能 get 人的一个思维，应该可以这么去理解。

Speaker 2 40:19 
不是 get 他能 get 人的思维，我觉得 gap 是说他不能理解我们 cultural 层面的一些东西，就比如说中国人文化里我们发朋友圈，那是一种是表达什么？幽默还是表达就是他可能在这方面深层，这种 human factors 这方面可能就没有那啥，他应该是更偏理性。

Speaker 1 40:38 
可能是吧，因为我没用过，所以我也不太懂他的这个可能生成出来的感觉就是说话好像就是文文绉绉的。

Speaker 2 40:46 
对，文文绉绉的，这就是这个感觉，对他说话就是这种感觉。

Speaker 1 40:51 
是，嗯，就这个可能我可能没有想到，因为可能就比如说可能像那种 marketing 的那个slogan，或者说那种文案怎么去写，就可能会有点类似的感觉吧。对诶，有没有可能比如说输入一些常见的朋友圈文案，然后再让他输出会不会有个更好的效果？

Speaker 2 41:13 
有可能，但我没试过这个，但是我觉得另一个场景也挺像的，就这个场景我在怀疑他是不是不太懂中文的阿求。就是他不懂中国人喜欢说什发什么朋友圈怎么样比较幽默、比较得体，比较好玩。但另一个场景很简单，就是你要还有一个宣传自己的场景，不就是论文的标题嘛，这一点我还挺爱让他做的，他经常会起出一些很有趣的标题，就是他在英文这上。

Speaker 2 41:37 
还挺你，比如说我们做一个，我们用嗯 AI agents 去修复一个 AI agents，对吧？因为你想 AI agents 现在不是说能修复代码中的问题，对吧嗯？嗯，那 AI agent 本身它也是代码写出来它也是一种软件，所以说我们就说我们比如说做一个工作，我们用 AI agent 去修复 AI agents，然后它给我们起的题目就很好，叫 can agents、 fix agents、冒号、问号就这种就会写得挺。那然后包括什么之前做什么，测一个什么自动驾驶系统是不是有啊？等等。

Speaker 2 42:06 
它题目就叫什么 BIAS behind the wheels，什么车轮后隐藏的偏见什么？就这种还挺有意思，就是我觉得它跟朋友圈还挺类比的，就是通过一些非常简练的文来答意，但是它在英文的标题词法上就比较好，但是在我在用它做中文朋友圈的时候，好像就似乎觉得一般。

Speaker 1 42:27 
明白，因为我也有用它来取标题，我喜欢的是比如说有没有什么电影的台词可以用进来？有。

Speaker 2 42:33 
没有？对，就比如说以前有个电影叫 who watch the watchman，对吧？然后我们有一个测试，是想我们想要测，就是你测一些东西，你不是有一堆测试试题嘛？然后我们想看这堆测试试题怎么样？它只提我们题目叫 who judges the judge，哈哈哈，就类似于就是跟那个对应嘛？对，就像你说的这种感觉，对自己。

Speaker 1 42:53 
的。对，我觉得这种题目就比较有意思，可以看让别人吸引到这种。对，所以我其我也会用 ChatGPT 来搞一下。对，ok。诶，其实那任务应该就没什么别的任务啊？其实我还有一些别的一些小问题，那你问，ok，好，就是那比如说就是因为你属于 critical thinking 比较高的，那比如说你带的学生可能有本科、硕士生可以应该有本科或者硕士生。

Speaker 2 43:23 
对，博士。

Speaker 1 43:24 
对，假如他们博士那 critical thinking 能力肯定比较高，就比如说哈本科生，那你给他交代一个任务的时候，那他你会鼓励他去用 AI 来完成吗啊？

Speaker 2 43:34 
我其实是不鼓励的，因为我发现有个问题，就比如说他有个学生，就上次反正被说得很惨，就是他那个文章一眼 GPT word，就是我一眼就能看出你这东西是 GPT 写的，就是逻辑很差，全部都是一些非常废话、非常冗余的话，就是不凝练不达意，因为你懂吗？就是那种我不知道你们文科是怎么样，我们理科的 scientific writing 讲究的是实事求是，不可以用很多的形容词，不可以用过多那个啥的话，就是你做了什么就说什么，就是要用主动式客观描述你做了什么东西，不要做过多的延伸，不要做过多的讨论，就是写这些东西，但那个学生写出来的东西就很夸张，就是写得废话连篇，特别是让你让他做literature，让他写一篇 survey 的时候，这种特别明显，就是经常一个文章写出来的描述，反正很不好。反正我就觉得在做 survey 和 literature review 上这个特别明显，然后就全都要打去重来。嗯，这个挺明显的一个。

Speaker 1 44:33 
就是说你的任务是让他给你整理一下相关文献的总结，不是，就是。

Speaker 2 44:37 
他自己要写一篇survey，一做写一篇survey，然后当他把这个 survey 给你的时候，你一眼就能看出来他高度依赖于LLM。写的文字，就是因为你比如说 survey 的话，这种东西他们会更相倾向于觉得这东西不就是基于以往知识的一个总结，他们会觉得 LM 非常擅长做，所以让他做，但是他没有想到一个 survey 最宝贵的是这些文章之间的内在联系，就你怎么去建立这个这些文章之间的联系，把这东西讲清楚，就这些地方他反而很弱。

Speaker 2 45:03 
然后写的话的时候反正罗里吧嗦的就是你比如说我一个survey，我可能有三个维度来综述这些文献，那在第一个上面的时候，我比如说我就侧重于讲它怎么生成这个数据，那你可能就要在这上面多聊，然后到test。但是你看他写的那文章，他根本就没有侧重点，就是他很少有一个他似乎看不到他在背后有自己的方法论，就是逻辑在支撑这个东西，感觉就是 LM 在做，然后论文也是那种刚开始写论文的学生，他们经常现在写出的文章就是逻辑性很差，你只要看到他逻辑性很差，有点，又没有什么语法错，逻辑性很差。然后好像有的时候还用一些比较高级的形容词或者一些动词的时候，就一眼是 GPT 写的。

Speaker 1 45:42 
对，那你会不会再给他们布置？就是说让他们去完成的时候，你会不会强调不要用GPT？会这么会这么去强调吗？

Speaker 2 45:49 
还是说不会，不让他用就会说你要少用一些东西，就是告诉他你，你不要，就是什么东西都依赖 AGB 去改，就是最后你必须要人工去把这个东西去品控，不能说都是让他去写，就他可以给你做一些润色，让你这个文章不要有语法问题，但你不要大量地去依赖他做这个东西，这肯定不行，就写出来明显不行的。

Speaker 1 46:09 
那就有个问题，比如说他本身就逻，就这个人，比如说本身他逻辑就不行，那他。

Speaker 2 46:15 
对，这个我也是发现了，我后来发现有很多人他并不是 GPT 用的，我觉得他自己本来逻辑就有漏洞，他根本就 get 不到这一句，跟这句之间其实有个gap。

Speaker 1 46:24 
对，那假如是他自己本身都有问题，也不能去理解 GPT 有什么。对。

Speaker 2 46:28 
像他这样，我觉得像这种人的话，就是 GPT 对他们来说简直就是灾难，就是感觉把他们就是思维根本就是在降级，就是整个。博士期间打做下来也达不到训练他逻辑思维的这个效果，整个就是，而反而偷懒， writing 也没训练上，逻辑也没训练上，因为我觉得比较好的方法是你以 GPT 来帮你负责，就是帮你做 writing 这部分减轻一些工作，但是我们更多地把自己的精力花在这个logic，对吧？就你逻辑上你自己来把关，这样再用它就是这样是我觉得比较好的一个交互方式。但有一些学生他就是会过于偷懒，或者怎么样，就是会好像所有都想依赖于他，这就很明显不行。

Speaker 1 47:07 
嗯，我，我懂。那其比如说对于诶博士也会出现这个问题吗？

Speaker 2 47:13 
博士会的，我还。

Speaker 1 47:14 
以为只有那种本科小朋友会这么去做。

Speaker 2 47:17 
没有博士他们也偷懒，因为他 expect 你会把整篇文章帮他重新改，所以有的时候包括你跟他明确说到哪一天要把论文给他一个初稿，你归过来的文章就明显能看得出有些问题你去喷他或者骂他什么的，他好像也无力反驳，所以我就估计他就是用 GPT 给他搞了很多东西。

Speaker 1 47:35 
OK，那你对于这种会有就你刚才也提到你的建议，就是说要保证自己的 Logic 在里面。那，那那有什么？就是对于他人的建议是保持Logic，那对于 GPT 你会有什么一个建议呢？比如说 GPT 多询问一下人该怎么去用，还是说该这些 logic 有哪些，去询问它会不会更好一些？

Speaker 2 48:05 
我觉得 GPT 倒没啥吧，人家就是一个很好的工具，你没必要限制它。我觉得主要是你使用的人该怎么把它用好，这是一个东西，因为你比如说像你刚刚说的，你如果在其实给它加很多限制，有可能就 limit 它的能力。嗯，但今天早上我的导师这个刘洋教授又提出来了，就说什么我们要限制 LM 的一些东西，就比如说你在运用于到教育场景的时候，我们可能做了一个改过的GPT，就比如说就会在很多地方限制他，比如说这个逻辑地方可能要让他思考怎么怎样，就他觉得不能说一股脑的所有都给你output，他觉得应该要做一些规范化的，就是这些，就是有点像你刚刚说那个东西，今天早上他就在讨论这个事情，他就觉得不然好像都让孩子退化了。因为我觉得他可能也结合自己的日常生活观察到自己孩子怎么样，他就觉得不行。他说我感觉这个东西会让教育退步。

Speaker 1 48:56 
对，但是这个限制又会导致我不想用GPT，我反而会转为其他的AI。

Speaker 2 49:03 
对，就是这个东西根本拦不住的。所以说我觉得。

Speaker 1 49:09 
明白。

Speaker 2 49:09 
就你说包括你们研究这些东西，你给他一些 critical thinking 的practice，但最后学生能不能用，这还是取决于学生。就好像以前传统教育也是传统教育的时候，提高师资，让什么教学法给老师进行培训，但最后这个东西他确实能提升一些学生，或者 average 提供一些学。但如果说这个学生个体上本身就爱偷懒，我就是不，你说什么我都不爱听，那你这个老师再，教学法再牛，对他也没有用，所以我觉得我们只能照顾到一个 average 的一个情况。

Speaker 1 49:37 
明白，没事，这个明天讨论的时候可能看看会有什么。

Speaker 2 49:41 
我估计刘洋老师明天会提了，因为他今天开始反思教育的本质，还有什么的，他说什么 Moe 肯定会关心这些问题，没有。

Speaker 1 49:48 
已经关注我这个问题，就是政策上已经写得很明确，说重点是重点。对对对。

Speaker 2 49:54 
对，他就是说这个很重要。嗯，对。

Speaker 1 49:56 
就是那个政策，新加坡政策写的是重点推进 AI 对于教育的一个问题，这是写了一小段。写了挺多的，就我感觉好像他们这种上级人，上层的他们就是会注意到这些问题，然后就去拿grant。

Speaker 2 50:09 
拿钱。对，因为我感觉教育是非常重要的一环，如果说教育出了问题，他下一代他们以后的人才怎么办？就是我觉得应该国家确实应该重视。

Speaker 1 50:18 
是，对，所以说明天可能就是讨论的就是关于这个怎么通过这些agent，就想说把这些，诶，其实也可以大概提一嘴，就是不是说那个agent，你们提的是说几个 agent 会一直输入嘛？对吧？一直输入，嗯嗯嗯。然后我们想法是说把 agent 全部拆出来，然后拆出来之后有些 agent 可能就是在对于这个用户在输出输入一些问题的时候，这个 agent 可能会，比如说第一个是帮他规划你，是你提出了这个问题，我们具体会怎么操作？然后这个用户肯定要先做一次判断，然后判断完之后，然后下一个 agent 可能会帮他头脑风暴给他一些点。然后你。

Speaker 2 50:56 
这个也是经典的 Multi agent 框架，就是不同的 agent 有不同的rule，对吧？ Critic 的是一个 brainstorming 的，是一个 planning 的是一个reasoning，是这典型的 Multi agent。对。

Speaker 1 51:06 
就是想说通过这么多个 agent 来让用户的，然后。

Speaker 2 51:09 
你们想说中间的时候是可视化的，完全白盒 human in the Loop，每一步人都可以干预，是吧？

Speaker 1 51:16 
差不多有这种感觉吧。是，然后其实。

Speaker 2 51:18 
也是，这是很，这很typical。

Speaker 1 51:20 
嗯，对，就很你们的 idea 过来的，就从你们 idea 的想法，然后结合我们的理论。因为商克讲理论就是说相当于把智能体和理论结合之后，然后看怎么一个协作和一个界面展示能把人的 critical thinking 提高。明天就想讨论一下这个。对。

Speaker 2 51:36 
你明天来。他很感兴趣，他应该会那啥的，但是就是你们这个里面和我们的不同就在于你们在乎你们value，你们非常在意人，所以说你们会期望每一步就用 human in the loop，但是其实你想从计算机的角度自计算机在意的是 Automation 如何自动化，所以我们搭建的 all marketing agent 的系统几乎就是希望不要有人我走，就是你能全自动的planning， planning 到下游去。就是甚至很多人在研究这个 LM 之间怎么沟通，本质上就是为了完全不需要人 planning 完了直接给下游去什么去critical，然后再给下游去怎么样？就他们所以研究的 philosophy 不太一样。

Speaker 1 52:11 
对，然后我导就提说能不能就是那你们计算机这边是这样的，那计算机这边就形成一个对照组，然后这边一个人的组，然后看这两个组的去比较之后会形成一个什么。我，我也就听他提了一嘴，然后看他说就是可以合作之后看两个组之间的一个比较。

Speaker 2 52:29 
好像也是可以，你看，对，之前看他能弄，说不定他们俩又能再聊出一个项目来。

Speaker 1 52:36 
希望能支持一下我的博后。对，哈哈。

Speaker 2 52:39 
对。那个 Kara 怎么消失了？我得让她给我input，我要赶紧把这个材料弄完。

Speaker 1 52:44 
对，你们不得 deadline 不是很急吗？我看了一下好像是在九月中，还是九月上吧，就要交。

Speaker 2 52:50 
了。9月中是交到学校去内部评审的话，9月其实这周按理说就得有，但他休息到 6 号，我再给他发个，我明天问问 professor boom。

Speaker 1 52:59 
对，你应该问问教授。估计是休假，休假是联系不上的，我给他发邮件都是联系不上的。

Speaker 2 53:04 
对，我问问他，我看看明天刘老师跟他在的时候，我问一下，看怎么说？Ok，OK.

Speaker 1 53:09 
OK.奇怪，那按理来说这个项目的推进，但明天难道不要叫 Tara 吗？对啊，就是就是这个项目。

Speaker 2 53:17 
Tara 不在诶。对。

Speaker 1 53:18 
就是不是这我的意思是说明天的讨论怎么没有 Tara 老师也没跟我提这件事情。

Speaker 2 53:23 
上次你来讨论也没有Tara，我也不知道为什么。

Speaker 1 53:26 
上次我来讨，哦对，难道我跟他项目是独立的吗？也不像你我，哎。

Speaker 2 53:31 
这个东西你也不知道老师怎么想，但anyway，他可能就是让你在做这个东西，有可能这个不是给 Tara 做。我也不知道，就好像他没有让 Tara 来， Tara 好像是不是感觉负责给他申经费啊？

Speaker 1 53:42 
我可能不止，我感觉他好像，比如说我的访谈需要他，那他就来帮个忙，然后我的这个问卷需要他看一下，他就过来看。

Speaker 2 53:50 
一下。你们只有他一个博士后是对。

Speaker 1 53:52 
人特别少，而且他年龄也比较大了，都 50 多岁了。博士后。对，所以就可能会出现很多问题，就可能比如说我很多东西都用 AI 处理，他也不会去用 AI 处理，他还是比较传统的方式去做这些事情，就，哎，没得说，反正就是大家还是有思维上的不同。

Speaker 2 54:13 
那他就会一直在这做博士后。

Speaker 1 54:15 
我感觉他应该要搞到退休，我看他好像也没办法去做别的，都 50 多岁了。对，感觉是这样。

Speaker 2 54:22 
s 挺好的。对，有点他那种什么理工科，有些实验室也是，比如说生物学，他可能有一个组做什么实验里面，比如说有一个要什么，有一个关键步骤非常难做，但有一些人当年在组里做博后，就他这一个做得很好，这一步就他做就能成功。然后他们就会一直做博一辈子，就在实验室做这种博后，然后做帮着做一些操作之类，对，估计也。

Speaker 1 54:44 
挺好，对，估计薪资也挺高的应该，所以就愿意留下来吧。

Speaker 2 54:48 
对，这边博后的工资有的时候比社会上他们那些工作人工资还高。

Speaker 1 54:52 
大概有六七千吗？还是七八千？还是按年来给啊？

Speaker 2 54:56 
我们组，反正我们是 7, 000 多。

Speaker 1 54:59 
我知道刘老师。

Speaker 2 55:00 
然后年限再高的话，他是每两年好像得涨一次，我们组来得比较早的三年博后已经 8 接近 8, 000 了。那。

Speaker 1 55:08 
你不是四年了吗？

Speaker 2 55:10 
不是，我一开始在英国做的，所以我的工龄不是很长，在这他们工龄长会越来越高，很多很 senior 的，不会到八九千都很有可能。

Speaker 1 55:19 
这完全可以 pr 之后在这里生活生存下来了。

Speaker 2 55:25 
也看对老板给他开的工资会不会高吧，比如说刚开始就开的很低。对。

Speaker 1 55:30 
他晚应该比较高，他都在新加坡买房了。

Speaker 2 55:34 
那就比较得到供的信任呗。

Speaker 1 55:37 
对对对，然后我看他们有合作很多，基本在写书，他们的合作论文很少都在写书，对，项目基本都在写书。

Speaker 2 55:45 
诶，书是不是还能赚钱之类的。

Speaker 1 55:48 
国内的话是国内，比如说出版一本书，然后他会给，比如说报酬 10% 还是多少会给到这个出书就是写书的这个人，然后每每每卖一本就10%，每卖一本10%。对啊，所以我。

Speaker 2 56:00 
觉得有可能他们在赚钱搞这种。

Speaker 1 56:02 
哈哈哈，那我感觉副校长那还缺钱吗？唉，也是，钱不嫌多的。对。

Speaker 2 56:07 
他反而你说副校长反而不缺论文吧。

Speaker 1 56:10 
哈哈哈，副校长我其实这么理解，就是他虽然不缺论文，他的顶刊很多，但他不去弄，我觉得他需要保持保证他自己在一个学术界的地位，所以他对。

Speaker 2 56:20 
他就保证自己的 setion 什么是固定的，然后且能持续发，然后在学术界是活跃，能各种就行了，他并不需要发很多的论文。对。

Speaker 1 56:28 
对对，所以他下面的合作的学生目前来看可能就那么一次，我知道了，在新加坡就我一个，然后另外一个博士生。小岛在带他也不管，他不怎么管，所以就完全在带我一个人。目前看是这样的。

Speaker 2 56:42 
那你还挺那啥的，他一个一个副校长专门带你一个CSC，不是挺爽？

Speaker 1 56:48 
他们都很惊讶，他们觉得 CSC 过来就是过来玩啊，对吧？过来写写自己的论文，不会说导师完全知道。我觉得外坊人挺好的，真的，十天 meeting 一次，然后又给钱又给人，就整个好像就是完全当博士在看嘛。

Speaker 2 57:02 
那挺好的。嗯，是的是的，所以我觉一个博后一个博士。

Speaker 1 57:09 
还有个RA。

Speaker 2 57:12 
RA 不也是博士？

Speaker 1 57:14 
没有，他的 RA 是个硕士毕业，然后是从业界招进来的，所以他很不能理解学术的东西，所以我叫他去做访谈，我就发现很大的问题他不能很好地去lead。对，他就只能我让他说，还是说去做一些，比如说那些工作的一些人的一些访谈，就不要去做学术上的，学术上他不能 get 到，或者说没办法去很好地问到一些insight。

Speaker 2 57:38 
我好奇怪他是博导，他为什么没有博士生呢？这好奇怪。

Speaker 1 57:43 
就他有一个，他就是新加坡这边不是两个老师共同指导吗？那他又不啊带，然后就说让小岛完全知道，所以那个博士生就比如说可能半年或者说三四个月 meeting 一次，然后了解一下他们在做什么，然后他挂个名就这么简单，也挺神奇的吧。我觉得也挺神奇，然后他永远都在做这个ChatGPT，他目前的项目好像就是 block chain，然后GPT，然后还一些横向。对，他目前就是这些很多，他好忙，哈哈哈，咋了咋了？

Speaker 2 58:22 
没有，我觉得还挺，怎么会这，哈哈哈。

Speaker 1 58:26 
就很难想象嘛，这种高 level 的结果没有博士生。对我们。

Speaker 2 58:29 
组那种感觉做挺正的， RA 都有好几个。

Speaker 1 58:34 
有。那如果行政 RA 他有 5 个秘书，就是毕竟。

Speaker 2 58:38 
所以他大部分人都给他做行政。

Speaker 1 58:41 
对，基本都在做行政，你看我那个对接时间的秘书，然后他还会对他各种秘书，我都分不清，我自己都分不清楚他有几个秘书。

Speaker 2 58:50 
对，我们组也是有什么搞财务的秘书，有搞管项目的秘书，然后有负责每天管他时间的秘书。有什么好几个秘书？

Speaker 1 58:59 
对啊对啊。对对，就秘书特别多，但是真的搞科研的就没有那么两个，心累，真心累。所以是，我就感觉就算我在这里做博后，我觉得我都要立得好几个项目。嗯，行吧。嗯诶，OK，应该没有漏什么问题诶。哦，学长，对了，你有没有接受过 prompt engineering 的一些学习或培训？

Speaker 2 59:21 
我是，我其实没有经过学习，但我知道一些 tricks 就是偶然间看到，包括我之前自己写了一篇。

Speaker 2 59:29 
Engineering. So it says on the mobile prom.

Speaker 2 59:32 
能弄好，所以这里面我可能看过一些，比如说要设置一个比较合适的rule。或者之类的就是那些。但我现在你问我脑海里有什么 prompt engineer 的技巧？我也，我就只记得要用rule，因为我发了这个文章，哈哈哈。

Speaker 1 59:47 
这个 role 指的是指定。

Speaker 2 59:49 
就是你去看那个就几每个大厂出 LM 的大厂，他都会给一个类似于guideline，然后他就会告诉你怎么去写 prompt 嘛，然后你就凝练共性。我记得有一个就是做 role playing，就比如说你让他去写一个，你让他规划一个什么东西，设计一个建筑图，你就说假设你是一个什么国家的建筑师或者怎么样，就是给他这种 rule 之后他能够做得更好。然后之前我们有研究过 LM 在 role playing 下的一些决策什么东西的，嗯，就，嗯，所以说我会知道有这个trick，这个是基本上每个大厂的都会写到 prompt engineering 的技巧里去的。

Speaker 1 01:00:23 
对，也，好像也是目前大家常用的一个技巧，但我发现有一个比较搞、比较好玩的一个技巧，就是商珂给我的一个idea，就是他说定义漏之后再定义一个相关利益者，就是你的相关利益者有哪些，他会更好地去帮你梳理你想要的东西，也是一种角色定义吧。我觉得也算在这，对，反正。

Speaker 2 01:00:42 
就这样。但是有很多人 AI 的人的想法是，当 LM 越来越强大之后，其实 prompt engineer 的一切技巧都变得没有那么必要。这模型很强了之后，你哪怕写的东西很有错别字，很有语病，语义不清，它也能知道你想干嘛。

Speaker 1 01:00:56 
对对，就好像是理解意图的一个研究领域吧。

Speaker 2 01:00:59 
好像，对，但这个东西跟你们这个研究不冲突，因为你们是想看怎么更好地使用LM，我反而觉得 LM 变得越强，人越来依赖它，反而 education 这一环就变得更重要。

Speaker 1 01:01:10 
对，所以 education 对于所以相对有点互补吧。你们希望技术更强，我们希望人不要变。对，所以我觉得可能真的这个，所以老师说合作可能是确实是这么一个大问题了。嗯嗯，对，目前。

Speaker 2 01:01:27 
行，那就先对这样，别的有什么问题吗？

Speaker 1 01:01:31 
我应该没有，就学长你有啥补充吗？我觉得应该我这边是没啥问题了。

Speaker 2 01:01:35 
没有补充，我觉得挺好。

Speaker 1 01:01:37 
OK，那比如说之后可能会有 experiment design，或者是不对 experience study 或 design study 的话，你有兴趣参加吗？就兴就钱的话可能不会有这么高，因为我发现我也是定高了一个小时 50 新币。

Speaker 2 01:01:51 
真的吗？ 50 好像高。我不知道，你到时候反正可以问问我。

Speaker 1 01:01:54 
呗。嗯，因为我看你有没事就 32 的邮件给你，然后你看有没有时间？对，然后可以，对，然后这个钱的话我大概应该下周，对，我下周应该会发给他的秘书，然后让他去帮忙处理。对，估计一两周时间会到账吧。对。

Speaker 2 01:02:09 
好好好，ok。

Speaker 1 01:02:10 
OK，OK，好，谢。

Speaker 2 01:02:11 
谢谢，好，好。

Speaker 1 01:02:13 
拜拜。嗯，好，明天见。

受访人25:
2025-09-09 20:37:26 CST|1h 10min 58s

Keywords:
交互、文献、框架、语料、模态、生成式、语境、计算机、智能、语言模型、人机交互、自然语言处理、生成式模型、代码输出、语境语言、语言表述、记忆系统、评估学生

Transcript:
Speaker 1 00:00 
好，行，那我们正式开始就是这边是商学院的一个项目，是关于基于交互记忆系统来优化人机团队表现的一个研究，主要是想了解一下，就是甚至是 AI 这个高频使用者，就是在你们在学习或者工作的过程中是如何跟 AI 进行协作的，也就是想了解你们每个任务中的一个具体的一个协作方式，或者是一个的思考方式。您对这个有什么问题吗？没有问题，我们就继续。

Speaker 2 00:37 
没有问题，可以继续。

Speaker 1 00:38 
好，行，那您能简单的描述一下你目前的职业或者学习的领域吗？

Speaker 2 00:47 
我现在是，现在的职业是算是做AI，然后和 AI 加教育这两个领域，然后目前的职业是算是科研从业者这样，然后，诶，第二个问题是什么？

Speaker 1 01:13 
对，也没关系，就是在对于这个领域的话，你通常会处理哪些类型的任务？

Speaker 2 01:22 
我最经常做的一个事就是在一般使用的过程中，或者使用那个已经有了那个前端 1 GUI 的那种大模型的，就比如说 ChatGPT cloud 这种主要是辅助，就是做一些工作，文字书面的工作，然后也包括代码的一些工作。然后还有的话就是用那个API，然后用 API 去搭建那个 AI 的多智能体框架，或者是智能体框架。然后常用的话一个是直接，我基本上是如果说是做 AI 相关的，基本上全都是用那个代码，直接那个去叫这个API，就直接 call API。然后有一些就是特殊的，比如说那个 AI for education，就是 nie 那边的项目的话，他们会要求就只能用 diffy 的那个框架，这个框架相当于它是专门为这个智能体设计的一种框架，当然它有局限，它又有好用的地方，这个就是各有利弊吧。对，然后所以就是纯自己搭的话也可以，然后也用框架的话也会用。对，嗯。

Speaker 1 02:45 
OK。那大概是从什么时候开始使用 AI 这些工具的？

Speaker 2 02:51 
嗯，是从 23 年开始，就准确来说应该是 22 年 11 月 10 就是十月 11 月这样。诶，因为那个时候是那个 GPT 刚出来，就是它刚商业化。

Speaker 1 03:03 
那是读硕吗？他还是。

Speaker 2 03:05 
在读硕士的时候，都不都是硕士，硕士。对对对。

Speaker 1 03:11 
那时候的话就会也是处理，也对，那时候也不是教育学的话，那会处理什么类型任务？那时候任务是不太一样。

Speaker 2 03:21 
那个时候主要还算是，我觉得那个时候其实开始的话就是 2 三年，应该说是 22 年年底的那段时间，其实主要是用那个他有这个用户交互页面的这个PPT。嗯嗯，也没有，这个啥也没有，就是能可以听到吗。

Speaker 1 03:44 
呃？有点小声，突然有点小声哦。

Speaker 2 03:53 
喂喂，可以听到吗。

Speaker 1 03:56 
现在可以。

Speaker 2 03:58 
ok，那我就这样，我比较好，OK，那个就是开始的时候其实就是对 API 是没有概念的，那个时候也不会说是，就是他不会说是直接给这种开放后端，他只会开放一个前端，然后让你从前端去使用，可以听到。

Speaker 1 04:18 
吗？可以，没问题。

Speaker 2 04:21 
OK，然后那然后到了 23 年开始的话，就是他开始慢慢的就是开放，就这些 commercial company 他们就会慢慢去 CO- 开放那个API，就相当于他在后端开了一个接口。然后你可以只要有这个觅食，然后就可以去调用它的API，然后直接用它的模型，然后按照这个字数或者说 TOKEN 数算钱。然后后面是这样的，然后但是前面就开发的话，肯定还是需要去用API，就是开二三年的时候是没有那个框架的，就是开始是没有框架。这样的后面有了，比如说那个 long chain，或者说是再到后面就是像 diffy 这种，它有这个用户直接能看到的这个 visualize 的界面，但是开始的那些框架都是代码为主的，就是它全都是代码帮你已经搭好的一些框架，它相当于给你节省时间，当然也不是说的所有你都可以依靠框架，但是这个就是后面的事情，对， API 更多是后面的事情，就是做开发。

Speaker 1 05:28 
那这个因为我现在好奇，就是因为学科的变化，就是会不会任务也会出现变化？就是跟 AI 之间的一些任务交互。

Speaker 2 05:39 
科研上面有一个非常，就是这个是科研上面的，还是说是学科学习，或者说是。

Speaker 1 05:45 
都行，或者。

Speaker 2 05:46 
某一个学科。

Speaker 1 05:48 
都行。对。

Speaker 2 05:50 
ok，就是从那个，就是我接触的比较多的是那个自然语言处理，就是这个领域，然后其他领域因为我接触的不是特别多，就开始的话自然语言处理就是当时 22 年的时候还在用一些大模型，但是没有说是像 GPT 这么大的模型，就是当时是在用T5，或者说是就是有一些Bert，然后各种个 Bert 模型它用得比较多。然后到了 22 年开始这不是有了，就是生成式大模型，而且是这种商业化的生成式大模型。嗯嗯，从那个阶段开始，就是大家才反应上，也不是反应，就是大家才发现，就是之前的这些比较小的模型的一些功能，可以被这些更大的模型替代，然后这些大的模型里面，就是这些超大模型也有开源的，也有闭源的，开源的也就是那个 LLAMA 或者千问，就是千问是之后的 LLAMA 开始比较能够是有开源、有闭源，但是整体来上，整体上来讲就这种模型的话，这种生成式模型它基本上可以满足之前使用，比如说使用 Bert 呀，或者使用 T5 呀。

Speaker 2 07:08 
就是这种模型的所有需求，不管是分类任务还是说是，就尤其是生成式任务，然后因为生成对于语言来说是一个非常重要的任务，就是语言它可以不说是，就是分类它可能是一个小任务，但生成其实才是语言的这个本质啊。然后就大家就开始就是转向这个生成，然后去研究生成的文本到底有怎么样的特征，然后怎么样去提升生成的文本的质量，然后就有各种各样的场景，所以基本上现在就 NLP 会有一部分是做这种传统任务的，就比如说分类传统任务，因为还是那样就是分类小模型，它还是在有一些任务上比这种通用性的大的生成式模型效果要好，因为它就是专门用来去分类的，所以它还是比这种通用型的模型会好一些。

Speaker 2 08:08 
然后但是这部分领域它会慢慢缩小，就是一直在缩小，就大家不会去干这件事情，就包括语言学里面有一个领域叫做计算语言学，跟那个自然语言处理就是搞的内容还不太一样。但是即使是因为，即使是像那个就是计算语言学，它更多关注的是语言现象，然后但是它现在照样得用这种生成式的大模型，它得去分析这个生成式大模型产生的这个语料它到底有怎么样的特征，是不是跟人类一些语言的特征是，比如说是相类似或者怎么样的？对，但是就是它没研究的重点就完全变了。

Speaker 1 08:55 
对，没没，我的好奇是就是你在读语言学其实的时候，其实也是跟计算机相关，是吗？

Speaker 2 09:03 
那我开始其实我本身学位是跟计算机是不相关的，但是因为我是走了实习，就是我不是去那个 NLP lab 然后实习的，然后这才跟计算机相关，因为 NLP lab 他们当时在做的是那个 African American language debiasing，就是做那个因为非裔英语和我们学习的标准英语，或者说就是打引号的标准英语，因为这个说标准英语是一个不是特别那个正确的说法，对，ok，就是我们学习的英语或者大众白白人，大众使用的英语和黑人。

Speaker 1 09:55 
哈喽哈喽。

Speaker 2 10:07 
hello，可以听到吗？

Speaker 1 10:09 
可以，怎么又断了？

Speaker 2 10:12 
我不知道，我这个电脑是跟这个是电脑连着，然后我那个我应该现在可以了。

Speaker 1 10:25 
可以，ok。

Speaker 2 10:26 
好的。就是。

Speaker 1 10:29 
什么白人黑人，当时。

Speaker 2 10:32 
对对对对对对，是，就是他们研究的是黑人英语，因为黑人英语其实他算是一种独立的英语，然后语法很多跟白人英语是不一样的。他比如说会省那个省略，那个过去式或者怎么样的？就是白人英语他不可能省略过去式，那黑人英语里面可以省略过去式，那就包括他一些词语的发音，然后拼写的这个变化，然后其实都是有区别的嗯。当然就是黑人英语也在一直影响着，就是咱们使用的英语，比如说那个一般来说是 want to，对吧？就是两个词，但是如果你把它简写成那个wanna，就是就后面加个 NA 的话，那个就是很明显的黑人英语。对，就是比如说汪娜还有高娜，就是全都是黑人英语，但是就是在现在美国英语来说的话，大家习以为常了，也相当于他也，他俩也在互相影响这样，嗯，但是就问题就在于就是黑人英语，因为他不是这个大多数人使用的英语，然后他总会被判定他的攻击性特别强，比如说黑人英语里面会用 n word，就是如果说是我是黑人的话，我可以称另外一个黑人为用那个 n word。这就有点像是兄弟的这个翻译，但是它是没有攻击性的。但又有问题，就是如果一个白人跟一个黑人说 n word 的话，这个就可能会有问题，就是这么一个问题，对，就是他们黑人自己可以说 n word。

Speaker 1 12:13 
对，就是说那时候的研究还没有用到大语言模型，对吧？就那时候还是说已经。

Speaker 2 12:21 
应该说是后期就开始用到了，就后期在做那个语料库扩充，就根据这个音韵学，然后做这个黑人、非裔、美国人英语的这个语料扩充的时候，就因为要让这个大语言模型或者语言模型去适应这个黑人英语，所以就是他必须得去扩充语量，像给他输入更多的这个非裔美国人的这个语言进去，然后让他适应，那个时候就他们加了一个Mixtra，就是也是一个开源模型，是法国的一个独角兽公司搞出来的一个模型，叫做Mixtra。 Mixtra 也是开源的。然后他们当时用在用那个模型，然后 LLAMA 都没有太用，那刚出来，所以他们没吃，然后下来就是T5， T5 就是 19 年的一个模型，当然他们用的不是原本的那个 19 年的模型，他是后又改进了的 T5 的模型。对，然后还有什么就基本上就是这两类，一个是生成式的大模型，就是 Mixtra 这种，然后还有的话就是 22 年之前的这些大的语言模型，但是生成可能不是特别好的。对。

Speaker 1 13:38 
ok，诶，那那，那我们可以具体聊一下，你跟你是，诶，不对，你目前用的是 AI g GPT 的什么版本呀？还是说有变化过？

Speaker 2 13:49 
一直有变化，我是从 3 开始用的，然后 3 它很快更新成3.5，然后到 4 到40，不是后 4 诶，四 4 到 4O 之间它搞了一个。嗯，你。

Speaker 1 14:05 
说没有？没有没有，我是说 4O 然后到 5 是吗？就是说你都是用的 Chat GPT 吗？还是说会用 Gemini 或者是其他的一些 AI 工具？

Speaker 2 14:18 
Jenny 不太用，而且 Jenny 也用它是我在用那个 Colab 的时候就是谷歌，因为 Jenny 是谷歌的，然后谷歌有一个Colab，就是 Colab 就是一种可以在网上跑的一种编译器。对，就是在用那个的时候，然后它会附带 AI 的功能，在那个时候用过，也就是说 Jenny 我只用它做这个coding，然后。对，然后用得比较少哦。现在主要用的是e，其实用的也不是特别多，就是最近就尤其搞科研的话，我们还是比较倾向于用cloud。就是 Claude 模型。

Speaker 1 15:01 
就是说你 Claude 和 GPT 都会用，对吧？

Speaker 2 15:06 
嗯，对，就是不做我的时候两个都会用，然后至于开发的时候就是让一个用哪个？

Speaker 1 15:15 
开发的时候用哪个？我这边有点吵，好像飞机在飞。

Speaker 2 15:20 
没事没事，就是开发的话GPT，然后DeepSeek，然后千问，就这些都会用，就是因为你要测试，就是不同的这个模型，再用相同的提示词或者怎么样，然后在不同的数据集上都得测一遍，ok，然后就都得测。对。

Speaker 1 15:41 
懂了，这就是什么搞代码的，哈哈。

Speaker 2 15:45 
嗯，对对对，就是开发的话那这个就限制不了了，就是让用什么用什么，但是如果说是个人的话就是辅助我个人的。嗯，就工作学习的话，那我会有明显的偏好，就 GPT 可能更多的是让它帮我做一下简单的搜索，然后做一些总结。对，然后的是本身都可以，就尤其是写代码，因为它可以写非常长篇的代码，比如说写 1, 000 多行的代码，它都是可以写的。当然我开的是 Max 版本。

Speaker 1 16:18 
就是 claude 你开会员，那 GPT 你开会员了吗？

Speaker 2 16:23 
GPT 开的是 plus 版，就不对， GPT 开的是那个 team 版本，就是 team 会比 plus 贵一点，然后它每年是能比这个 plus 多一点，并且因为它每年的话最低是开两个号的才能组成一个team，所以就是它会贵一点，所以是算相当于是翻倍的。然后 Claude 那个就是GPT，它不是也有嘛？就是也有一个这个 Pro 的版本，就是 200 刀每个月，你开200，我没有开GPT，我开的是 Claude 的 200 刀那一个月就是 Max 版本。

Speaker 1 16:59 
就是我懂了，就 GPT 你开的是 20 刀不， 40 美刀的那个是吗？然后 Claude 你开的是 200 刀的。

Speaker 2 17:17 
明白。

Speaker 1 17:17 
明白了，就是说你会根据需求来看要不要开会员哈。

Speaker 2 17:21 
对对对对。然后目前的一个小的问题，就是那你用的时长或者这个模型公布的时间越长，它越会可能会出现偷懒的行为，就是它不给你回答，完全会有这种情况。对。

Speaker 1 17:42 
GPT 比较常见这个问题。

Speaker 2 17:45 
对，就是 GPT 开始很常见，所以这就为什么我给 cloud 开了Max，但是 cloud 现在也有这个问题了，但这个问题可以绕过去，你就是你可以强制它，然后输出所有的这个代码，或者说输出所有的文档，这个是没问题的。

Speaker 1 18:00 
明白？这是你的一个使用习惯了，对吧？你怎么去强制它输出？

Speaker 2 18:06 
你可以告诉他，我看你这个代码输出的不完整，你给我把代码补全，然后它就会。但是 GPT 有时候不听你的话，那就是之前的话，我 GPT 不听你的话， GPT 就会给你，还是给你一个片段，它只给你补全，它不把那个补的东西加在它原本的那个框架里面，所以就 cloud 还算是比较听话，那他。

Speaker 1 18:32 
还是可能开的钱不一样。

Speaker 2 18:36 
有可能有，有这个可能性，确实有这个可能性，还有就是我估计跟他们的设置是有关，因为这个如果说是上每个人都让 cloud 播这么 1, 000 行、 2, 000 行代码的话，那他们的这个压力会相当大的。是。

Speaker 1 18:54 
这也是个他们可能考虑的输出的那个 TOKEN 的长度的问题了。

Speaker 2 18:59 
对对对，就是这个，就是用那个UGI，就是用户这个能直接接触到那个界面的一个限制，这也是为什么开发和大家我会有这，尤其，哎，就是直接用后端。

Speaker 1 19:11 
对，但我也发现个问题，就是如果是我 GPT 和那个谷歌的都开了会员了，然后我发现就是在输出的时候， GPT 就是不会输出完整，就是它说啊，我这个太长了，我帮你一节一节输出，然后谷歌的那个就会全部输出，我觉得区别真的是蛮大的。

Speaker 2 19:32 
对，就是就卖那个应该还没到那个限度，就是它还没到那个用户的上限，我觉得，但 GPT 我感觉早饱和了。

Speaker 1 19:41 
有可能就对，是诶，那你比较常用的一些任务有哪些？比如说你刚才提到了 coding 或者是API，然后可能还会有 writing 什么的，还有summarize，对吧？

Speaker 2 19:57 
对，就是如果是问卷上那个问题的话。其实就是除了就是其他模态的，比如说这个 visual 的，就比如说 picture generation 这个不太用，或者 video generation 我也不太用，然后 Audio generation 我也不太用，就是这些我都不太用，我主要是作为就是用那个文字的生成。嗯，没问题，这个比较多。

Speaker 1 20:21 
那可以具体聊一聊，比如说要不然一个一个聊，比如说writing，你 writing 会用到什么样的任务上？

Speaker 2 20:30 
writing 的话，比如说写文章的话，现在写文章我不会说是自己完全先写一个非常完整的草稿出来，然后让再让他帮我修改，而是我会先把，比如说这个段落的大纲列出来，我要先说什么再说什么，然后具体哪一步需要注意什么，然后这个写出来，然后告诉他，让他帮我写出一这么一个自然段，然后再去看他写出来这个自然段，我再修改，然后这就是最终的成稿。

Speaker 1 21:02 
对，这个有个问题，就是这个自然段，比如说你现在要写，比如说就写那个 edu prompt 那个，那你是，对，是会跟他讲背景呢？还是说就直接地跟他讲这个段？我的开头。什么？你要注意什么？还是说就是你整个流程是什么样的？

Speaker 2 21:26 
这个不太一样，就是如果说是开头的那个段，开头那个段不是要做一些背景介绍嘛？像那种背景介绍，我就基本上让 GPT 去帮我找背景的，因为第一段背景介绍没人会看，但是它又必须。

Speaker 1 21:41 
得有。对，那相当于就是说你会根据不同的自然段，然后你的处理方式也会不一样。

Speaker 2 21:50 
对，然后比如说就是不需要做任何引用的话，那其实我知道这个段要干什么，我直接告诉它就可以了，然后我把数据给他，然后让他帮我写就可以了。

Speaker 1 22:04 
那会不会出现可能他用的某些词？ GPT 很常用，然后就可能会被什么查到什么的。

Speaker 2 22:16 
就怎么说，因为我不用 GPT 也就靠的能好一些，那在这个频长频词上面肯定会好一些。还有就是我一般会给告诉他，就是我让他先帮我写出来了一版，我发现他的这个语气或者怎么样？特别的生硬，或者怎么样，我会告诉他就是 be natural。然后 clarify the details，就是用这些词就更像人一些，并且就是比如说就在细节上面你需要clarify，然后扩写哪块需要再扩写一些，因为人的话他是知道重点的，所以他知道哪一块是可以扩写，哪块不需要扩写，所以我只需要按照我觉得哪一块需要扩写，哪块不需要扩写，然后告诉他，让他帮我扩写就可以了。

Speaker 2 23:03 
就是整个应该说是，我大概就是写作的时候，其实大概脑子里面有个大概的结构，但是中间的很多细节都不是特别清晰。然后我把这个大概的结构输入给他了以后，他先帮我产生了一个比较细节的这么一个，嗯嗯，就你一段话，假如说一段话，然后我发现有一些步骤他写得特别的粗糙，嗯，然后需要某一些需要再细致一些，或者说某一些写得特别细致，我不需要他这么细致，然后我会告诉他，就这一块你缩写一下，这一块你详细写一下，然后这块的这个数字符号的表示不太清楚，你帮我把这个数字和表示说明一下，我会这么样告诉他。

Speaker 2 23:45 
所以就是这怎么说呢？就是其实写出来他确实会有一些高频词了，就是高频词是很常见的，就是现在你也没办法分辨这个高频词到底是人在使用还是跟 GPT 在使用。嗯，这确实，嗯，对，就是我觉得更多的是人会通过就是行文的风格，比如说这个文章的节奏的说明的节奏的把控，然后我去那个啥，就是去辨别这个到底是不是 AI 写的。

Speaker 1 24:17 
哦，那比如说你这些段落写好了，那之后是比如说都丢进去吗？还是说因为你因为肯定会有点不顺嘛？就是肯定逻辑上因为是一段写的，会让他再重新帮你看一下逻辑什么的吗？

Speaker 2 24:33 
对，不会让他帮我看，我会自己看，就是他输出一段，然后我现在就该我来该写就中间怎么样过渡呀？怎么样写呀？这个是我会搞的。

Speaker 1 24:44 
明白，就是说之后的反正就段落他写，然后之后你会再修改完善，然后拼起来。嗯，对，是这样，明白，那对于writing， wri- writing 就这么这样的任务吗？还是说还有一些别的任务形式？

Speaker 2 25:02 
比如说写邮件？嗯，写邮件基本上他给我写。

Speaker 1 25:07 
然后。

Speaker 2 25:08 
现在差不多了。对，那个就是我会告诉他这个邮件我要表述什么，你帮我写这么一个邮件出来。

Speaker 1 25:16 
对哦，明白，就是说你，然后我再改你，你是这样就是说什么啊？这封要发给谁的邮件？然后内容大概是什么，对吧？然后，嗯，那这个邮件你是你用的一般是用英文跟他对话还是用中文跟他对话？

Speaker 2 25:31 
嗯，一般来说是英文，然后中文的话我会用DeepSeek，就是中文的话基本上都是写微信的，就是写微信的这个发微信的这个祝福语或者怎么样？这个用DeepSeek。OK。

Speaker 1 25:45 
没有，因为我其实有一直有个问疑问，就是在使用 CHAT 又或者Claude，因为他们一直说对于英语输入和对中文输入会不会有一些偏差？我因为我是没感觉你，你有这种感觉吗？就是可能你英文输入它反馈的结果会更好吗？

Speaker 2 26:12 
对，他又断开了。

Speaker 1 26:17 
都没听到，是吗？我就是。

Speaker 2 26:19 
我，我听到了，没事，我。我能听到好像是断开的话，你听不到我说话？对，稍等一下应该可以了。ok，就是反正断开了，然后你就听不到我说话了，我会重新说，没关系，好的，不好意思。对对，不好意思，不好意思，这个东西这块网不太好，我只能用流量。

Speaker 1 26:45 
没关系，没关系，就刚刚说到什么，哦哦，对，就是偏差的问题。

Speaker 2 26:52 
嗯，我感觉的话 cloud 和 GPT 中文的话差异不是特别大了，就是因为我用 cloud 和 GPT 基本上都不用中，所以其实我不是特别清楚它俩的这个中文语言表述到底怎么样，但是我能感受出来的是 cloud 就 GP 这一类的模型跟 DeepSeek 去比的话，在中文语境下就会差得比较大。对。

Speaker 1 27:25 
就相当于说因为可能也是语料的问题，就是他们抓国内的语料肯定没有 DeepSeek 好抓。

Speaker 2 27:33 
对，就是因为你这些模型，基本上你给他输入的东西你就默认，除非他会告诉你我们不用你的数据或者怎么样，然后他不说我们不用你的数据，或者是不让你选可不可以用你的数据，这种都是用你的数据的。明白？ DeepSeek 就是默认就是肯定是会用你的数据的。

Speaker 1 27:52 
但 DeepSeek 我觉得有个最大问题就是它的幻觉特别严重，你有感觉到这个问题吗？

Speaker 2 28:00 
嗯，因为 DeepSeek 我基本上都是用来写那个啥，哼。哦，写祝福语。

Speaker 1 28:06 
哈哈，明白明白。对。

Speaker 2 28:09 
我不是特别会让他去帮我干活，因为我感觉这个是幻觉，是必经的一步，就是g， g 就是 GPT 之前不是也有一阵子幻觉特别严重嘛？

Speaker 1 28:23 
对。

Speaker 2 28:25 
然后现在就还好。

Speaker 1 28:27 
那会不会存在我，我可能是之前的访谈中存在这么个问题，就是比如说他换解这么多，然后或者说用户会不会对 AI 产生一个上瘾的一个机制呀？我我我是说从你的教育学角度来看。

Speaker 2 28:42 
那幻觉就是 AI 的幻觉，它是应该说的是那个产生不真实的输出，就是它个输的输出跟现实不相符，对。

Speaker 1 28:52 
就是这个是幻觉，对，我就觉得会有出现错误的引导，然后导致用户可能会对这种引导可能会比较上瘾，就是可能。嗯，我觉得可能在心理支持上，或者在什么支持上的时候会不会出现这种问题？

Speaker 2 29:10 
就是它确实会产生那个 account is all flow 的，就是这个 all flow 的其实跟幻觉没有直接的关系，它只是因为就是 GPT 在表述的过程中，它表述得特别的官方，特别的正式，然后就造成了一种它非常权威的假象，然后人就信了。

Speaker 1 29:32 
好像我在哪个报告上看到说因为 GPT 产生的流畅度太高，导致人就会相信它所有的表述，这好像是某对不很写。

Speaker 2 29:44 
对，我觉得人会考虑这一点，就是如果说是他前文不搭后，就前后的这个意思都不太一样的话，人不会相信，那就因为他是根据之前的输出或者之前的这个记忆，然后去输出后面的内容，所以他一直都是相关的，他相关性很高，他前后文的相关性特别高，这就导致人没办法去鉴定他到底知道不知道，因为人之前就是鉴定我，假如说你鉴定过我到底可不可信的时候，嗯，你会观察我说话到底有没有逻辑性。嗯，然后我的这个，这说话的内容能不能说服你？然后甚至有可能因为咱们俩专业不太一样，对吧？然后我说的一些话可能你压根不懂，但是你能感觉到你到底能不能相信我？因为你是会去衡量我说话中到底有没有逻辑。对，就是前言不能前文不答，后面的这个。

Speaker 1 30:43 
后文。对，对。但你。

Speaker 2 30:45 
就是你有一个基础的判断。对。

Speaker 1 30:47 
对，但你提到一个很关键的点，就是熟悉和不熟悉，就相当于比如说我现在，比如说就想去了解AI，就比如说假设就了解计算机某些方面的知识，然后再 chat GPT 输入了，对不对？但是我又不是很懂，那我不就是会相信它所说的东西吗？那假如是商科或者是某些方面我了解的知识，然后去跟它对话，我就能看得出它有些不一样的点。

Speaker 2 31:14 
嗯，会不会是这样的？所以就是，嗯，您，您说。

Speaker 1 31:19 
没没没，我就想说就。就是说那这样不就会出现所谓的，就是我也没办法去判断他的前言后语对不对？因为我本身也不太懂。

Speaker 2 31:30 
对，这不就是为什么人会被传销？哈哈哈，因为我也不知道他到底是不是说的真的，我就觉得他可信，所以我就信了，然后我就开始进入这个庞氏骗局。

Speaker 1 31:42 
明白，对，所以意思就是说这种东西其实不可避免的，对吧？就是因为我本身就不熟悉，我也只能完全信任。

Speaker 2 31:51 
对，也就是不熟悉，所以完全信任。但是还有一种破局的方法，就是你对 AI 非常熟悉，你知道他在某种情况下容易去产生不正确的信息，所以你不给人，不让他去干这些任务，这是破局的方法之一。

Speaker 1 32:08 
对，明白，就是其实有些任务就是他肯定造假程度比较高的时候反，你觉得会，一般会有什么样的任务会出现所谓的这种问题啊？大概是什么样的任务？数学我第一反应是数学。

Speaker 2 32:26 
数学其实还好，因为数学现在测的特别多，因为他们现在做那个大模型推理的时候，用的数学和代码这两种任务，基本上就是用这两种任务去做那个大模型推理的，所以其实还好，就推理模型其实都还好。嗯，但是问题就在于它如果说是遇到了不熟悉的领域，就是推理它是整个逻辑是连贯的，但问题是很多场景下的很多问，就是很多任务它逻辑是不连贯的。比如说我说，就或者不是说是逻辑不连贯的问题了，而是有很多隐藏的信息。就人他是有这个，有对这个隐藏能力，就隐藏信息的这个理解能力。就比如说最简单的就是日语的话，它是对于上下文，就是你理解一句日文的话，它可能更多的是要理解这一句话在上下文之间的这个作用，然后你才能理解到这句话的含义，就是你如果没有上下文的话，很有可能你这句话理解错了。

Speaker 2 33:35 
日文就是一个语境语言，它必须靠语境，然后去理解这句话。中文也是偏语境的，但英文不是对英文的，对语境的这个要求会低很多，就是它整句话它可以独立存在，但是中文和日文在有些话里面就不太行，就尤其是日文，它对于语境的要求特别高。然后语境这个东西相当于是你的，就是人的这个 prior knowledge，它不是一个，就是显性的，它可以直接输入的一种knowledge，就是我甚至都不知道我有这个经验，但是我脑子里面已经有这个经验了，所以我可以通过这个语境推导出来这句话到底是什么。嗯嗯，但是大语言模型如果说是没有足够的训练的语料的话，它是推导不出来的。

Speaker 1 34:25 
我大概能对。

Speaker 2 34:26 
像这种。

Speaker 1 34:27 
对，就是说你背景信息不够的情况下，它其实是没办法去理解对的。对，就因为对日语就属于那种，你需要提供很多的背景信息以及上下文的一些关联，它才能很好地去理解你是表达的意思。

Speaker 2 34:47 
那也就是一个是这个，还有一个是，嗯，就是如果说是，这是一个非常非常复杂的任务，就比如说我问GPT，当然就是这个任务跟现实是有关系的。假如说我问GPT，我造一栋楼要怎么样搞？就是我完全不给他提供任何信息，然后我也不告诉他造的是什么样的楼，他会生成的，他确实是会生成，怎么一个造楼？但是你要说造炸弹他不会，就是造楼他是会的，但是他跟现实的这个差距就非常大，一个是他缺乏信息，对，就是一个是缺他缺乏信息，还有一个是这件事情非常复杂，他没有考虑到所有的情况，如果说是一个就是非常有经验的一个建筑师的话，他在考虑造一栋楼的时候，就你如果问一个建筑师怎么样去造一栋楼，这个建筑师会反问你要造什么样的楼？具体有什么样的这个功能或者怎么样，建筑师是会问，因为他脑子里面有多种方案，他不知道你在说哪一种，但是对，就是模型他是没有，他会只会给你输出一个。

Speaker 1 35:54 
明白，就是就是。嗯，你，你说。

Speaker 2 36:00 
对，就是他，你可以让他说出输出多个，但是他不会意识到他输出的这些内容，他不会去验证他输出的这些内容到底和你说的这些东西是不是相符。对，他没有 Meta cognition，就是这个意思。

Speaker 1 36:16 
我觉得他可能更像是一个服从性的，就是他并不需要去考虑你的，就是可能也是我们提供的信息不足，但他也不太嗯 care 你到底足不足，就是他也不用考虑这件事情真实性就能不能完成，可以这么说。

Speaker 2 36:33 
对对对，就是人在说话的时候，我觉得大家都知道自己说的哪些是真的，哪些是假假的，起码就是知道哪一些是自己相信的，哪些自是自己不相信的，对吧？就是这个是属于是说话内容的一个属性，嗯，人是有这个对这个属性的掌握的，然后但是大模型它没有，就是它不会说是去先去想我说这句话到底我相信不相信它不会去想这个问题？没有这个功能。

Speaker 1 37:08 
但好像这可能是后续的，就因为可能是不是 TT 反问一句，诶？那你具体的目标是什么呀？那你到底是为了什么？群体还是建的楼，对吧？就是多问几句，可能反而用户他就会更加表达自己的需求，这些可能，对。

Speaker 2 37:26 
吧？对，是这样的。对对对，就是，但是，嗯，就这块需要注意的点就是他反问，他不是说是自己觉得应该反，就是自己认为有必要反问，有一必要去验证一下，而是他学习的是这样，就是人告诉他你必须要反问，或者说训练语调里面基本上最后会带这么一句反问的。

Speaker 1 37:48 
明白，所以他这么反问明白，所以可能在我们之后，比如说智能体的考虑中，就有些就专门干这种事情，有些就是去做别的事情，这样分工的话可能会出现一些不同的。叫什么？叫不同的感觉吧。

Speaker 2 38:06 
对对对。

Speaker 1 38:08 
对。ok，这刚聊的是属于一个 writing 以下的任务，也算是 writing 以下的任务。那除了 writing 刚才提到的有什么来着？ coding 还是就是。

Speaker 2 38:23 
coding？对，coding。

Speaker 1 38:25 
哦，诶，不对。刚才提到还有一个跟 writing 比较相像的，就是summarize，就是总结，是吗？你是会让它总结文献还是总结什么？

Speaker 2 38:34 
到时候不会让它总结文献？我基本上现在用，比如说GPT，直接是上网搜帮我爬文件也是这种，那个 AI 给你。 AI powered searching. 然后就开始的话比较多用的是比如说perplexity，就这个也是一个 AI power 的一个 search machine，然后它主要就是做 searching 的，帮你去 search 各种的东西，然后后面逐渐的像Claude、GPT，然后DeepSeek，就是这些他们都会有这个 searching 的功能。所以其实就。

Speaker 1 39:09 
你是说那个搜索功能吗？还是我，我都没有用过，是哪一个啊？是 Web search 吗？

Speaker 2 39:20 
对，就是 GPT 也有，然后我不知道Germany，但是那个 Claude 也有，但是它会帮你去搜索。

Speaker 1 39:27 
但这个搜索的话我有个疑问，就是它一定要点吗？我好像就算不去点这个功能，然后输入帮我在网上搜一些信息，它好像也会去干这个事情。

Speaker 2 39:39 
嗯，对，就是只要你不关这个功能，它就会用，它觉得需要用它就。

Speaker 1 39:44 
会用，就是它自动调用，是吧。

Speaker 2 39:48 
嗯，对对对。

Speaker 1 39:50 
ok，你说的意思就是说这个是属于一般搜什么样的资料的时候你会用到它呀？是比如说了解一个领域，还是说只是当前需要一些资料来帮你写什么东西的时候。

Speaker 2 40:05 
我其实就是我已经知道了，我要做就是了解这个领域，然后会帮他，我会让他帮我搜文献。就这个领域里面有哪些引用量比较高的文献啊？你帮我搜出来或者说是有几个大类，这个大类的下面有哪些代表的文献？你帮我搜出来这样。

Speaker 1 40:24 
但会不会有个问题，就是在搜文献的时候会出现文献不正确，或者是说文献有遗漏，这些都是没关系的吗？还是说现在已经。

Speaker 2 40:34 
有遗漏是肯定的？对，就是遗漏是肯定，他没办法防止，就是有点像人。他在总结人的文献，第一就是人，他也没办法把所有一个领域里面的所有文章全都给你搞出来，就是没有办法做到完全没有遗漏。还有一个就是他是有限制的，因为我觉得我记得那个Claude，他一个对话框一次，一次搜索只能搜索五六次，好像有这么一个限制。哦，明白明白。那，那他然后说到你说没？

Speaker 1 41:07 
没，你说。

Speaker 2 41:10 
对，因为我就说没，没回答完。因为这个除了移动之外，不是还有一个错误，完全错误。就是这个其实现在很少，因为他会给链接，就是他会给那个他搜索的这个网页的网址的链接，你可以直接点那个链接，然后过去查看。

Speaker 1 41:27 
对，明白，就是说这些就是以前存在的那种虚假文献，在现阶段其实都已经被完善。

Speaker 1 41:43 
啊，没没没，刚刚好像可能小小断了一下，我听到。

Speaker 2 41:49 
那个。对，就是现在因为有了搜索功能之后，他其实不会说是在这方面有特别多的幻觉，就是他这边的幻觉会少一些。

Speaker 1 42:01 
嗯嗯，那对于其他你刚才说 coding 的话，你是让他写代码，那这种情况下就是说你会给他让他写一个一个完整项目的代码，是吗？还是属于你会分工之后让他写某些模块的代码？

Speaker 2 42:20 
基本上是让他们帮我写完整的代码，因为完整的代码也就 1, 000 多行，所以也不是说那种完成不了的，哈哈，工作量，所以就是我会告诉他这个代码我要干什么呀？你需要调用什么样的模型？然后具体这个，比如说是提示词的工作的话，那就是这个提示词该怎么样去写？甚至提示词我都自己不写了，就是我会告诉他你用哪种技，就是技哪种技巧去写这个提示词。

Speaker 2 42:47 
比如说用那个 chain of thoughts，或者说是用其他的一些不同的这个写 prompt 的一些格式，或者说是这些 agent 之间有怎样的沟通？就是他的，他之间的这个交流是怎么样的一个交流方式？然后你只需要告诉他，让他去帮你完成就可以了。

Speaker 1 43:09 
所以说就是其实你已经很清晰地知道你这个项目每一块是什么了。就是说也不需要的话， AI 来给你构思这个项目中的某一些部分需要怎么去实现，就是就没有一些是那种 brainstorming 的，就是说头脑风暴上的一些事情，对吧？他只是一个执行者。

Speaker 2 43:30 
头脑风暴我用得很少，我觉得就个位数，因为好像我能记得的就一两次，就好像就是感觉没有太多的灵感了，就问一下他这样或者说是实在不知道？嗯，就是对，实在不知道用什么模型了。问一下他，对。

Speaker 1 43:50 
但其实就是说你还是会自己去读文献，然后去看最新的研究，然后去构思你的idea。可以这么理解吗？其实因为GPT。

Speaker 2 43:59 
我其实不看，对，我是不看的，就是我只会去看一些非常相关的跟我这篇文章非常相关的文章。比如说就是最近的一个baseline，然后它的这个因为我要通过最近的这个baseline，然后去找出这个 research gap，然后这个 research gap 是我必须得自己找到的，就是 AI 很难帮我找到一个非常好的哦。但是其他文章我都不看。

Speaker 1 44:29 
但我有个问题就是说比如说 edu 这一篇，那你的 idea 的就是第一步的出来是跟 AI 交互，还是说自己去就是看到了这篇文献，然后想到了 gap 是哪一种方式去完成这个的？

Speaker 2 44:46 
我觉得更多的是我自己有一个idea，然后这个 idea 可能并不来源于我去做文献综述，或者而是我就发现有这么一个需求，然后可以这么样去做，然后我去查了一下，没人做，是吧？你那我来做，或者说是别人做了他有什么样的缺点，然后去解决这个缺点，更多的是这种。

Speaker 1 45:07 
明白，所以相当于更多的是自己的想法灵光一现，对吧？就自己的突然想到可以这么去构思。

Speaker 2 45:17 
对对对，然后极少的情况，比如说我看见了一篇文章，然后我觉得他的这个方法有哪一些的缺点？然后我去改进，但是这种就是他的创新性会低一些，就这种创新性都会低很多。对，嗯。

Speaker 1 45:35 
那其实相当于，其实这些你已经构思清晰了，就是说每一步的逻辑你也很清楚，然后这时候，然后让 cloud 来把你所有代码写出来，可以这么理解吗？那会不会有问题？就是这个代码可能会，比如说中间有些步骤他写错了，或者是导致就跟你想的不太一样，会有这种这些问题。

Speaker 2 45:58 
我这种问题就是这种问题，其实你很好看出来的，要不然这个代码跑不起来，就是他很乘客是有问题的，跑不起来你让他修改就好。还有一种是你会发现跑出来的这个结果跟你想象的差别很大，就因为这个你可以让他写代码，然后让他把所有的这个 input 或者output，每一步骤的 input 和 output 全都是，就是打印出来， print out 出来明白，然后你就能看到，然后你只需要看这个 print out 就可以了。

Speaker 1 46:30 
是，所以相当于就是说这种反而就是能够节省你比如说一大堆的代码之后，然后发现也不知道哪里错在哪里，反而每一小部分写一个print，对吧？就可能可以，对。

Speaker 2 46:43 
对对。

Speaker 1 46:44 
ok，ok，是对，对于这个就属于coding。那 coding 一般就这种任务上，是吗？还是说还会有一些别的任务上？

Speaker 2 46:57 
那个怎么说呢？就是现在做的跟提示词相关的，或者跟大语言模型相关的，就是基本上 coding 都可以直接让它帮忙写，但有一类的没办法让它帮忙写，就是你做模型本身的创新的时候，这个是没办法让它帮你写的。

Speaker 1 47:16 
但模型上的创新这是应该比较难了，毕竟这种东西需要各种的 GPU 或者是，对吧？就要训练它的model。

Speaker 2 47:26 
其实也不一定就是我刚才我不是说有一类非常，就是现在这个领，这个范，就是这个领域越来越小，但是它还是存在的，就比如说做一些小模型，然后小模型你必须得去把这个小模型的一些已经不是调参了，把它的结构给它。嗯，调整，因为其实说是模型，但是它其实咱们更多的说的是那个学习的过程，然后这个学习的对象到底是什么？怎么样去学习？然后这个每个 neural 和 neural 之间的是怎么样去连接的？这些都是可以改变的。嗯，然后就是做这个的时候，你必须得明确你到底想怎么样改变，你改的是第几层？然后比比，或者说是你到底让他学习的是什么？然后你让他做 embedding 的话该怎么样去做？就这些你必须得非常的明确，然后你才能让他去修改，也是可以修改，就是他也是可以修改的，但你必须非常明确。

Speaker 1 48:25 
明白，所以说我觉得好像更多他都是处于一个执行的阶段，反而不会对，他并没有说给你产生一些好的idea，比如说你的那个论文中会说不，比如说把这个输入这一层，然后再把他们两个东西输入下一层，对吧？这种东西具体可能就没办法去给到你一个好的idea，对吧？

Speaker 2 48:48 
对，就是这个，也是刚才所说的，就是他没有这个 Meta cognition，他没有这个概，就是没有价值的概念嗯。嗯，他没有价值，就是人是有价值，人是知道好坏的，所以他是有价值。对，就是他是知道这个，有这个价值观，但他是没有价值观，他不知道什么东西值得做，哪些东西不值得做。

Speaker 1 49:09 
明白，其实有点类似于，比如说我们提出了多智能体，然后这时候需要一个理论来支撑，他可能可以这种，我觉得反而他可能可以给一些，因为理论都现有理论，我觉得这种时候他反而能提供一些brainstorm，或者是应该叫信息检索，这种东西应该算信息检索。对。

Speaker 2 49:31 
是，就是只要有方法论他就可以执行，或者说是有一步一步的这种明白方法的，或者说是这个 chain of source，然后他就可以执行。对，但如果没有的话，那就比较难了。对对对。

Speaker 1 49:45 
所以 idea 还是掌握在我们手里面的。对，然后他还是更多是一个执行者。那对，就其实我比较好奇，因为就我觉得你已经完全偏计算机的方向去了，那假如就因为可能之前我访谈过教育学的，他说就是可能会把它当做一个学生，然后跟他很有耐心地去跟他沟通指导，可能这时候他说会产生一些比较有趣的idea，这是这可能你还没有接，可能你不会这么去用它吧，对吧？就是这种方式的话。

Speaker 2 50:22 
我会觉得就是它给我就是在交互的过程，当然交互过程中然后我有了灵感，这个也是正常的，就是我只不过是这个我交互的对象，就我的交互对象不是AI。我交互对象可能是其他的文献或者怎么样，就是那可能其他人他可能交互的是AI， AI 也是有这个文献的训练的语料的，所以他可以提供一些就是文献里面的一些观点或者立场，然后这个学生他就是他在做科研的时候，他先跟 AI 去交互，然后先去就是去探索，然后慢慢地把这个他的 research question narrow down，然后成为一个可以研究的这个 research question，这个是可能，嗯，这个是肯定可以的。明白，但我不需要，就是，呵。

Speaker 1 51:10 
对对，这这肯定根据每个人的需求来说还是不一样的。对。

Speaker 2 51:16 
对对对，就是他是有这个能力的，就是他没办法直接告诉你什么是有价值或者哪个这个问题该怎么样去 narrow down，什么东西值得去做？他没办法告诉你这个，但是他可以帮你去。

Speaker 2 51:30 
To brainstorm, need to brainstor.

Speaker 2 51:32 
我们就可以了，就把所有的相关信息全都给你罗列出来，这个其实它是可以的。

Speaker 1 51:36 
是明白。然后刚才说到除了 coding 还有一个是还会有什么样的任务 API 吗？你是想说这种。

Speaker 2 51:48 
但是我就。

Speaker 1 51:50 
但我觉得 API 这种写的方式好像看不出来交互，对吧？这种好像看不出来交互。

Speaker 2 51:58 
也不一定就是这个，就是你用 API 的话它也是需要交互，就在测试阶段，你要测这个 pump 到底合不合适，或者说是这个 agent 和 agent 之间的交互，它能不能让这个表现最后的 performance 最大化啊？就是会测这些。

Speaker 1 52:17 
但这个的交互好像不是人人机交互嘛，对吧？好像更像是技术层面上的交互了。可以这么理解吗？

Speaker 2 52:26 
对对对对，就不是那种人机交互，比如它不是说是为了你达成一个目的，而是我为了达成这个目的，然后我用了这个工具去搭建，仅此而已。对。

Speaker 1 52:40 
那比如说还会有一些什么样的任务？就你觉得你常用会用 GPT 去帮你完成的。

Speaker 2 52:52 
基本上比如说现在感觉，比如说搜索或者怎么样，我就会让 GP 帮我搜索，就我不会用谷歌浏览器，或者说是用得稍微少了一些。对。

Speaker 1 53:08 
明白，就是说也就是信息检索，把它相当于快速帮你整理你想要的东西。

Speaker 2 53:15 
嗯，对，是这样，然后其他就没啥了，我基本上不用它生成，就是图片声音，就是那个 Audio 啊。什么？就是我不用这些。

Speaker 1 53:27 
明白，然后我想想，诶假，我其实有个疑问，比如说因为其实，嗯，就其实对于我们这一类群体，就是硕博，就是其实他我们的 critical thinking 能力都比较高嘛。那假如说，对于，比如说你可能，比如说比你低的学弟学妹，或者说你可能你指导的学生，或者说就那种 critical thinking，你会鼓励他们去使用 AI 吗？

Speaker 2 53:59 
我觉得他们已经是 creative thinking 之前的问题了，就是他们的积累过于少，所以他们必须得靠一 AI 去快速地就是完成原始积累，就是知识的原始积累。嗯，就是我觉得他这个 creative thinking 可能更多的是，就是我了解了很多知识，然后我在看到新的领域的时候，然后我突然就是，当然这个不是有意识的行为，而是我，嗯，脑子里面觉得这个场景跟我之前接触的某一个场景非常相似。然后我就会去类比，然后去这个思考明白。

Speaker 1 54:35 
对，这好像是，这应该是属于我发现另一个，就是从你这里发现另一个点，就是说通过 AI 来学习新的知识之后，让自己的知识领域扩增拓增嘛。对，然后增加之后你就能去判断这些东西写得怎么样，但也会出问题，就是他假设就是完全也不懂，比如说你可能再带一个本科生，让他帮你写把，去写一篇文、论文，对吧？或者说让你去让他去总结个什么东西，就发现就是个 AI 生成的，那这时候不就会出现很不具有 critical thinking 这么一个能力吗？

Speaker 2 55:13 
对，我是我们会觉得就是把这些任务直接交给他，就本身这个事就是我的这个判断本身可能是有错的，就是我不会，我尤其是本科生的话，我会让他执行那种非常简单，只需要摁两个按键就可以执行的，就是比如说直接把代码就是复制过去，然后复制到那个服务器上面去帮我跑一下，然后只需要他干这件事情，然后把这个结果记录下来就可以了。然后至于修改的话，对，我修改的话我基本上都会告诉他们怎么样去修改，就是这个我想让你帮我改成什么样？具体这块可以改，那块可以改，具体怎么样，改好了我把这些事情全告诉你了，你可以交给 g GPT 了哈。对。

Speaker 1 56:00 
那其实这个事情有点像，我给你规定好了你的任务、工作要求等等这些条条框框，然后其实你相当于就是说他去帮你校对 GPT 输出的内容是否符合你的条条框框。

Speaker 2 56:16 
对对对对，就是他只是有点像是这个对像，那只不过是监控一下就。

Speaker 1 56:22 
可以。对对对，相当于他没有处在一个需要他 critical thinking 的这个层面上的一个问题。

Speaker 2 56:30 
对，我就是刻意的不让他。去做 creative thinking，因为我不知道他 creative thinking 出来的东西到底是啥。

Speaker 1 56:35 
所以对，白明白，就是我懂了，就属于这个监控层放在了自己手里，而不是而不放在他们那一块那。嗯，但是假如说，比如说，就是比如说你在带一门课，然后你布置了个作业，然后你怎么去防范，或者说怎么去避免？尽量地避免他们所交的答案都是 AI 生成的。即使你说了你们不要用 AI 去生成，但他们肯定还是多多少少会去用的。

Speaker 2 57:04 
我会生，我会给他们布置那种 AI 没办法很好执行的任务，但对，就是他必须得自己去想才能行，比如说他自己得，必须得确立这个他研究的目标，因为 AI 他如果说是研究问题的话， AI 提的研究问题会非常非常的Vague，就是他不是一个可以研究的问题，他的要不然他输出的那个研究问题会非常长，但是我们不需要那么长的研究问题，就是一下子能看出来，要不然就是他会输出得非常vague，就是他就那么短的一句话。然后他也没有，就有任何可以值得研究的点，就是它的范围太大了，所以研究不了，就 AI 会生成这种，就是这就一下就能看出来了，那很明显就是你就算，就是这个学生，他就算全用 AI 去生成了这篇文章，再用我一看我就知道这个不合格嘛。你不管它是怎么样，就是 AI 它也是不合格的，就算是他自己写出来的也是不合格的，就没有关系了。

Speaker 1 58:08 
那这种你一般会比如说会更相更倾向于 coding 呢？还是 writing 呢？还是就这种一般会是像什么样的任务？应该是开放式的。

Speaker 2 58:21 
对， writing 会多一些，就是其实 coding 很难去杜绝他们用 GPT 的。

Speaker 1 58:27 
要 o 应该难杜绝的是 coding 这种东西代码能力肯定，我觉得 GPT 的能力肯定是比人强的，就在 coding 上。对对。

Speaker 2 58:37 
那起码比本科生强。那其实。对是。

Speaker 1 58:41 
我觉得其实大家其实已经不管硕博，反正大家很多代码任务都会让 GPT 来完成了，基本都是。

Speaker 2 58:48 
对对对，是对。

Speaker 1 58:50 
那你就是，嗯，您说没有？你说。

Speaker 2 58:55 
没有？没有没有，我只不过是一个comments，你要是下一个问题的话，你说下一个问题。

Speaker 1 59:00 
对，我其实就是有个问题，就是完了打断，等一下让我想一下。

Speaker 2 59:07 
嗯，好的好的。

Speaker 1 59:16 
刚刚才是说到什么来着？突然断了。哦哦，该说的那我没，那还挺对的。嗯，那比如说什么样的？比如说是那种，比如因为我之前就在想这个实验任务一般会定到什么样的一个程度，然后让他们会没办法只用 AI 就能完成。然后我就想，比如说政府颁布了什么，什么什么一个政策，你然后就开放式讨论嘛？或者说在校园里面实施 AI 监控会不会侵犯什么什么权益？这种就这种会不会很开放导致这样？但我又觉得 GPT 好像也能给出很多观点。

Speaker 2 59:57 
对，就是我觉得更多是可能咱们这个后面培养学生的时候考虑的是，如果是 GPT 会干的，我就不要求学生一定会自己干，因为你防止不了他跟 GPT 合作，但是有一些东西目前是 GPT 没办法干的，但是如果说 GPT 有这个原认知，或者说是怎么干，他也是可以干的，就是你这理论上是可以取代的，就是理，只是现在目前来说是理论上是可以取代的，就有可以有一些可以取代这个本硕博以下的，这个这些就是人。对，但是当然他以后会取代博士的，这是肯定的。就是那我觉得更多的是怎么样培养学生跟 AI 去协作完成一件事情，他只需要知道这个，这件事情该怎么样去，就是什么是好，什么是坏，我觉得就可以。

Speaker 1 01:00:51 
了。明白，所以这个实验任务的具体制定也可以后续再讨论，对。

Speaker 2 01:00:57 
不对？对对，是的，就是以后也许他不需要知道，就是 1 + 1 = 2，然后或者说是 8 × 8 = 64，就是他不需要背那个乘法口诀，他只需要摁一下计算器，或者说是问一下GPT。明白就可以了，但是他必须得知道就是怎么样去判断是不是对的，就是他可以跟 GPT 合作，但是他如果和 GPT 合作下来， 8 × 8 = 72 的话，那这个，哼，那我得让他知道这是错的。

Speaker 1 01:01:28 
对，明白是能理解。能理解诶，那你有没有就因为你刚才也提到了那个，那个 chain 是什么？我突然间忘了。是那个思维链的诶，计算机怎么说来着？那个，对，椣树那个 chain of thought，对对对，就计算机中这种，你是不是也是接受过提示工程的培训，或者说学习过相关的知识？

Speaker 2 01:01:54 
嗯，没有这东西纯粹靠自学，就是提示词怎么样写，我觉得现在目前还是你得尝试，因为有一些情况下就是 chain of source 不是一个最佳的策略，他可能你直接提问就可以了。对对对，然后让他回答。

Speaker 1 01:02:12 
我，我好像也遇到好几个人跟我说，就是现阶段好像就跟他讲个简单点的东西，反而他输出的东西更好。

Speaker 2 01:02:21 
对，就是他的灵活，就是他会，就是有点像是你如果让他走那个 chain of source，或者是说走这个 Multi agent 这种框架的话，他会限制他的灵活度。然后很多时候就是人在我在设计这个 chain of source，或者说设计这个多智能体的时候，我不会考虑到他可能需要某些的灵活度，嗯，我可能没考虑到，但是实际在测试的时候我又需要是，然后这就是为什么它不太好？对。

Speaker 1 01:02:54 
是这样，那就比如说用 GPT 来说，你觉得会对你的思维深度有变化吗？还是增加啊？

Speaker 2 01:03:04 
应该。嗯，增加，可这个肯定是正向增加，它不会说是减少，但是写代码的时候也会，也许会那个 call native offload 也会，也许可能是这样的，就是。对对对，就尤其是我不熟悉的东西，我越有可能会offload，但是熟悉的东西我不反而不会offload。对。

Speaker 1 01:03:29 
是这样的，就所以还是根据那怎么说来说去都是属于那种这个知识到底是熟悉的领域还是不熟悉的领域？

Speaker 2 01:03:38 
对对对，就是如果熟悉一切都不是问题。但是对，就是学生面临的问题是他们不熟悉，咱们也不知道他到底哪块不熟悉。对。

Speaker 1 01:03:48 
对对对对对对对，这就是学生端的一个问题了，这也很难去考虑到，不应该很难说去计算出来。

Speaker 2 01:03:56 
对，就是很多老师他都没办法去考。对，可能只很有经验的老师才行。对。

Speaker 1 01:04:03 
对对对，是这样，我应该没有遗漏什么。你，你有什么补充吗？就是因为我觉得好像问的也差不多了。

Speaker 2 01:04:14 
嗯，那就查死我了，我还不知道，我已经忘了刚才问卷调查里面的内容了。

Speaker 1 01:04:22 
没关系，就因为我其实很关注于协作方式，就比如说你可能会有一些 interesting insights，就是比较有趣的点，然后就是我们没有考虑到的一些点，嗯。

Speaker 2 01:04:40 
应该，那我觉得你说。

Speaker 1 01:04:44 
没有就看你有没有什么补充的点。

Speaker 2 01:04:47 
我补充的点我主要是想的是那个assessment，就是因为如果说是后面要做这么一个系统，它是就它必须会涉及到评估，就测试评估，因为你不测试和评估你不知道。

Speaker 1 01:05:03 
你想说评估学生端是吗？还是评估。

Speaker 2 01:05:06 
对学生端，就是你不知道学生到底是属于什么样一个状态，就是如果学生在教室里，他就在你我的面前，我知道他的一举一动，我能看到他的表情，对对对对，但是 GPT 看不到。

Speaker 1 01:05:22 
但我就比如说什么摄像头监控学生状态，或者是我感觉都不太现实，这种通过这种方式。

Speaker 2 01:05:33 
对，现在主要问题在于模态的对齐，就是就包括那个 NLE 那边也在研究就怎么样把这个模态能够对齐，比如说我的那个EDA，我的 EDA 数据就是那个皮肤电数据，嗯，在某一个时间点，然后它有一个非常巨大的波动，然后这个是这个相当于说明我在这个时间点的时候经历了一个 physical arousal，就我的身体生理然后被激活了，我有可能是激动，我有可能是兴奋，我有可能是生气，一切都有可能对我的情绪是有起伏的。然后我再去看这个，比如说这个学生他在这个时间点到底在干什么？就是这两个就怎么说呢？这个就存在一个问题，就是到底是把重心放在哪个模态上？就是把重心放在就是以哪个模态的。的信息为中心，像这种情况我是以视觉的这个数据提供的信息为重点，就是我通过视觉去看这个学生可能站起来跳了一下或者是怎么样，就是他现在面临一个考试或者怎么，就是我可以通过视觉去看，但是这个是必须得去，因为我们要做这个模态之间的对齐，所以他必须得知道什么时间该看，什么模态是以哪个模态为准，他又知道这一点，这个是一个难点。

Speaker 1 01:07:07 
对，所以反而我们能观测到的最多是他，比如说他提问的这个提示词有没有什么变化，或者是就是只能从他的交互轨迹来看这个学生的状态。

Speaker 2 01:07:25 
对对对，就是大多数他只有一个数据来源，就是他的对，这个对话。

Speaker 1 01:07:34 
是这样，所以可能就很难去测量，因为心理状态不可能通过这个来表现。

Speaker 2 01:07:42 
对，然后他们就会，比如说就 nie 那边在做的，他们会加皮肤电，对吧？就是带一个小手表，他可以测那个皮肤电，然后他会给那个大脑上面带电极。嗯，测脑电，然后或者说是去看那个眼动，测这个就是去用那个眼动力，你去看这个眼睛注视在哪，然后去分析，但是很难对齐。就是这些东西你必须总结出来一套方法论，然后把这些不同的布局给他对齐了，然后才能形成一个非常合理的解释。

Speaker 1 01:08:17 
对，是，但说实话，假如我们只关注于这个学生有没有 critical thinking，就假设我就是去 assess 这一个点，我觉得可能就是会简单很多，因为我只关注于你的 critical thinking 有没有降低和提高，我不去关注于你的长期表现，也不去关注于你的精神状态，我觉得好像会好衡量一些，因为你的 critical thinking 可以通过，比如说你的 chat log，或者是你的output，或者是反正就是我觉得好像是能通过文本来量化个人感觉。

Speaker 2 01:08:54 
对，其实这 critical thinking 主要我感觉评估的话就评估两方面。对，对，就我们不说这个 critical thinking 它是对还是错，或者有价值或者没价值，我只看它有没有 critical thinking。对，这就很好量化。

Speaker 2 01:09:07 
对，就你看它的engagement，对，然后一个是一个方面，是它的 engagement 到底是高还是低？然后看它这个 engagement 它的输出的这个内容的在语义层面到底跟上一次输出的语义关系是什么？是扩大了还是更深入了呢？还是他如果缩小的话可能是一个不好的迹象？然后或者说是他一直在问同样一个问题，他也没有进行 creative thinking，但是如果说是他这个范围扩大了，或者是说是他的这个深度增加了，嗯，然后他的这个 engagement 还特别的频繁，嗯，那就说明他在 creative thinking，我是这么想。

Speaker 1 01:09:49 
的，对，因为我觉得这个是这么一回事，我也这么想的。就如果我一定要将脑电波这些就会变得很复杂，因为常就是很正常的一个问题，就是大家在用这个 GPT 的时候，我也不可能实时监测这些东西，就很现实的一个问题。

Speaker 2 01:10:06 
嗯，就是所以可以从文本上面，然后咱们就是这种情况就必须对学生进行限制，就是比如说必须得坐满多少轮的这个交互，对，然后每一次交互都必须得有一个完整的输入，就是必须有这种限制。

Speaker 1 01:10:24 
对，这个在实验的过程中肯定是能要求他们这么去做的，然后如果真的要强制性要求，就相当于说你这个提示词写得不够规范，就是可能就对话中让他去改他的提示词，只能这么说。

Speaker 2 01:10:39 
对对对，是的。

Speaker 1 01:10:41 
对，那访谈应该就先这样，然后我们可以往下去对一下那个 PPT 什么的，那我就先结束录音哈。诶，ok，好好，谢谢访谈。

Speaker 2 01:10:57 
好的，不客气。


