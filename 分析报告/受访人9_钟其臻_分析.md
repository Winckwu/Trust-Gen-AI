# 受访人9：钟其臻 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 钟其臻 |
| 年龄 | 22岁 |
| 学历 | 厦门大学电子商务专业，本科大四 |
| 使用频率 | 每天（工作时） |
| 主要工具 | ChatGPT（4o免费版）、DeepSeek |

## 使用场景

### 场景1：课程作业/案例分析

**工作流程**：
1. PDF转Word上传给GPT
2. 先测试GPT能否识别
3. 直接丢问题效果不好，改为一个个拆解

> "你全部问题，丢进去的时候一般它效果都不会太好。因为他的回答永远是有限的"

**内容采用策略**：
- 有些理由"很强行"就不采用
- 课程比较水就可能直接用

> "我这课可能比较水，我可能直接用"
> "我是就是做材料的，然后汇报的不是我"

**GPT阅读替代**：
> "GPT就是可以帮你阅读，主要是你阅读就很强了"
- 案例自己"简单瞄了一眼"
- 主要靠GPT阅读和回答

### 场景2：代码辅助（Stata/Python）

**基础功能**：
> "前面的可以就是他跑寻跑回归肯定是可以的"

**复杂功能的问题** ⭐⭐⭐⭐：
> "后面我想让他直接帮我把能不能直接把能显著的找出来...然后就不行了"
> "它这个代码输进去它是能跑出来，但是它结果是错的"
> "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果，就他这个东西是不会回答这个东西没有办法实现的"

**报错处理**：
> "我就会把那个报错，它不会显示不是会显示东西，就把那个显示的东西放进去"
- 有时行，有时不行
- 不行就搜Google

### 场景3：论文写作（复现论文）

**核心态度**：
> "我觉得完全生成效果不会好"
> "因为他不可能生成，你如果不先把它提前给一点东西给他，怎么可能生成能直接生成"

**工作流程**：
1. 把原文method部分喂给GPT（作为背景信息）
2. 找写得好的参考文章
3. 自己先改写（英文夹杂中文）
4. 让GPT改写润色连接

> "我一般就是不可能全部一起，我就是有一比如说一句一句话写。或者是一段一段一段一段话写"
> "我自己会先改，然后改完之后我让他再改改写论"

**GPT角色**：
- 改写润色
- 连接句子
- 不完全生成段落

### 场景4：学习/信息搜索

**DID方法论学习**：
> "先问的如何解决内生性问题，然后如何使用DID解决内生性问题解决的思路是怎么样的"

**为什么选择GPT而非视频**：
> "因为视频之前看过...如果要马上的话，我就想先看一下CHAT GPT，他直接文字出来的话也很快的"
> "你看了GPT你问他之后，你又可以马上直接把你要解决的事情，你又可以再问他"

**效果评价**：
> "挺好的...然后再往下我就提出了一个提出一点特定的问题"

### 场景5：文献阅读

> "论文我感觉基本上要么是翻译，要么是概括了"
> "有的时候也会针对于文章中某一个东西让他去解答"
> "感觉他至少会根据文章内容来给你解释"

### 不使用/规避的场景

**完全生成内容**：
> "我感觉他，你让他自己写的话，应该效果不会很好"
> "肯定写出来就是AI的味道会很重"

## 信任轨迹：效率导向型

### 信任特征

以任务完成为导向，信任程度随课程/任务重要性调整。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 水课作业 | ⭐⭐⭐⭐ 较高 | 可能直接用 |
| 基础代码 | ⭐⭐⭐⭐ 较高 | 能跑通 |
| 复杂代码 | ⭐⭐ 低 | 会强行输出错误 |
| 论文写作 | ⭐⭐ 低 | 只润色不生成 |
| 信息搜索 | ⭐⭐⭐⭐ 较高 | 快速获取 |
| 幻觉问题 | ⭐⭐⭐ 中等 | 只作为参考 |

### 核心信任逻辑

> "只作为参考。只做一参考吧"
> "这个理由感觉写的挺正常的，我原本就觉得不一定可以，我只是满问他一下"

## 核心专家策略

### 策略1：问题拆解策略

> "后面就给他说清楚...1.1开始只想去试一下"
> "一个问题，一个问题"

- 全部问题效果差
- 拆解后逐个提问

### 策略2：多方参考策略

> "我肯定多方参考，一般做作业的时候，我就不会只看一个"
> "比如说老师又特别强调了。我们还会把那一部稍微多多写一点"

### 策略3：阅读替代策略

> "GPT就是可以帮你阅读，主要是你阅读就很强了"

- 让GPT阅读材料
- 自己只看GPT输出
- 判断输出合不合理

### 策略4：改写而非生成

> "我一般让他改写乱色，我也没有说时间很多让他把这两句话连在一起"

- 自己先写内容
- GPT负责改写润色
- 不完全依赖GPT生成

### 策略5：任务重要性分层

> "我这课可能比较水，我可能直接用"

- 水课：可直接使用
- 重要任务：自己多参与

## 深层认知

### 对GPT能力边界的认知

> "他一开始没有领会你的意思"
> "你全部问题，丢进去的时候一般它效果都不会太好"
> "我觉得完全生成效果不会好"

### 对GPT"强行输出"的发现 ⭐⭐⭐⭐

> "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果"
> "就他这个东西是不会回答这个东西没有办法实现的"

**理论价值**：GPT不会承认自己做不到，而是强行给出错误答案

### 对隐私的态度

> "还是会担心吧，但是我感觉我肯定算比较不担心的"
> "因为我感觉也没有什么什么什么好泄露的"

### DeepSeek vs ChatGPT

> "deep seek他有时候就会弄出来很多七七八八的东西，我觉得就很不好"
> "有很多中国人才会有表了这种一些词汇"

## 独特发现

### 1. GPT"强行输出"问题 ⭐⭐⭐⭐⭐

> "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果"

**理论价值**：GPT不会告知用户某任务无法实现，而是强行生成错误结果，这增加了用户判断负担

### 2. 阅读替代模式 ⭐⭐⭐⭐

让GPT阅读材料，自己只判断输出是否合理。这是一种**极致效率导向**的使用方式。

### 3. 任务重要性决定使用深度

> "我这课可能比较水，我可能直接用"

课程/任务的重要程度直接影响GPT使用策略。

### 4. 交互式学习优势

> "你看了GPT你问他之后，你又可以马上直接把你要解决的事情，你又可以再问他"

GPT的交互性让学习更连贯，可以即时追问。

## 对论文的核心价值

### 1. GPT"强行输出"作为信任风险

> "它这个代码输进去它是能跑出来，但是它结果是错的"
> "就他这个东西是不会回答这个东西没有办法实现的"

**理论启示**：GPT不会主动告知能力边界，用户需自行判断输出是否可靠

### 2. 任务重要性作为使用策略调节变量

不同重要程度的任务采用不同的GPT使用深度。

### 3. 阅读替代作为效率最大化策略

让GPT承担阅读工作，用户只需判断输出质量。

### 关键引用（可用于论文）

1. **问题拆解必要性**：
   > "你全部问题，丢进去的时候一般它效果都不会太好。因为他的回答永远是有限的"

2. **GPT强行输出**：
   > "我觉得这个东西是没办法实现的，但他还是会强行给你输出一个结果，就他这个东西是不会回答这个东西没有办法实现的"

3. **阅读替代**：
   > "GPT就是可以帮你阅读，主要是你阅读就很强了"

4. **完全生成效果差**：
   > "我觉得完全生成效果不会好"
   > "因为他不可能生成，你如果不先把它提前给一点东西给他，怎么可能生成能直接生成"

5. **任务重要性分层**：
   > "我这课可能比较水，我可能直接用"

6. **交互式学习优势**：
   > "你看了GPT你问他之后，你又可以马上直接把你要解决的事情，你又可以再问他"

7. **只作为参考**：
   > "只作为参考。只做一参考吧"

8. **多方参考**：
   > "我肯定多方参考，一般做作业的时候，我就不会只看一个"

## 八、分析验证

待核对的关键引用：
- [x] "强行给你输出一个结果" ✓ (line 4759)
- [x] "这课可能比较水，我可能直接用" ✓ (line 4665)
- [x] "只作为参考" ✓ (line 4841)
- [x] "多方参考" ✓ (line 4850)
- [x] "帮你阅读，主要是你阅读就很强了" ✓ (line 4690)

---
*分析完成时间：2025年1月*
