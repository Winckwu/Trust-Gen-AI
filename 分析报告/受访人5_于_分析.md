# 受访人5：于 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | 于（＆） |
| 年龄 | 23岁（01年） |
| 学历 | NTU物理与数学学院，分析学硕士在读 |
| 本科背景 | 东北大学应用统计 |
| 使用频率 | 几乎每天 |
| 主要工具 | DeepSeek、豆包、ChatGPT，偶尔kimi |

## 使用场景

### 场景1：课堂学习
- **实时概念解释**：
  > "上课正在上课中的时候，比如说老师在PPT上有一些词汇，或者是有一些英文的专属名词...我就会把它复制到GPT，然后让他先解释这个词的基本意思，然后再让他给我举几个例子"

- **课后PPT理解**：
  > "有些PPT老师在PPT，然后看不懂，然后就会把整页截图给他"
  - 一页一页提问，不整体投喂
  - 让GPT翻译+拓展

- **整体投喂效果差**：
  > "之前尝试过把整个文档丢给他，但是觉得那种就是太粗略了，后来还是主要是以PPT一页一页的形式"

### 场景2：专业概念 vs 数学计算（关键差异）

- **专业概念**：高信任
  > "像这些，比如说在上一些financial的课，这些基本专业的这些名词，包括解释，这些比较偏专业性的东西，我还是比较相信GPT的准确性"

- **数学计算**：低信任 ⭐⭐⭐
  > "碰到了一些概率论的那些计算，细微的计算，GPT的准确性还是有待提高的"
  > "我觉得可能准确率可能百分之跟一半"
  - 策略：GPT给思路，自己验算
  - 会尝试引导修正，"有时候可以成功，有时候提示不过来，然后我就放弃了"

### 场景3：项目代码（Kaggle比赛等）
- **选择模型**：
  > "然后让他帮我们想有什么可以比较创新的模型...它提供的还是挺全面的"
  - GPT提供选项，团队人工筛选
  - 只选择"有学过或者是大家有了解的"

- **代码生成流程**：
  > "会让他先写一个基础的模型...基本上一小块一小块的写"
  - 数据清洗："我觉得还是挺不错的"
  - 建模代码："要一直反反复复改好几次才能改对"

- **代码学习**：
  > "有些代码是他生成的，然后可能不太了解，我想如果想知道每行代码的意思，就会让他解释一下"

- **手写代码减少**：
  > "本科大一大二的时候敲一敲，大三就有（GPT）...几乎没有了吧"

### 场景4：工作中的SQL
> "工作中会让他帮我写写sql...基本上会跟他讲一个逻辑，然后让他实现代码，然后自己再改"
- SQL报错比较少
- Python/模型代码报错较多

### 场景5：邮件写作
> "一般是会先写个中文，然后让他写英文...语气格式没什么要改"
- 使用频率低
- 满意度高（因为用得少，没发现问题）

### 场景6：简历/模拟面试 ⭐⭐⭐（独特场景）
> "比如说把一段经历发给他，然后让他针对这段经历...从各个方面提出什么问题"
> "假如你是面试官，针对我的经历从不同方面提出几个问题"

- 不是让GPT修改简历
- 是让GPT扮演面试官提问
- 效果："有少数会被问到，主要是在让我对一段经验思考能更加全面一些"

### 场景7：生活信息搜索
- **药品/症状查询**：
  > "因为之前说GPT4水平相当于一家三甲医院的医生...不是什么大病的话，我觉得还是可以相信"
  > "确实有一些用"

### 场景8：算命（娱乐）
> "效果就看个乐吧...主要还是好玩"
> "我可能会等那年过了看看他说的准不准"
- 纯娱乐，不会认真对待
- 不会追问细节

### 不使用的场景
- **PPT制作**：
  > "因为我觉得要他封顶的话，我觉得我自己差不多"
  > "基本很少有文字"（内容偏数理）

- **文献搜索**：
  > "论文，可能我就是要不就直接看，就没有问过GPT"

- **学术写作**：
  > "硕士项目没有论文，就是实习答辩"

## 信任轨迹：实用主义型

### 信任特征

基于任务性质（解释性 vs 计算性）区分信任程度。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 专业概念解释 | ⭐⭐⭐⭐⭐ 高 | 直接采用，不验证 |
| 代码生成 | ⭐⭐⭐⭐ 较高 | 分块生成，出错再改 |
| SQL代码 | ⭐⭐⭐⭐ 较高 | 报错少，逻辑对 |
| 模拟面试 | ⭐⭐⭐⭐ 较高 | 帮助全面思考 |
| 药品咨询 | ⭐⭐⭐⭐ 较高 | 小病可信 |
| 数学计算 | ⭐⭐ 低 | "准确率一半"，需自己验算 |
| 算命娱乐 | ⭐ 娱乐 | 看个乐 |
| PPT制作 | ❌ 不需要 | 内容偏数理 |

### 核心信任逻辑

> "大体的逻辑跟思路肯定是没有问题，遇到一些比较繁琐计算题的时候，它的一些计算过程中间经常会有一些小小问题"

**结论**：逻辑思路可信，数值计算需验证

## 核心专家策略

### 策略1：逐页投喂原则

> "之前尝试过把整个文档丢给他，但是觉得那种就是太粗略了"
> "还是主要是以PPT一页一页的形式"

### 策略2：角色扮演提示词

> "我比较喜欢让他带入，比如说如果你是一个什么什么，然后让他给我解答"
> "比如说如果你是一名医生，如果你是一名面试官"

- 特定场景使用角色设定
- 承认可能是"心理作用"

### 策略3：思路采纳+自我验算

> "GPT给思路，自己验算"
> "会提示他，会引导他，有时候可以成功，有时候提示不过来就放弃"

### 策略4：模型选择的边界控制

> "我们一般都会选有学过或者是大家有了解的，就不会选完全没有接触过的"

- GPT提供选项
- 只采用熟悉的选项

### 策略5：代码依赖但学习意识

> "有些代码是他生成的，然后可能不太了解，我想如果想知道每行代码的意思，就会让他解释一下"

- 生成代码后会学习理解

## 深层认知

### 对AI能力的边界认知

> "解释一些概念的东西...第二个就是代码的方面"（出色）
> "复杂的计算数字的计算那种"（不行）

### 对专业匹配的认知

> "因为我们这个专业也不像计算机那...主要是数理，对代码要求其实没有特别高"

- 使用方式与专业需求匹配
- 不需要深度学习代码，只需完成任务

### 对手写代码减少的认知

> "本科大一大二的时候敲一敲，大三就有（GPT）"
> "几乎没有了吧"

### 数据隐私态度

> "没怎么担心过，因为我给他的数据不是隐私的数据"
> "简历我觉得无所谓"

### 对提示词效果的怀疑

> "感觉有可能加不加差别不大，我加了可能是心理作用"
> "会觉得他可能会输出的更好"

## 独特发现

### 1. 模拟面试场景 ⭐⭐⭐⭐

这是一个**独特且有价值的使用场景**：
- 不是让AI修改简历
- 而是让AI扮演面试官提问
- 目的是"让我对一段经验思考能更加全面一些"

**理论价值**：AI作为思维训练工具，而非内容生成工具

### 2. 解释性 vs 计算性的信任分化 ⭐⭐⭐⭐⭐

| 任务性质 | 信任程度 | 原因 |
|----------|----------|------|
| 解释性任务 | 高 | "比较偏专业性的东西，我还是比较相信" |
| 计算性任务 | 低 | "准确率可能百分之跟一半" |

**这是一个重要的边界条件**：任务是否涉及精确计算

### 3. 工具依赖的专业差异

> "因为会计真的不要求你代码能力有多好"

- 专业需求决定使用深度
- 不需要学习代码 → 完全依赖GPT生成

## 对论文的核心价值

### 1. 解释性 vs 计算性任务的信任边界

> "这些比较偏专业性的东西，我还是比较相信GPT的准确性"
> "概率论的那些计算...准确率可能百分之跟一半"

**理论启示**：AI信任不仅与任务领域相关，也与任务性质（解释vs计算）相关

### 2. AI作为思维训练工具

模拟面试场景展示了AI的**非生成性用途**：
- 不是让AI产出内容
- 而是让AI帮助人类思考更全面

### 3. 专业背景对使用深度的影响

数理分析专业 → 对代码学习需求低 → 完全依赖AI生成

### 关键引用（可用于论文）

1. **解释性任务信任**：
   > "像这些financial的课，这些基本专业的这些名词，包括解释，这些比较偏专业性的东西，我还是比较相信GPT的准确性"

2. **计算性任务不信任**：
   > "概率论的那些计算，细微的计算，GPT的准确性还是有待提高的，可能准确率百分之跟一半"

3. **模拟面试用法**：
   > "假如你是面试官，针对我的经历从不同方面提出几个问题...主要是在让我对一段经验思考能更加全面一些"

4. **角色扮演提示词**：
   > "我比较喜欢让他带入，比如说如果你是一个什么什么...可能是心理作用，会觉得他可能会输出的更好"

5. **手写代码减少**：
   > "本科大一大二的时候敲一敲，大三就有（GPT）...几乎没有了吧"

6. **药品咨询信任来源**：
   > "之前说GPT4水平相当于一家三甲医院的医生...不是什么大病的话，我觉得还是可以相信"

---
*分析完成时间：2025年1月*
