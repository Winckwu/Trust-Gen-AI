# 受访人7：zqz - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 姓名 | zqz |
| 年龄 | 21岁 |
| 学历 | 本科，管理科学专业，电子商务方向 |
| 使用频率 | 看情况，有任务时使用 |
| 主要工具 | ChatGPT（4o免费版）、DeepSeek、Kimi |

## 使用场景

### 场景1：信息搜索
- **替代百度**：
> "现在有ChatGPT之后，你应该就不一定会在百度搜了"
> "他至少能直接给出来一个答案"

- **常识性信息**：直接相信
> "相信常识性的"

- **理论/算法**：
> "先大致先了解一下...看一下要不要用"
- 后续会搜资料补充

### 场景2：代码辅助
**完整工作流程**：
1. **任务开始前**：让GPT解释算法原理
   > "先信息检索一下"

2. **任务进行中**：
   - 让GPT生成代码
   - **绝不完全抄袭** ⭐⭐⭐⭐⭐
   > "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"
   - 在自己理解基础上改变

3. **遇到报错**：
   - 方案1：让GPT从前面重新生成
   - 方案2：去CSDN等权威渠道搜索
   > "有时候会很蠢"
   > "很正常，这个挺正常的，肯定会出现不能解决报错的情况"

4. **任务结束后**：写实验报告
   - 让GPT生成算法原理综述
   - 让GPT解释每段代码作用
   - 让GPT总结可能的问题
   > "看看他有没有多提一点什么我没有注意到问题"

### 场景3：文献阅读
- **快速筛选**：
> "先大概先看一下"
> "让他先阅读，先大概先看一下，下一步之后我就先大致有一个了解"

- **信任程度**：
> "他再怎么生成，你自己肯定也得看一下的"

- **相关性判断**：
  - 相关 → 看原文
  - 不相关 → 暂时忽略
  > "有可能会有问题...暂时忽略了吧"

### 场景4：论文写作（Method部分）

**核心评价**：
> "用ChatGPT没什么用，顶多就是把中文翻译成英文"

**工作流程**：
1. 自己写中文大概
2. 让GPT翻译成英文
3. 让GPT润色/完善

**为什么不直接投喂**：
> "理论上来说应该直接丢进去，它会应该会过于雷同"

**遇到的问题**：
> "他没有办法完全理解"
> "他理解能力没有很强"

### 场景5：心得感想等内容生成
> "跟报告其实差不多"
- AI痕迹明显
> "有AI痕迹的话就比较，就表达就比较雷同，我反正我感觉就是他就首先其次然而这种就特别多"

### 不使用/规避的场景

1. **隐私敏感内容**
2. **需要特别准确的场景**
   > "法律78的政治相关"
   > "不能出错的地方"

## 信任轨迹：实用怀疑型

### 信任特征

高度实用但保持怀疑，不完全依赖。

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 常识性搜索 | ⭐⭐⭐⭐ 较高 | 直接采用 |
| 代码生成 | ⭐⭐⭐ 中等 | 绝不完全抄，自己改 |
| 报告写作 | ⭐⭐⭐ 中等 | 生成后修改 |
| 文献筛选 | ⭐⭐⭐ 中等 | 参考但必看原文 |
| 论文写作 | ⭐⭐ 低 | 仅翻译润色 |
| 法律/政治 | ❌ 不使用 | 刻意规避 |

### 核心信任逻辑

> "他就是擅长搜还有写，我就是擅长分析输入"
> "没有思考能力...那我要思考，那我不思考，那这做了还有任何意义吗？"

## 核心专家策略

### 策略1：反模板化意识 ⭐⭐⭐⭐⭐

> "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"

- 代码：在自己理解基础上修改
- 文字：删除AI痕迹词汇
- 论文：不直接投喂，怕"过于雷同"

### 策略2：分段式代码调试

> "并不是一次性全部都跑，他们是一个框跑了"

- 一段一段验证
- 前面跑通的不再动
- 错误的地方重新生成

### 策略3：模板优于参考

> "如果你在这种情况下把它放进去的话，它有时候就会出现一些莫名那篇文章里面的词"

- 自己写步骤模板 > 喂别人论文
- GPT无法区分"仿照文章"还是"仿照写法"

### 策略4：时间驱动使用

> "需要快速的时候会最想要用"
> "比如说让你写一个东西明天要交的时候，这种时候你肯定最想用它"

### 策略5：多渠道验证

> "那就再是在别的地方再搜呗，百度啊"
> "去比较权威的，比如说什么CSDN，一些七七八八的地方"

- 常识内的：可不验证
- 非常识内的：被发现后才知道错

## 深层认知

### 对GPT理解能力的评价

> "他没有办法完全理解"
> "他理解能力没有很强"
> "有时候会很蠢"

### 对自身角色的认知

> "他就是擅长搜还有写，我就是擅长分析输入"
> "没有思考能力...那我要思考，那我不思考，那这做了还有任何意义吗？"

- 明确分工：GPT负责搜索和生成，人负责分析和判断

### 对错误信息的态度

> "不是常识之内，那应该判断不出来"
> "只有到后面发现他是错了，你才知道他是错的"

- 承认局限性
- 时间允许会验证

### 对隐私风险的态度

> "用都用了，对，你肯定至少意识到会有可能会有这个问题，也没办法采取任何措施"

- 意识到风险
- 但无可奈何

### 对AI痕迹的敏感

> "首先其次然而这种就特别多，然后还得这个还得改"

- 高度敏感
- 主动去除

## 独特发现

### 1. 反模板化作为核心原则 ⭐⭐⭐⭐⭐

这是本受访者最显著的特征：
- 不完全抄代码
- 不完全抄文字
- 不直接投喂论文

**原因**："完全抄就会出现很多人都是差不多的情况"

### 2. 模板 vs 参考的区分 ⭐⭐⭐⭐

> "他没办法理解你这个真正的仿照是仿照这个文章，还是只是仿照写法"

**洞察**：GPT无法理解用户的深层意图（仿照内容 vs 仿照形式）

### 3. 时间压力作为使用驱动力

> "比如说让你写一个东西明天要交的时候，这种时候你肯定最想用它"

### 4. 人机分工的清晰认知

> "他就是擅长搜还有写，我就是擅长分析输入"

## 对论文的核心价值

### 1. 反模板化意识

> "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"

**理论启示**：用户主动规避GPT输出的同质化风险

### 2. GPT理解能力的边界

> "他没办法理解你这个真正的仿照是仿照这个文章，还是只是仿照写法"

**理论启示**：GPT无法理解用户的深层意图和语境

### 3. 时间压力与使用意愿的关系

时间紧迫程度正向影响GPT使用意愿。

### 关键引用（可用于论文）

1. **反模板化意识**：
   > "不会完全抄他的...完全抄就会出现很多人都是差不多的情况"

2. **GPT理解能力不足**：
   > "他没有办法完全理解...理解能力没有很强"
   > "有时候会很蠢"

3. **人机分工**：
   > "他就是擅长搜还有写，我就是擅长分析输入"

4. **时间驱动使用**：
   > "需要快速的时候会最想要用"
   > "比如说让你写一个东西明天要交的时候"

5. **模板vs参考**：
   > "他没办法理解你这个真正的仿照是仿照这个文章，还是只是仿照写法"

6. **AI痕迹意识**：
   > "首先其次然而这种就特别多，然后还得这个还得改"

7. **隐私风险态度**：
   > "用都用了...也没办法采取任何措施"

---
*分析完成时间：2025年1月*
