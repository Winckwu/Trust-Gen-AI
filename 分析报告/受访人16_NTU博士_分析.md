# 受访人16：NTU博士 - 深度分析报告

## 基本画像

| 项目 | 内容 |
|------|------|
| 身份 | 南洋理工大学CCDS学院博士三年级 |
| 研究方向 | 大语言模型安全性、自动驾驶领域应用 |
| 专业背景 | 软件工程 |
| 使用起始 | 2023年8月入学后开始使用 |
| 使用频率 | 重度使用者 |
| 主要工具 | Gemini（主力，开会员）、GPT（辅助验证）、Claude |

## 使用场景

### 场景1：代码编写 ⭐⭐⭐⭐⭐（最核心）

**使用方式演变**：

早期模式：
> "如果说是在我初期使用的时候，我可能还是会比如说写一个大概，然后只有这个我觉得比较复杂的步骤，我会把它空下，然后我说你请帮我补全这部分代码"

现在模式：
> "现在我是说我直接有点略有偷懒的嫌疑...我会先写，OK，下面我想我就要做的任务是比如说我要写一段这个自动驾驶的这个代码，首先要处理图像，然后再把那个什么拼起来再怎么样"

**AI承担比例**：
> "我觉得至少在写代码这个任务上的话，现在人工智能就是AI的话，它大概承担了得有80%的任务，我主要是做一个double check后续检测"

**效率提升**：
> "很可能之前一周的工作，现在大概一两天就可以完成"

### 场景2：学术写作润色 ⭐⭐⭐⭐

**使用方式**：
> "我会先写一个大概，然后让他帮我润色，这样我觉得效率会更高一些"

**不让AI主导逻辑**：
> "我不想让我的逻辑跟着人工智能走"
> "我不会让它就是说完全改变我的逻辑，或者让它自己创造逻辑"

**对AI写作水平的评价**：
> "他的写作水平似乎这以雅思的来说的话得在8.0以上，我感觉就是他的流畅度确实非常好"

### 场景3：知识检索与学习 ⭐⭐⭐

**使用方式**：
> "大概把它当成一个历史检索引擎"
> "比如说一八几年就有一个学者提出了一种...这种我会让他给我讲一下，然后这样就我就不用去搜了嘛"

**验证逻辑**：
> "我看到他说的差不多符合老师讲的和我...就觉得OK，好像这个是对的"

### 场景4：日常写作 ⭐⭐⭐

**邮件撰写**：
> "你帮我一封给这个实验室管理员的邮件，说我键盘坏掉了，然后语气要得体，然后是询问帮助，然后吧一下就给我写完了"

### 场景5：科研Brainstorm ⭐⭐

**使用方式**：
> "我可能有一个初步的idea...我可能会问他一下，就是你觉得可能怎么做？就是让他帮我指指一些路径"

**对效果的认知**：
> "他可能不能直接说出一个完成的新的可行的idea，但是就是你在这种对话过程中他的一些想法...可能会多多少少跟之前的人有一些不一样的地方"
> "我只会把他和他的这种科研上的brainstorm当做一种给自己思维的发散和参考"

## 信任轨迹：渐进信任型

### 信任演变过程 ⭐⭐⭐⭐⭐

**初期不信任**：
> "那个时候的AI也比那个时候的GPT也比较笨，比如说它比不出来2.11和2.9谁比较大这种问题它就比不出来，所以我也不太信任他"

**逐步建立信任**：
> "随着这个人工智能...他们开发这个谷歌、Germany这几个模型进步实在是太快了...我的使用是逐渐加深，就是我感觉对他的信任度也是逐渐加深"

**现在高度信任**：
> "我现在更加信任Jamie的答案"

### 信任边界

| 任务类型 | 信任水平 | 使用策略 |
|----------|----------|----------|
| 简单代码 | ⭐⭐⭐⭐⭐ 很高 | 直接使用 |
| 复杂代码 | ⭐⭐⭐⭐ 较高 | 多轮修正 |
| 写作润色 | ⭐⭐⭐⭐ 较高 | 不改变原有逻辑 |
| 知识检索 | ⭐⭐⭐ 中等 | 需验证 |
| 科研创新 | ⭐⭐ 较低 | 仅做参考 |
| 新领域知识 | ⭐⭐ 较低 | 必须double check |

## 核心专家策略

### 策略1：分条分点策略 ⭐⭐⭐⭐⭐

> "一定要呃，就是分条分点地告诉他，AI更喜欢这种分条分点的东西，就是很明确地告诉他，你第一步要干什么，第二步要干什么"
> "指令越明晰，他任完成任务的这个质量就会越高"

**反面教训**：
> "如果你的指令不分条分点，嗯，你是想到哪里写到哪...他写出来的代码有的时候那个逻辑结构就会乱一些"

### 策略2：双模型互补策略（左右脑互补）⭐⭐⭐⭐⭐

> "让两个AI左右脑互补"
> "我问一个问题，然后Jimmy给我一段答案。嗯，如果我对答案里面有不确定的地方...我就会把这条命令移到GPT上去问问它"

**使用场景**：
- 高风险操作验证
- 不确定答案验证
- 新领域知识获取

### 策略3：搜索功能应对幻觉 ⭐⭐⭐⭐

> "对于一个他会乱说的情况，我往往会打开搜索功能，就是让他去检索一下当今互联网上真实存在的东西"
> "参考链接如果能点开的话，一般就是对的"

### 策略4：Double Check策略 ⭐⭐⭐⭐⭐

> "一定要记住人工智能也会犯错，这一点就是当你问他一个事情的时候，要养成，就是要养成double check的习惯"
> "我强烈建议就是人工double check，就是一定要去自己搜索一下，然后看一看大家就是真人说的话"

### 策略5：角色从"补全"到"主导"的转变 ⭐⭐⭐⭐⭐

> "之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑"

## 深层认知

### 对AI本质的理解 ⭐⭐⭐⭐⭐

> "我只觉得它是一种基于历史的，能够提高生产力的非常好用的工具"
> "它只是一种基于历史经验能给我们一些建议的东西"

### 对AI科研能力的认知

> "在科研这块上的话，我觉得他是不太行的，就是它的发散，它并不是真的在发散，它只能帮助人来发散"
> "它能回答出来的大概率...可以作为负例，就是可以排除的那一块"

### 对AI依赖性的警惕 ⭐⭐⭐⭐⭐

> "我感觉我的写作上好像不如之前流畅了"
> "我甚至有一点提笔困难，就是如果就是总依赖他去帮我写东西的话"
> "大模型这东西挺像吸...有点有会让人上瘾"

**应对措施**：
> "我会强迫自己说一定要先用，哪怕是先用自己的母语汉语去把逻辑写一遍，也不要直接让大模型来帮我写"
> "尽量要少用一些，然后就是关于逻辑组织的部分，嗯，要自己来"

### 对幻觉的认知

> "当他出现幻觉的时候，你跟他说这个东西他并不存在，他就会说你是对的，这个东西并不存在，然后开始给你就是用另一个幻觉来演示这个幻觉"
> "他一旦陷入幻觉，我感觉他就难以自拔"

### 对隐私的担忧

> "我会把那个隐私相关的东西给它关掉，就是比如说improve the model for everyone，share your data之类的"

## 独特发现

### 1. 角色演变理论：从补全到主导 ⭐⭐⭐⭐⭐

用户与AI的协作模式经历了根本性转变：
- 早期：用户主导，AI补全
- 现在：AI主导，用户验证

> "之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑"

### 2. 双模型互补（左右脑）策略 ⭐⭐⭐⭐⭐

> "让两个AI左右脑互补"

**理论价值**：用户发展出多模型交叉验证的策略，用不同AI的"思维方式"互补验证

### 3. 幻觉陷入的自我强化现象

> "他一旦陷入幻觉，我感觉他就难以自拔，这个模型它会变得难以自拔"

**理论价值**：观察到AI幻觉的自我强化特性

### 4. AI依赖的上瘾性认知 ⭐⭐⭐⭐⭐

> "大模型这东西挺像吸...有点有会让人上瘾"
> "刚开始可能并没有那么依赖，但是如果用多了确实依赖性会变强"

**理论价值**：将AI依赖比喻为成瘾行为，提出了依赖性递增的观察

### 5. 指令明晰度与输出质量的正相关

> "指令越明晰，他任完成任务的这个质量就会越高"

### 6. 科研中AI的"负例"价值

> "它能回答出来的大概率...可以作为负例，就是可以排除的那一块"

**理论价值**：在科研创新中，AI的价值在于排除已知路径

## 对论文的核心价值

### 1. 信任演变的纵向视角

从不信任到信任的完整过程记录，展示了用户信任如何随AI能力提升而变化

### 2. 人机协作模式的转变

从"人主导-AI辅助"到"AI主导-人验证"的转变，反映了人机协作范式的根本变化

### 3. 依赖性警惕与自我调节

用户意识到依赖风险并主动采取措施，展示了高水平用户的自我调节能力

### 关键引用（可用于论文）

1. **80%任务承担**：
   > "我觉得至少在写代码这个任务上的话，现在人工智能就是AI的话，它大概承担了得有80%的任务，我主要是做一个double check后续检测"

2. **角色转变**：
   > "之前我是相当于我先写一个大纲，让他去帮我check，然后写补补全，现在我是说我直接有点略有偷懒的嫌疑"

3. **左右脑互补**：
   > "让两个AI左右脑互补"

4. **指令明晰度**：
   > "指令越明晰，他任完成任务的这个质量就会越高"

5. **AI上瘾性**：
   > "大模型这东西挺像吸...有点有会让人上瘾...刚开始可能并没有那么依赖，但是如果用多了确实依赖性会变强"

6. **能力下降**：
   > "我感觉我的写作上好像不如之前流畅了"
   > "我甚至有一点提笔困难"

7. **科研负例价值**：
   > "它能回答出来的大概率...可以作为负例，就是可以排除的那一块"

8. **Double Check建议**：
   > "一定要记住人工智能也会犯错...要养成double check的习惯"

9. **效率提升**：
   > "很可能之前一周的工作，现在大概一两天就可以完成"

## 八、分析验证

待核对的关键引用：
- [x] "大模型这东西挺像吸...有点有会让人上瘾" ✓ (line 609)
- [x] "我甚至有一点提笔困难" ✓ (line 330)
- [x] "让两个AI左右脑互补" ✓ (line 78)
- [x] "分条分点地告诉他" ✓ (line 135)
- [x] "人工double check" ✓ (line 582)

---
*分析完成时间：2025年1月*
