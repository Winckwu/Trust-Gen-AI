# 受访人22分析报告：强化学习博士生

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | 博士三年级学生 |
| 专业领域 | 强化学习/深度学习，水下无人潜航器自主调度 |
| 主要工具 | GPT（主力）、Gemini Pro |
| 偏好模型 | GPT o4-mini（速度快、满足基本需求） |
| 使用频率 | 高频使用 |
| 技术背景 | 深厚（CS背景，熟悉AI底层原理） |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：边缘模块代码生成**
- 将已定义好的数学公式转化为代码
- 强调"封装"和"可切换性"
- 例如：水下潜艇动力学模块的代码化
- 特点：任务边界清晰，输入输出明确

**场景二：数学概念学习**
- 快速理解与项目相关的数学概念
- 目的是"拿来就用"而非深入推导
- 自述："我毕竟不是数学系的同学...我更多的只是希望把这个公式拿来用"

**场景三：写作结构生成**
- 已有内容框架，请AI帮助整理逻辑顺序
- 强调"说服观众"的逻辑排列
- 自述："每一个大纲内部我要讲哪些东西我大概是有数的，但是这些东西它之间的逻辑顺序如何把它排列起来"

### 2.2 明确不使用的场景

- 完整项目代码生成
- 跨模块的复杂代码任务
- 文献综述和长文本处理
- 创意发散和idea生成

## 三、信任轨迹：技术洞察型

### 3.1 信任特征

**模块化信任模式**：
- 对边界清晰的小任务高度信任
- 对复杂、长程任务明确不信任
- 信任建立在对任务可验证性的判断上

### 3.2 信任边界的量化表达

受访者提供了罕见的**数字化信任边界**：
- 代码交互："可能10轮以后他可能就会忘记一些内容"
- 写作任务："六轮、7轮它就会出一些问题"
- 润色任务："单纯润色就无所谓"

### 3.3 不信任的根源

**长文本处理不信任**：
- "我还是不相信他的这个长文本处理的能力，我觉得他会偏到其他的地方去"
- 自我反思："这可能是我对于他的一个比较刻板印象的问题"

**对"偏离"的担忧**：
- "paper直接丢进去它可能抓不到太多的重点，它可能会偏到一些其他的方向上面去"
- 应对策略：自己提取关键词，给定context

## 四、核心专家策略

### 4.1 任务分解策略

**边缘模块法**：
- 只让AI处理边界清晰的"边缘模块"
- 不交给AI跨模块的复杂任务
- 保持人类对整体架构的控制

### 4.2 输入预处理策略

**关键词提取法**：
- 不直接丢入完整paper
- 自己先提取关键词和context
- 减少AI"偏离"的可能性

### 4.3 封装思维

**代码封装要求**：
- "我希望它可以有更好的封装，这样保证我在用不同的动力学模块的时候，我可以比较方便地切换"
- 将软件工程的封装思维应用于AI协作

### 4.4 轮次控制策略

基于经验的对话轮次上限：
- 代码任务：控制在10轮以内
- 写作任务：控制在6-7轮以内
- 超出则开启新对话或人工接管

## 五、深层认知分析

### 5.1 工程师思维模式

受访者展现出典型的**软件工程思维**：
- 模块化、封装、可切换性
- 边界清晰、输入输出明确
- 对复杂系统的分而治之

### 5.2 技术内行的审慎

作为AI领域研究者，对AI能力有清醒认识：
- 知道长上下文的局限性
- 了解模型"遗忘"的机制
- 对自己的"刻板印象"有元认知

### 5.3 工具化定位

将AI严格定位为"模块化工具"：
- 执行边界清晰的子任务
- 不期待其处理复杂、模糊的任务
- 人类保持系统性控制

## 六、对论文的核心价值

### 6.1 独特贡献：信任的量化边界

**数字化轮次阈值**是本访谈最独特的发现：
- 代码任务：10轮上限
- 写作任务：6-7轮上限
- 这种量化表达在其他访谈中罕见

### 6.2 理论贡献

**"边缘模块"信任模型**：
- 信任不是二元的，而是与任务边界清晰度相关
- 边界越清晰，输入输出越明确，信任度越高
- 跨模块、长程任务则信任度低

### 6.3 技术内行视角

**专业用户的差异化使用**：
- AI专业背景导致更精准的能力评估
- 不盲目信任也不盲目拒绝
- 基于技术理解的理性使用边界

### 6.4 "刻板印象"的元认知

受访者承认自己对AI的不信任可能是"刻板印象"：
- 显示出高度的自我反思能力
- 但仍然选择保持谨慎
- 体现了"宁可保守"的专家态度

## 七、关键引用

### 关于边缘模块
> "我可以这么说，比如说我要控制这个水下的这个潜艇，那它有一个动力学的模块...我希望它可以有更好的封装，这样保证我在用不同的动力学模块的时候，我可以比较方便地切换。"

### 关于轮次限制
> "我觉得长代码交互的话，可能10轮以后他可能就会忘记一些内容。"

> "writing的话...如果是，比如说有逻辑性的一些写作的话，我觉得可能在写作方面可能要短一点，我觉得可能六轮、7轮它就会出一些问题。"

### 关于长文本不信任
> "我还是不相信他的这个长文本处理的能力，我觉得他会偏到其他的地方去，这可能是我对于他的一个比较刻板印象的问题。"

### 关于数学概念应用
> "我毕竟不是数学系的同学，我很多时候他只是我找到一个很好的一个概念，我觉得他跟我这个项目比较契合，那么我也只是希望简单地了解一下，然后我直接拿来就用。"

### 关于写作结构
> "每一个大纲内部我要讲哪些东西我大概是有数的，但是这些东西它之间的逻辑顺序如何把它排列起来，然后讲得让观众听得更加...可以说服观众，这个是我需要他去帮我总结这个前后顺序。"

## 八、分析验证

- [x] 基本画像：博三、强化学习、水下潜航器 ✓
- [x] 边缘模块策略：动力学模块代码化示例 ✓
- [x] 10轮/6-7轮量化阈值：原文直接引用 ✓
- [x] 长文本不信任+"刻板印象"元认知 ✓
- [x] 数学概念"拿来就用"的实用态度 ✓
- [x] 写作结构整理而非内容生成 ✓

---

**信任类型标签**：技术洞察型 / 模块化信任 / 量化边界意识

**核心发现**："10轮代码/6-7轮写作"的量化信任阈值，以及"边缘模块"的任务分解策略
