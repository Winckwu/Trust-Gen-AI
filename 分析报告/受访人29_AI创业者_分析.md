# 受访人29分析报告：AI创业者（邮件管理产品）

## 一、基本画像

| 维度 | 信息 |
|------|------|
| 身份 | AI创业者（Clarity AI创始人） |
| 专业背景 | 土木工程 |
| 创业经历 | 连续创业者，第四个产品（前两个失败，一个拿到VC） |
| 产品方向 | AI邮件管理、智能日程整合 |
| 主要工具 | ChatGPT Plus、Gemini、千问 |
| 地理位置 | 美国（此前在澳大利亚） |
| 团队规模 | 约10人 |
| 使用AI比例 | 30%（自评） |

## 二、使用场景分析

### 2.1 核心使用场景

**场景一：代码编写**
- "大部分写代码"
- 自己不会写代码，完全依赖AI生成
- 愿意与AI"拜托五轮"直到得到正确结果
- 例子："今天刚commit了一个我改了50多遍的代码"

**场景二：资料查询**
- 用自然语言替代Google关键词搜索
- "我不知道关键词是什么，所以我就用自然语言去替代了我的关键词"

**场景三：产品调研**
- "所有的这些工作现在全都可以用ai代替了"
- "之前需要去做客户访谈，现在不需要了"
- AI训练数据已包含用户输入

### 2.2 团队使用情况

**全员使用AI**：
- 前端工程师用Cursor管理GitHub
- "一个模块一个模块的改，ai可以帮他把其他类似的地方都改掉"
- 管理态度："只看结果"

## 三、信任轨迹：达尔文主义型

### 3.1 信任定位

**工具化+适者生存**：
- "ai永远的是辅助角色"
- "相信不相信的问题没有那么重要，因为世界的真相都不是很重要"
- "这是人怎么使用工具，而不是工具怎么驯化人"

### 3.2 验证方式

**靠经验判断**：
- "AI说错了，我肯定知道"
- "我干这事儿，他如果说错了，那说明我问的问题就错了"
- 会直接骂AI："你给我瞎掰什么东西呢？"

### 3.3 对过度依赖的态度

**社会达尔文主义**：
- "影响了也就影响了，这个人该怎么长，这是他的命数"
- "社会就是分层的，它这么使用它，说明就在这个层次"
- "能用好ai的人自然就能用好，用不好的被驯化了，也就被驯化了"

## 四、核心专家策略

### 4.1 持续对抗策略

**不怕多轮交互**：
- 愿意改50多遍代码
- 即使浪费时间也要跟AI"拜托"到底
- 原因："我不会写代码呀"

### 4.2 明确纠错策略

**看到错误立即指出**：
- "你不要给我建议，你刚才说的这些东西，我告诉你，为什么你不需要给我建议"
- 阻止AI脑补不需要的条件

### 4.3 成本导向策略

**按成本选择模型**：
- GPT Plus因为"包月了"
- 其他按token算，哪个低用哪个
- Flash模型处理垃圾邮件

## 五、深层认知分析

### 5.1 趋势不可逆论

**强烈的技术决定论**：
- "这个趋势就是趋势，你如果不能跟ai共存的话，你就被淘汰"
- "全世界没有像ai这次革命一样花过这么大的全人类的力量去做一件事情"

### 5.2 哲学化的世界观

**虚无主义倾向**：
- "世界都是假的，你何必较真呢？"
- "我们无非就是过来经历了，经历完了，体验好坏也没有差别"
- 将生活比作"戴了虚拟眼镜"的游戏

### 5.3 对批判性思维问题的看法

**个人责任论**：
- "这是人怎么使用工具，而不是工具怎么驯化人"
- 不会主动在产品中加入认知预警："对我来说是成本"
- 除非regulation要求，否则不会做

### 5.4 职业替代预测

**程序员最先被替代**：
- "单纯是因为现在ai在代码能力的进化上是最快的"
- "因为它有最多的数据"
- 但学科教育仍需要："像人会说话就不教语文了吗？"

### 5.5 无法被替代的领域

- 前沿物理
- 体育运动
- 娱乐艺术
- "anything that kills time"

## 六、对论文的核心价值

### 6.1 独特贡献：创业者的务实主义

**不关心信任，只关心结果**：
- "我只看结果"
- 这是所有受访者中最"结果导向"的态度
- 代表了一类不纠结于信任问题的用户

### 6.2 理论贡献

**"社会达尔文主义"的AI使用观**：
- 用户分层是自然的
- AI只是加速了优胜劣汰
- 这挑战了"所有人都需要保护"的假设

### 6.3 产品开发者视角

**"反产品"的认知预警**：
- 激活用户自我认知"有点反产品"
- "产品最核心的就是要易用性"
- 除非regulation，否则不会做

### 6.4 小麦驯化人类的类比

**独特的历史视角**：
- "你喜欢吃面条...那么小麦驯化人类，这个事情你也接受了呀"
- AI驯化人类只是历史进程的延续

## 七、关键引用

### 关于趋势不可逆
> "不会的趋势不可逆，没有必要去探讨这个问题，这个趋势就是趋势，你如果不能跟ai共存的话，你就被淘汰。就这么简单。"

### 关于信任问题
> "我一直感觉这个相信不相信的问题没有那么重要，因为世界的真相都不是很重要。"

### 关于工具驯化人
> "没错，这是人怎么使用工具，而不是工具怎么驯化人。"

### 关于经验判断
> "我不会啊，就是ai说错了，我肯定知道啊，我干这事儿，他如果说错了，那说明我问的问题就错了。"

### 关于社会分层
> "那没办法，社会就是分层的，它这么使用它，说明就在这个层次。"

### 关于认知预警
> "我不会的，因为对我来说是成本...这个他们有点反产品啊，因为产品最最核心的就是要是易用性嘛。"

### 关于AI永远是工具
> "对啊，我一直认为它就是一个工具啊...他是一直都是个tool，他永远的是辅助角色。"

## 八、分析验证

待核对的关键引用：
- [ ] "趋势不可逆...你就被淘汰"
- [ ] "相信不相信的问题没有那么重要"
- [ ] "人怎么使用工具，而不是工具怎么驯化人"
- [ ] "社会就是分层的"
- [ ] "他永远的是辅助角色"

---

**信任类型标签**：达尔文主义型 / 结果导向 / 工具化定位

**核心发现**："趋势不可逆"的技术决定论，"适者生存"的社会达尔文主义，以及"只看结果"的极端务实主义
